{"doc_key": "1507.01422-a71f5d25-76fb-4465-8490-e3a78a417665", "sentences": [["The", "limited", "amount", "of", "training", "data", "for", "our", "architecture", "made", "overfitting", "a", "significant", "challenge", ",", "so", "we", "used", "different", "techniques", "to", "minimize", "its", "effects", "."], ["Firstly", ",", "we", "apply", "norm", "constraint", "regularization", "for", "the", "maxout", "layers", "-LSB-", "7", "-RSB-", "."], ["Secondly", ",", "we", "use", "data", "augmentation", "technique", "by", "mirroring", "all", "images", "."], ["We", "also", "tested", "a", "dropout", "layer", "-LSB-", "9", "-RSB-", "after", "the", "first", "fully", "connected", "layer", ",", "with", "a", "dropout", "ratio", "of", "0.5", "-LRB-", "50", "%", "of", "probability", "to", "set", "a", "neuron", "\u2019", "s", "output", "value", "to", "zero", "-RRB-", "."], ["However", ",", "this", "did", "not", "make", "much", "of", "a", "difference", ",", "so", "it", "is", "not", "included", "to", "the", "final", "model", "."]], "ner": [[], [[29, 31, "a"]], [[44, 45, "a"]], [[56, 57, "a"], [70, 71, "p"], [73, 73, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[29, 31, "a"], [34, 34, "a"]], [], [[56, 56, "a"], [70, 71, "p"], [73, 73, "v"], [75, 76, "v"], [88, 88, "v"]], []], "predicted_relations": [[], [], [], [[70, 71, 56, 57, "USED-FOR"], [73, 73, 70, 71, "USED-FOR"]], []]}
{"doc_key": "1507.01422-5da36b15-fccf-4f3e-8b9c-b773edcc7010", "sentences": [["The", "weights", "in", "all", "layers", "are", "initialized", "from", "a", "normal", "Gaussian", "distribution", "with", "zero", "mean", "and", "a", "standard", "deviation", "of", "0.01", ",", "with", "biases", "initialized", "to", "0.1", "."], ["Ground", "truth", "values", "that", "we", "used", "for", "training", "are", "saliency", "maps", "with", "normalized", "values", "between", "0", "and", "1", "."]], "ner": [[[9, 11, "a"], [14, 14, "p"], [20, 20, "v"], [26, 26, "v"], [13, 13, "v"], [17, 18, "p"], [20, 20, "v"], [20, 20, "v"], [26, 26, "v"], [26, 26, "v"]], [[43, 43, "v"], [37, 38, "a"], [40, 41, "p"], [43, 43, "v"], [45, 45, "v"]]], "relations": [[], []], "predicted_ner": [[[13, 13, "v"], [20, 20, "v"], [26, 26, "v"]], [[43, 43, "v"], [45, 45, "v"]]], "predicted_relations": [[[14, 14, 9, 11, "USED-FOR"], [20, 20, 17, 18, "USED-FOR"], [13, 13, 17, 18, "USED-FOR"], [17, 18, 9, 11, "USED-FOR"], [20, 20, 17, 18, "USED-FOR"], [20, 20, 17, 18, "USED-FOR"]], [[40, 41, 37, 38, "USED-FOR"]]]}
{"doc_key": "1507.01422-3306e18c-8eac-4c0c-8296-eedf475c6e5c", "sentences": [["For", "validation", "control", "purposes", ",", "we", "split", "the", "training", "partitions", "of", "iSUN", "and", "SALICON", "datasets", "into", "80", "%", "for", "training", "and", "the", "rest", "for", "real", "time", "validation", "."], ["The", "network", "was", "trained", "with", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "and", "Nesterov", "momentum", "SGD", "optimization", "method", "that", "helps", "the", "loss", "function", "to", "converge", "faster", "."], ["The", "learning", "rate", "was", "changing", "over", "time", ";", "it", "started", "with", "a", "higher", "learning", "rate", "0.03", "and", "decreased", "during", "the", "course", "of", "training", "until", "0.0001", "."], ["We", "set", "1,000", "epochs", "to", "train", "a", "separate", "network", "for", "each", "dataset", "."], ["Figures", "REF", "and", "REF", "present", "the", "learning", "curves", "for", "the", "iSUN", "and", "SALICON", "models", ",", "respectively", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [[55, 56, "p"], [67, 68, "p"], [69, 69, "v"], [78, 78, "v"]], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"], [13, 13, "a"], [16, 17, "v"]], [[33, 38, "a"]], [[55, 56, "p"], [67, 68, "p"], [69, 69, "v"], [78, 78, "v"]], [[82, 82, "v"], [83, 83, "p"]], [[103, 103, "a"], [105, 105, "a"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1506.05929-c004364a-cbc4-4a56-8304-284910a85531", "sentences": [["All", "networks", "were", "trained", "using", "an", "effective", "training", "procedure", "-LRB-", "cf", "."], ["-LSB-", "0", "-RSB-", "-RRB-", ",", "with", "the", "values", "of", "the", "learning", "rate", ",", "momentum", ",", "and", "weight", "decay", "hyperparameters", "being", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "and", "\\", "-LRB-", "5", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "respectively", "."], ["Whenever", "the", "error", "on", "the", "validation", "set", "stopped", "decreasing", "the", "learning", "rate", "was", "decreased", "by", "a", "factor", "10", "."], ["To", "deal", "with", "the", "increased", "size", "of", "the", "images", "the", "number", "of", "images", "per", "batch", "was", "adjust", "to", "fit", "into", "memory", "."]], "ner": [[[7, 8, "a"]], [[22, 23, "p"], [25, 25, "p"], [43, 43, "v"], [28, 29, "p"]], [[69, 70, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[22, 23, "p"], [25, 25, "p"], [28, 29, "a"], [34, 37, "v"], [43, 43, "v"], [49, 49, "v"], [51, 54, "v"]], [[69, 70, "p"], [76, 76, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1501.05759-13416f55-51eb-4199-b3a2-7d2b1f52130e", "sentences": [["Unless", "otherwise", "specified", "we", "train", "all", "our", "models", "using", "the", "following", "parameters", "."], ["Feature", "channels", "are", "HOG+LUV", "only", "."], ["The", "final", "classifier", "includes", "4096", "level-2", "decision", "trees", "-LRB-", "L2", ",", "3", "stumps", "per", "tree", "-RRB-", ",", "trained", "via", "vanilla", "discrete", "Adaboost", "."], ["Each", "tree", "is", "built", "by", "doing", "exhaustive", "greedy", "search", "for", "each", "node", "-LRB-", "no", "randomization", "-RRB-", "."], ["The", "model", "has", "size", "\\", "-LRB-", "60\\hspace", "-LCB-", "0.0pt", "-RCB-", "\\times", "\\hspace", "-LCB-", "0.0pt", "-RCB-", "120\\", "\\mbox", "-LCB-", "pixels", "-RCB-", "\\", "-RRB-", ",", "and", "is", "built", "via", "four", "rounds", "of", "hard", "negative", "mining", "-LRB-", "starting", "from", "a", "model", "with", "32", "trees", ",", "and", "then", "512", ",", "1024", ",", "2048", ",", "4096", "trees", "-RRB-", "."], ["Each", "round", "adds", "\\", "-LRB-", "10\\,000\\", "-RRB-", "additional", "negatives", "to", "the", "training", "set", "."], ["The", "sliding", "window", "stride", "is", "\\", "-LRB-", "6\\", "\\mbox", "-LCB-", "pixels", "-RCB-", "\\", "-RRB-", "-LRB-", "both", "during", "hard", "negative", "mining", "and", "at", "test", "time", "-RRB-", "."]], "ner": [[], [], [[40, 40, "a"], [24, 26, "p"], [23, 23, "v"], [31, 33, "p"], [30, 30, "v"]], [], [[109, 109, "v"], [89, 91, "a"], [87, 87, "p"]], [[120, 121, "p"]], [[128, 130, "a"], [130, 130, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [], [[23, 23, "v"], [30, 30, "v"], [38, 40, "a"]], [], [[86, 86, "v"], [98, 98, "v"], [103, 103, "v"], [105, 105, "v"], [107, 107, "v"], [109, 109, "v"]], [[118, 118, "v"]], []], "predicted_relations": [[], [], [[23, 23, 31, 33, "USED-FOR"], [31, 33, 40, 40, "USED-FOR"], [30, 30, 31, 33, "USED-FOR"]], [], [[109, 109, 87, 87, "USED-FOR"]], [], [[130, 130, 128, 130, "USED-FOR"]]]}
{"doc_key": "1511.04587-16d019a5-f214-4c51-95d1-0cbd51bf181a", "sentences": [["We", "provide", "parameters", "used", "to", "train", "our", "final", "model", "."], ["We", "use", "a", "network", "of", "depth", "20", "."], ["Training", "uses", "batches", "of", "size", "64", "."], ["Momentum", "and", "weight", "decay", "parameters", "are", "set", "to", "0.9", "and", "\\", "-LRB-", "0.0001\\", "-RRB-", ",", "respectively", "."]], "ner": [[[8, 8, "a"]], [[15, 15, "p"], [16, 16, "v"]], [[23, 23, "v"]], [[33, 33, "v"], [27, 28, "p"], [37, 37, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[16, 16, "v"]], [[23, 23, "v"]], [[27, 28, "a"], [33, 33, "v"], [37, 37, "v"]]], "predicted_relations": [[], [[16, 16, 15, 15, "USED-FOR"]], [], []]}
{"doc_key": "1511.04587-c802d327-4b3c-4889-9f52-590a5bb2664f", "sentences": [["We", "train", "all", "experiments", "over", "80", "epochs", "-LRB-", "9960", "iterations", "with", "batch", "size", "64", "-RRB-", "."], ["Learning", "rate", "was", "initially", "set", "to", "0.1", "and", "then", "decreased", "by", "a", "factor", "of", "10", "every", "20", "epochs", "."], ["In", "total", ",", "the", "learning", "rate", "was", "decreased", "3", "times", ",", "and", "the", "learning", "is", "stopped", "after", "80", "epochs", "."], ["Training", "takes", "roughly", "4", "hours", "on", "GPU", "Titan", "Z", "."]], "ner": [[[5, 5, "v"], [13, 13, "v"]], [[16, 17, "a"], [22, 22, "v"], [30, 30, "v"], [32, 33, "v"]], [[52, 52, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "v"], [6, 6, "p"], [8, 8, "v"], [9, 9, "p"], [11, 12, "p"], [13, 13, "v"]], [[16, 17, "p"], [22, 22, "v"], [30, 30, "v"], [32, 32, "v"], [33, 33, "p"]], [[39, 40, "p"], [43, 43, "v"], [52, 52, "v"], [53, 53, "p"]], [[58, 58, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1511.04491-1a9669db-22a2-4b4e-b517-5d974263d5e2", "sentences": [["We", "use", "16", "recursions", "unless", "stated", "otherwise", "."], ["When", "unfolded", ",", "the", "longest", "chain", "from", "the", "input", "to", "the", "output", "passes", "20", "conv", "."], ["layers", "-LRB-", "receptive", "field", "of", "41", "by", "41", "-RRB-", "."], ["We", "set", "the", "momentum", "parameter", "to", "0.9", "and", "weight", "decay", "to", "0.0001", "."], ["We", "use", "256", "filters", "of", "the", "size", "\\", "-LRB-", "3", "\\times", "3\\", "-RRB-", "for", "all", "weight", "layers", "."], ["Training", "images", "are", "split", "into", "41", "by", "41", "patches", "with", "stride", "21", "and", "64", "patches", "are", "used", "as", "a", "mini-batch", "for", "stochastic", "gradient", "descent", "."]], "ner": [[], [], [], [[45, 45, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [3, 3, "p"]], [[21, 21, "v"]], [[29, 29, "v"], [31, 31, "v"]], [[37, 38, "p"], [40, 40, "v"], [42, 43, "p"], [45, 45, "v"]], [[49, 49, "v"], [56, 56, "v"], [58, 58, "v"]], [[70, 70, "v"], [72, 72, "v"], [76, 76, "v"], [78, 78, "v"], [86, 88, "a"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1511.04491-34ab474f-d60b-4aa1-9c84-542d1b0984fa", "sentences": [["Learning", "rate", "is", "initially", "set", "to", "0.01", "and", "then", "decreased", "by", "a", "factor", "of", "10", "if", "the", "validation", "error", "does", "not", "decrease", "for", "5", "epochs", "."], ["If", "learning", "rate", "is", "less", "than", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", ",", "the", "procedure", "is", "terminated", "."], ["Training", "roughly", "takes", "6", "days", "on", "a", "machine", "using", "one", "Titan", "X", "GPU", "."]], "ner": [[[6, 6, "v"], [14, 14, "v"], [23, 24, "v"]], [[27, 28, "a"], [34, 34, "v"]], [[53, 53, "p"], [55, 58, "v"], [49, 50, "v"]]], "relations": [[], [], []], "predicted_ner": [[[0, 1, "p"], [6, 6, "v"], [14, 14, "v"], [23, 23, "v"], [24, 24, "p"]], [[27, 28, "p"], [34, 36, "v"]], [[49, 49, "v"], [55, 55, "v"]]], "predicted_relations": [[], [], [[49, 50, 53, 53, "USED-FOR"]]]}
{"doc_key": "1509.07308-2492d078-df51-4743-8cd7-04e696199e89", "sentences": [["Training", "Data", "."], ["To", "induce", "bilingual", "word", "embeddings", "as", "well", "as", "to", "be", "directly", "comparable", "with", "baseline", "representations", "from", "prior", "work", ",", "we", "use", "a", "dataset", "comprising", "a", "subset", "of", "comparable", "Wikipedia", "data", "available", "in", "three", "language", "pairs", "-LSB-", "106", "-RSB-", ",", "-LSB-", "107", "-RSB-", "Available", "online", ":", "people.cs.kuleuven.be/\\", "-LRB-", "\\sim", "\\", "-RRB-", "ivan.vulic/software/", ":", "-LRB-", "i", "-RRB-", "a", "collection", "of", "13", ",", "696", "Spanish-English", "Wikipedia", "article", "pairs", "-LRB-", "ES-EN", "-RRB-", ",", "-LRB-", "ii", "-RRB-", "a", "collection", "of", "18", ",", "898", "Italian-English", "Wikipedia", "article", "pairs", "-LRB-", "IT-EN", "-RRB-", ",", "and", "-LRB-", "iii", "-RRB-", "a", "collection", "of", "7", ",", "612", "Dutch-English", "Wikipedia", "article", "pairs", "-LRB-", "NL-EN", "-RRB-", "."], ["All", "corpora", "are", "theme-aligned", "comparable", "corpora", ",", "that", "is", ",", "the", "aligned", "document", "pairs", "discuss", "similar", "themes", ",", "but", "are", "in", "general", "not", "direct", "translations", "of", "each", "other", "."], ["To", "be", "directly", "comparable", "to", "prior", "work", "in", "the", "two", "evaluation", "tasks", "-LSB-", "106", "-RSB-", ",", "-LSB-", "107", "-RSB-", ",", "we", "retain", "only", "nouns", "that", "occur", "at", "least", "5", "times", "in", "the", "corpus", "."], ["Lemmatized", "word", "forms", "are", "recorded", "when", "available", ",", "and", "original", "forms", "otherwise", "."], ["TreeTagger", "-LSB-", "87", "-RSB-", "is", "used", "for", "POS", "tagging", "and", "lemmatization", "."], ["After", "the", "preprocessing", "steps", "vocabularies", "comprise", "between", "7,000", "and", "13,000", "noun", "types", "for", "each", "language", "in", "each", "language", "pair", ",", "and", "the", "training", "corpora", "are", "quite", "small", ":", "ranging", "from", "approximately", "1.5M", "tokens", "for", "NL-EN", "to", "4M", "for", "ES-EN", "."], ["Exactly", "the", "same", "training", "data", "and", "vocabularies", "are", "used", "to", "train", "all", "representation", "models", "in", "comparison", "-LRB-", "both", "from", "Group", "I", "and", "Group", "II", ",", "see", "Section", "-RRB-", "."]], "ner": [[[0, 1, "a"]], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[25, 25, "a"], [35, 35, "v"], [61, 63, "v"], [78, 80, "v"], [96, 98, "v"]], [], [[145, 145, "v"], [164, 164, "v"]], [], [[183, 183, "a"]], [[202, 202, "v"], [204, 204, "v"], [226, 226, "v"], [231, 231, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1509.07308-b7a5f42b-995f-4bc5-b689-66284b45b1b2", "sentences": [["Trained", "BWESG", "Models", "To", "test", "the", "effect", "of", "random", "shuffling", "in", "the", "merge", "and", "shuffle", "BWESG", "strategy", ",", "we", "have", "trained", "the", "BWESG", "model", "with", "10", "random", "corpora", "shuffles", "for", "all", "three", "training", "corpora", "."], ["We", "also", "train", "BWESG", "with", "the", "length-ratio", "shuffle", "strategy", "."], ["All", "parameters", "are", "set", "to", "default", "suggested", "parameters", "for", "SGNS", "from", "the", "word2vec", "package", ":", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "a", "linearly", "decreasing", "global", "learning", "rate", "of", "0.025", ",", "25", "negative", "samples", ",", "subsampling", "rate", "\\", "-LRB-", "1e-4\\", "-RRB-", ",", "and", "15", "epochs", "."]], "ner": [[[22, 23, "a"], [8, 9, "a"]], [[41, 43, "a"]], [[70, 72, "p"], [74, 74, "v"], [77, 78, "p"], [76, 76, "v"], [80, 81, "p"], [84, 84, "v"], [89, 89, "p"], [88, 88, "v"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [22, 23, "a"], [25, 25, "v"], [31, 31, "v"]], [[38, 38, "a"]], [[54, 54, "a"], [60, 65, "a"], [70, 72, "p"], [74, 74, "v"], [76, 76, "v"], [80, 81, "p"], [84, 84, "v"], [88, 88, "v"], [89, 89, "p"]]], "predicted_relations": [[], [], [[74, 74, 89, 89, "USED-FOR"], [76, 76, 77, 78, "USED-FOR"], [76, 76, 89, 89, "USED-FOR"], [84, 84, 70, 72, "USED-FOR"], [84, 84, 80, 81, "USED-FOR"], [88, 88, 77, 78, "USED-FOR"], [88, 88, 80, 81, "USED-FOR"], [88, 88, 89, 89, "USED-FOR"]]]}
{"doc_key": "1509.07308-170cc148-4ec4-4d68-a979-7918a92f9757", "sentences": [["We", "have", "varied", "the", "number", "of", "dimensions", "\\", "-LRB-", "d=100,200,300\\", "-RRB-", "."], ["We", "have", "also", "trained", "BWESG", "with", "\\", "-LRB-", "d=40\\", "-RRB-", "to", "be", "directly", "comparable", "to", "readily", "available", "sets", "of", "BWEs", "from", "prior", "work", "-LSB-", "12", "-RSB-", "."], ["Moreover", ",", "to", "test", "the", "effect", "of", "window", "size", "on", "the", "final", "results", ",", "i.e.", ",", "the", "number", "of", "positives", "used", "for", "training", ",", "we", "have", "varied", "the", "maximum", "window", "size", "\\", "-LRB-", "cs\\", "-RRB-", "from", "4", "to", "60", "in", "steps", "of", "4.We", "remind", "the", "reader", "that", "we", "slightly", "abuse", "terminology", "here", ",", "as", "the", "BWESG", "windows", "do", "not", "include", "the", "locality", "component", "any", "more", "."]], "ner": [[[4, 6, "p"], [9, 9, "v"], [9, 9, "v"], [9, 9, "v"]], [[16, 16, "a"], [20, 20, "v"], [36, 36, "v"], [20, 20, "v"]], [[94, 94, "a"], [67, 69, "p"], [75, 75, "v"], [81, 81, "v"], [77, 77, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[16, 16, "a"], [20, 20, "v"], [31, 31, "a"]], [[72, 72, "p"], [75, 75, "v"], [77, 77, "v"], [94, 94, "a"]]], "predicted_relations": [[[9, 9, 4, 6, "USED-FOR"], [9, 9, 4, 6, "USED-FOR"], [9, 9, 4, 6, "USED-FOR"]], [], []]}
{"doc_key": "1509.07308-3de07620-2b8b-4ba2-9830-5026defb7dfb", "sentences": [["For", "Basic-MuPTM", "and", "Association-MuPTM", ",", "as", "in", "-LSB-", "105", "-RSB-", ",", "a", "bilingual", "latent", "Dirichlet", "allocation", "-LRB-", "BiLDA", "-RRB-", "model", "was", "trained", "with", "\\", "-LRB-", "K=2000\\", "-RRB-", "topics", "and", "the", "standard", "values", "for", "hyper-parameters", ":", "\\", "-LRB-", "\\alpha", "=", "50/K\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=0.01\\", "-RRB-", "-LSB-", "92", "-RSB-", "."], ["Post-hoc", "semantic", "space", "pruning", "was", "employed", "with", "the", "pruning", "parameter", "set", "to", "200", "for", "Basic-MuPTM", "and", "to", "2000", "for", "Association-MuPTM", "."], ["We", "refer", "the", "reader", "to", "the", "relevant", "paper", "for", "more", "details", "."]], "ner": [[[25, 25, "p"], [39, 39, "p"], [25, 25, "v"], [37, 37, "p"], [39, 39, "v"], [44, 44, "p"], [45, 45, "v"], [1, 1, "c"], [25, 25, "v"], [3, 3, "c"]], [[68, 68, "v"], [51, 54, "a"], [59, 60, "p"], [63, 63, "v"], [65, 65, "c"], [68, 68, "v"], [70, 70, "c"]], []], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [3, 3, "a"], [12, 19, "a"], [25, 25, "v"], [37, 37, "p"], [44, 44, "p"], [45, 45, "v"]], [[59, 60, "p"], [63, 63, "v"], [65, 65, "a"], [68, 68, "v"], [70, 70, "a"]], []], "predicted_relations": [[[25, 25, 25, 25, "USED-FOR"], [25, 25, 25, 25, "USED-FOR"], [39, 39, 39, 39, "USED-FOR"], [25, 25, 25, 25, "USED-FOR"], [39, 39, 25, 25, "USED-FOR"], [39, 39, 39, 39, "USED-FOR"], [39, 39, 37, 37, "USED-FOR"], [39, 39, 44, 44, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 44, 44, "USED-FOR"], [1, 1, 25, 25, "USED-FOR"], [1, 1, 25, 25, "USED-FOR"], [25, 25, 25, 25, "USED-FOR"], [3, 3, 25, 25, "USED-FOR"], [3, 3, 25, 25, "USED-FOR"]], [[68, 68, 59, 60, "USED-FOR"], [59, 60, 51, 54, "USED-FOR"], [63, 63, 59, 60, "USED-FOR"], [65, 65, 68, 68, "USED-FOR"], [65, 65, 68, 68, "USED-FOR"], [68, 68, 59, 60, "USED-FOR"], [70, 70, 68, 68, "USED-FOR"], [70, 70, 63, 63, "USED-FOR"], [70, 70, 68, 68, "USED-FOR"]], []]}
{"doc_key": "1509.07308-c385af36-8215-4a77-bc55-3732fb03894d", "sentences": [["Baseline", "Representations", ":", "Group", "II", "All", "baseline", "BWE", "models", "were", "trained", "with", "the", "same", "number", "of", "dimensions", "as", "BWESG", ":", "\\", "-LRB-", "d=100,200,300\\", "-RRB-", "."], ["Other", "model-specific", "parameters", "were", "taken", "as", "suggested", "in", "prior", "work", "."]], "ner": [[[7, 8, "a"], [14, 16, "p"], [22, 22, "v"], [22, 22, "v"], [22, 22, "v"]], []], "relations": [[], []], "predicted_ner": [[[7, 8, "a"], [18, 18, "a"], [22, 22, "v"]], []], "predicted_relations": [[[14, 16, 7, 8, "USED-FOR"], [22, 22, 14, 16, "USED-FOR"], [22, 22, 14, 16, "USED-FOR"], [22, 22, 14, 16, "USED-FOR"]], []]}
{"doc_key": "1509.07308-57124faa-c740-4dd8-bcea-bdd99ec336c5", "sentences": [["For", "BiCVM", ",", "we", "use", "the", "tool", "released", "by", "the", "authors.https", ":", "//github.com/karlmoritz/bicvm", "We", "train", "an", "additive", "model", ",", "with", "hinge", "loss", "margin", "\\", "-LRB-", "mrg=d\\", "-RRB-", "as", "in", "the", "original", "paper", ",", "batch", "size", "of", "50", ",", "and", "noise", "parameter", "of", "10", "."], ["All", "models", "were", "trained", "with", "200", "iterations", "."]], "ner": [[[1, 1, "a"], [16, 17, "a"], [20, 22, "p"], [33, 34, "p"], [39, 40, "p"]], [[49, 49, "v"], [50, 50, "p"]]], "relations": [[], []], "predicted_ner": [[[1, 1, "a"], [33, 34, "p"], [36, 36, "v"], [39, 40, "p"], [42, 42, "v"]], [[49, 49, "v"], [50, 50, "p"]]], "predicted_relations": [[[20, 22, 1, 1, "USED-FOR"], [20, 22, 16, 17, "USED-FOR"]], [[49, 49, 50, 50, "USED-FOR"]]]}
{"doc_key": "1509.07308-951e187c-75db-4722-bd37-c70bccaa71ab", "sentences": [["For", "Mikolov", ",", "we", "train", "two", "monolingual", "SGNS", "models", "using", "the", "original", "word2vec", "package", ",", "SGD", "with", "a", "global", "learning", "rate", "of", "0.025", ",", "25", "negative", "samples", ",", "subsampling", "rate", "\\", "-LRB-", "1e-4\\", "-RRB-", ",", "and", "15", "epochs", "."], ["The", "seed", "lexicon", "required", "to", "learn", "the", "mapping", "between", "two", "monolingual", "spaces", "is", "exactly", "the", "same", "as", "for", "Traditional-PPMI", "."]], "ner": [[[7, 8, "a"], [18, 20, "p"], [22, 22, "v"], [25, 26, "p"], [24, 24, "v"], [28, 29, "p"], [32, 32, "v"], [37, 37, "p"], [36, 36, "v"], [15, 15, "a"]], []], "relations": [[], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "v"], [12, 12, "a"], [18, 20, "p"], [22, 22, "v"], [24, 24, "v"], [28, 29, "p"], [32, 32, "v"], [36, 36, "v"], [37, 37, "p"]], [[48, 48, "v"]]], "predicted_relations": [[[18, 20, 7, 8, "USED-FOR"], [18, 20, 15, 15, "USED-FOR"], [25, 26, 7, 8, "USED-FOR"], [25, 26, 15, 15, "USED-FOR"], [24, 24, 25, 26, "USED-FOR"], [24, 24, 37, 37, "USED-FOR"], [28, 29, 7, 8, "USED-FOR"], [28, 29, 15, 15, "USED-FOR"], [32, 32, 28, 29, "USED-FOR"], [36, 36, 25, 26, "USED-FOR"], [36, 36, 28, 29, "USED-FOR"], [36, 36, 37, 37, "USED-FOR"]], []]}
{"doc_key": "1509.07308-25e90e19-0da3-4272-ad42-611b316432a1", "sentences": [["For", "BilBOWA", ",", "we", "use", "SGD", "with", "a", "global", "learning", "rate", "0.15", "for", "trainingSuggestions", "for", "parameter", "values", "received", "through", "personal", "correspondence", "with", "the", "authors", "."], ["The", "software", "is", "available", "online", ":", "https", ":", "//github.com/gouwsmeister/bilbowa", ",", "25", "negative", "samples", ",", "subsampling", "rate", "\\", "-LRB-", "1e-4\\", "-RRB-", ",", "and", "15", "epochs", "."], ["For", "BilBOWA", "and", "Mikolov", ",", "we", "vary", "the", "window", "size", "the", "same", "way", "as", "in", "BWESG", "."]], "ner": [[[5, 5, "a"], [8, 10, "p"], [11, 11, "v"], [1, 1, "a"], [11, 11, "v"]], [[36, 37, "p"], [35, 35, "v"], [39, 40, "p"], [43, 43, "v"], [48, 48, "p"], [47, 47, "v"]], [[51, 51, "a"], [53, 53, "a"], [58, 59, "p"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "a"], [8, 10, "p"], [11, 11, "v"]], [[35, 35, "v"], [39, 40, "p"], [43, 43, "v"], [47, 47, "v"], [48, 48, "p"]], [[51, 51, "a"], [53, 53, "a"], [65, 65, "a"]]], "predicted_relations": [[[8, 10, 5, 5, "USED-FOR"], [8, 10, 1, 1, "USED-FOR"], [11, 11, 8, 10, "USED-FOR"], [11, 11, 8, 10, "USED-FOR"]], [[35, 35, 36, 37, "USED-FOR"], [43, 43, 39, 40, "USED-FOR"], [47, 47, 48, 48, "USED-FOR"]], [[58, 59, 51, 51, "USED-FOR"], [58, 59, 53, 53, "USED-FOR"]]]}
{"doc_key": "1512.09272-4bdc369f-b70c-4f7d-8556-60ad29c09055", "sentences": [["The", "model", "training", "is", "based", "on", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "that", "involves", ":", "1", "-RRB-", "the", "use", "of", "a", "learning", "rate", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "that", "gradually", "-LRB-", "automatically", "computed", "based", "on", "the", "number", "of", "epochs", "set", "for", "training", "-RRB-", "decreases", "after", "each", "epoch", "until", "it", "reaches", "\\", "-LRB-", "0.0001\\", "-RRB-", ";", "2", "-RRB-", "a", "momentum", "set", "at", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "3", "-RRB-", "weight", "decay", "of", "\\", "-LRB-", "0.0005\\", "-RRB-", ",", "and", "4", "-RRB-", "data", "augmentation", "by", "rotating", "the", "pair", "of", "patches", "by", "90", ",", "180", ",", "and", "270", "degrees", ",", "and", "flipping", "the", "images", "horizontally", "and", "vertically", "-LRB-", ",", "augmented", "5", "times", ":", "3", "rotations", "and", "2", "flippings", "-RRB-", "-LSB-", "35", "-RSB-", "."], ["The", "training", "set", "for", "the", "triplet", "and", "siamese", "networks", "consists", "of", "a", "set", "of", "\\", "-LRB-", "250,000\\", "-RRB-", "triplets", ",", "which", "are", "sampled", "randomly", "from", "the", "aforementioned", "set", "of", "\\", "-LRB-", "500,000\\", "-RRB-", "pairs", "of", "matching", "and", "non-matching", "image", "patches", ",", "where", "it", "is", "important", "to", "make", "sure", "that", "the", "triplet", "contains", "one", "pair", "of", "matching", "image", "patches", "and", "one", "patch", "that", "belongs", "to", "a", "different", "class", "of", "this", "pair", "."], ["The", "mini-batch", "of", "the", "SGD", "optimisation", "consists", "of", "250", "triplets", "-LRB-", "randomly", "picked", "from", "this", "\\", "-LRB-", "250K\\", "-RRB-", "set", "of", "triplets", "-RRB-", ",", "which", "is", "used", "to", "compute", "the", "global", "loss", "in", "-LRB-", "REF", "-RRB-", "and", "-LRB-", "REF", "-RRB-", "."], ["Our", "Matlab", "implementation", "takes", "\\", "-LRB-", "\\approx", "56\\", "-RRB-", "hours", "for", "training", "a", "model", "and", "processes", "\\", "-LRB-", "16K\\", "-RRB-", "images/sec", "during", "testing", "on", "a", "GTX", "980", "GPU", "."]], "ner": [[[26, 26, "v"], [52, 52, "v"], [63, 63, "v"], [73, 73, "v"], [88, 88, "v"], [90, 90, "v"], [93, 93, "v"]], [[135, 135, "v"], [137, 137, "c"]], [[199, 199, "c"], [211, 211, "c"]], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 11, "a"], [21, 22, "p"], [26, 26, "v"], [52, 52, "v"], [63, 63, "v"], [68, 69, "p"], [73, 73, "v"], [88, 88, "v"], [90, 90, "v"], [93, 93, "v"], [106, 106, "v"], [109, 109, "v"], [112, 112, "v"]], [[124, 124, "a"], [126, 127, "a"], [135, 135, "v"], [150, 150, "v"], [171, 171, "v"], [178, 178, "v"]], [[198, 198, "v"], [207, 207, "v"]], [[238, 238, "v"], [249, 249, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1512.09272-8e0b015b-71a8-477d-a61e-215feb53c0d2", "sentences": [["The", "triplet", "networks", "TNet-TLoss", "and", "TNet-TGLoss", "use", "the", "three", "towers", "of", "ConvNets", "-LRB-", "see", "Fig", "."], ["REF", "-RRB-", "to", "learn", "an", "embedding", "of", "size", "256", "-LRB-", "we", "choose", "this", "number", "of", "dimensions", "based", "on", "the", "feature", "dimensionality", "of", "the", "models", "in", "-LSB-", "35", "-RSB-", ",", "which", "also", "have", "256", "dimensions", "before", "the", "fully", "connected", "layer", "-RRB-", "."], ["During", "testing", ",", "only", "one", "tower", "is", "used", "-LRB-", "all", "three", "towers", "are", "in", "fact", "the", "same", "after", "training", "-RRB-", "to", "compute", "the", "embedded", "features", ",", "which", "are", "compared", "based", "on", "the", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "norm", "of", "the", "distance", "between", "these", "embedded", "features", "."], ["The", "network", "weights", "for", "the", "TNet-TLoss", "network", "are", "initialised", "randomly", "and", "trained", "for", "100", "epochs", ",", "whereas", "the", "weights", "for", "the", "TNet-TGLoss", "network", "are", "trained", "for", "50", "epochs", "after", "being", "initialised", "using", "the", "weights", "from", "TNet-TLoss", "network", "trained", "for", "50", "epochs", "-LRB-", "the", "initialisation", "from", "the", "TNet-TLoss", "model", "trained", "with", "early", "stopping", "provided", "a", "good", "initialisation", "for", "TNet-TGLoss", "-RRB-", "."], ["This", "number", "of", "epochs", "for", "training", "is", "decided", "based", "on", "the", "convergence", "obtained", "in", "the", "training", "set", "with", "respect", "to", "the", "loss", "function", "."], ["Moreover", ",", "the", "margin", "parameter", "\\", "-LRB-", "m=0.01\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=1\\", "-RRB-", ",", "\\", "-LRB-", "t=0.4\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "=0.8\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "are", "estimated", "via", "cross", "validation", "."], ["For", "the", "siamese", "networks", "SNet-GLoss", "and", "CS-SNet-GLoss", ",", "the", "weights", "are", "randomly", "initialised", "and", "trained", "for", "80", "epochs", "-LRB-", "again", ",", "based", "on", "the", "convergence", "of", "the", "training", "set", "-RRB-", "."], ["Finally", ",", "\\", "-LRB-", "m=1\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "=1\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "are", "also", "estimated", "via", "cross", "validation", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[3, 3, "a"], [5, 5, "a"], [11, 11, "a"]], [[16, 16, "a"], [16, 16, "a"]], [], [[108, 108, "a"], [138, 138, "a"], [149, 149, "a"], [124, 124, "a"], [160, 160, "a"]], [], [[190, 191, "p"], [194, 194, "v"], [203, 203, "p"], [204, 204, "v"], [209, 209, "p"], [209, 209, "v"], [214, 214, "p"], [215, 215, "v"], [190, 191, "p"], [204, 204, "v"], [214, 214, "p"], [204, 204, "v"], [190, 191, "p"], [204, 204, "v"], [214, 214, "p"], [204, 204, "v"], [198, 198, "a"], [219, 219, "a"], [190, 191, "p"], [194, 194, "v"], [203, 203, "p"], [204, 204, "v"], [209, 209, "p"], [209, 209, "v"], [214, 214, "p"], [215, 215, "v"], [198, 198, "a"], [219, 219, "a"], [190, 191, "p"], [204, 204, "v"], [214, 214, "p"], [204, 204, "v"]], [[231, 231, "a"], [233, 233, "a"], [233, 233, "a"]], [[262, 262, "v"], [268, 268, "v"], [267, 267, "p"], [262, 262, "v"], [268, 268, "v"], [267, 267, "p"], [262, 262, "v"], [268, 268, "v"], [262, 262, "v"], [268, 268, "v"], [267, 267, "p"], [262, 262, "v"], [268, 268, "v"], [272, 272, "a"], [262, 262, "v"], [268, 268, "v"], [267, 267, "p"], [272, 272, "a"], [262, 262, "v"], [268, 268, "v"], [267, 267, "p"], [262, 262, "v"], [268, 268, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [3, 3, "a"], [5, 5, "a"], [8, 8, "v"], [11, 11, "a"]], [[24, 24, "v"], [48, 48, "v"]], [[61, 61, "v"], [67, 67, "v"], [91, 92, "p"]], [[108, 109, "a"], [116, 116, "v"], [124, 125, "a"], [129, 129, "v"], [138, 139, "a"], [142, 142, "v"], [149, 149, "a"], [160, 160, "a"]], [], [[190, 191, "p"], [194, 194, "v"], [203, 204, "p"], [209, 209, "v"], [214, 215, "p"], [215, 215, "v"], [224, 225, "a"]], [[231, 231, "a"], [233, 233, "a"], [243, 243, "v"]], [[262, 262, "v"], [267, 268, "p"], [278, 279, "a"]], []], "predicted_relations": [[], [], [], [], [], [[190, 191, 198, 198, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [203, 203, 198, 198, "USED-FOR"], [203, 203, 198, 198, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 203, 203, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 203, 203, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [215, 215, 209, 209, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 209, 209, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [194, 194, 190, 191, "USED-FOR"], [203, 203, 198, 198, "USED-FOR"], [203, 203, 198, 198, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 203, 203, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 203, 203, "USED-FOR"], [209, 209, 209, 209, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [209, 209, 214, 214, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [215, 215, 209, 209, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 209, 209, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [214, 214, 198, 198, "USED-FOR"], [214, 214, 219, 219, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"], [204, 204, 203, 203, "USED-FOR"], [204, 204, 190, 191, "USED-FOR"]], [], [[262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [267, 267, 272, 272, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [262, 262, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"], [268, 268, 267, 267, "USED-FOR"]], []]}
{"doc_key": "1611.02064-61d392f8-ad12-402f-9237-b325ef1576de", "sentences": [["Throughout", "the", "experiments", ",", "we", "have", "fixed", "the", "learning", "rate", "to", "be", "\\", "-LRB-", "0.0001\\", "-RRB-", "and", "RMSprop", "-LSB-", "12", "-RSB-", "optimization", "algorithm", "is", "used", "with", "momentum", "fixed", "at", "\\", "-LRB-", "0.7\\", "-RRB-", "."], ["Our", "model", "is", "trained", "for", "60", "epochs", "with", "a", "batch", "size", "of", "32", "."]], "ner": [[[17, 17, "a"], [8, 9, "p"], [14, 14, "v"], [26, 26, "p"], [31, 31, "v"]], [[40, 40, "a"], [43, 44, "a"]]], "relations": [[], []], "predicted_ner": [[[8, 9, "p"], [14, 14, "v"], [17, 17, "a"], [26, 26, "p"], [31, 31, "v"]], [[35, 35, "a"], [39, 39, "v"], [40, 40, "p"], [43, 44, "p"], [46, 46, "v"]]], "predicted_relations": [[[26, 26, 17, 17, "USED-FOR"]], []]}
{"doc_key": "1611.01487-4e8306de-3238-43c9-814c-e48dd1e609d4", "sentences": [["To", "train", "our", "models", ",", "we", "used", "the", "train", "portion", "of", "the", "datasets", "as-is", "and", "evaluated", "on", "the", "test", "portion", "the", "model", "which", "performed", "best", "on", "the", "development", "portion", "of", "the", "dataset", ",", "without", "conducting", "any", "specific", "pre-processing", "steps", "on", "the", "data", "."], ["We", "train", "the", "models", "for", "a", "maximum", "of", "100", "epochs", "over", "the", "training", "set", "."], ["To", "avoid", "long", "training", "time", ",", "we", "trained", "the", "model", "for", "20", "epochs", "for", "datasets", "larger", "than", "50k", "examples", ",", "and", "for", "5", "epochs", "for", "datasets", "larger", "than", "200k", "examples", "."], ["The", "models", "were", "implemented", "using", "the", "python", "bindings", "of", "the", "dynet", "toolkit.https", ":", "//github.com/clab/dynet"]], "ner": [[[12, 12, "a"], [21, 21, "a"]], [[51, 51, "v"]], [[72, 72, "a"], [83, 83, "a"], [67, 67, "a"], [69, 69, "v"], [72, 76, "c"], [80, 80, "v"], [83, 87, "c"]], [[99, 100, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[51, 51, "v"], [52, 52, "p"]], [[69, 69, "v"], [70, 70, "p"], [75, 75, "v"], [80, 80, "v"], [81, 81, "p"], [86, 86, "v"]], []], "predicted_relations": [[], [], [[72, 76, 69, 69, "USED-FOR"], [72, 76, 80, 80, "USED-FOR"], [83, 87, 69, 69, "USED-FOR"], [83, 87, 80, 80, "USED-FOR"]], []]}
{"doc_key": "1611.01487-aedcf278-ef49-4806-90e3-9ae6a3665b9f", "sentences": [["We", "trained", "the", "network", "by", "optimizing", "the", "expected", "output", "sequence", "likelihood", "using", "cross-entropy", "loss", "as", "mentioned", "in", "equation", "REF", "."], ["For", "optimization", "we", "used", "ADADELTA", "-LSB-", "42", "-RSB-", "without", "regularization", "."], ["We", "updated", "the", "weights", "after", "every", "example", "-LRB-", "i.e", "."], ["mini-batches", "of", "size", "1", "-RRB-", "."], ["We", "used", "the", "dynet", "toolkit", "implementation", "of", "an", "LSTM", "network", "with", "two", "layers", "for", "all", "models", ",", "each", "having", "100", "entries", "in", "both", "the", "encoder", "and", "decoder", "."], ["The", "character", "embeddings", "were", "also", "vectors", "with", "100", "entries", "for", "the", "CELEX", "experiments", ",", "and", "with", "300", "entries", "for", "the", "SIGMORPHON", "and", "Wiktionary", "experiments", "."]], "ner": [[[12, 13, "a"]], [[24, 24, "a"]], [], [], [[55, 56, "a"], [66, 66, "v"]], [[82, 82, "v"], [86, 87, "c"], [91, 91, "v"], [95, 98, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [12, 13, "a"]], [[24, 24, "a"]], [], [[44, 44, "v"]], [[50, 51, "a"], [55, 56, "a"], [58, 58, "v"], [66, 66, "v"]], [[82, 82, "v"], [91, 91, "v"], [95, 95, "a"]]], "predicted_relations": [[], [], [], [], [], [[86, 87, 82, 82, "USED-FOR"], [86, 87, 91, 91, "USED-FOR"], [95, 98, 91, 91, "USED-FOR"]]]}
{"doc_key": "1611.01487-1b610d25-c2e2-4e91-aa4f-0c5925af6d25", "sentences": [["The", "morpho-syntactic", "attribute", "embeddings", "were", "vectors", "of", "20", "entries", "in", "all", "experiments", "."], ["We", "did", "not", "use", "beam", "search", "while", "decoding", "for", "both", "the", "hard", "and", "soft", "attention", "models", "as", "it", "is", "significantly", "slower", "and", "did", "not", "show", "clear", "improvement", "in", "previous", "experiments", "we", "conducted", "."], ["For", "the", "character", "level", "alignment", "process", "we", "use", "the", "implementation", "provided", "by", "the", "organizers", "of", "the", "SIGMORPHON2016", "shared", "task.https", ":", "//github.com/ryancotterell/sigmorphon2016"]], "ner": [[[1, 3, "a"], [7, 7, "v"]], [[17, 18, "a"]], [[48, 51, "a"]]], "relations": [[], [], []], "predicted_ner": [[[7, 7, "v"]], [[17, 18, "a"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1606.02003-b3e6fbe7-bf38-45e7-995a-baa21ab43df0", "sentences": [["In", "training", "of", "the", "neural", "networks", ",", "we", "limit", "the", "source", "and", "target", "vocabularies", "to", "the", "most", "frequent", "30K", "words", "in", "both", "Chinese", "and", "English", ",", "covering", "approximately", "\\", "-LRB-", "97.7\\", "%", "\\", "-RRB-", "and", "\\", "-LRB-", "99.3\\", "%", "\\", "-RRB-", "of", "the", "two", "corpora", "respectively", "."], ["The", "dimensions", "of", "word", "embedding", "is", "512", "and", "the", "size", "of", "the", "hidden", "layer", "is", "1024", "."], ["The", "dimemsion", "of", "each", "cell", "in", "\\", "-LRB-", "\\mathbf", "-LCB-", "M", "-RCB-", "^\\textsc", "-LCB-", "B", "-RCB-", "\\", "-RRB-", "is", "set", "to", "1024", "and", "the", "number", "of", "cells", "\\", "-LRB-", "n\\", "-RRB-", "is", "set", "to", "8", "."]], "ner": [[[18, 19, "v"]], [[53, 53, "v"], [62, 62, "v"], [62, 62, "v"]], [[85, 85, "v"], [85, 85, "v"], [98, 98, "v"]]], "relations": [[], [], []], "predicted_ner": [[[18, 18, "v"], [30, 31, "v"], [37, 38, "v"], [43, 43, "v"]], [[53, 53, "v"], [62, 62, "v"]], [[85, 85, "v"], [98, 98, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1606.07659-f19ea6f7-f7d6-469f-80eb-082dffcf0c6d", "sentences": [["We", "train", "a", "one-hidden", "layer", "autoencoders", "with", "hyperbolic", "tangent", "transfer", "functions", "."], ["The", "layers", "have", "600", "hidden", "neurons", "."], ["Weights", "are", "randomly", "initialized", "with", "a", "uniform", "law", "\\", "-LRB-", "\\mathbf", "-LCB-", "W_", "-LCB-", "ij", "-RCB-", "-RCB-", "\\sim", "-LCB-", "\\cal", "U", "-RCB-", "\\left", "-LSB-", "-1/\\sqrt", "-LCB-", "n", "-RCB-", ",", "1/\\sqrt", "-LCB-", "n", "-RCB-", "\\right", "-RSB-", "\\", "-RRB-", "."], ["The", "latent", "dimension", "of", "the", "low", "rank", "matrix", "of", "tags/friendships", "is", "set", "to", "50", "."], ["Hyperparamenters", "were", "are", "fine-tuned", "by", "a", "genetic", "algorithm", "and", "the", "final", "learning", "rate", ",", "learning", "decay", "and", "weight", "decay", "are", "respectively", "set", "to", "\\", "-LRB-", "0.7\\", "-RRB-", ",", "\\", "-LRB-", "0.3\\", "-RRB-", "and", "\\", "-LRB-", "0.5\\", "-RRB-", "."], ["\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "and", "masking", "ratio", "are", "set", "to", "1", ",", "\\", "-LRB-", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "0.25\\", "-RRB-", "."]], "ner": [[[3, 5, "a"], [7, 10, "a"]], [[16, 17, "p"], [15, 15, "v"]], [[43, 43, "v"], [48, 48, "v"]], [[58, 59, "p"], [70, 70, "v"], [62, 66, "a"]], [[83, 84, "p"], [97, 97, "v"], [86, 87, "p"], [102, 102, "v"], [89, 90, "p"], [107, 107, "v"], [107, 107, "v"], [78, 79, "a"]], [[131, 131, "v"], [127, 127, "v"], [131, 131, "v"], [122, 123, "p"], [136, 136, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[15, 15, "v"], [16, 17, "p"]], [], [[70, 70, "v"]], [[83, 84, "p"], [86, 87, "p"], [89, 90, "p"], [97, 97, "v"], [102, 102, "v"], [107, 107, "v"]], [[112, 112, "p"], [118, 118, "p"], [122, 123, "p"], [127, 127, "v"], [131, 131, "v"], [136, 136, "v"]]], "predicted_relations": [[], [[15, 15, 16, 17, "USED-FOR"]], [], [[70, 70, 58, 59, "USED-FOR"]], [[83, 84, 78, 79, "USED-FOR"], [86, 87, 78, 79, "USED-FOR"], [89, 90, 78, 79, "USED-FOR"]], [[127, 127, 122, 123, "USED-FOR"]]]}
{"doc_key": "1608.07636-246f038e-9600-43b9-b1b7-e40a9e4552cf", "sentences": [["\\", "-LRB-", "\\theta", "_", "-LCB-", "\\max", "-RCB-", "\\in", "\\lbrace", "0,1\\rbrace", "\\", "-RRB-", ":", "We", "can", "identify", "\\", "-LRB-", "A+q_0B+D\\", "-RRB-", "and", "\\", "-LRB-", "q_1B-AD\\", "-RRB-", "."], ["Note", "that", "for", "\\", "-LRB-", "\\theta", "_", "-LCB-", "\\max", "-RCB-", "=0\\", "-RRB-", ",", "we", "have", "\\", "-LRB-", "q_0=1\\", "-RRB-", "and", "\\", "-LRB-", "q_1=0\\", "-RRB-", "."], ["\\", "-LRB-", "\\theta", "_", "-LCB-", "\\max", "-RCB-", "\\ge", "2\\", "-RRB-", ":", "We", "can", "identify", "\\", "-LRB-", "A+q_0B+D\\", "-RRB-", ",", "\\", "-LRB-", "q_1B-AD\\", "-RRB-", ",", "and", "the", "matrix", "\\", "-LRB-", "B\\", "-RRB-", "up", "to", "a", "scalar", "multiple", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1612.05386-1f7b234b-e6e2-4cff-8258-779100f2257c", "sentences": [["In", "our", "system", ",", "the", "dimensions", "of", "the", "encoded", "question/image/fact", "features", "-LRB-", "\\", "-LRB-", "d\\", "-RRB-", "in", "Eq", "."], ["REF", "-RRB-", "and", "the", "hidden", "layers", "of", "the", "LSTM", "and", "co-attention", "models", "-LRB-", "\\", "-LRB-", "h\\", "-RRB-", "in", "Eq", "."], ["REF", "-RRB-", "are", "set", "to", "512", "."], ["For", "facts", ",", "the", "subject/relation/object", "entities", "are", "embedded", "to", "128/128/256", "dimensional", "vectors", "respectively", "and", "concatenated", "to", "form", "512d", "vectors", "."], ["We", "used", "two", "layers", "of", "LSTM", "model", "."], ["For", "the", "MLP", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", ",", "the", "dimensions", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "h", "-RCB-", "^w\\", "-RRB-", "and", "\\", "-LRB-", "\\mathbf", "-LCB-", "h", "-RCB-", "^p\\", "-RRB-", "are", "also", "512", ",", "while", "the", "dimension", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "h", "-RCB-", "^q\\", "-RRB-", "is", "set", "to", "1024", "for", "the", "VQA", "dataset", "and", "2048", "for", "the", "Visual", "Genome", "dataset", "."], ["For", "prediction", ",", "we", "take", "the", "top", "3000", "answers", "for", "the", "VQA", "dataset", "and", "the", "top", "5000", "answers", "for", "the", "Visual", "Genome", "dataset", "."], ["The", "whole", "system", "is", "implemented", "on", "the", "Torch7", "-LSB-", "5", "-RSB-", "The", "code", "and", "pre-trained", "models", "will", "be", "released", "upon", "the", "acceptance", "of", "the", "paper", "."], ["and", "trained", "end-to-end", "but", "with", "fixed", "CNN", "features", "."], ["For", "optimzation", ",", "the", "RMSProp", "method", "is", "used", "with", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "momentum", "\\", "-LRB-", "0.99\\", "-RRB-", "."], ["The", "model", "is", "trained", "for", "up", "to", "256", "epochs", "until", "the", "validation", "error", "has", "not", "improved", "in", "the", "last", "5", "epochs", "."]], "ner": [[], [[27, 27, "a"]], [], [], [[71, 71, "a"]], [[76, 76, "a"]], [], [], [], [], [[199, 199, "a"], [205, 207, "p"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[27, 27, "a"], [29, 30, "a"]], [[44, 44, "v"]], [[63, 63, "v"]], [[68, 68, "v"], [71, 71, "a"]], [[76, 76, "a"]], [[106, 106, "v"], [123, 123, "v"], [126, 127, "a"], [129, 129, "v"], [132, 134, "a"]], [[143, 143, "v"], [147, 148, "a"], [152, 152, "v"], [156, 158, "a"]], [[167, 167, "a"]], [[192, 192, "a"]], [[199, 200, "a"], [212, 215, "v"], [219, 219, "p"], [222, 222, "v"]], [[232, 232, "v"], [233, 233, "p"], [244, 244, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [[205, 207, 199, 199, "USED-FOR"]], []]}
{"doc_key": "1604.02426-7f2cbaf1-474c-48ef-a8e3-44bd9891c3a3", "sentences": [["Our", "training", "samples", "are", "derived", "from", "the", "dataset", "used", "in", "the", "work", "of", "Schonberger", "et", "al", "."], ["-LSB-", "39", "-RSB-", ",", "which", "consists", "of", "7.4", "million", "images", "downloaded", "from", "Flickr", "using", "keywords", "of", "popular", "landmarks", ",", "cities", "and", "countries", "across", "the", "world", "."], ["The", "clustering", "procedure", "-LSB-", "36", "-RSB-", "gives", "\\", "-LRB-", "19,546\\", "-RRB-", "images", "to", "serve", "as", "query", "seeds", "."], ["The", "extensive", "retrieval-SfM", "reconstruction", "-LSB-", "46", "-RSB-", "of", "the", "whole", "dataset", "results", "in", "\\", "-LRB-", "1,474\\", "-RRB-", "reconstructed", "3D", "models", "."], ["Removing", "overlapping", "models", "leaves", "us", "with", "713", "3D", "models", "containing", "\\", "-LRB-", "163,671\\", "-RRB-", "unique", "images", "from", "the", "initial", "dataset", "."], ["The", "initial", "dataset", "contained", "on", "purpose", "all", "images", "of", "Oxford5k", "and", "Paris6k", "datasets", "."], ["In", "this", "way", ",", "we", "are", "able", "to", "exclude", "98", "clusters", "that", "contain", "any", "image", "-LRB-", "or", "their", "near", "duplicates", "-RRB-", "from", "these", "test", "datasets", "."]], "ner": [[], [], [[44, 45, "a"]], [[63, 64, "a"]], [], [[112, 112, "a"], [114, 114, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[24, 25, "v"], [29, 29, "a"]], [[52, 52, "v"]], [[76, 76, "v"]], [[88, 88, "v"], [94, 94, "v"]], [[112, 112, "a"], [114, 114, "a"]], [[126, 126, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1604.02426-9347437a-f807-4993-b7e3-a5cbbdfbfcf1", "sentences": [["Each", "training", "and", "validation", "tuple", "contains", "1", "query", ",", "1", "positive", "and", "5", "negative", "images", "."], ["The", "pool", "of", "candidate", "positives", "consists", "of", "\\", "-LRB-", "k=100\\", "-RRB-", "images", "with", "closest", "camera", "centers", "to", "the", "query", "."], ["In", "particular", ",", "for", "method", "\\", "-LRB-", "m_3\\", "-RRB-", ",", "the", "inliers", "overlap", "threshold", "is", "\\", "-LRB-", "t_i=0.2\\", "-RRB-", ",", "and", "the", "scale", "change", "threshold", "\\", "-LRB-", "t_s=1.5\\", "-RRB-", "."], ["Hard", "negatives", "are", "re-mined", "3", "times", "per", "epoch", ",", "i.e", "."], ["roughly", "every", "\\", "-LRB-", "2,000\\", "-RRB-", "training", "queries", "."], ["Given", "the", "chosen", "queries", "and", "the", "chosen", "positives", ",", "we", "further", "add", "20", "images", "per", "cluster", "to", "serve", "as", "candidate", "negatives", "during", "re-mining", "."], ["This", "constitutes", "a", "training", "set", "of", "\\", "-LRB-", "22,156\\", "-RRB-", "images", "and", "it", "corresponds", "to", "the", "case", "that", "all", "3D", "models", "are", "included", "for", "training", "."]], "ner": [[], [], [[47, 49, "p"], [53, 53, "v"], [58, 60, "p"], [63, 63, "v"]], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [9, 9, "v"], [12, 12, "v"]], [[25, 25, "v"]], [[43, 43, "v"]], [[70, 70, "v"]], [[81, 81, "v"]], [[98, 98, "v"]], [[118, 118, "v"]]], "predicted_relations": [[], [], [[53, 53, 47, 49, "USED-FOR"], [63, 63, 58, 60, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1609.05722-82e2a16c-6826-4a24-907b-6376c099b131", "sentences": [["Taking", "into", "account", "the", "fact", "that", "generic", "natural", "image", "priors", "have", "an", "interesting", "effect", "only", "at", "medium", "noise", "levels", "-LSB-", "20", "-RSB-", ",", "we", "conduct", "our", "training", "experiments", "based", "on", "the", "images", "with", "relatively", "high", "peak", "value", "."], ["In", "this", "study", ",", "we", "choose", "\\", "-LRB-", "\\text", "-LCB-", "peak", "-RCB-", "=", "40\\", "-RRB-", "."]], "ner": [[[35, 35, "a"], [35, 36, "a"], [35, 35, "p"]], [[48, 48, "a"], [48, 48, "p"], [51, 51, "v"]]], "relations": [[], []], "predicted_ner": [[], [[51, 51, "v"]]], "predicted_relations": [[[35, 35, 35, 35, "USED-FOR"], [35, 35, 35, 36, "USED-FOR"]], [[48, 48, 48, 48, "USED-FOR"], [51, 51, 48, 48, "USED-FOR"]]]}
{"doc_key": "1609.05722-0323aa2b-09a6-4206-9f0f-ad5a874e105b", "sentences": [["As", "we", "focus", "on", "the", "problem", "of", "Poisson", "denoising", "for", "natural", "images", "in", "a", "general", "sense", ",", "FoE", "prior", "models", "should", "be", "trained", "based", "on", "natural", "image", "datasets", "."], ["We", "conducted", "our", "training", "experiments", "using", "the", "training", "images", "from", "the", "BSDS300", "image", "segmentation", "database", "-LSB-", "1", "-RSB-", "."], ["We", "used", "the", "whole", "200", "training", "images", ",", "and", "randomly", "sampled", "one", "\\", "-LRB-", "128", "\\times", "128\\", "-RRB-", "patch", "from", "each", "training", "image", ",", "resulting", "in", "a", "total", "of", "200", "training", "samples", "."], ["The", "gray", "value", "range", "of", "all", "the", "images", "was", "first", "scaled", "with", "peak", "value", "\\", "-LRB-", "\\text", "-LCB-", "peak", "-RCB-", "=", "40\\", "-RRB-", ",", "and", "then", "corrupted", "with", "Poisson", "noise", "using", "the", "Matlab", "function", "poissrnd", "."]], "ner": [[[17, 19, "a"]], [], [], [[93, 93, "p"], [99, 99, "p"], [102, 102, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [[52, 52, "v"], [59, 59, "v"], [62, 62, "v"], [64, 64, "v"], [77, 77, "v"]], [[102, 102, "v"], [115, 115, "a"]]], "predicted_relations": [[], [], [], [[102, 102, 99, 99, "USED-FOR"]]]}
{"doc_key": "1609.05722-e0e272d8-2fe2-4620-a18b-c10fadd6951e", "sentences": [["Concerning", "the", "model", "capacity", "of", "the", "trained", "FoE", "models", ",", "following", "a", "common", "setup", "of", "filters", "for", "the", "FoE", "model", "in", "-LSB-", "5", "-RSB-", ",", "we", "learned", "48", "filters", "with", "dimension", "\\", "-LRB-", "7", "\\times", "7\\", "-RRB-", "."], ["As", "we", "focused", "on", "mean-zero", "filters", ",", "we", "made", "use", "of", "a", "modified", "DCT-7", "basis", "-LRB-", "the", "atom", "with", "constant", "entries", "is", "excluded", "-RRB-", "to", "construct", "our", "learned", "filters", "."], ["We", "initialized", "the", "filters", "using", "the", "modified", "DCT-7", "basis", "."], ["All", "filters", "have", "the", "same", "norm", "and", "weight", ",", "which", "are", "0.1", "and", "1", ",", "respectivelyAs", "shown", "in", "previous", "work", "-LSB-", "5", "-RSB-", ",", "the", "training", "process", "is", "not", "sensitive", "to", "the", "initialization", ".."]], "ner": [[[18, 19, "a"], [30, 30, "p"]], [[50, 52, "a"]], [[74, 76, "a"]], [[83, 83, "p"], [89, 89, "v"], [85, 85, "p"], [89, 89, "v"], [91, 91, "v"], [103, 104, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[27, 27, "v"], [33, 33, "v"], [35, 35, "v"]], [[51, 51, "a"]], [[75, 75, "a"]], [[89, 89, "v"], [91, 91, "v"]]], "predicted_relations": [[[30, 30, 18, 19, "USED-FOR"]], [], [], [[91, 91, 85, 85, "USED-FOR"]]]}
{"doc_key": "1608.05604-5281dcc0-273d-4ad9-9d2c-a7fe42ce3757", "sentences": [["For", "both", "the", "reader", "and", "the", "decoder", "networks", ",", "we", "choose", "a", "one-layer", "LSTM", "network", "with", "1,000", "memory", "cells", "."], ["The", "attention", "network", "is", "a", "one-layer", "feedforward", "network", "."], ["For", "the", "loss", "estimator", "\\", "-LRB-", "U\\", "-RRB-", ",", "we", "use", "a", "bidirectional", "LSTM", "with", "20", "memory", "cells", "."], ["Input", "data", "is", "split", "into", "sequences", "of", "50", "tokens", ",", "which", "are", "used", "as", "the", "input", "sequences", "for", "NEAT", ",", "disregarding", "sentence", "boundaries", "."], ["Word", "embeddings", "have", "100", "dimensions", ",", "are", "shared", "between", "the", "reader", "and", "the", "attention", "network", ",", "and", "are", "only", "trained", "during", "the", "training", "of", "the", "reader", "."], ["The", "vocabulary", "consists", "of", "the", "10,000", "most", "frequent", "words", "from", "the", "training", "corpus", "."], ["We", "trained", "NEAT", "on", "the", "training", "set", "of", "the", "Daily", "Mail", "section", "of", "the", "corpus", "described", "by", ",", "which", "consists", "of", "195,462", "articles", "from", "the", "Daily", "Mail", "newspaper", ",", "containing", "approximately", "200", "million", "tokens", "."], ["The", "recurrent", "networks", "and", "the", "attention", "network", "were", "each", "trained", "for", "one", "epoch", "."], ["For", "initialization", ",", "weights", "are", "drawn", "from", "the", "uniform", "distribution", "."], ["We", "set", "\\", "-LRB-", "\\alpha", "=", "5.0\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "=", "5.0\\", "-RRB-", ",", "and", "used", "a", "constant", "learning", "rate", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "for", "\\", "-LRB-", "A\\", "-RRB-", "."]], "ner": [[[13, 14, "a"], [17, 18, "p"], [17, 18, "p"]], [[25, 27, "a"]], [[45, 46, "p"], [41, 42, "a"], [45, 46, "p"], [44, 44, "v"]], [[63, 64, "a"], [56, 56, "p"], [55, 55, "v"], [66, 66, "a"]], [[76, 76, "p"], [75, 75, "v"]], [[100, 100, "a"], [107, 107, "p"], [104, 104, "v"]], [[146, 146, "p"], [115, 115, "a"]], [], [], [[177, 177, "p"], [179, 179, "v"], [186, 186, "v"], [184, 184, "p"], [179, 179, "v"], [186, 186, "v"], [193, 194, "p"], [198, 198, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[13, 14, "a"], [16, 16, "v"]], [[21, 22, "a"], [25, 25, "v"], [26, 27, "a"]], [[31, 32, "a"], [35, 35, "p"], [42, 42, "a"], [44, 44, "v"], [45, 46, "p"]], [[55, 55, "v"], [66, 66, "a"]], [[75, 75, "v"], [85, 86, "a"]], [[104, 104, "v"]], [[115, 115, "a"], [134, 134, "v"], [144, 144, "v"]], [[149, 150, "a"], [153, 154, "a"], [159, 159, "v"]], [], [[177, 177, "p"], [178, 179, "v"], [184, 184, "p"], [186, 186, "v"], [193, 194, "p"], [198, 198, "v"], [203, 203, "p"]]], "predicted_relations": [[[17, 18, 13, 14, "USED-FOR"], [17, 18, 13, 14, "USED-FOR"]], [], [[45, 46, 41, 42, "USED-FOR"], [45, 46, 41, 42, "USED-FOR"]], [[56, 56, 63, 64, "USED-FOR"]], [[75, 75, 76, 76, "USED-FOR"]], [[107, 107, 100, 100, "USED-FOR"], [104, 104, 107, 107, "USED-FOR"]], [], [], [], [[186, 186, 193, 194, "USED-FOR"], [186, 186, 193, 194, "USED-FOR"]]]}
{"doc_key": "1610.02692-cba9760d-4002-47ae-a881-bac86a55b4e5", "sentences": [["We", "set", "the", "batch", "size", "to", "be", "the", "maximum", "that", "we", "could", "save", "in", "the", "GPU", "RAM", ",", "having", "a", "value", "of", "just", "32", "samples", "."], ["We", "need", "to", "consider", "that", "we", "also", "need", "to", "fit", "the", "compiled", "model", "-LRB-", "its", "weights", "-RRB-", "in", "the", "GPU", "RAM", "and", "this", "is", "very", "expensive", "as", "some", "of", "our", "layers", ",", "and", "thus", "its", "weights", ",", "are", "huge", "as", "we", "will", "see", "now", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[3, 4, "p"], [23, 23, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "1610.02692-50a2e261-30ff-4d90-82a8-58cecfbe04a0", "sentences": [["For", "the", "question", "maximum", "length", "we", "have", "taken", "the", "length", "of", "the", "largest", "question", "in", "the", "training", "subset", "."], ["This", "parameter", "is", "used", "in", "the", "last", "LSTM", "so", "it", "knows", "when", "it", "has", "seen", "the", "whole", "question", "and", "can", "output", "its", "state", "."], ["We", "found", "that", "for", "the", "training", "set", ",", "the", "maximum", "question", "length", "is", "22", "."], ["The", "questions", "that", "have", "a", "smaller", "length", "have", "been", "left-padded", "with", "0", ",", "so", "the", "input", "is", "'inactive", "'", "and", "then", "it", "is", "activated", "with", "the", "question", "tokens", "."], ["The", "network", "has", "been", "configured", "to", "ignore", "these", "padding", "zeros", "."]], "ner": [[], [[26, 26, "a"]], [[52, 54, "p"], [56, 56, "v"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[26, 26, "a"]], [[56, 56, "v"]], [[69, 69, "v"]], []], "predicted_relations": [[], [], [[56, 56, 52, 54, "USED-FOR"]], [], []]}
{"doc_key": "1610.02692-d4070d91-e572-4d1e-acce-a3abbce37c25", "sentences": [["The", "vocabulary", "size", "is", "crucial", "for", "the", "softmax", "layer", "as", "this", "will", "set", "the", "number", "of", "neurons", "of", "this", "layer", "."], ["A", "value", "of", "20.000", "was", "chosen", "as", "it", "is", "quite", "common", "and", "respects", "the", "tradeoff", "between", "number", "of", "words", "-LRB-", "which", "give", "more", "flexibility", "to", "the", "model", "-RRB-", "and", "number", "of", "weights", "to", "train", "-LRB-", "time", "consuming", ",", "training", "problems", ",", "memory", "constraints", "-RRB-", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[7, 7, "a"]], [[24, 24, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1610.02692-ccda4f97-9b03-449f-b588-7ca7a744c5d9", "sentences": [["For", "this", "model", "we", "chose", "the", "number", "of", "LSTM", "hidden", "units", "and", "the", "embedding", "size", "to", "be", "the", "same", ",", "with", "a", "value", "of", "100", "."], ["We", "used", "this", "value", "for", "simplicity", "and", "due", "to", "some", "experience", "of", "a", "team", "member", "regarding", "these", "parameters", "."]], "ner": [[[8, 8, "a"], [24, 24, "v"], [13, 14, "p"], [24, 24, "v"]], []], "relations": [[], []], "predicted_ner": [[[8, 8, "a"], [24, 24, "v"]], []], "predicted_relations": [[[13, 14, 8, 8, "USED-FOR"]], []]}
{"doc_key": "1603.06067-05c506d7-b372-4b94-984e-27343aa0cbd2", "sentences": [["As", "mentioned", "above", ",", "Eq", "."], ["-LRB-", "REF", "-RRB-", "and", "-LRB-", "-RRB-", "show", "that", "the", "non-compositional", "embeddings", "are", "mainly", "updated", "when", "\\", "-LRB-", "\\alpha", "-LRB-", "p", "-RRB-", "\\", "-RRB-", "is", "close", "to", "0", ",", "and", "vice", "versa", "."], ["The", "partial", "derivative", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "-LCB-", "J", "-RCB-", "-RCB-", "-LCB-", "\\partial", "-LCB-", "\\mathbf", "-LCB-", "c", "-RCB-", "-LRB-", "p", "-RRB-", "-RCB-", "-RCB-", "\\", "-RRB-", "is", "used", "to", "update", "the", "model", "parameters", "in", "the", "composition", "function", "via", "the", "backpropagation", "algorithm", "."], ["Any", "differentiable", "composition", "functions", "can", "be", "used", "in", "our", "method", "."]], "ner": [[], [], [[77, 78, "a"]], [[81, 83, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[32, 32, "v"]], [[77, 78, "a"]], [[89, 89, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1602.07776-ee4130fc-bc1f-40eb-9f59-78e59d2c7016", "sentences": [["For", "the", "discriminative", "model", ",", "we", "used", "hidden", "dimensions", "of", "128", "and", "2-layer", "LSTMs", "-LRB-", "larger", "numbers", "of", "dimensions", "reduced", "validation", "set", "performance", "-RRB-", "."], ["For", "the", "generative", "model", ",", "we", "used", "256", "dimensions", "and", "2-layer", "LSTMs", "."], ["For", "both", "models", ",", "we", "tuned", "the", "dropout", "rate", "to", "maximize", "validation", "set", "likelihood", ",", "obtaining", "optimal", "rates", "of", "0.2", "-LRB-", "discriminative", "-RRB-", "and", "0.3", "-LRB-", "generative", "-RRB-", "."], ["For", "the", "sequential", "LSTM", "baseline", "for", "the", "language", "model", ",", "we", "also", "found", "an", "optimal", "dropout", "rate", "of", "0.3", "."], ["For", "training", "we", "used", "stochastic", "gradient", "descent", "with", "a", "learning", "rate", "of", "0.1", "."], ["All", "parameters", "were", "initialized", "according", "to", "recommendations", "given", "by", "-LSB-", "22", "-RSB-", "."]], "ner": [[[10, 10, "v"], [12, 12, "v"], [12, 12, "v"]], [[35, 35, "v"], [32, 32, "v"], [35, 35, "v"]], [[57, 57, "v"], [57, 57, "v"], [57, 57, "v"], [62, 62, "v"], [62, 62, "v"]], [[85, 85, "v"], [85, 85, "v"]], [[99, 99, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 8, "p"], [10, 10, "v"], [12, 12, "v"], [13, 13, "a"]], [[32, 32, "v"], [33, 33, "p"], [36, 36, "a"]], [[45, 46, "p"], [57, 57, "v"], [62, 62, "v"]], [[70, 70, "a"], [82, 83, "p"], [85, 85, "v"]], [[91, 93, "a"], [96, 97, "p"], [99, 99, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1612.01202-caf7dc65-db65-4a2b-8d2e-442be9c3579e", "sentences": [["Training", "Databases", "."], ["We", "train", "our", "system", "using", "the", "3DDFA", "data", "of", "-LSB-", "54", "-RSB-", "."], ["The", "3DDFA", "data", "provides", "projection", "and", "3DMM", "model", "parameters", "for", "the", "Basel", "-LSB-", "34", "-RSB-", "+", "FaceWarehouse", "-LSB-", "6", "-RSB-", "model", "for", "each", "image", "of", "the", "300W", "database", "."], ["We", "use", "the", "topology", "defined", "by", "this", "model", "to", "define", "our", "UV", "space", "and", "rasterize", "the", "images", "to", "obtain", "per-pixel", "ground", "truth", "UV", "coordinates", "."], ["Our", "training", "set", "consists", "of", "the", "LFPW", "trainset", ",", "Helen", "trainset", "and", "AFW", ",", "thus", "3148", "images", "that", "are", "captured", "under", "completely", "unconstrained", "conditions", "and", "exhibit", "large", "variations", "in", "pose", ",", "expression", ",", "illumination", ",", "age", ",", "etc", "."], ["Many", "of", "these", "images", "contain", "multiple", "faces", ",", "some", "of", "which", "are", "not", "annotated", "."], ["We", "deal", "with", "this", "issue", "by", "employing", "the", "out-of-the-box", "DPM", "face", "detector", "of", "Mathias", "et", "al", "."], ["-LSB-", "31", "-RSB-", "to", "obtain", "the", "regions", "that", "contain", "a", "face", "for", "all", "of", "the", "images", "."], ["The", "detected", "regions", "that", "do", "not", "overlap", "with", "the", "ground", "truth", "landmarks", "do", "not", "contribute", "to", "the", "loss", "."], ["For", "training", "and", "testing", ",", "we", "have", "rescaled", "the", "images", "such", "that", "their", "largest", "side", "is", "800", "pixels", "."]], "ner": [[], [[9, 10, "a"]], [[17, 18, "a"], [27, 36, "a"]], [], [[76, 77, "a"], [79, 80, "a"], [82, 82, "a"]], [], [[133, 135, "a"]], [], [], [[193, 194, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[6, 6, "a"]], [[32, 32, "a"], [42, 42, "v"]], [], [[79, 79, "a"], [82, 82, "a"], [85, 85, "v"]], [], [], [], [], [[193, 193, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1612.01202-10dc50b9-c6f3-4ef3-a0f0-75b48640c9c9", "sentences": [["CNN", "Training", "."], ["For", "the", "dense", "regression", "network", ",", "we", "adopt", "a", "ResNet101", "-LSB-", "18", "-RSB-", "architecture", "with", "dilated", "convolutions", "-LRB-", "atrous", "-RRB-", "-LSB-", "9", "-RSB-", ",", "-LSB-", "28", "-RSB-", ",", "such", "that", "the", "stride", "of", "the", "CNN", "is", "8", "."], ["We", "use", "bilinear", "interpolation", "to", "upscale", "both", "the", "\\", "-LRB-", "\\hat", "-LCB-", "q", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\hat", "-LCB-", "r", "-RCB-", "\\", "-RRB-", "branches", "before", "the", "losses", "."], ["The", "losses", "are", "applied", "at", "the", "input", "image", "scale", "and", "back-propagated", "through", "interpolation", "."], ["We", "apply", "a", "weight", "to", "the", "smooth", "\\", "-LRB-", "L1\\", "-RRB-", "loss", "layers", "to", "balance", "their", "contribution", "."], ["In", "our", "experiments", ",", "we", "have", "used", "a", "weight", "of", "40", "for", "quantized", "-LRB-", "\\", "-LRB-", "d=0.1\\", "-RRB-", "-RRB-", "and", "a", "weight", "of", "70", "for", "non-quantized", "regression", ",", "which", "are", "determined", "by", "a", "coarse", "cross", "validation", "."], ["We", "initialize", "the", "training", "with", "a", "network", "pre-trained", "for", "the", "MS", "COCO", "segmentation", "task", "-LSB-", "26", "-RSB-", "."], ["The", "new", "layers", "are", "initialized", "with", "random", "weights", "drawn", "from", "Gaussian", "distributions", "."], ["Large", "weights", "of", "the", "regression", "losses", "can", "be", "problematic", "at", "initialization", "even", "with", "moderate", "learning", "rates", "."], ["To", "cope", "with", "this", ",", "we", "use", "initial", "training", "with", "a", "lower", "learning", "rate", "for", "a", "warm", "start", "for", "a", "few", "iterations", "."], ["We", "then", "use", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "with", "a", "polynomial", "decay", "policy", "for", "\\", "-LRB-", "20k\\", "-RRB-", "iterations", "with", "a", "batch", "size", "of", "10", "images", "."], ["During", "training", ",", "each", "sample", "is", "randomly", "scaled", "with", "one", "of", "the", "ratios", "\\", "-LRB-", "-LSB-", "0.5", ",", "0.75", ",", "1", ",", "1.25", ",", "1.5", "-RSB-", "\\", "-RRB-", "and", "cropped", "to", "form", "a", "fixed", "\\", "-LRB-", "321\\times", "321\\", "-RRB-", "input", "image", "."]], "ner": [[], [[12, 12, "a"]], [[43, 44, "a"]], [], [], [[128, 129, "c"], [119, 119, "v"]], [[150, 153, "a"]], [[168, 169, "a"]], [], [[209, 209, "p"]], [[215, 217, "p"], [225, 227, "a"], [233, 233, "p"], [236, 237, "p"]], [[260, 260, "v"], [262, 262, "v"], [264, 264, "v"], [266, 266, "v"], [264, 264, "v"], [266, 266, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"], [39, 39, "v"]], [], [], [[94, 94, "v"]], [[113, 113, "v"], [119, 119, "v"], [126, 126, "v"], [137, 138, "a"]], [], [], [], [[200, 201, "p"], [208, 208, "v"]], [[221, 221, "v"], [231, 231, "v"], [236, 237, "p"], [239, 239, "v"]], [[251, 251, "v"], [266, 266, "v"], [279, 279, "v"]]], "predicted_relations": [[], [], [], [], [], [[128, 129, 119, 119, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "1606.01561-5f2eb951-123f-4424-bad4-413291a5fcc0", "sentences": [["We", "train", "faster", "R-CNN", "networks", "built", "on", "the", "VGG16", "-LSB-", "20", "-RSB-", "and", "AlexNet", "-LSB-", "15", "-RSB-", ",", "pretrained", "on", "the", "ImageNet-1k", "-LSB-", "3", "-RSB-", "classification", "dataset", "."], ["VGG16", "has", "sixteen", "convolution", "layers", "-LSB-", "20", "-RSB-", "and", "AlexNet", "has", "only", "five", "convolutional", "layers", "-LSB-", "15", "-RSB-", "."], ["Rather", "than", "using", "the", "convolution", "features", "of", "the", "last", "pooled", "layer", "-LRB-", "as", "is", "done", "in", "the", "original", "faster", "R-CNN", "paper", "-RRB-", ",", "we", "use", "features", "from", "convolutional", "layers", "that", "are", "the", "bottom", "layers", "of", "the", "previous", "pooling", "layer", "."], ["For", "VGG16", "it", "is", "conv4_3", "."], ["We", "resize", "the", "\\", "-LRB-", "roi", "pooling\\", "-RRB-", "window", "size", "accordingly", "."], ["For", "VGG16", "the", "window", "size", "changes", "from", "7x7", "to", "13x13", "."], ["We", "also", "reduce", "the", "feature", "stride", "by", "a", "factor", "of", "two", "for", "avoiding", "one", "pooling", "stage", "."], ["For", "VGG16", "and", "AlexNet", ",", "fully", "connected", "layers", "are", "used", "as", "the", "R-CNN", "branch", "."], ["The", "weights", "in", "these", "layers", "are", "initialized", "with", "random", "gaussian", "noise", "."], ["As", "the", "standard", "procedure", "introduced", "in", "faster", "R-CNN", ",", "we", "randomly", "sample", "128", "positive", "and", "128", "negative", "\\", "-LRB-", "roi\\", "-RRB-", "proposals", "per", "batch", "to", "train", "the", "R-CNN", "layer", "."], ["For", "all", "the", "experiments", ",", "we", "use", "initial", "learning", "rate", "of", "0.0005", ",", "step", "size", "50000", "and", "momentum", "0.9", "."], ["A", "total", "of", "70K", "iterations", "are", "run", "during", "R-CNN", "training", "starting", "from", "imagenet", "pre-trained", "weights", "for", "the", "convolution", "layers", "."]], "ner": [[[8, 8, "a"], [13, 13, "a"], [21, 21, "a"]], [[28, 28, "a"], [37, 37, "a"]], [], [[88, 88, "a"]], [[98, 99, "a"], [101, 102, "p"]], [[106, 106, "a"], [108, 109, "p"], [112, 112, "v"], [114, 114, "v"]], [[120, 121, "p"]], [[134, 134, "a"], [136, 136, "a"], [145, 146, "a"]], [], [], [[197, 199, "p"], [201, 201, "v"], [203, 204, "p"], [205, 205, "v"], [207, 207, "p"], [208, 208, "v"]], [[214, 214, "p"], [213, 213, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [8, 8, "a"], [13, 13, "a"], [21, 21, "a"]], [[28, 28, "a"], [30, 30, "v"], [37, 37, "a"], [40, 40, "v"]], [[66, 66, "a"]], [[88, 88, "a"], [91, 91, "a"]], [], [[106, 106, "a"], [112, 112, "v"], [114, 114, "v"]], [[126, 126, "v"], [129, 129, "v"]], [[134, 134, "a"], [136, 136, "a"], [145, 145, "a"]], [], [[167, 167, "a"], [172, 172, "v"], [175, 175, "v"], [187, 187, "a"]], [[198, 199, "p"], [201, 201, "v"], [205, 205, "v"], [208, 208, "v"]], [[213, 213, "v"], [218, 218, "a"], [222, 222, "a"]]], "predicted_relations": [[], [], [], [], [[101, 102, 98, 99, "USED-FOR"]], [[108, 109, 106, 106, "USED-FOR"], [112, 112, 108, 109, "USED-FOR"]], [], [], [], [], [[201, 201, 197, 199, "USED-FOR"], [205, 205, 197, 199, "USED-FOR"], [205, 205, 203, 204, "USED-FOR"], [205, 205, 207, 207, "USED-FOR"]], [[213, 213, 214, 214, "USED-FOR"]]]}
{"doc_key": "1611.03718-3a679289-f7ca-4c6c-bf5b-d602fa7078ee", "sentences": [["The", "weights", "for", "the", "Deep", "Q-network", "were", "initialized", "from", "a", "normal", "distribution", "."], ["For", "learning", ",", "we", "used", "Adam", "optimizer", "-LSB-", "6", "-RSB-", "with", "a", "learning", "rate", "of", "1e-6", "to", "avoid", "that", "the", "gradients", "explode", "."], ["We", "trained", "each", "model", "for", "50", "epochs", "."]], "ner": [[[4, 5, "a"], [10, 11, "a"]], [[18, 19, "a"], [25, 26, "p"], [28, 28, "v"]], [[42, 42, "a"]]], "relations": [[], [], []], "predicted_ner": [[[5, 5, "a"]], [[18, 18, "a"], [25, 26, "p"], [28, 28, "v"]], [[41, 41, "v"], [42, 42, "p"]]], "predicted_relations": [[], [[25, 26, 18, 19, "USED-FOR"], [28, 28, 25, 26, "USED-FOR"]], []]}
{"doc_key": "1602.01255-9cf3228a-b467-41e3-afe1-7e9c76281b12", "sentences": [["All", "networks", "were", "trained", "using", "an", "effective", "training", "procedure", "-LRB-", "cf", "."], ["-LSB-", "0", "-RSB-", "-RRB-", ",", "with", "the", "values", "of", "the", "learning", "rate", ",", "momentum", ",", "and", "weight", "decay", "hyperparameters", "being", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "and", "\\", "-LRB-", "5", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "respectively", "."], ["Whenever", "the", "error", "on", "the", "validation", "set", "stopped", "decreasing", "the", "learning", "rate", "was", "decreased", "by", "a", "factor", "10", "."]], "ner": [[[7, 8, "a"]], [[22, 23, "p"], [25, 25, "p"], [43, 43, "v"], [28, 29, "p"]], [[69, 70, "p"]]], "relations": [[], [], []], "predicted_ner": [[], [[22, 23, "p"], [25, 25, "p"], [34, 37, "v"], [43, 43, "v"], [49, 49, "v"], [51, 54, "v"]], [[69, 70, "p"], [76, 76, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1601.02225-cd0224ed-bf66-418e-8dc2-b08ea3185c37", "sentences": [["In", "this", "section", ",", "parameter", "quantization", "is", "described", ",", "separately", "."], ["Parameter", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "varies", "in", "range", "\\", "-LRB-", "-LSB-", "0", ",", "\\pi", "-RRB-", "\\", "-RRB-", "to", "cover", "all", "directions", "."], ["For", "this", "purpose", "two", "points", "\\", "-LRB-", "C\\", "-RRB-", "and", "\\", "-LRB-", "O\\", "-RRB-", "were", "used", "to", "represent", "orientation", "."], ["The", "angle", "between", "the", "line", "passing", "from", "points", "\\", "-LRB-", "C\\", "-RRB-", "and", "\\", "-LRB-", "O\\", "-RRB-", "and", "the", "horizontal", "axis", "of", "coordinate", "system", ",", "forms", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "."], ["Suppose", "that", "square", "\\", "-LRB-", "S\\", "-RRB-", "is", "\\", "-LRB-", "m\\times", "n\\", "-RRB-", "."], ["Point", "\\", "-LRB-", "C\\", "-RRB-", "is", "fixed", "and", "located", "at", "pixel", "\\", "-LRB-", "C=", "-LRB-", "\\lfloor", "\\frac", "-LCB-", "m", "-RCB-", "-LCB-", "2", "-RCB-", "\\rfloor", ",", "\\lceil", "\\frac", "-LCB-", "n", "-RCB-", "-LCB-", "2", "-RCB-", "\\rceil", "-RRB-", "\\", "-RRB-", "."], ["Location", "of", "point", "\\", "-LRB-", "O\\", "-RRB-", "varies", "and", "can", "be", "any", "pixel", "in", "set", "\\", "-LRB-", "D_O=\\lbrace", "-LRB-", "0", ",", "y", "-RRB-", "|y=0", ",", "\\ldots", ",", "n-1\\rbrace", "\\cup", "\\lbrace", "-LRB-", "x", ",", "n-1", "-RRB-", "|x=0", ",", "\\ldots", ",", "m-1\\rbrace", "\\", "-RRB-", "."], ["Thus", ",", "the", "number", "of", "difference", "state", "of", "parameter", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "is", "equal", "to", "\\", "-LRB-", "m+n-1\\", "-RRB-", "."]], "ner": [[], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[37, 37, "v"]], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1612.02482-e9bcbfed-d494-4bc1-9e57-d5e6a1b3e526", "sentences": [["The", "error", "function", "used", "was", "the", "sampled", "SoftMax", "loss", "to", "ensure", "a", "large", "target", "vocabulary", "could", "be", "accommodated", "-LSB-", "15", "-RSB-", "."], ["A", "zoomed", "inset", "graph", "-LRB-", "Fig", "."], ["REF", "-RRB-", "has", "been", "used", "to", "visualize", "the", "values", "of", "the", "error", "function", "for", "the", "RNNSearch", "+", "Word2Vec", "and", "RNNMorph", "models", "with", "4", "hidden", "layers", "."], ["It", "can", "be", "seen", "that", "the", "RNNMorph", "model", "is", "consistently", "better", "in", "terms", "of", "the", "perplexity", "values", "through", "the", "time", "steps", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[7, 8, "a"]], [], [[44, 46, "a"], [48, 48, "a"]], [[61, 61, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 8, "a"]], [], [[44, 46, "a"], [48, 49, "a"], [51, 51, "v"], [52, 53, "p"]], [[61, 62, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1610.09300-e7dbd4e5-1f83-4afd-8d3e-f92c857d9cb9", "sentences": [["Let", "\\", "-LRB-", "Q", ",", "Q\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "m\\times", "m", "-RCB-", "_+\\", "-RRB-", "and", "assume", "\\", "-LRB-", "0", "\\le", "Q_", "-LCB-", "i", ",", "j", "-RCB-", "\\le", "Q_", "-LCB-", "i", ",", "j", "-RCB-", "\\", "-RRB-", "for", "every", "\\", "-LRB-", "i", ",", "j\\in", "-LSB-", "m", "-RSB-", "\\", "-RRB-", ",", "then", "\\", "-LRB-", "\\rho", "-LRB-", "Q", "-RRB-", "\\le", "\\rho", "-LRB-", "Q", "-RRB-", "\\", "-RRB-", ",", "see", "Corollary", "3.30", "-LSB-", "2", "-RSB-", "."], ["It", "follows", "that", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "\\", "-RRB-", "in", "Theorem", "REF", "is", "increasing", "w.r.t", "."], ["\\", "-LRB-", "\\rho", "_u", ",", "\\rho", "_w", ",", "\\rho", "_x\\", "-RRB-", "and", "the", "number", "of", "hidden", "units", "\\", "-LRB-", "n_1\\", "-RRB-", "."], ["Moreover", ",", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "\\", "-RRB-", "is", "decreasing", "w.r.t", "."], ["\\", "-LRB-", "p_u", ",", "p_w\\", "-RRB-", "and", "in", "particular", ",", "we", "note", "that", "for", "any", "fixed", "architecture", "\\", "-LRB-", "-LRB-", "n_1", ",", "\\alpha", ",", "\\rho", "_u", ",", "\\rho", "_w", "-RRB-", "\\", "-RRB-", "it", "is", "always", "possible", "to", "find", "\\", "-LRB-", "p_u", ",", "p_w\\", "-RRB-", "large", "enough", "so", "that", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "<", "1\\", "-RRB-", "."], ["Indeed", ",", "we", "know", "from", "the", "Collatz-Wielandt", "formula", "-LRB-", "Theorem", "8.1.26", "in", "-LSB-", "9", "-RSB-", "-RRB-", "that", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "=\\rho", "-LRB-", "A^T", "-RRB-", "\\le", "\\max", "_", "-LCB-", "i\\in", "-LSB-", "K+1", "-RSB-", "-RCB-", "-LRB-", "A^Tv", "-RRB-", "_i/v_i\\", "-RRB-", "for", "any", "\\", "-LRB-", "v\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "K+1", "-RCB-", "_", "-LCB-", "++", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "this", "to", "derive", "lower", "bounds", "on", "\\", "-LRB-", "p_u", ",", "p_w\\", "-RRB-", "that", "ensure", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "<", "1\\", "-RRB-", "."], ["Let", "\\", "-LRB-", "v=", "-LRB-", "p_w-1", ",", "\\ldots", ",", "p_w-1", ",", "p_u-1", "-RRB-", "\\", "-RRB-", ",", "then", "\\", "-LRB-", "-LRB-", "A^Tv", "-RRB-", "_i", "<", "v_i\\", "-RRB-", "for", "every", "\\", "-LRB-", "i\\in", "-LSB-", "K+1", "-RSB-", "\\", "-RRB-", "guarantees", "\\", "-LRB-", "\\rho", "-LRB-", "A", "-RRB-", "<", "1\\", "-RRB-", "and", "is", "equivalent", "to", "\\", "-LRB-", "p_w", ">", "4", "-LRB-", "K+1", "-RRB-", "\\xi", "_1+3", "\\qquad", "\\text", "-LCB-", "and", "-RCB-", "\\qquad", "p_u", ">", "2", "-LRB-", "K+1", "-RRB-", "-LRB-", "\\Vert", "\\alpha", "\\Vert", "_", "-LCB-", "\\infty", "-RCB-", "+2\\xi", "_2", "-RRB-", "-1", ",", "\\", "-RRB-"]], "ner": [[], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [], [[191, 192, "a"]], [], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1602.08210-e1b829b4-26bb-43b1-baed-f20eca539f71", "sentences": [["For", "each", "experiment", ",", "we", "use", "Adam", "for", "optimization", ",", "and", "conduct", "a", "grid", "search", "on", "the", "learning", "rate", "in", "\\", "-LRB-", "\\lbrace", "10^", "-LCB-", "-2", "-RCB-", ",", "10^", "-LCB-", "-3", "-RCB-", ",10^", "-LCB-", "-4", "-RCB-", ",10^", "-LCB-", "-5", "-RCB-", "\\rbrace", "\\", "-RRB-", "."], ["For", "\\", "-LRB-", "tanh\\", "-RRB-", "RNNs", ",", "the", "parameters", "are", "initialized", "with", "samples", "from", "a", "uniform", "distribution", "."], ["For", "the", "LSTM", "networks", "we", "adopt", "a", "similar", "initialization", "scheme", ",", "while", "the", "forget", "gate", "biases", "are", "chosen", "by", "the", "grid", "search", "on", "\\", "-LRB-", "\\lbrace", "-5", ",", "-3", ",", "-1", ",", "0", ",", "1", ",", "3", ",", "5\\rbrace", "\\", "-RRB-", "."], ["We", "employ", "early", "stopping", "during", "training", ",", "and", "the", "batch", "size", "is", "set", "to", "50", "."]], "ner": [[[6, 6, "a"], [17, 18, "p"], [30, 30, "v"], [38, 38, "v"]], [[49, 49, "a"]], [[64, 65, "a"], [75, 77, "p"], [94, 94, "v"], [92, 92, "v"], [96, 96, "v"], [90, 90, "v"], [98, 98, "v"], [88, 88, "v"], [100, 100, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"], [13, 14, "c"], [17, 18, "p"]], [[49, 49, "a"]], [[64, 65, "a"], [82, 83, "c"]], [[106, 107, "a"], [108, 109, "c"], [113, 114, "p"], [118, 118, "v"]]], "predicted_relations": [[[17, 18, 6, 6, "USED-FOR"]], [], [[75, 77, 64, 65, "USED-FOR"]], []]}
{"doc_key": "1605.08618-680879a2-d4d0-417b-855d-62a44eb33490", "sentences": [["Do", "we", "need", "to", "include", "actual", "prior", "knowledge", "when", "using", "VI", "approaches", "?"], ["No", ",", "the", "main", "advantage", "in", "relying", "on", "a", "training", "that", "is", "based", "on", "variational", "Bayesian", "inference", "is", ",", "that", "the", "introduction", "of", "the", "distributions", "over", "the", "model", "parameters", "prevents", "us", "from", "running", "into", "local", "minima", "."], ["Especially", "those", "that", "arise", "when", "a", "component", "-LRB-", "or", "a", "state", "-RRB-", "collapses", "over", "a", "single", "observation", "-LRB-", "or", "multiple", "observations", "with", "identical", "characteristics", "-RRB-", "."], ["In", "that", "case", "the", "variance", "approaches", "0", "-LRB-", "and", "the", "mean", "\\", "-LRB-", "\\infty", "\\", "-RRB-", "since", "\\", "-LRB-", "\\int", "p", "-LRB-", "x", "-RRB-", "\\mathrm", "-LCB-", "d", "-RCB-", "x", "=", "1\\", "-RRB-", "-RRB-", "and", "would", "normally", "dramatically", "increase", "the", "likelihood", "for", "the", "model", "\u2013", "this", "is", "also", "known", "as", "singularity", "-LRB-", "and", "one", "of", "the", "known", "drawbacks", "of", "normal", "EM", "-RRB-", "."], ["Using", "the", "2nd", "order", "approaches", "prevents", "this", "by", "a", "low", "density", "in", "the", "parameter", "space", "where", "the", "variance", "approaches", "0", "-LRB-", "Therefore", "\\", "-LRB-", "p", "-LRB-", "x|\\sigma", "-RRB-", "\\rightarrow", "\\infty", "\\", "-RRB-", "is", "attenuated", "by", "a", "low", "density", "for", "\\", "-LRB-", "p", "-LRB-", "\\sigma", "-RRB-", "\\", "-RRB-", "-RRB-", "."]], "ner": [[], [], [], [[80, 80, "p"]], [[140, 142, "a"], [155, 155, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[82, 82, "v"], [128, 128, "v"]], [[157, 157, "v"]]], "predicted_relations": [[], [], [], [], [[155, 155, 140, 142, "USED-FOR"]]]}
{"doc_key": "1611.06624-6c45afe0-9c45-41d5-87d3-03e20d2effd6", "sentences": [["All", "the", "parameters", "used", "in", "the", "optimizer", "are", "the", "same", "as", "those", "of", "the", "original", "WGAN", "."], ["Specifically", ",", "we", "used", "the", "RMSProp", "optimizer", "-LSB-", "40", "-RSB-", "with", "the", "learning", "rate", "of", "\\", "-LRB-", "0.00005\\", "-RRB-", "."], ["All", "the", "weights", "in", "the", "temporal", "generator", "and", "the", "discriminator", "are", "initialized", "with", "HeNormal", "-LSB-", "7", "-RSB-", ",", "and", "the", "weights", "in", "the", "image", "generator", "are", "initialized", "with", "the", "uniform", "distribution", "within", "a", "range", "of", "\\", "-LRB-", "-LSB-", "-0.01", ",", "0.01", "-RSB-", "\\", "-RRB-", "."], ["Chainer", "-LSB-", "41", "-RSB-", "was", "used", "to", "implement", "all", "models", "and", "for", "experiments", "."]], "ner": [[], [[22, 23, "a"], [29, 30, "p"], [34, 34, "v"]], [[50, 50, "a"], [66, 67, "a"], [70, 70, "p"]], [[82, 82, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[15, 15, "a"]], [[22, 22, "a"], [29, 30, "p"], [34, 34, "v"]], [[50, 50, "a"], [77, 78, "v"]], [[82, 82, "a"]]], "predicted_relations": [[], [[29, 30, 22, 23, "USED-FOR"], [34, 34, 29, 30, "USED-FOR"]], [[70, 70, 50, 50, "USED-FOR"], [70, 70, 66, 67, "USED-FOR"]], []]}
{"doc_key": "1611.06624-7dcd9c0f-218f-42f2-a7b6-172beed8d4e0", "sentences": [["For", "comparison", ",", "we", "employed", "the", "conventional", "clipping", "method", "and", "the", "SVC", "to", "train", "models", "with", "the", "WGAN", "."], ["In", "the", "conventional", "clipping", "method", ",", "we", "carefully", "searched", "clipping", "parameter", "\\", "-LRB-", "c\\", "-RRB-", "and", "confirmed", "that", "the", "best", "value", "is", "\\", "-LRB-", "c", "=", "0.01\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "n_D\\", "-RRB-", "to", "1", "for", "the", "both", "methods", "."]], "ner": [[[6, 8, "a"], [11, 11, "a"], [17, 17, "a"]], [[21, 23, "a"], [45, 45, "v"]], [[52, 52, "a"]]], "relations": [[], [], []], "predicted_ner": [[[11, 11, "a"], [17, 17, "a"]], [[32, 32, "p"], [43, 43, "p"], [44, 45, "v"]], [[55, 55, "v"], [56, 59, "c"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1610.01030-7b8d4098-200f-4f9c-a029-b2194dee45e0", "sentences": [["Before", "performing", "the", "online", "learning", ",", "we", "assume", "that", "an", "initial", "model", "\\", "-LRB-", "\\theta", "_0\\", "-RRB-", "exists", "."], ["In", "our", "case", ",", "we", "train", "the", "initial", "model", "using", "all", "the", "datasets", "from", "CrisisNLP", "except", "the", "Nepal", "earthquake", "."], ["For", "online", "training", ",", "we", "sort", "the", "Nepal", "labeled", "data", "based", "on", "the", "time", "stamp", "of", "the", "tweets", "."], ["This", "brings", "the", "tweets", "in", "their", "posting", "order", "."], ["Next", ",", "the", "dataset", "\\", "-LRB-", "D\\", "-RRB-", "is", "divided", "at", "each", "time", "interval", "\\", "-LRB-", "d_t\\", "-RRB-", "in", "which", "case", "\\", "-LRB-", "D\\", "-RRB-", "is", "defined", "as", ":", "D", "=", "\\", "-LRB-", "\\sum", "_", "-LCB-", "t=1", "-RCB-", "^T", "d_t\\", "-RRB-", "where", "\\", "-LRB-", "d_t=", "200\\", "-RRB-", "."], ["For", "each", "time", "interval", "\\", "-LRB-", "t\\", "-RRB-", ",", "we", "divide", "the", "available", "labeled", "dataset", "into", "a", "train", "set", "-LRB-", "70", "%", "-RRB-", ",", "dev", "set", "-LRB-", "10", "%", "-RRB-", ",", "and", "a", "test", "set", "-LRB-", "20", "%", "-RRB-", "using", "ski-learn", "toolkit", "'s", "module", "-LSB-", "18", "-RSB-", ",", "which", "ensured", "that", "the", "class", "distribution", "remains", "reasonably", "balanced", "in", "each", "subset", "."]], "ner": [[[10, 11, "a"]], [[26, 27, "a"]], [], [], [[70, 70, "a"], [79, 80, "p"], [112, 112, "v"]], [[129, 129, "a"], [117, 118, "p"], [155, 158, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [], [], [[112, 112, "v"]], [[135, 136, "v"], [142, 143, "v"], [151, 152, "v"]]], "predicted_relations": [[], [], [], [], [[79, 80, 70, 70, "USED-FOR"]], []]}
{"doc_key": "1610.01030-2f8fdf63-d657-441a-b9ae-bc995f9014bd", "sentences": [["Based", "on", "the", "data", "splitting", "strategy", "mentioned", "above", ",", "we", "start", "online", "learning", "to", "train", "a", "binary", "and", "a", "multi-class", "classifier", "."], ["For", "the", "binary", "classifier", "training", ",", "we", "merge", "all", "the", "informative", "classes", "to", "create", "one", "general", "Informative", "class", "."], ["We", "train", "CNN", "models", "by", "optimizing", "the", "cross", "entropy", "in", "Equation", "REF", "using", "the", "gradient-based", "online", "learning", "algorithm", "ADADELTA", "-LSB-", "26", "-RSB-", ".Other", "algorithms", "-LRB-", "SGD", ",", "Adagrad", "-RRB-", "gave", "similar", "results", "."], ["The", "learning", "rate", "and", "the", "parameters", "were", "set", "to", "the", "values", "as", "suggested", "by", "the", "authors", "."], ["The", "maximum", "number", "of", "epochs", "was", "set", "to", "25", "."], ["To", "avoid", "overfitting", ",", "we", "use", "dropout", "-LSB-", "22", "-RSB-", "of", "hidden", "units", "and", "early", "stopping", "based", "on", "the", "accuracy", "on", "the", "validation", "set.\\", "-LRB-", "l_1\\", "-RRB-", "and", "\\", "-LRB-", "l_2\\", "-RRB-", "regularization", "on", "weights", "did", "not", "work", "well", "."], ["We", "experimented", "with", "\\", "-LRB-", "\\lbrace", "0.0", ",", "0.2", ",", "0.4", ",", "0.5\\rbrace", "\\", "-RRB-", "dropout", "rates", "and", "\\", "-LRB-", "\\lbrace", "32", ",", "64", ",", "128\\rbrace", "\\", "-RRB-", "minibatch", "sizes", "."], ["We", "limit", "the", "vocabulary", "-LRB-", "\\", "-LRB-", "V\\", "-RRB-", "-RRB-", "to", "the", "most", "frequent", "\\", "-LRB-", "P\\", "%", "\\", "-RRB-", "-LRB-", "\\", "-LRB-", "P\\in", "\\lbrace", "80", ",", "85", ",", "90\\rbrace", "\\", "-RRB-", "-RRB-", "words", "in", "the", "training", "corpus", "."], ["The", "word", "vectors", "in", "\\", "-LRB-", "L\\", "-RRB-", "were", "initialized", "with", "the", "pre-trained", "embeddings", "."], ["We", "use", "rectified", "linear", "units", "-LRB-", "ReLU", "-RRB-", "for", "the", "activation", "functions", "-LRB-", "\\", "-LRB-", "f\\", "-RRB-", "-RRB-", ",", "\\", "-LRB-", "\\lbrace", "100", ",", "150", ",", "200\\rbrace", "\\", "-RRB-", "filters", "each", "having", "window", "size", "-LRB-", "\\", "-LRB-", "L\\", "-RRB-", "-RRB-", "of", "\\", "-LRB-", "\\lbrace", "2", ",", "3", ",", "4\\rbrace", "\\", "-RRB-", ",", "pooling", "length", "-LRB-", "\\", "-LRB-", "p\\", "-RRB-", "-RRB-", "of", "\\", "-LRB-", "\\lbrace", "2,3", ",", "4\\rbrace", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\lbrace", "100", ",", "150", ",", "200\\rbrace", "\\", "-RRB-", "dense", "layer", "units", "."], ["All", "the", "hyperparameters", "are", "tuned", "on", "the", "development", "set", "."]], "ner": [[[11, 12, "a"], [19, 20, "a"]], [[24, 26, "a"]], [[43, 44, "a"], [56, 57, "a"], [48, 49, "a"], [59, 59, "a"], [66, 66, "a"], [68, 68, "a"]], [[75, 76, "p"], [85, 89, "v"]], [[92, 95, "p"], [99, 99, "v"]], [[107, 107, "a"], [115, 116, "a"]], [[147, 147, "v"], [149, 149, "v"], [151, 151, "v"], [153, 153, "v"], [162, 162, "v"], [164, 164, "v"], [166, 166, "v"], [149, 149, "v"], [151, 151, "v"], [149, 149, "v"], [151, 151, "v"], [156, 156, "a"]], [[175, 175, "p"]], [], [[258, 259, "p"], [270, 270, "v"], [290, 290, "v"], [272, 272, "v"], [290, 290, "v"], [274, 274, "v"], [292, 292, "v"], [278, 279, "p"], [270, 270, "v"], [290, 290, "v"], [272, 272, "v"], [290, 290, "v"], [274, 274, "v"], [292, 292, "v"], [307, 309, "p"], [248, 248, "v"], [300, 300, "v"], [250, 250, "v"], [302, 302, "v"], [252, 252, "v"], [304, 304, "v"], [232, 232, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[36, 36, "v"]], [[43, 44, "a"], [48, 49, "a"], [59, 59, "a"], [68, 68, "a"]], [[75, 76, "p"]], [[99, 99, "v"]], [[107, 107, "a"], [115, 116, "a"]], [[146, 153, "v"], [156, 157, "p"], [161, 166, "v"]], [[196, 201, "v"]], [], [[228, 233, "a"], [247, 252, "v"], [269, 274, "v"], [289, 292, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [[258, 259, 232, 232, "USED-FOR"], [270, 270, 278, 279, "USED-FOR"], [290, 290, 278, 279, "USED-FOR"], [272, 272, 278, 279, "USED-FOR"], [290, 290, 278, 279, "USED-FOR"], [274, 274, 278, 279, "USED-FOR"], [292, 292, 278, 279, "USED-FOR"], [278, 279, 232, 232, "USED-FOR"], [270, 270, 278, 279, "USED-FOR"], [290, 290, 278, 279, "USED-FOR"], [272, 272, 278, 279, "USED-FOR"], [290, 290, 278, 279, "USED-FOR"], [274, 274, 278, 279, "USED-FOR"], [292, 292, 278, 279, "USED-FOR"], [302, 302, 278, 279, "USED-FOR"]], []]}
{"doc_key": "1609.04337-78e9a2b0-ec1f-4e53-a341-a94a660a885d", "sentences": [["We", "collected", "stereo", "image", "pairs", "using", "a", "PointGrey", "BumbleBee2", "BB2-03S2C-25", "wide-angle", "color", "stereoscopic", "camera", ",", "with", "focal", "length", "\\", "-LRB-", "f=2.5mm\\", "-RRB-", ",", "baseline", "distance", "\\", "-LRB-", "B=120mm\\", "-RRB-", "and", "resolution", "\\", "-LRB-", "640", "\\times", "480\\", "-RRB-", "at", "25", "frames", "per", "second", "."], ["The", "images", "were", "rectified", "using", "the", "Triclops", "proprietary", "PointGrey", "middleware", "."], ["The", "camera", "was", "mounted", "on", "a", "TurtleBot", "2", "mobile", "robot", "base", ",", "which", "was", "manually", "controlled", "in", "an", "office", "environment", "to", "collect", "data", "."], ["A", "total", "of", "6301", "frames", "were", "captured", ",", "corresponding", "to", "4", "minutes", "and", "10", "seconds", "of", "video", "."]], "ner": [[[7, 13, "a"], [16, 17, "p"], [20, 20, "v"], [23, 24, "p"], [27, 27, "v"], [30, 30, "p"]], [[49, 52, "a"]], [[60, 64, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[7, 8, "a"], [33, 33, "v"], [35, 35, "v"], [38, 38, "v"]], [], [[60, 64, "a"]], [[81, 81, "v"], [88, 88, "v"], [91, 91, "v"]]], "predicted_relations": [[[16, 17, 7, 13, "USED-FOR"], [20, 20, 16, 17, "USED-FOR"], [20, 20, 23, 24, "USED-FOR"], [20, 20, 30, 30, "USED-FOR"], [23, 24, 7, 13, "USED-FOR"], [27, 27, 16, 17, "USED-FOR"], [27, 27, 23, 24, "USED-FOR"], [27, 27, 30, 30, "USED-FOR"], [30, 30, 7, 13, "USED-FOR"]], [], [], []]}
{"doc_key": "1301.2840-ade41ecb-3144-4203-87df-69976bedbefd", "sentences": [["Different", "to", "-LSB-", "1", "-RSB-", ",", "our", "models", "are", "trained", "in", "an", "unsupervised", "fashion", "on", "the", "available", "patches", "."], ["We", "train", "on", "one", "scene", "-LRB-", "400,000", "randomly", "selected", "patches", "from", "this", "scene", "-RRB-", "and", "evaluate", "the", "performance", "on", "the", "test", "set", "of", "every", "scene", "."], ["This", "allows", "us", "to", "investigate", "the", "self-taught", "learning", "paradigm", "-LSB-", "31", "-RSB-", "."], ["We", "also", "train", "on", "all", "three", "scenes", "jointly", "-LRB-", "represented", "by", "1.2", "million", "image", "patches", "-RRB-", "and", "then", "evaluate", "again", "every", "scene", "individually", "."]], "ner": [[], [[20, 23, "a"], [23, 23, "p"], [31, 31, "p"], [43, 43, "p"]], [[51, 53, "a"]], [[79, 79, "p"], [69, 72, "v"], [60, 65, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[22, 22, "v"], [25, 25, "v"]], [], [[63, 63, "v"], [69, 69, "v"]]], "predicted_relations": [[], [[23, 23, 20, 23, "USED-FOR"], [31, 31, 20, 23, "USED-FOR"]], [], [[79, 79, 60, 65, "USED-FOR"]]]}
{"doc_key": "1311.7251-9518e949-f6d6-40c8-bb0f-3189fa27239d", "sentences": [["For", "each", "location", "\\", "-LRB-", "q\\", "-RRB-", "in", "the", "image", "matrix", ",", "extract", "its", "disk-shaped", "neighborhood", "from", "each", "of", "the", "\\", "-LRB-", "K\\", "-RRB-", "images", "\\", "-LRB-", "\\tilde", "-LCB-", "f", "-RCB-", "_i\\", "-RRB-", ",", "\\", "-LRB-", "i=1", ",", "...", ",", "K\\", "-RRB-", "."], ["The", "radius", "of", "the", "disk", "is", "set", "to", "3", "pixels", "-LRB-", "containing", "29", "pixels", "-RRB-", "."], ["Compose", "a", "set", "of", "inputs", "for", "the", "ANN", "by", "stacking", "the", "pixel", "intensities", "from", "the", "\\", "-LRB-", "K\\", "-RRB-", "neighborhoods", "into", "one", "vector", "."], ["Normalize", "this", "vector", "in", "the", "training", "stage", "-LRB-", "discussed", "below", "-RRB-", "."], ["Apply", "the", "ANN", "to", "produce", "a", "set", "of", "output", "values", ",", "which", "are", "the", "intensity", "values", "in", "the", "disk-shaped", "neighborhood", "of", "\\", "-LRB-", "q\\", "-RRB-", "in", "the", "image", "\\", "-LRB-", "\\hat", "-LCB-", "f", "-RCB-", "\\", "-RRB-", "."], ["This", "disk", "has", "the", "same", "radius", "of", "3", "pixels", "."], ["By", "this", "design", ",", "each", "pixel", "in", "the", "output", "image", "is", "covered", "by", "29", "disk-shaped", "patches", ";", "its", "final", "value", "is", "computed", "by", "averaging", "all", "those", "contributions", "."]], "ner": [[], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[22, 22, "p"]], [[51, 51, "v"], [55, 55, "v"]], [[66, 66, "a"], [76, 76, "p"], [80, 80, "v"]], [], [[97, 97, "a"]], [[139, 139, "v"]], [[155, 155, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1311.7251-7dd6b1cf-0d09-41b1-949e-1f2752fe8b98", "sentences": [["We", "detail", "now", "on", "the", "several", "of", "the", "steps", "in", "the", "list", "above", "."], ["In", "the", "training", "stage", ",", "the", "neural", "network", "is", "tuned", "to", "minimize", "the", "discrepancy", "between", "true", "values", "in", "each", "output", "vector", "and", "those", "produced", "by", "the", "network", "from", "the", "set", "of", "noisy", "inputs", "."], ["A", "vector", "of", "inputs", "is", "built", ",", "as", "described", "above", ",", "for", "a", "location", "\\", "-LRB-", "q\\", "-RRB-", "in", "a", "reference", "image", "\\", "-LRB-", "f\\", "-RRB-", "from", "a", "training", "set", ",", "using", "data", "from", "noisy", "reconstructions", "."], ["The", "corresponding", "vector", "of", "outputs", "is", "the", "disk-shaped", "neighborhood", "of", "\\", "-LRB-", "q\\", "-RRB-", "in", "the", "reference", "image", "."], ["Thus", ",", "for", "each", "image", "\\", "-LRB-", "f\\", "-RRB-", "we", "produce", "the", "set", "\\", "-LRB-", "\\tilde", "-LCB-", "f", "-RCB-", "_1", ",", "...", ",", "\\tilde", "-LCB-", "f", "-RCB-", "_K\\", "-RRB-", "using", "pre-defined", "FBP", "filters", "and", "sample", "them", "to", "build", "the", "training", "dataset", "."], ["The", "image", "is", "sampled", "on", "a", "cartesian", "grid", ",", "choosing", "every", "third", "pixel", "\\", "-LRB-", "q\\", "-RRB-", "both", "in", "horizontal", "and", "vertical", "directions", "."], ["The", "pair", "of", "input", "and", "output", "vectors", "for", "the", "neural", "networks", "is", "an", "example", "used", "in", "the", "training", "process", "."], ["Examples", "from", "all", "the", "training", "images", "\\", "-LRB-", "f\\", "-RRB-", "are", "put", "in", "one", "pool", "."], ["A", "portion", "of", "this", "pool", ",", "having", "a", "very", "low", "variance", "in", "the", "inputs", "vector", ",", "is", "discarded", "-LRB-", "specifically", ",", "the", "threshold", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "times", "the", "maximal", "variance", "-RRB-", "."], ["Those", "examples", "correspond", "to", "regions", "of", "air", ",", "since", "no", "constant", "patch", "in", "any", "kind", "of", "tissue", "can", "be", "observed", "in", "the", "noisy", "FBP", "images", "."], ["This", "step", "leads", "to", "an", "empirical", "improvement", "in", "the", "performance", "of", "the", "ANN", "."]], "ner": [[], [], [], [], [[135, 136, "a"]], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [], [], [], [[203, 203, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "cs/0001020-4eb461a8-9643-4e96-908e-947763054765", "sentences": [["\\", "-LRB-", "\\underline", "-LCB-", "z", "-RCB-", "=h_0.tag", ",", "h_0.word", ",", "h_", "-LCB-", "-1", "-RCB-", ".tag", ",", "h_", "-LCB-", "-1", "-RCB-", ".word\\", "-RRB-", "for", "order", "4", ";", "\\", "-LRB-", "\\underline", "-LCB-", "z", "-RCB-", "=h_0.tag", ",", "h_0.word", ",", "h_", "-LCB-", "-1", "-RCB-", ".tag\\", "-RRB-", "for", "order", "3", ";", "\\", "-LRB-", "\\underline", "-LCB-", "z", "-RCB-", "=h_0.tag", ",", "h_0.word\\", "-RRB-", "for", "order", "2", ";", "\\", "-LRB-", "\\underline", "-LCB-", "z", "-RCB-", "=h_0.tag\\", "-RRB-", "for", "order", "1", ";"]], "ner": [[]], "relations": [[]], "predicted_ner": [[[24, 24, "v"], [44, 44, "v"], [58, 58, "v"]]], "predicted_relations": [[]]}
{"doc_key": "cs/0001020-467c422e-c11c-4b9b-84f2-74d220c26dd6", "sentences": [["The", "higher", "order", "events", "\u2014", "closer", "to", "the", "root", "of", "the", "linear", "interpolation", "scheme", "in", "Figure", "REF", "\u2014", "become", "more", "and", "more", "diverse", "during", "the", "first", "estimation", "stage", ",", "as", "opposed", "to", "the", "lower", "order", "events", "."], ["This", "shows", "that", "the", "\u201c", "N-best", "\u201d", "parses", "for", "a", "given", "sentence", "change", "from", "one", "iteration", "to", "the", "next", "."], ["Although", "the", "E0", "counts", "were", "collected", "from", "\u201c", "1-best", "\u201d", "parses", "\u2014", "binarized", "treebank", "parses", "\u2014", "the", "increase", "in", "number", "of", "maximal", "order", "types", "from", "E0", "to", "E1", "\u2014", "collected", "from", "\u201c", "N-best", "\u201d", ",", "N", "=", "10", "\u2014", "is", "far", "from", "dramatic", ",", "yet", "higher", "than", "that", "from", "E1", "to", "E2", "\u2014", "both", "collected", "from", "\u201c", "N-best", "\u201d", "parses", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [[51, 51, "v"]], [[94, 94, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1911.10470-f4354352-9548-4e8c-8d79-65af3d089386", "sentences": [["To", "use", "the", "pre-trained", "BERT", "models", ",", "we", "used", "the", "public", "code", "base", ",", "pytorch-transformers", ",", "https", ":", "//github.com/huggingface/pytorch-transformers", "."], ["written", "in", "PyTorch.https", ":", "//pytorch.org/", "."], ["For", "optimization", ",", "we", "used", "the", "code", "base", "'s", "implementation", "of", "the", "Adam", "optimizer", "-LSB-", "11", "-RSB-", ",", "with", "a", "weight-decay", "coefficient", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "for", "non-bias", "parameters", "."], ["A", "warm-up", "strategy", "in", "the", "code", "base", "was", "also", "used", ",", "with", "a", "warm-up", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["Most", "of", "the", "settings", "follow", "the", "default", "settings", "."], ["To", "train", "our", "recurrent", "retriever", ",", "we", "set", "the", "learning", "rate", "to", "\\", "-LRB-", "3\\cdot", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "the", "maximum", "number", "of", "the", "training", "epochs", "to", "three", "."], ["The", "mini-batch", "size", "is", "four", ";", "a", "mini-batch", "example", "consists", "of", "a", "question", "with", "its", "corresponding", "paragraphs", "."], ["To", "train", "our", "reader", "model", ",", "we", "set", "the", "learning", "rate", "to", "\\", "-LRB-", "3\\cdot", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "the", "maximum", "number", "of", "training", "epochs", "to", "two", "."], ["Empirically", "we", "observe", "better", "performance", "with", "a", "larger", "batch", "size", "as", "discussed", "in", "previous", "work", "-LSB-", "17", "-RSB-", ",", "-LSB-", "25", "-RSB-", ",", "and", "thus", "we", "set", "the", "mini-batch", "size", "to", "120", "."], ["A", "mini-batch", "example", "consists", "of", "a", "question", "with", "its", "evidence", "paragraphs", "."], ["We", "will", "release", "our", "code", "to", "follow", "our", "experiments", "."]], "ner": [[[4, 5, "a"]], [], [[38, 39, "a"], [46, 47, "p"], [51, 51, "v"]], [[70, 71, "p"], [75, 75, "v"]], [], [[96, 97, "a"], [90, 91, "p"], [90, 91, "p"]], [[121, 122, "a"]], [[147, 148, "a"], [141, 142, "p"], [141, 142, "p"]], [[198, 199, "a"], [201, 201, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [14, 14, "a"]], [], [[38, 38, "a"], [46, 47, "p"], [51, 51, "v"]], [[70, 71, "p"], [75, 75, "v"]], [], [[90, 91, "a"], [96, 97, "p"], [115, 116, "p"], [118, 118, "v"]], [[121, 122, "p"], [124, 124, "v"]], [[147, 148, "p"], [152, 156, "v"], [165, 166, "p"], [168, 168, "v"]], [[178, 179, "p"], [198, 199, "p"], [201, 201, "v"]], [], []], "predicted_relations": [[], [], [[46, 47, 38, 39, "USED-FOR"], [51, 51, 46, 47, "USED-FOR"]], [[75, 75, 70, 71, "USED-FOR"]], [], [[90, 91, 96, 97, "USED-FOR"], [90, 91, 96, 97, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1909.08103-f735a951-04ef-40ca-9c7d-ea549c081c21", "sentences": [["The", "rest", "of", "the", "571", "hrs", "of", "3,207", "lecture", "recordings", "-LRB-", "excluding", "the", "same", "speaker", "'s", "lectures", "in", "the", "evaluation", "sets", "-RRB-", "were", "used", "for", "AM", "and", "language", "model", "-LRB-", "LM", "-RRB-", "training", "."], ["We", "generated", "two-speaker", "mixed", "speech", "for", "training", "data", "in", "accordance", "with", "the", "following", "protocol", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[4, 4, "v"], [7, 7, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "1909.08103-80243f9c-89f6-4997-8210-0ad2e5e60367", "sentences": [["Prepare", "a", "list", "of", "speech", "samples", "-LRB-", "=", "main", "list", "-RRB-", "."], ["Shuffle", "the", "main", "list", "to", "create", "a", "second", "list", "under", "the", "constraint", "that", "the", "same", "speaker", "does", "not", "appear", "in", "the", "same", "line", "in", "the", "main", "and", "second", "lists", "."], ["Mix", "the", "audio", "in", "the", "main", "and", "second", "lists", "one-by-one", "with", "a", "specific", "signal-to-interference", "ratio", "-LRB-", "SIR", "-RRB-", "."], ["For", "training", "data", ",", "we", "randomly", "sampled", "an", "SIR", "as", "follows", "."], ["In", "1/3", "probability", ",", "sample", "the", "SIR", "from", "a", "uniform", "distribution", "between", "-10", "and", "10", "dB", "."], ["In", "1/3", "probability", ",", "sample", "the", "SIR", "from", "a", "uniform", "distribution", "between", "10", "and", "60", "dB", "."], ["The", "transcription", "of", "the", "interference", "speaker", "was", "set", "to", "null", "."], ["In", "1/3", "probability", ",", "sample", "the", "SIR", "from", "a", "uniform", "distribution", "between", "-60", "and", "-10", "dB", "."], ["The", "transcription", "of", "the", "target", "speaker", "was", "set", "to", "null", "."], ["The", "volume", "of", "each", "mixed", "speech", "was", "randomly", "changed", "to", "enhance", "robustness", "against", "volume", "difference", "."]], "ner": [[], [], [], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [[74, 74, "v"], [85, 85, "v"], [87, 88, "v"]], [[91, 91, "v"], [102, 102, "v"], [104, 105, "v"]], [], [[119, 119, "v"], [130, 130, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1909.08103-4f6637ea-3ea2-4586-88bb-c42b80af5750", "sentences": [["We", "trained", "a", "TS-AM", "consisting", "of", "a", "convolutional", "neural", "network", "-LRB-", "CNN", "-RRB-", ",", "time-delay", "NN", "-LRB-", "TDNN", "-RRB-", ",", "and", "long", "short-term", "memory", "-LRB-", "LSTM", "-RRB-", ",", "as", "shown", "in", "fig", ":", "ts-am", "."], ["The", "input", "acoustic", "feature", "for", "the", "network", "was", "a", "40-dimensional", "FBANK", "without", "normalization", "."], ["A", "100-dimensional", "i-vector", "was", "also", "extracted", "and", "used", "for", "the", "target-speaker", "embedding", "to", "indicate", "the", "target", "speaker", "."], ["For", "extracting", "this", "i-vector", ",", "we", "randomly", "selected", "an", "utterance", "of", "the", "same", "speaker", "."], ["We", "conducted", "8", "epochs", "of", "training", "on", "the", "basis", "of", "LF-MMI", ",", "where", "the", "initial", "learning", "rate", "was", "set", "to", "0.001", "and", "exponentially", "decayed", "to", "0.0001", "by", "the", "end", "of", "the", "training", "."], ["We", "applied", "\\", "-LRB-", "l2\\", "-RRB-", "-regularization", "and", "CE-regularization", "with", "scales", "of", "0.00005", "and", "0.1", ",", "respectively", "."], ["The", "leaky", "hidden", "Markov", "model", "coefficient", "was", "set", "to", "0.1", "."], ["A", "backstitch", "technique", "with", "a", "backstitch", "scale", "of", "1.0", "and", "backstitch", "interval", "of", "4", "was", "also", "used", "."]], "ner": [[], [], [], [], [[92, 92, "a"], [96, 98, "p"], [102, 102, "v"], [107, 107, "v"]], [[129, 129, "v"], [127, 127, "v"], [123, 123, "a"], [129, 129, "v"]], [[134, 138, "p"], [142, 142, "v"], [142, 142, "v"]], [[150, 150, "p"], [150, 150, "p"], [145, 146, "a"], [149, 150, "p"], [152, 152, "v"], [154, 155, "p"], [157, 157, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [7, 12, "a"], [14, 15, "a"], [21, 26, "a"], [33, 33, "a"]], [[44, 44, "v"], [45, 45, "a"]], [[50, 50, "v"]], [], [[84, 84, "v"], [85, 85, "p"], [92, 92, "a"], [97, 98, "p"], [102, 102, "v"], [107, 107, "v"]], [[119, 119, "a"], [123, 123, "a"], [127, 127, "v"], [129, 129, "v"]], [[134, 137, "a"], [142, 142, "v"]], [[145, 146, "a"], [149, 150, "p"], [152, 152, "v"], [154, 155, "p"], [157, 157, "v"]]], "predicted_relations": [[], [], [], [], [[96, 98, 92, 92, "USED-FOR"]], [], [], [[150, 150, 145, 146, "USED-FOR"], [150, 150, 145, 146, "USED-FOR"], [149, 150, 145, 146, "USED-FOR"], [152, 152, 149, 150, "USED-FOR"], [152, 152, 154, 155, "USED-FOR"], [154, 155, 145, 146, "USED-FOR"], [157, 157, 150, 150, "USED-FOR"], [157, 157, 150, 150, "USED-FOR"], [157, 157, 149, 150, "USED-FOR"], [157, 157, 154, 155, "USED-FOR"]]]}
{"doc_key": "1909.08103-dff733f3-25be-4c56-9983-db2d422e3549", "sentences": [["For", "comparison", ",", "we", "trained", "another", "TS-AM", "without", "the", "auxiliary", "loss", "."], ["We", "also", "trained", "a", "\u201c", "clean", "AM", "\u201d", "using", "clean", ",", "non-speaker-mixed", "speech", "."], ["For", "this", "clean", "model", ",", "we", "used", "a", "model", "architecture", "without", "the", "auxiliary", "output", "branch", ",", "and", "an", "i-vector", "was", "extracted", "every", "100", "msec", "for", "online", "speaker/environment", "adaptation", "."]], "ner": [[[6, 6, "a"]], [[17, 18, "a"]], [[38, 40, "p"], [44, 44, "p"], [48, 49, "v"], [50, 53, "c"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"]], [], [[48, 48, "v"]]], "predicted_relations": [[], [], [[48, 49, 44, 44, "USED-FOR"], [50, 53, 48, 49, "USED-FOR"]]]}
{"doc_key": "1910.14388-20675fec-0c63-4bc9-b76a-19eff83543f8", "sentences": [["For", "all", "the", "baselines", "and", "Generative", "Graph", "Transformer", "variations", ",", "we", "run", "the", "same", "hyper-parameter", "search", "on", ":", "learning", "rate", ",", "batch", "size", ",", "weight", "decay", ",", "and", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "coefficient", "."], ["In", "all", "the", "experiments", "we", "use", "the", "Adam", "optimizer", "-LSB-", "31", "-RSB-", "with", "parameters", "\\", "-LRB-", "\\eta", "\\in", "-LSB-", "3", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", ";", "5", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", "-RSB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "."], ["For", "all", "the", "models", ",", "the", "batch", "size", "is", "set", "to", "64", ",", "except", "for", "the", "RNN", "where", "we", "find", "16", "to", "be", "better", "."], ["Weight", "decay", "parameters", "in", "the", "range", "\\", "-LRB-", "-LSB-", "10^", "-LCB-", "-5", "-RCB-", ",", "5\\cdot", "10^", "-LCB-", "-5", "-RCB-", "-RSB-", "\\", "-RRB-", "are", "found", "to", "be", "optimal", "for", "regularization", "."], ["For", "the", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "hyper-parameter", ",", "we", "notice", "best", "performance", "in", "the", "range", "\\", "-LRB-", "-LSB-", "0.30", ",", "0.70", "-RSB-", "\\", "-RRB-", ",", "and", "we", "set", "\\", "-LRB-", "\\lambda", "=0.5\\", "-RRB-", "in", "our", "experiments", "."], ["We", "also", "try", "different", "sizes", "for", "the", "output", "of", "the", "node-wise", "GRU", "in", "GraphRNN", ",", "and", "for", "the", "number", "of", "decoder", "blocks", "and", "heads", "in", "the", "GGT", "."]], "ner": [[[18, 19, "p"], [21, 22, "p"], [24, 25, "p"], [30, 30, "p"]], [[42, 43, "a"], [76, 76, "v"], [84, 84, "v"], [89, 89, "p"]], [[104, 105, "p"], [109, 109, "v"], [118, 118, "v"], [114, 114, "c"]], [], [[157, 157, "p"], [184, 184, "p"], [172, 172, "v"], [174, 174, "v"]], [[204, 204, "a"], [217, 217, "a"], [209, 212, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[18, 19, "p"], [21, 22, "p"], [24, 25, "p"], [30, 30, "p"]], [[42, 42, "a"], [76, 76, "v"], [84, 84, "v"], [91, 94, "v"]], [[104, 105, "p"], [109, 109, "v"], [114, 114, "a"], [118, 118, "v"]], [], [[157, 157, "p"], [172, 172, "v"], [174, 175, "v"], [184, 184, "p"], [185, 185, "v"]], [[202, 202, "a"], [204, 204, "a"]]], "predicted_relations": [[], [[84, 84, 89, 89, "USED-FOR"]], [], [], [[172, 172, 184, 184, "USED-FOR"], [174, 174, 184, 184, "USED-FOR"]], [[209, 212, 204, 204, "USED-FOR"]]]}
{"doc_key": "1911.09994-d587a66f-9e29-4af5-befa-b936ca27d63f", "sentences": [["After", "each", "hidden", "layer", ",", "a", "dropout", "layer", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "probability", "for", "regularization", "is", "added", "."], ["Regularization", "helps", "in", "over-fitting", "of", "the", "model", "."], ["Then", "each", "epoch", "of", "the", "training", "phase", "is", "optimized", "using", "the", "Adam", "optimizer", "-LSB-", "13", "-RSB-", "."], ["Adam", "is", "a", "momentum", "based", "gradient", "descent", "optimization", "technique", "."], ["We", "are", "using", "a", "mini-batch", "of", "size", "128", "pairs", "in", "each", "training", "epoch", "."], ["The", "first", "hidden", "layer", "has", "512", "units", "and", "the", "second", "hidden", "layer", "has", "128", "units", "."], ["We", "use", "Rectified", "Linear", "Unit", "\\", "-LRB-", "-LRB-", "relu", "-RRB-", "\\", "-RRB-", "activation", "functions", "in", "both", "the", "hidden", "layers", "and", "Sigmoid", "for", "the", "last", "layer", "."]], "ner": [[[6, 7, "a"], [13, 13, "p"], [11, 11, "v"]], [], [[38, 39, "a"]], [], [], [], [[104, 104, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "v"]], [], [[38, 38, "a"]], [[44, 44, "a"]], [[58, 58, "a"], [61, 61, "v"]], [[73, 73, "v"], [81, 81, "v"]], [[86, 88, "a"], [104, 104, "a"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1906.00891-75f890be-3282-47db-9a33-12d57daf7f7e", "sentences": [["The", "network", "architecture", "used", "in", "our", "experiment", "is", "composed", "of", "four", "convolutional", "layers", ",", "four", "pooling", "layers", "and", "three", "fully", "connected", "layers", ",", "as", "shown", "in", "Fig", "."], ["REF", "."], ["The", "network", "was", "trained", "by", "the", "stochastic", "gradient", "descent", "algorithm", "-LSB-", "31", "-RSB-", "."], ["\\", "-LRB-", "L_2\\", "-RRB-", "regularization", "with", "a", "weight", "decay", "0.0001", "was", "adopted", "to", "prevent", "overfitting", "."], ["The", "learning", "rate", "was", "set", "as", "0.001", "and", "the", "training", "was", "stopped", "after", "40", "epochs", "."], ["The", "implementation", "of", "CNN-DC", "was", "based", "on", "Tensorflow", "-LSB-", "32", "-RSB-", "."], ["The", "training", "was", "conducted", "on", "a", "Intel", "Xeon", "E5-2690", "CPU", "with", "a", "TITAN", "Xp", "GPU", "."]], "ner": [[], [], [], [[53, 53, "v"]], [[66, 66, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[10, 10, "v"], [14, 14, "v"], [18, 18, "v"]], [], [[36, 39, "a"]], [[46, 46, "a"], [51, 52, "p"], [53, 53, "v"]], [[61, 62, "p"], [66, 66, "v"], [73, 73, "v"], [74, 74, "p"]], [[79, 79, "a"], [83, 83, "a"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1905.00921-338bd0ac-0072-4357-a832-2fb6b02b3c33", "sentences": [["We", "implement", "the", "model", "in", "PyTorch", "-LSB-", "13", "-RSB-", "."], ["All", "of", "the", "experiments", "are", "conducted", "on", "an", "Amazon", "AWS", "p3.16xlargehttps", ":", "//aws.amazon.com/ec2/instance-types/p3/", "cluster", "with", "8", "Tesla", "V100", "GPUs", "."], ["For", "initial", "training", ",", "we", "train", "the", "model", "for", "20", "epochs", "with", "learning", "rate", "0.001", ",", "batch", "size", "512", "."], ["For", "the", "continuous", "domain", "adaptation", ",", "we", "add", "the", "new", "domains", "in", "a", "random", "order", "."], ["Each", "domain", "data", "will", "be", "trained", "independently", "one-by-one", "for", "10", "epochs", ",", "with", "learning", "rate", "0.01", "and", "batch", "size", "128", "."], ["For", "both", "training", "procedures", ",", "we", "use", "Adam", "as", "the", "optimizer", "."], ["The", "development", "data", "is", "used", "to", "pick", "the", "best", "model", "in", "different", "epoch", "runs", "."], ["We", "evaluate", "the", "classification", "accuracy", "on", "the", "test", "set", "."]], "ner": [[[5, 5, "a"]], [], [[42, 43, "a"], [44, 44, "p"], [44, 44, "v"], [31, 32, "c"], [46, 47, "a"], [48, 48, "p"], [48, 48, "v"], [31, 32, "c"]], [[52, 54, "c"], [52, 54, "c"]], [[79, 80, "a"], [81, 81, "p"], [81, 81, "v"], [83, 84, "a"], [85, 85, "p"], [85, 85, "v"]], [[94, 94, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"]], [[25, 25, "v"]], [[39, 39, "v"], [40, 40, "p"], [42, 43, "p"], [44, 44, "v"], [46, 47, "p"], [48, 48, "v"]], [], [[73, 73, "v"], [75, 75, "v"], [76, 76, "p"], [79, 80, "p"], [81, 81, "v"], [83, 84, "p"], [85, 85, "v"]], [[94, 94, "a"]], [], []], "predicted_relations": [[], [], [[44, 44, 42, 43, "USED-FOR"], [44, 44, 44, 44, "USED-FOR"], [31, 32, 44, 44, "USED-FOR"], [31, 32, 48, 48, "USED-FOR"], [48, 48, 42, 43, "USED-FOR"], [48, 48, 46, 47, "USED-FOR"], [48, 48, 48, 48, "USED-FOR"], [31, 32, 44, 44, "USED-FOR"], [31, 32, 48, 48, "USED-FOR"]], [], [[81, 81, 79, 80, "USED-FOR"], [81, 81, 81, 81, "USED-FOR"], [85, 85, 79, 80, "USED-FOR"], [85, 85, 83, 84, "USED-FOR"]], [], [], []]}
{"doc_key": "1908.04577-1c0cab00-0fb8-488d-b407-427ffb4d5b29", "sentences": [["We", "used", "documents", "from", "English", "Wikipedia", "-LRB-", "2,500M", "words", "-RRB-", "and", "BookCorpus", "-LSB-", "34", "-RSB-", "as", "pre-training", "data", ",", "following", "the", "preprocessing", "and", "the", "WordPiece", "tokenization", "from", "-LSB-", "5", "-RSB-", "."], ["The", "maximum", "length", "of", "input", "sequence", "was", "set", "to", "512", "."]], "ner": [[[4, 5, "a"], [11, 11, "a"], [24, 25, "a"]], [[32, 36, "p"], [40, 40, "v"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "v"], [11, 11, "a"]], [[40, 40, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1908.04577-8503f9d6-a71d-4d0c-83fd-8104e9069b42", "sentences": [["We", "ran", "Adam", "with", "learning", "rate", "of", "1e-4", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", ",", "L2", "weight", "decay", "of", "0.01", ",", "learning", "rate", "warm-up", "over", "the", "first", "10", "%", "of", "the", "total", "steps", ",", "and", "linear", "decay", "of", "the", "learning", "rate", "."], ["We", "set", "a", "dropout", "probability", "of", "0.1", "for", "every", "layer", "."], ["The", "gelu", "activation", "-LSB-", "9", "-RSB-", "was", "used", "as", "done", "in", "GPT", "-LSB-", "19", "-RSB-", "."]], "ner": [[[2, 2, "a"], [4, 5, "p"], [27, 28, "p"], [45, 46, "p"], [7, 7, "v"], [12, 12, "v"], [18, 18, "v"], [21, 23, "p"], [25, 25, "v"], [27, 29, "p"], [30, 38, "v"], [41, 46, "p"]], [[51, 51, "a"], [52, 52, "p"], [54, 54, "v"]], [[60, 61, "a"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [4, 5, "p"], [7, 7, "v"], [21, 21, "p"], [22, 23, "p"], [25, 25, "v"], [27, 28, "p"], [33, 34, "v"], [41, 42, "a"], [45, 46, "p"]], [[51, 52, "p"], [54, 54, "v"]], [[60, 61, "a"], [70, 70, "a"]]], "predicted_relations": [[[4, 5, 2, 2, "USED-FOR"], [27, 28, 2, 2, "USED-FOR"], [7, 7, 4, 5, "USED-FOR"], [18, 18, 21, 23, "USED-FOR"], [21, 23, 2, 2, "USED-FOR"], [25, 25, 27, 28, "USED-FOR"], [25, 25, 21, 23, "USED-FOR"], [25, 25, 27, 29, "USED-FOR"], [27, 29, 2, 2, "USED-FOR"], [30, 38, 27, 28, "USED-FOR"], [30, 38, 45, 46, "USED-FOR"], [30, 38, 21, 23, "USED-FOR"], [30, 38, 27, 29, "USED-FOR"]], [], []]}
{"doc_key": "1908.04577-18a9ac7e-7173-499a-83eb-1e281ec60d06", "sentences": [["StructBERTBase", ":", "\\", "-LRB-", "L=12\\", "-RRB-", ",", "\\", "-LRB-", "H=768\\", "-RRB-", ",", "\\", "-LRB-", "A=12\\", "-RRB-", ",", "Number", "of", "parameters\\", "-LRB-", "=110\\", "-RRB-", "M"]], "ner": [[[0, 0, "a"], [4, 4, "p"], [4, 4, "v"], [14, 14, "v"], [9, 9, "p"], [9, 9, "v"], [14, 14, "p"], [4, 4, "v"], [14, 14, "v"], [17, 19, "p"]]], "relations": [[]], "predicted_ner": [[[0, 0, "a"]]], "predicted_relations": [[[4, 4, 0, 0, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [14, 14, 4, 4, "USED-FOR"], [14, 14, 9, 9, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"], [9, 9, 0, 0, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [9, 9, 4, 4, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [14, 14, 0, 0, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [14, 14, 4, 4, "USED-FOR"], [14, 14, 9, 9, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"]]]}
{"doc_key": "1908.04577-0ee286a1-bb43-412a-b6dc-aa7dd3f8076c", "sentences": [["StructBERTLarge", ":", "\\", "-LRB-", "L=24\\", "-RRB-", ",", "\\", "-LRB-", "H=1024\\", "-RRB-", ",", "\\", "-LRB-", "A=16\\", "-RRB-", ",", "Number", "of", "parameters\\", "-LRB-", "=340\\", "-RRB-", "M"]], "ner": [[[0, 0, "a"], [4, 4, "p"], [4, 4, "v"], [9, 9, "p"], [9, 9, "v"], [14, 14, "p"], [14, 14, "v"], [17, 19, "p"]]], "relations": [[]], "predicted_ner": [[[0, 0, "a"], [21, 21, "v"]]], "predicted_relations": [[[4, 4, 0, 0, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"], [9, 9, 0, 0, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [9, 9, 4, 4, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [14, 14, 0, 0, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"], [14, 14, 4, 4, "USED-FOR"], [14, 14, 9, 9, "USED-FOR"], [14, 14, 14, 14, "USED-FOR"]]]}
{"doc_key": "1908.05408-65136269-4235-49fd-b126-0d3a0b6ba953", "sentences": [["All", "the", "baselines", "are", "implemented", "by", "PyTorch", "."], ["One-hot", "input", "tokens", "are", "embedded", "into", "a", "64-dimensional", "space", "."], ["The", "goals", "are", "encoded", "by", "\\", "-LRB-", "GRU^", "-LCB-", "-LRB-", "g", "-RRB-", "-RCB-", "\\", "-RRB-", "with", "a", "hidden", "layer", "of", "size", "64", "."], ["The", "sizes", "of", "hidden", "states", "in", "input", "utterance", "encoder", "\\", "-LRB-", "GRU^", "-LCB-", "-LRB-", "u", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "GRU^", "-LCB-", "-LRB-", "c", "-RRB-", "-RCB-", "\\", "-RRB-", "and", "looking-ahead", "module", "\\", "-LRB-", "GRU^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "h_k^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "are", "all", "set", "to", "256", "."], ["A", "stochastic", "gradient", "descent", "method", "is", "employed", "to", "optimize", "the", "model", "with", "a", "mini-batch", "size", "of", "32", "for", "supervised", "learning", ",", "an", "initial", "learning", "rate", "of", "1.0", ",", "momentum", "with", "\\", "-LRB-", "\\mu", "=0.1\\", "-RRB-", ",", "and", "clipping", "gradients", "0.5", "in", "\\", "-LRB-", "L^2\\", "-RRB-", "norm", "."], ["The", "best", "model", "is", "chosen", "from", "the", "processing", "of", "training", "the", "model", "for", "400", "epochs", "."], ["After", "that", ",", "the", "learning", "rate", "decays", "by", "a", "factor", "of", "2", "for", "every", "epoch", "."], ["The", "initial", "hyper-parameters", "setting", "in", "the", "loss", "function", "-LRB-", "Equation", "-LRB-", "11", "-RRB-", "-RRB-", "is", "\\", "-LRB-", "\\alpha", "=0.05\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "=1.0\\", "-RRB-", "."], ["Words", "that", "appear", "in", "the", "training", "dataset", "for", "less", "than", "5", "times", "are", "replaced", "with", "the", "`", "unknown", "'", "-LRB-", "\\", "-LRB-", "\\left", "<", "unk\\right", ">", "\\", "-RRB-", "-RRB-", "token", "."], ["A", "validation", "dataset", "is", "employed", "to", "choose", "the", "optimal", "hyper-parameters", "."]], "ner": [[[6, 6, "a"]], [[8, 10, "a"]], [[25, 25, "a"]], [[52, 52, "a"], [63, 63, "a"], [76, 76, "a"]], [[130, 130, "p"], [139, 140, "p"]], [], [], [[204, 204, "p"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[15, 15, "v"]], [[35, 36, "p"], [39, 39, "v"]], [[100, 100, "v"]], [[103, 106, "a"], [115, 116, "p"], [118, 118, "v"], [119, 121, "c"], [125, 126, "p"], [128, 128, "v"], [141, 141, "v"]], [[162, 162, "v"], [163, 163, "p"]], [[169, 170, "p"], [176, 176, "v"]], [[198, 198, "p"], [199, 199, "v"]], [[218, 218, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1901.05049-276190ee-351a-43f2-9eec-5bbe0c376384", "sentences": [["All", "training", "tools", "generate", "both", "the", "training", "model", "and", "the", "solver", "definition", "files", "automatically", "."], ["We", "have", "trained", "the", "CNN", "and", "DS_CNN", "models", "using", "Bonseyes-Caffe", ",", "-LSB-", "4", "-RSB-", "."], ["These", "tools", "import", "the", "output", "generated", "in", "the", "MFCC", "generation", "step", "using", "the", "training", "dataset", "where", "the", "extracted", "MFCC", "features", "and", "labels", "are", "packed", "all", "together", "into", "an", "HDF5", "file", "."], ["Training", "is", "carried", "out", "with", "a", "multinomial", "logistic", "loss", "and", "Adam", "optimizer", "-LSB-", "65", "-RSB-", "over", "a", "batch", "of", "100", "MFCC", "samples", "-LRB-", "since", "our", "input", "sample", "size", "is", "\\", "-LRB-", "40\\times", "32\\", "-RRB-", ",", "we", "opt", "to", "use", "a", "relatively", "big", "batch", "size", "-RRB-", "."], ["The", "batch", "size", "and", "number", "of", "iterations", "are", "specified", "in", "the", "workflow", "files", "that", "control", "the", "execution", "of", "the", "tools", "."], ["Each", "model", "is", "trained", "for", "40K", "iterations", "following", "a", "multi-step", "training", "strategy", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["With", "every", "step", "of", "10K", "iterations", ",", "learning", "rate", "drops", "to", "30", "%", "of", "the", "previous", "step", "."]], "ner": [[], [[24, 24, "a"]], [], [[67, 69, "a"], [71, 72, "a"], [103, 104, "a"]], [[108, 109, "a"], [111, 113, "a"]], [], [[142, 144, "p"], [142, 144, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[19, 19, "a"], [21, 21, "a"], [24, 24, "a"]], [], [[67, 69, "a"], [71, 71, "a"], [80, 80, "v"], [93, 93, "v"]], [], [[133, 133, "v"]], [[143, 144, "p"], [149, 151, "v"]], [[160, 160, "v"], [163, 164, "p"], [167, 168, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[142, 144, 142, 144, "USED-FOR"]], []]}
{"doc_key": "1902.04574-a53b2ac2-6520-44d5-86fd-c41f4e091353", "sentences": [["For", "training", ",", "we", "use", "the", "Adam", "-LSB-", "38", "-RSB-", "optimizer", "with", "decaying", "learning", "rate", ",", "as", "implemented", "in", "TensorFlow", "-LSB-", "39", "-RSB-", "."], ["We", "start", "with", "the", "following", "values", ":", "learning", "rate", "\\", "-LRB-", "\\eta", "=", "-LCB-", "5e-04", "-RCB-", "\\", "-RRB-", ",", "exponential", "decay", "rate", "for", "the", "1st", "and", "the", "2nd", "momentum", "\\", "-LRB-", "\\beta", "_1", "=", "-LSB-", "round-precision=1", "-RSB-", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2", "=", "-LCB-", "0.999", "-RCB-", "\\", "-RRB-", ",", "and", "constant", "for", "prevention", "of", "division", "by", "zero", "\\", "-LRB-", "\\epsilon", "=", "-LCB-", "1e-7", "-RCB-", "\\", "-RRB-", "."], ["Then", ",", "we", "decay", "the", "learning", "after", "each", "epoch", "by", "a", "factor", "of", "0.99", "."], ["We", "also", "apply", "dropout", "with", "a", "probability", "of", "0.1", ",", "and", "L2", "weight", "decay", "on", "all", "trainable", "variables", "with", "\\", "-LRB-", "\\lambda", "=", "-LCB-", "3e-7", "-RCB-", "\\", "-RRB-", "."], ["We", "train", "each", "model", "for", "42K", "steps", "with", "a", "batch", "size", "of", "64", "."], ["We", "found", "these", "values", "by", "running", "a", "grid", "search", "on", "a", "dev", "set", "-LRB-", "extracted", "as", "a", "fraction", "of", "the", "training", "data", "-RRB-", "and", "using", "the", "values", "suggested", "in", "-LSB-", "0", "-RSB-", ",", "where", "applicable", "."]], "ner": [[[6, 6, "a"], [13, 14, "p"], [12, 14, "a"]], [[31, 32, "p"], [38, 38, "v"], [43, 52, "p"], [62, 62, "v"], [73, 73, "v"], [79, 85, "p"], [91, 91, "v"]], [[107, 107, "p"], [109, 109, "v"]], [[114, 114, "a"], [117, 117, "p"], [119, 119, "v"], [122, 124, "a"], [132, 132, "p"], [135, 135, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [13, 14, "p"], [19, 19, "a"]], [[31, 32, "p"], [38, 38, "v"], [43, 45, "p"], [62, 62, "v"], [73, 73, "v"], [85, 85, "v"], [91, 91, "v"]], [[109, 109, "v"]], [[114, 114, "a"], [119, 119, "v"], [122, 124, "a"], [132, 132, "p"], [135, 135, "v"]], [[145, 145, "v"], [149, 150, "p"], [152, 152, "v"]], []], "predicted_relations": [[[13, 14, 6, 6, "USED-FOR"]], [[38, 38, 31, 32, "USED-FOR"], [91, 91, 79, 85, "USED-FOR"]], [[109, 109, 107, 107, "USED-FOR"]], [[119, 119, 117, 117, "USED-FOR"], [119, 119, 132, 132, "USED-FOR"], [132, 132, 114, 114, "USED-FOR"], [132, 132, 122, 124, "USED-FOR"]], [], []]}
{"doc_key": "1902.00293-cf22102b-bd8d-4632-ba3e-67265e6c865e", "sentences": [["ERFNet", "-LSB-", "27", "-RSB-", "is", "used", "as", "the", "network", "architecture", "."], ["The", "last", "layer", "is", "adapted", "to", "output", "two", "feature", "maps", ",", "one", "for", "each", "ego-lane", "line", "."], ["In", "both", "the", "cross-entropy", "and", "end-to-end", "experiments", ",", "we", "train", "for", "350", "epochs", "on", "a", "single", "GPU", "with", "image", "resolution", "of", "256x512", ",", "batch", "size", "of", "8", ",", "and", "Adam", "-LSB-", "18", "-RSB-", "with", "a", "learning", "rate", "of", "1e-4", "."], ["As", "a", "simple", "data", "augmentation", "technique", "the", "images", "are", "randomly", "flipped", "horizontally", "."], ["In", "the", "end-to-end", "experiments", ",", "we", "use", "a", "fixed", "transformation", "matrix", "H", "to", "transform", "the", "weighted", "pixel", "coordinates", "to", "the", "ortho-view", "."], ["Note", "that", "the", "input", "image", "itself", "is", "not", "transformed", "to", "the", "ortho-view", ",", "although", "that", "would", "also", "be", "an", "option", "."], ["The", "system", "is", "implemented", "in", "PyTorch", "-LSB-", "25", "-RSB-", "."]], "ner": [[[0, 0, "a"]], [], [[57, 57, "a"], [63, 64, "p"], [66, 66, "v"]], [], [], [], [[129, 129, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[18, 18, "v"], [22, 22, "v"]], [[31, 31, "a"], [39, 39, "v"], [40, 40, "p"], [49, 49, "v"], [51, 52, "p"], [54, 54, "v"], [57, 57, "a"], [63, 64, "p"], [66, 66, "v"]], [], [], [], [[125, 125, "a"], [129, 129, "a"]]], "predicted_relations": [[], [], [[63, 64, 57, 57, "USED-FOR"], [66, 66, 63, 64, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1905.05979-85cde488-edb8-4756-95d8-b3747d55e5ff", "sentences": [["We", "follow", "the", "setup", "of", "Transformer", "base", "model", "-LSB-", "29", "-RSB-", "."], ["More", "precisely", ",", "the", "number", "of", "layers", "in", "the", "base", "encoder", ",", "base", "decoder", "and", "CADed", "is", "\\", "-LRB-", "N=6\\", "-RRB-", "."], ["We", "employ", "\\", "-LRB-", "h", "=", "8\\", "-RRB-", "parallel", "attention", "layers", ",", "or", "heads", "."], ["The", "dimensionality", "of", "input", "and", "output", "is", "\\", "-LRB-", "d_", "-LCB-", "model", "-RCB-", "=", "512\\", "-RRB-", ",", "and", "the", "inner-layer", "of", "a", "feed-forward", "networks", "has", "dimensionality", "\\", "-LRB-", "d_", "-LCB-", "ff", "-RCB-", "=2048\\", "-RRB-", "."]], "ner": [[[5, 7, "a"]], [[16, 18, "p"], [31, 31, "v"]], [[40, 40, "v"]], [[50, 54, "p"], [63, 63, "v"], [81, 81, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 7, "a"]], [[31, 31, "v"]], [[38, 40, "v"]], [[63, 63, "v"], [71, 72, "a"], [77, 80, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1901.03559-95ed2ff4-3532-4f9e-adc9-2d01a288c9d2", "sentences": [["We", "use", "the", "V-trace", "actor-critic", "algorithm", "described", "by", "-LSB-", "7", "-RSB-", ",", "with", "4", "GPUs", "for", "each", "learner", "and", "200", "actors", "generating", "trajectories", "."], ["We", "reduce", "variance", "and", "improve", "stability", "by", "using", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "-returns", "targets", "-LRB-", "\\", "-LRB-", "\\lambda", "=0.97\\", "-RRB-", "-RRB-", "and", "a", "smaller", "discount", "factor", "-LRB-", "\\", "-LRB-", "\\gamma", "=0.97\\", "-RRB-", "-RRB-", "."], ["This", "marginally", "reduces", "the", "maximum", "performance", "observed", ",", "but", "increases", "the", "stability", "and", "average", "performance", "across", "runs", ",", "allowing", "better", "comparisons", "."], ["For", "all", "experiments", ",", "we", "use", "a", "BPTT", "-LRB-", "Backpropagation", "Through", "Time", "-RRB-", "unroll", "of", "length", "20", "and", "a", "batch", "size", "of", "32", "."], ["We", "use", "the", "Adam", "optimizer", "-LSB-", "19", "-RSB-", "."], ["The", "learning", "rate", "is", "initialized", "to", "4e-4", "and", "is", "annealed", "to", "0", "over", "1.5e9", "environment", "steps", "with", "polynomial", "annealing", "."], ["The", "other", "Adam", "optimizer", "parameters", "are", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2=0.999", ",", "\\epsilon", "=\\", "-RRB-", "1e-4", "."], ["The", "entropy", "and", "baseline", "loss", "weights", "are", "set", "to", "0.01", "and", "0.5", "respectively", "."], ["We", "also", "apply", "a", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "^2\\", "-RRB-", "norm", "cost", "with", "a", "weight", "of", "1e-3", "on", "the", "logits", ",", "and", "a", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "^2\\", "-RRB-", "regularization", "cost", "with", "a", "weight", "of", "1e-5", "to", "the", "linear", "layers", "that", "compute", "the", "baseline", "value", "and", "logits", "."]], "ner": [[[3, 5, "a"]], [[43, 43, "v"], [55, 55, "v"], [48, 50, "a"], [43, 43, "v"], [55, 55, "v"]], [], [[97, 97, "v"], [100, 101, "p"], [103, 103, "v"]], [[108, 109, "a"]], [[115, 116, "p"], [120, 120, "v"]], [[136, 137, "a"], [143, 143, "v"], [146, 146, "v"], [151, 151, "v"]], [[154, 158, "a"], [154, 154, "p"], [162, 162, "v"], [156, 157, "p"], [164, 164, "v"]], [[183, 183, "p"], [204, 204, "p"], [185, 185, "v"], [183, 183, "p"], [204, 204, "p"], [206, 206, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [4, 5, "a"], [13, 13, "v"], [19, 19, "v"]], [[34, 34, "p"], [42, 42, "p"], [43, 43, "v"], [49, 50, "p"], [54, 54, "p"], [55, 55, "v"]], [], [[97, 97, "v"], [100, 101, "p"], [103, 103, "v"]], [[108, 108, "a"]], [[115, 116, "p"], [120, 120, "v"], [125, 125, "v"], [127, 127, "v"]], [[136, 136, "a"], [151, 151, "v"]], [[162, 162, "v"], [164, 164, "v"]], [[185, 185, "v"], [206, 206, "v"]]], "predicted_relations": [[], [], [], [], [], [[120, 120, 115, 116, "USED-FOR"]], [], [[156, 157, 154, 158, "USED-FOR"]], [[185, 185, 183, 183, "USED-FOR"], [185, 185, 183, 183, "USED-FOR"], [206, 206, 204, 204, "USED-FOR"], [206, 206, 204, 204, "USED-FOR"]]]}
{"doc_key": "1901.03788-cb50be40-a031-446d-a025-3b66bed13580", "sentences": [["In", "BOW", ",", "we", "put", "words", "that", "appear", "more", "than", "twice", "into", "the", "dictionary", "."], ["For", "SVM", ",", "parameters", "\\", "-LRB-", "C\\", "-RRB-", "and", "\\", "-LRB-", "g\\", "-RRB-", "are", "searched", "via", "five-fold", "cross", "validations", "from", "-LCB-", "0.1", ",", "1", ",", "5", ",", "10", ",", "100", "-RCB-", "and", "-LCB-", "0.01", ",", "0.1", ",", "1", ",", "5", ",", "10", "-RCB-", ",", "respectively", "."], ["For", "LR", ",", "the", "codes", "in", "MATLAB", "are", "used", ",", "and", "all", "the", "parameters", "are", "set", "to", "default", "."], ["For", "deep", "models", ",", "the", "word", "embedding", "dimension", "is", "set", "to", "300", "by", "GloVe", "-LSB-", "20", "-RSB-", "."], ["In", "both", "IAN\\", "-LRB-", "^+\\", "-RRB-", "and", "Semi-IAN", ",", "the", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "-hot", "encoding", "-LSB-", "21", "-RSB-", "is", "used", "in", "the", "lexical", "and", "option", "embeddings", "."], ["In", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "-hot", "encoding", ",", "the", "size", "\\", "-LRB-", "k\\", "-RRB-", "is", "searched", "in", "-LSB-", "1", ",", "2", ",", "4", ",", "\\", "-LRB-", "\\cdots", "\\", "-RRB-", ",", "16", "-RSB-", ";", "the", "parameter", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "is", "searched", "in", "-LSB-", "0.1", ",", "0.2", ",", "\\", "-LRB-", "\\cdots", "\\", "-RRB-", ",", "1", "-RSB-", "."]], "ner": [[[1, 1, "a"]], [[16, 16, "a"], [36, 36, "v"], [50, 50, "v"], [36, 36, "v"], [38, 38, "v"], [50, 50, "v"], [52, 52, "v"]], [[62, 62, "a"]], [[93, 93, "a"]], [[105, 105, "a"]], [[140, 140, "p"], [172, 172, "v"], [174, 174, "v"], [146, 146, "v"], [172, 172, "v"], [182, 182, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[16, 16, "a"], [31, 31, "v"], [44, 44, "v"], [48, 48, "v"]], [[62, 62, "a"]], [[91, 91, "v"]], [[105, 105, "a"]], [[174, 174, "v"], [182, 182, "v"]]], "predicted_relations": [[], [], [], [], [], [[146, 146, 140, 140, "USED-FOR"]]]}
{"doc_key": "1909.10363-028949de-2383-4d5d-8783-d01ddfaaf306", "sentences": [["For", "both", "the", "synthetic", "and", "real", "datasets", ",", "we", "train", "the", "Shadow", "Transfer", "networks", "for", "50", "epochs", "with", "a", "learning", "rate", "of", "2e-4", "and", "a", "batch", "size", "of", "2", "."], ["To", "accommodate", "the", "requirement", "of", "the", "U-net", "encoder-decoder", ",", "the", "input", "images", "are", "resized", "to", "512x512", "."], ["The", "SunEst-CNN", "networks", "are", "initialized", "using", "the", "weights", "of", "a", "VGG-16", "network", "trained", "to", "perform", "scene", "classification", "on", "Places-365", "."], ["They", "are", "trained", "for", "20", "epochs", "at", "a", "learning", "rate", "of", "1e-5", ",", "batch", "size", "of", "2", "."], ["The", "input", "images", "are", "resized", "to", "256x256", "to", "accommodate", "the", "architecture", "requirements", "."], ["The", "two", "state", "of", "the", "art", "multi-domain", "to", "multi-domain", "transfer", "methods", ",", "ComboGAN", "and", "StarGAN", ",", "are", "trained", "on", "CARLA-sun", "using", "the", "training", "hyperparameters", "given", "in", "the", "paper", "and", "respective", "github", "repositories", "."], ["All", "networks", "were", "train", "on", "a", "single", "Titan", "X", "GPU", "."]], "ner": [[[11, 13, "a"], [19, 20, "p"], [22, 22, "v"], [25, 26, "p"], [28, 28, "v"], [16, 16, "p"], [15, 15, "v"], [19, 20, "p"], [25, 26, "p"], [28, 28, "v"], [16, 16, "p"]], [], [[48, 49, "a"]], [[75, 76, "p"], [80, 81, "p"], [83, 83, "v"], [72, 72, "p"], [75, 76, "p"], [78, 78, "v"], [80, 81, "p"], [83, 83, "v"], [72, 72, "p"], [71, 71, "v"]], [], [[110, 110, "a"], [112, 112, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 13, "a"], [15, 15, "v"], [16, 16, "p"], [19, 20, "p"], [22, 22, "v"], [25, 26, "p"], [28, 28, "v"]], [[36, 36, "a"], [45, 45, "v"]], [[48, 49, "a"], [57, 58, "a"]], [[71, 71, "v"], [72, 72, "p"], [75, 76, "p"], [78, 78, "v"], [80, 81, "p"], [83, 83, "v"]], [[91, 91, "v"]], [[99, 99, "v"], [110, 110, "a"], [112, 112, "a"], [117, 117, "a"]], []], "predicted_relations": [[[19, 20, 11, 13, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [16, 16, 11, 13, "USED-FOR"], [15, 15, 16, 16, "USED-FOR"], [15, 15, 16, 16, "USED-FOR"], [19, 20, 11, 13, "USED-FOR"], [16, 16, 11, 13, "USED-FOR"]], [], [], [[78, 78, 75, 76, "USED-FOR"], [78, 78, 75, 76, "USED-FOR"], [71, 71, 72, 72, "USED-FOR"], [71, 71, 72, 72, "USED-FOR"]], [], [], []]}
{"doc_key": "1908.10940-675aa1bc-a761-4910-9007-ad4b1446bc57", "sentences": [["The", "sentence", "encoder", "has", "a", "shared", "200k", "token", "multilingual", "vocabulary", "with", "10k", "OOV", "buckets", "."], ["For", "each", "token", ",", "we", "also", "extract", "character", "n-grams", "-LRB-", "\\", "-LRB-", "n=", "-LSB-", "3", ",", "6", "-RSB-", "\\", "-RRB-", "-RRB-", "hashed", "to", "200k", "buckets", "."], ["Word", "token", "items", "and", "character", "n-gram", "items", "are", "mapped", "to", "320", "dim", "."], ["character", "embeddings", "."], ["Word", "and", "character", "n-gram", "representations", "are", "summed", "together", "to", "produce", "the", "final", "input", "token", "representation", "."], ["The", "encoder", "is", "a", "3-layer", "Transformer", "with", "hidden", "size", "of", "512", ",", "filter", "size", "of", "2048", ",", "and", "8", "attention", "heads", "."], ["We", "train", "for", "40M", "steps", "using", "an", "SGD", "optimizer", "with", "batch", "size", "K=100", "and", "learning", "rate", "\\", "-LRB-", "0.003\\", "-RRB-", "."], ["During", "training", ",", "the", "word", "and", "character", "embeddings", "are", "scaled", "by", "a", "gradient", "multiplier", "of", "25", "."]], "ner": [[[6, 6, "v"], [11, 11, "v"]], [[38, 38, "v"]], [], [], [], [[78, 78, "a"], [83, 83, "v"], [88, 88, "v"], [91, 91, "v"]], [[107, 107, "v"], [113, 113, "v"]], [[131, 131, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [11, 11, "v"]], [[38, 38, "v"]], [[51, 51, "v"]], [], [], [[77, 77, "v"], [80, 81, "p"], [83, 83, "v"], [88, 88, "v"], [91, 91, "v"]], [[98, 98, "v"], [102, 102, "a"], [105, 106, "p"], [107, 107, "v"], [109, 110, "p"], [113, 113, "v"]], [[128, 129, "p"], [131, 131, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1910.03177-0df55479-a065-49b4-9039-4b70ec441fb9", "sentences": [["For", "all", "the", "plain", "NSE", "models", ",", "we", "have", "truncated", "the", "article", "to", "a", "maximum", "of", "400", "tokens", "and", "the", "summary", "to", "100", "tokens", "."], ["For", "the", "hierarchical", "NSE", "models", ",", "articles", "are", "truncated", "to", "have", "a", "maximum", "of", "20", "sentences", "and", "20", "words", "per", "sentence", "each", "."], ["Shorter", "sequences", "are", "padded", "with", "`", "PAD", "`", "tokens", "."], ["Since", "the", "factored", "models", "have", "lemma", ",", "PoS", "tag", "and", "the", "separator", "`", "|", "`", "for", "each", "word", ",", "sequence", "lengths", "should", "be", "close", "to", "3", "times", "the", "non-factored", "counterparts", "."], ["For", "practical", "reasons", "of", "memory", "and", "time", ",", "we", "have", "used", "800", "tokens", "per", "article", "and", "300", "tokens", "for", "the", "summary", "."]], "ner": [[[4, 5, "a"], [14, 17, "p"], [16, 16, "v"], [14, 15, "c"], [22, 22, "v"], [14, 15, "c"], [14, 15, "c"], [14, 15, "c"]], [[28, 29, "a"], [37, 38, "c"], [37, 38, "c"], [37, 40, "p"], [39, 39, "v"], [42, 42, "v"], [37, 38, "c"], [39, 39, "v"], [42, 42, "v"], [37, 38, "c"]], [], [], [[100, 103, "p"], [100, 100, "v"], [102, 103, "c"], [105, 109, "p"], [105, 105, "v"], [107, 109, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[16, 16, "v"], [22, 22, "v"]], [[39, 39, "v"], [42, 42, "v"]], [], [[83, 83, "v"]], [[100, 100, "v"], [105, 105, "v"]]], "predicted_relations": [[[14, 17, 4, 5, "USED-FOR"], [16, 16, 14, 17, "USED-FOR"], [14, 15, 16, 16, "USED-FOR"], [14, 15, 22, 22, "USED-FOR"], [14, 15, 16, 16, "USED-FOR"], [14, 15, 22, 22, "USED-FOR"], [14, 15, 16, 16, "USED-FOR"], [14, 15, 22, 22, "USED-FOR"], [14, 15, 16, 16, "USED-FOR"], [14, 15, 22, 22, "USED-FOR"]], [[37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 40, 28, 29, "USED-FOR"], [39, 39, 37, 40, "USED-FOR"], [42, 42, 37, 40, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [39, 39, 37, 40, "USED-FOR"], [42, 42, 37, 40, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"], [37, 38, 39, 39, "USED-FOR"], [37, 38, 42, 42, "USED-FOR"]], [], [], [[100, 100, 100, 103, "USED-FOR"], [102, 103, 100, 100, "USED-FOR"], [102, 103, 105, 105, "USED-FOR"], [105, 105, 105, 109, "USED-FOR"], [107, 109, 100, 100, "USED-FOR"], [107, 109, 105, 105, "USED-FOR"]]]}
{"doc_key": "1910.03177-526b6131-c99b-4129-9958-07a18ef5545d", "sentences": [["For", "all", "the", "models", ",", "including", "the", "pointer-generator", "model", ",", "we", "use", "a", "vocabulary", "size", "of", "50,000", "words", "for", "both", "source", "and", "target", "."], ["Though", "some", "previous", "works", "-LSB-", "14", "-RSB-", "have", "used", "large", "vocabulary", "sizes", "of", "150,000", ",", "since", "our", "models", "have", "a", "copy", "mechanism", ",", "smaller", "vocabulary", "is", "enough", "to", "obtain", "good", "performance", "."], ["Large", "vocabularies", "increase", "the", "computation", "time", "."], ["Since", "memory", "plays", "a", "prominent", "role", "in", "retrieval", "and", "update", ",", "it", "is", "vital", "to", "start", "with", "a", "good", "initialization", "."], ["We", "have", "used", "300-dimensional", "pre-trained", "GloVe", "-LSB-", "18", "-RSB-", "word-vectors", "to", "represent", "the", "input", "sequence", "to", "a", "model", "."], ["Sentence", "memories", "are", "initialized", "with", "GloVe", "word-vectors", "of", "all", "the", "words", "in", "that", "sentence", "."], ["Document", "memories", "are", "initialized", "with", "vector", "representations", "of", "all", "the", "sentences", "where", "a", "sentence", "is", "represented", "with", "the", "average", "of", "the", "GloVe", "word-vectors", "of", "all", "its", "words", "."], ["All", "the", "models", "are", "trained", "using", "the", "Adam", "optimizer", "with", "the", "default", "learning", "rate", "of", "0.001", "."], ["We", "have", "not", "applied", "any", "regularization", "as", "the", "usage", "of", "dropout", ",", "and", "\\", "-LRB-", "L_", "-LCB-", "2", "-RCB-", "\\", "-RRB-", "penalty", "resulted", "in", "similar", "performance", ",", "however", "with", "a", "drastically", "increased", "training", "time", "."]], "ner": [[[7, 8, "a"], [20, 20, "p"], [16, 17, "v"], [13, 14, "a"], [22, 22, "p"]], [], [], [], [[89, 89, "a"]], [[108, 108, "a"]], [[139, 139, "a"]], [[153, 154, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 8, "a"], [16, 16, "v"]], [[37, 37, "v"]], [], [], [[87, 87, "v"], [89, 89, "a"]], [[108, 108, "a"]], [[139, 139, "a"]], [[153, 153, "a"], [158, 159, "p"], [161, 161, "v"]], [[173, 173, "a"]]], "predicted_relations": [[[20, 20, 7, 8, "USED-FOR"], [20, 20, 13, 14, "USED-FOR"], [16, 17, 20, 20, "USED-FOR"], [16, 17, 22, 22, "USED-FOR"], [22, 22, 7, 8, "USED-FOR"], [22, 22, 13, 14, "USED-FOR"]], [], [], [], [], [], [], [], []]}
{"doc_key": "1909.01326-ecee810a-b1cc-4b19-bfd3-8cfb8dfd62b2", "sentences": [["paragraph40ex", "plus.2ex", "minus.2ex-1emBERT", "We", "use", "the", "pretrained", "uncased", "version", "of", "BERT-Base", "-LRB-", "12", "layers", "-RRB-", "with", "mostly", "default", "parameters", ",", "except", "that", "we", "use", "a", "max", "sequence", "length", "of", "50", "and", "train", "for", "5", "epochs", "."], ["paragraph40ex", "plus.2ex", "minus.2ex-1emLSTM", "We", "use", "a", "two-layer", "LSTM", "with", "100", "units", "each", ",", "followed", "by", "a", "linear", "layer", "with", "a", "softmax", "activation", "."], ["We", "use", "Adam", "as", "the", "optimization", "function", "."], ["For", "other", "parameters", ",", "we", "try", "to", "use", "values", "comparable", "to", "those", "of", "the", "BERT", "model", ",", "except", "that", "we", "need", "to", "train", "for", "20", "epochs", "."]], "ner": [[[10, 10, "a"], [25, 27, "p"], [29, 29, "v"], [34, 34, "p"], [33, 33, "v"], [34, 34, "p"]], [[43, 43, "a"], [46, 46, "p"], [45, 45, "v"]], [[64, 65, "p"], [61, 61, "v"]], [[81, 81, "a"], [92, 92, "p"], [92, 92, "p"], [91, 91, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[0, 0, "a"], [10, 10, "a"], [12, 12, "v"], [13, 13, "p"], [25, 27, "p"], [29, 29, "v"], [33, 33, "v"], [34, 34, "p"]], [[43, 43, "a"], [45, 45, "v"], [46, 46, "p"], [56, 57, "a"]], [[61, 61, "a"]], [[81, 82, "a"], [91, 91, "v"], [92, 92, "p"]]], "predicted_relations": [[[25, 27, 10, 10, "USED-FOR"], [29, 29, 25, 27, "USED-FOR"], [29, 29, 34, 34, "USED-FOR"], [29, 29, 34, 34, "USED-FOR"], [33, 33, 25, 27, "USED-FOR"], [33, 33, 34, 34, "USED-FOR"], [33, 33, 34, 34, "USED-FOR"]], [[45, 45, 46, 46, "USED-FOR"]], [], [[91, 91, 92, 92, "USED-FOR"], [91, 91, 92, 92, "USED-FOR"]]]}
{"doc_key": "1912.01966-1024e84a-7928-44be-85b9-ec206a7505b6", "sentences": [["As", "convolutional", "neural", "network", ",", "we", "use", "a", "densly-connected", "model", "-LRB-", "DenseNet", "-RRB-", "with", "121", "layers", "-LSB-", "4", "-RSB-", "."], ["We", "load", "the", "ImageNet", "pretrained", "weights", "before", "starting", "the", "training", "."], ["The", "input", "image", "is", "accordingly", "normalized", "and", "provided", "in", "the", "three", "input", "channels", "."], ["The", "output", "layer", "of", "the", "network", "is", "reduced", "such", "that", "one", "sigmoidal", "unit", "is", "returned", "."], ["During", "training", "we", "use", "the", "Adam", "optimizer", "-LSB-", "5", "-RSB-", "-LRB-", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=", "0.9", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=", "0.999", "-RRB-", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "stop", "the", "training", "and", "jump", "back", "to", "the", "best", "epoch", "if", "the", "validation", "accuracy", "does", "not", "improve", "after", "a", "patience", "of", "8", "epochs", "."], ["We", "apply", "the", "binary", "cross-entropy", "function", "to", "predict", "the", "loss", "."], ["Each", "batch", "is", "filled", "with", "16", "examples", "."], ["The", "performance", "on", "the", "test", "set", "is", "evaluated", "with", "the", "area", "under", "ROC", "curve", "-LRB-", "AUC", "-RRB-", "."]], "ner": [[[11, 11, "a"]], [], [], [], [[66, 67, "a"], [78, 78, "v"], [86, 86, "v"], [90, 91, "a"], [90, 91, "p"]], [[122, 122, "a"], [122, 122, "p"], [124, 124, "v"], [125, 125, "c"]], [[130, 131, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 3, "a"], [8, 9, "a"], [14, 14, "v"]], [[23, 23, "a"]], [[41, 41, "v"]], [[55, 55, "v"]], [[66, 66, "a"], [78, 78, "v"], [86, 86, "v"], [90, 91, "p"], [95, 99, "v"]], [[124, 124, "v"], [125, 125, "p"]], [[130, 132, "a"]], [[143, 143, "v"]], []], "predicted_relations": [[], [], [], [], [], [[122, 122, 122, 122, "USED-FOR"], [124, 124, 122, 122, "USED-FOR"]], [], [], []]}
{"doc_key": "1909.10649-33b709a6-d4cd-4a65-9fb8-c0d91b7c2b3d", "sentences": [["The", "pre-training", "input", "sequences", "are", "generated", "with", "default", "parameters", "and", "use", "whole", "work", "masking", "-LRB-", "if", "a", "word", "composed", "of", "multiple", "subword", "units", "is", "masked", ",", "all", "of", "its", "subword", "units", "are", "masked", "and", "have", "to", "be", "predicted", "in", "Masked", "Language", "Modeling", "task", "-RRB-", "."], ["The", "models", "are", "trained", "for", "1,000,000", "steps", "."], ["We", "use", "a", "learning", "rate", "of", "1e-4", ",", "learning", "rate", "warmup", "over", "the", "first", "10,000", "steps", "followed", "by", "a", "linear", "decay", "of", "the", "learning", "rate", "."]], "ner": [[[1, 3, "a"], [7, 8, "p"], [11, 13, "p"]], [[46, 46, "a"], [50, 50, "v"]], [[56, 57, "p"], [61, 62, "p"], [76, 77, "p"], [59, 59, "v"], [61, 77, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[50, 50, "v"]], [[56, 57, "p"], [59, 59, "v"], [67, 67, "v"], [76, 77, "p"]]], "predicted_relations": [[[7, 8, 1, 3, "USED-FOR"], [11, 13, 1, 3, "USED-FOR"]], [], [[59, 59, 56, 57, "USED-FOR"], [59, 59, 61, 62, "USED-FOR"]]]}
{"doc_key": "1909.10649-900ad026-74ee-4039-b2ed-f71cb5d0bb66", "sentences": [["For", "BERT", "Base", "models", ",", "the", "weights", "are", "initialized", "with", "the", "checkpoint", "of", "Multilingual", "BERT", "Base", "."], ["We", "use", "a", "batch", "size", "of", "128", "and", "sequences", "of", "512", "tokens", "the", "entire", "training", "."], ["This", "training", "takes", "4", "days", "on", "a", "TPUv3-8", "instance", "and", "performs", "about", "8", "epochs", "over", "the", "training", "data", "."]], "ner": [[[1, 3, "a"], [13, 15, "a"]], [[20, 21, "a"], [20, 21, "p"], [23, 23, "v"], [25, 28, "a"], [27, 27, "v"]], [[40, 41, "a"], [49, 50, "a"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [14, 15, "a"]], [[20, 21, "p"], [23, 23, "v"], [27, 27, "v"]], [[36, 36, "v"], [40, 40, "v"], [45, 45, "v"], [46, 46, "p"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1909.10649-5dd8aca4-4c94-4365-b1c4-0b6760bd2843", "sentences": [["For", "BERT", "Large", ",", "the", "weights", "are", "initialized", "with", "the", "checkpoint", "of", "English", "BERT", "Large", "."], ["Since", "it", "is", "a", "bigger", "model", "with", "longer", "training", "time", ",", "we", "follow", "the", "instructions", "of", "-LSB-", "6", "-RSB-", "and", "use", "sequences", "of", "128", "tokens", "in", "batches", "of", "size", "256", "for", "the", "first", "900,000", "steps", "and", "then", "sequences", "of", "512", "tokens", "and", "batch", "size", "128", "for", "the", "last", "100,000", "steps", "."], ["This", "training", "takes", "7", "days", "on", "a", "TPUv3-8", "instance", "and", "performs", "about", "6", "epochs", "over", "the", "training", "data", "."]], "ner": [[[1, 2, "a"], [13, 14, "a"]], [[37, 45, "a"], [39, 39, "v"], [60, 60, "v"], [58, 59, "p"], [53, 60, "a"]], []], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [13, 13, "a"]], [[39, 39, "v"], [45, 45, "v"], [49, 49, "v"], [55, 55, "v"], [60, 60, "v"], [64, 64, "v"]], [[70, 70, "v"], [74, 74, "a"], [79, 79, "v"]]], "predicted_relations": [[], [[58, 59, 53, 60, "USED-FOR"]], []]}
{"doc_key": "1903.11626-7c3faae5-5c04-49c7-a143-897f467e42a3", "sentences": [["All", "adversarial", "attacks", "in", "this", "paper", "were", "optimized", "to", "maximize", "the", "cross", "entropy", "loss", "or", "the", "CW", "surrogate", "objective", "with", "40", "iterations", "of", "PGD", "."], ["Following", "previous", "works", "-LSB-", "26", "-RSB-", "and", "-LSB-", "21", "-RSB-", ",", "during", "adversarial", "training", ",", "we", "trained", "on", "adversarial", "images", "only", "."], ["That", "is", ",", "we", "did", "not", "mix", "natural", "and", "adversarial", "images", "."], ["We", "describe", "the", "adversarial", "training", "procedure", "and", "attack", "settings", "used", "in", "each", "section", "."]], "ner": [[[11, 13, "a"], [16, 18, "a"], [21, 21, "p"], [20, 20, "v"], [23, 23, "a"]], [[37, 38, "a"]], [], [[62, 63, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[11, 13, "a"], [16, 16, "a"], [20, 20, "v"], [23, 23, "a"]], [], [], []], "predicted_relations": [[[21, 21, 16, 18, "USED-FOR"], [21, 21, 23, 23, "USED-FOR"], [20, 20, 21, 21, "USED-FOR"]], [], [], []]}
{"doc_key": "1906.03787-652b9eb8-ac16-457e-a65e-db0b0761aec1", "sentences": [["We", "use", "the", "publicly", "available", "adversarial", "training", "pipelinehttps", ":", "//github.com/facebookresearch/ImageNet-Adversarial-Training", "to", "train", "all", "models", "with", "different", "strategies", "on", "ImageNet", "."], ["We", "select", "ResNet-152", "-LSB-", "10", "-RSB-", "as", "the", "baseline", "network", ",", "and", "apply", "projected", "gradient", "descent", "-LRB-", "PGD", "-RRB-", "-LSB-", "19", "-RSB-", "as", "the", "adversarial", "attacker", "to", "generate", "adversarial", "examples", "during", "training", "."], ["The", "hyper-parameters", "of", "the", "PGD", "attacker", "are", ":", "maximum", "perturbation", "of", "each", "pixel", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "=", "16", ",", "attack", "step", "size", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "=", "1", ",", "number", "of", "attack", "iterations", "N", "=", "30", ",", "and", "the", "targeted", "class", "is", "selected", "uniformly", "at", "random", "over", "the", "1000", "ImageNet", "categories", "."], ["We", "initialize", "the", "adversarial", "image", "by", "the", "clean", "counterpart", "with", "probability", "=", "0.2", ",", "or", "randomly", "within", "the", "allowed", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "cube", "with", "probability", "=", "0.8", "."], ["All", "models", "are", "trained", "for", "a", "total", "of", "110", "epochs", ",", "and", "we", "decrease", "the", "learning", "rate", "by", "10\\", "-LRB-", "\\times", "\\", "-RRB-", "at", "the", "35-th", ",", "70-th", ",", "and", "95-th", "epoch", "."]], "ner": [[], [[22, 22, "a"]], [[61, 65, "p"], [72, 72, "v"], [74, 76, "p"], [83, 83, "v"], [85, 88, "p"], [91, 91, "v"], [95, 96, "p"], [104, 106, "v"]], [[115, 120, "v"]], [[153, 154, "a"], [151, 151, "p"], [147, 147, "p"], [163, 163, "v"], [165, 165, "v"], [168, 168, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[18, 18, "a"]], [[22, 22, "a"], [33, 38, "a"]], [[72, 72, "v"], [83, 83, "v"], [91, 91, "v"], [104, 104, "v"], [105, 105, "a"]], [[120, 120, "v"], [136, 136, "v"]], [[146, 146, "v"], [147, 147, "p"], [153, 154, "p"], [156, 156, "v"], [158, 158, "p"], [163, 163, "v"], [165, 165, "v"], [168, 168, "v"]]], "predicted_relations": [[], [], [[72, 72, 61, 65, "USED-FOR"], [91, 91, 95, 96, "USED-FOR"]], [], [[151, 151, 153, 154, "USED-FOR"], [147, 147, 153, 154, "USED-FOR"], [163, 163, 151, 151, "USED-FOR"], [165, 165, 151, 151, "USED-FOR"]]]}
{"doc_key": "1906.03787-f2f4e385-d225-420f-977d-7d5bf5e43bda", "sentences": [["By", "following", "the", "parameter", "settings", "listed", "in", "the", "ALP", "paperFor", "easier", "implementation", ",", "we", "apply", "48", "GPUs", "-LRB-", "which", "can", "be", "distributed", "over", "6", "8-GPU", "machines", "-RRB-", "for", "adversarial", "training", ",", "instead", "of", "using", "the", "original", "number", ",", "i.e.", ",", "50", "GPUs.", ",", "we", "can", "train", "a", "ResNet-101", "with", "an", "accuracy", "of", "38.1", "%", "against", "PGD-10", "."], ["The", "ResNet-101", "performance", "reported", "in", "the", "ALP", "paper", "is", "30.2", "%", "accuracy", "against", "an", "attack", "suiteThis", "attack", "suite", "contains", "8", "different", "attackers", ",", "including", "PGD-10", "."], ["However", ",", "due", "to", "the", "vague", "description", "of", "parameter", "settings", "in", "this", "attack", "suite", ",", "we", "are", "not", "able", "to", "reproduce", "it", ".."], ["This", "\\", "-LRB-", "\\scriptstyle", "\\sim", "\\", "-RRB-", "8", "%", "performance", "gap", "is", "possibly", "due", "to", "different", "attacker", "settings", "in", "evaluation", "."], ["However", ",", "by", "evaluating", "this", "model", "against", "PGD-2000", ",", "we", "are", "able", "to", "obtain", "a", "similar", "result", "that", "reported", "in", "-LSB-", "5", "-RSB-", ",", "i.e.", ",", "-LSB-", "5", "-RSB-", "reports", "ALP", "obtains", "0", "%", "accuracy", ",", "and", "in", "our", "implementation", "the", "accuracy", "is", "2.1", "%", "."]], "ner": [[[47, 47, "a"], [8, 8, "a"], [15, 15, "v"], [55, 55, "a"]], [[58, 58, "a"], [63, 63, "a"], [81, 81, "a"]], [], [], [[157, 157, "a"], [134, 134, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[15, 15, "v"], [23, 23, "v"], [40, 40, "v"], [47, 47, "a"], [52, 53, "v"], [55, 55, "a"]], [[58, 58, "a"], [66, 67, "v"], [76, 76, "v"], [81, 81, "a"]], [], [[113, 114, "v"]], [[132, 132, "a"], [134, 134, "a"], [159, 160, "v"], [170, 171, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1912.04663-7f296c03-85b8-45e9-a3f5-db097a62c15b", "sentences": [["We", "use", "the", "Adam", "optimizer", "with", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "mini", "batch", "size", "is", "set", "to", "64", "."], ["Training", "loss", "is", "averaged", "in", "each", "mini", "batch", "."], ["We", "use", "\\", "-LRB-", "80\\", "%", "\\", "-RRB-", "of", "the", "3D", "models", "in", "ShapeNet", "for", "training", ",", "\\", "-LRB-", "10\\", "%", "\\", "-RRB-", "for", "validation", ",", "and", "the", "rest", "for", "testing", "."]], "ner": [[[3, 4, "a"], [6, 7, "p"]], [[19, 21, "p"], [25, 25, "v"]], [], [[49, 49, "a"], [51, 51, "p"], [60, 60, "p"], [66, 66, "p"], [64, 64, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [6, 7, "p"], [11, 15, "v"]], [[19, 21, "p"], [25, 25, "v"]], [], [[40, 41, "v"], [49, 49, "a"], [55, 56, "v"]]], "predicted_relations": [[[6, 7, 3, 4, "USED-FOR"]], [], [], [[51, 51, 49, 49, "USED-FOR"], [60, 60, 49, 49, "USED-FOR"], [66, 66, 49, 49, "USED-FOR"], [64, 64, 60, 60, "USED-FOR"], [64, 64, 66, 66, "USED-FOR"]]]}
{"doc_key": "1912.04711-53689382-c4b3-4eb7-839a-eb49defb074e", "sentences": [["On", "all", "training", "instances", ",", "we", "used", "a", "uniform", "distribution", "for", "weights", "initialization", "and", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "0.0001", "for", "optimization", "."], ["Using", "single", "NVIDIA", "Titan", "X", "we", "were", "able", "to", "use", "a", "batch", "size", "of", "115", "and", "took", "approximately", "two", "days", "to", "train", "each", "individual", "model", "."], ["All", "models", "were", "implemented", "using", "the", "Pytorch", "framework", "-LSB-", "39", "-RSB-", "."]], "ner": [[[14, 15, "a"], [18, 19, "p"], [21, 21, "v"], [8, 9, "a"]], [], [[57, 58, "a"]]], "relations": [[], [], []], "predicted_ner": [[[14, 14, "a"], [18, 19, "p"], [21, 21, "v"]], [[36, 37, "p"], [39, 39, "v"], [43, 43, "v"]], []], "predicted_relations": [[[18, 19, 14, 15, "USED-FOR"], [21, 21, 18, 19, "USED-FOR"]], [], []]}
{"doc_key": "1905.13570-8556ae84-f467-4dba-b91b-a399f1a87d3f", "sentences": [["We", "briefly", "discuss", "training", "differences", "between", "BFVI", "and", "other", "methods", "here", "."], ["For", "the", "RNN-based", "methods", ",", "no", "bidirectional", "training", "is", "involved", ",", "so", "we", "only", "minimized", "the", "-LRB-", "forward", "-RRB-", "filtering", "ELBO", "-LRB-", "for", "F-Mask", ",", "F-Skip", "-RRB-", "or", "the", "smoothing", "ELBO", "-LRB-", "for", "B-Mask", ",", "B-Skip", "-RRB-", "."], ["While", "we", "also", "tried", "to", "use", "the", "multimodal", "training", "paradigm", "-LRB-", "i.e", "."], ["minimizing", "the", "sum", "of", "\\", "-LRB-", "L^", "-LCB-", "1", ":", "M", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "L^m\\", "-RRB-", "-RRB-", "for", "the", "RNN-based", "methods", ",", "the", "effects", "of", "this", "were", "mixed", ":", "On", "the", "spirals", "dataset", ",", "performance", "dropped", "very", "sharply", "with", "the", "multimodal", "paradigm", ",", "whereas", "performance", "increased", "on", "the", "Weizmann", "video", "dataset", "."], ["As", "such", ",", "the", "results", "we", "report", "in", "the", "main", "manuscript", "use", "the", "multimodal", "training", "paradigm", "only", "for", "the", "video", "dataset", "."], ["For", "the", "spirals", "dataset", ",", "we", "only", "minimize", "\\", "-LRB-", "L^", "-LCB-", "1", ":", "M", "-RCB-", "\\", "-RRB-", ",", "with", "all", "inputs", "provided", ",", "but", "not", "\\", "-LRB-", "L^m\\", "-RRB-", ",", "which", "is", "computed", "with", "only", "modality", "\\", "-LRB-", "m\\", "-RRB-", "provided", "as", "input", "."], ["Finally", ",", "we", "used", "a", "higher", "learning", "rate", "-LRB-", "0.02", "-RRB-", "for", "BFVI", "on", "the", "spirals", "dataset", "because", "we", "noticed", "slow", "convergence", "with", "the", "lower", "rate", "of", "0.01", "."], ["Increasing", "the", "learning", "rate", "to", "0.02", "for", "the", "other", "methods", "hurt", "their", "performance", "."]], "ner": [[[6, 6, "a"], [8, 9, "c"]], [[14, 15, "a"]], [[57, 59, "a"]], [[97, 98, "c"], [85, 86, "a"]], [[131, 133, "a"]], [[142, 143, "c"]], [[197, 197, "a"], [191, 192, "p"], [194, 194, "v"], [200, 201, "c"], [212, 212, "v"]], [[216, 217, "p"], [219, 219, "v"], [222, 223, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [], [], [[97, 98, "a"], [114, 116, "a"]], [], [[142, 143, "a"]], [[191, 192, "p"], [194, 194, "v"], [197, 197, "a"], [200, 201, "a"], [212, 212, "v"]], [[216, 217, "p"], [219, 219, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[191, 192, 197, 197, "USED-FOR"], [200, 201, 194, 194, "USED-FOR"], [200, 201, 212, 212, "USED-FOR"]], [[222, 223, 219, 219, "USED-FOR"]]]}
{"doc_key": "1907.02848-57035e68-22e1-4f1f-a3b0-4daace63849a", "sentences": [["Open-Subtitles", ":", "Additionally", ",", "we", "show", "results", "with", "the", "unannotated", "Open-Subtitles", "dataset", "-LSB-", "35", "-RSB-", "-LRB-", "we", "randomly", "sample", "up", "to", "2", "million", "dialogs", "for", "training", "and", "validation", "-RRB-", "."], ["We", "tag", "the", "dataset", "with", "dialog", "attributes", "using", "pre-trained", "classifiers", "."]], "ner": [[[0, 0, "a"], [10, 10, "a"]], []], "relations": [[], []], "predicted_ner": [[[0, 0, "a"], [21, 22, "v"]], [[33, 33, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1907.02848-6fffecd1-f1f9-4676-aa24-cf8c3d67fa4c", "sentences": [["Model", "Details", ":", "We", "use", "two-layer", "GRUs", "-LSB-", "3", "-RSB-", "for", "both", "encoder", "and", "decoders", "with", "hidden", "sizes", "of", "512", "."], ["We", "restrict", "the", "vocabulary", "for", "both", "the", "datasets", "to", "top", "25000", "frequency", "occurring", "tokens", "."], ["The", "dialog", "attribute", "classifier", "for", "dialog", "attributes", "is", "a", "simple", "2-layer", "MLP", "with", "layer", "sizes", "of", "256", ",", "and", "10", "respectively", "."], ["We", "use", "the", "rectified", "linear", "unit", "-LRB-", "ReLU", "-RRB-", "as", "the", "non-linear", "activation", "function", "for", "the", "MLPs", "and", "use", "dropout", "rate", "of", "\\", "-LRB-", "0.3\\", "-RRB-", "for", "the", "token", "embeddings", ",", "hidden-hidden", "transition", "matrices", "of", "the", "encoder", "and", "decoder", "GRUs", "."]], "ner": [[[6, 6, "a"], [16, 17, "p"], [19, 19, "v"]], [], [[47, 47, "a"], [49, 50, "p"], [52, 52, "v"], [55, 55, "v"]], [[97, 97, "a"], [69, 71, "p"], [65, 65, "v"], [77, 78, "a"], [77, 78, "p"], [82, 82, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"], [19, 19, "v"]], [[31, 31, "v"]], [[46, 46, "v"], [47, 47, "a"], [52, 52, "v"], [55, 55, "v"]], [[61, 66, "a"], [77, 78, "p"], [82, 82, "v"], [97, 97, "a"]]], "predicted_relations": [[[16, 17, 6, 6, "USED-FOR"]], [], [[49, 50, 47, 47, "USED-FOR"]], [[77, 78, 77, 78, "USED-FOR"]]]}
{"doc_key": "1907.02848-cb9e3535-2fbb-4ddb-9002-9c1729f7974f", "sentences": [["Training", "Details", ":", "We", "ran", "our", "experiments", "in", "Nvidia", "Tesla-K80", "GPUs", "and", "optimized", "using", "the", "ADAM", "optimizer", "with", "the", "default", "hyper-parameters", "used", "in", "-LSB-", "19", "-RSB-", ",", "-LSB-", "20", "-RSB-", "."], ["All", "models", "are", "trained", "with", "batch", "size", "128", "and", "a", "learning", "rate", "\\", "-LRB-", "0.0001\\", "-RRB-", "."]], "ner": [[[15, 16, "a"]], [[41, 42, "p"], [45, 45, "v"]]], "relations": [[], []], "predicted_ner": [[[15, 15, "a"]], [[36, 37, "p"], [38, 38, "v"], [41, 42, "p"], [45, 45, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1907.03089-a9645c92-09a9-4276-92ad-d9c8a7d65a98", "sentences": [["All", "the", "experiments", "are", "implemented", "with", "PyTorch", "1.1.0", ",", "CUDA", "9.0", "and", "CuDNN", "7", "."], ["The", "networks", "run", "200", "epochs", "on", "single", "Tesla", "V100", "GPU", ",", "using", "Adam", "optimizer", "with", "weight", "decay", "of", "2e-4", "and", "momentum", "of", "0.9", "."], ["The", "initial", "learning", "rate", "is", "5e-4", "and", "we", "adopt", "``", "ploy", "''", "learning", "rate", "policy", "with", "power", "of", "0.9", "."], ["We", "set", "batch", "size", "to", "16", "to", "fit", "our", "GPU", "memory", "."], ["In", "order", "to", "alleviate", "the", "unbalanced", "categories", ",", "we", "adopt", "cross", "entropy", "loss", "with", "weight", "\\", "-LRB-", "W_", "-LCB-", "class", "-RCB-", "=\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "log", "-LRB-", "P_", "-LCB-", "class", "-RCB-", "+c", "-RRB-", "-RCB-", "\\", "-RRB-", "and", "we", "set", "\\", "-LRB-", "c\\", "-RRB-", "to", "1.12", "."]], "ner": [[[6, 6, "a"], [9, 9, "a"], [12, 12, "a"]], [[27, 28, "a"], [30, 31, "p"], [33, 33, "v"], [35, 35, "p"], [37, 37, "v"], [30, 30, "p"]], [[57, 57, "v"], [40, 42, "p"], [44, 44, "v"], [55, 57, "v"]], [[61, 62, "p"], [64, 64, "v"]], [[81, 83, "a"], [85, 85, "p"], [103, 103, "p"], [113, 113, "p"], [116, 116, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 13, "a"]], [[18, 18, "v"], [19, 19, "p"], [27, 27, "a"], [30, 31, "p"], [33, 33, "v"], [35, 35, "p"], [37, 37, "v"]], [[41, 42, "p"], [44, 44, "v"], [57, 57, "v"]], [[61, 62, "p"], [64, 64, "v"]], [[81, 83, "a"], [116, 116, "v"]]], "predicted_relations": [[], [[33, 33, 30, 31, "USED-FOR"], [33, 33, 30, 30, "USED-FOR"], [35, 35, 27, 28, "USED-FOR"]], [[44, 44, 40, 42, "USED-FOR"]], [], [[85, 85, 81, 83, "USED-FOR"], [103, 103, 81, 83, "USED-FOR"], [116, 116, 113, 113, "USED-FOR"]]]}
{"doc_key": "1911.09338-66fc3bb1-17a9-4c89-90c6-f514e94aa872", "sentences": [["Model", "settings", "."], ["The", "voice", "embedding", "network", "and", "face", "embedding", "network", "are", "pre-trained", "by", "VoxCeleb2", "and", "VGGFace2", "respectively", "."], ["Margin", "\\", "-LRB-", "m\\", "-RRB-", "for", "Triplet", "Loss", "is", "set", "to", "1", ",", "and", "scale", "\\", "-LRB-", "s\\", "-RRB-", "for", "L2", "normalization", "is", "set", "to", "128", "."], ["Adam", "Optimizer", "is", "adopted", "in", "this", "paper", "."], ["The", "total", "number", "of", "learning", "steps", "is", "70k", "."], ["The", "learning", "rate", "of", "FC", "layer", "for", "\u201c", "step\\", "-LRB-", "<", "\\", "-RRB-", "20k", "\u201d", ",", "\u201c", "20k\\", "-LRB-", "<", "\\", "-RRB-", "step\\", "-LRB-", "<", "\\", "-RRB-", "40k", "\u201d", ",", "\u201c", "40k\\", "-LRB-", "<", "\\", "-RRB-", "step\\", "-LRB-", "<", "\\", "-RRB-", "60k", "\u201d", "and", "\u201c", "step\\", "-LRB-", ">", "\\", "-RRB-", "60k", "\u201d", "is", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", ",10^", "-LCB-", "-4", "-RCB-", ",10^", "-LCB-", "-5", "-RCB-", ",10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "respectively", "."], ["The", "learning", "rate", "of", "face", "embedding", "network", "is", "fixed", "to", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."]], "ner": [[], [[14, 14, "a"], [16, 16, "a"], [8, 10, "p"]], [[25, 26, "a"], [30, 30, "v"], [33, 33, "p"], [44, 44, "v"]], [[46, 47, "a"]], [], [[64, 65, "a"], [67, 68, "p"]], [[139, 140, "a"], [142, 144, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[8, 10, "a"], [14, 14, "a"], [16, 16, "a"]], [[22, 22, "p"], [25, 26, "a"], [30, 30, "v"], [39, 40, "a"], [44, 44, "v"]], [[46, 46, "a"]], [[61, 61, "v"]], [[64, 65, "p"], [76, 76, "v"], [90, 90, "v"], [104, 104, "v"], [113, 113, "v"]], [[139, 140, "p"], [142, 144, "a"]]], "predicted_relations": [[], [[8, 10, 14, 14, "USED-FOR"], [8, 10, 16, 16, "USED-FOR"]], [[30, 30, 33, 33, "USED-FOR"], [33, 33, 25, 26, "USED-FOR"], [44, 44, 33, 33, "USED-FOR"]], [], [], [[67, 68, 64, 65, "USED-FOR"]], [[142, 144, 139, 140, "USED-FOR"]]]}
{"doc_key": "1903.00827-8c639f9a-b063-410e-8677-cb698022eb8c", "sentences": [["The", "difficulty", "level", "of", "L2R", "environment", "is", "set", "to", "be", "2", "for", "all", "of", "our", "experiments", "in", "this", "paper", ",", "which", "means", "that", "there", "are", "three", "stumbling", "blocks", "with", "random", "sizes", "and", "positions", "in", "each", "episode", "."], ["To", "handle", "the", "high-dimensional", "observation", "vector", "and", "action", "vector", ",", "we", "specially", "design", "the", "network", "architecture", "depicted", "in", "Figure", "REF", "."], ["Adam", "-LSB-", "12", "-RSB-", "is", "adopted", "to", "train", "the", "agent", "networks", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "3e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "mini-batch", "size", "\\", "-LRB-", "N=96\\", "-RRB-", ",", "discount", "factor", "\\", "-LRB-", "\\gamma", "=0.99\\", "-RRB-", ",", "soft", "update", "rate", "\\", "-LRB-", "\\tau", "=1e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "and", "size", "of", "replay", "buffer", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "=10e^", "-LCB-", "6", "-RCB-", ",", "\\mathcal", "-LCB-", "M", "-RCB-", "_H=5\\times", "10^", "-LCB-", "4", "-RCB-", "\\", "-RRB-", "."], ["Specially", ",", "we", "tune", "the", "probability", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "of", "sampling", "from", "\u201c", "HMemory", "\u201d", "in", "\\", "-LRB-", "-LSB-", "0.05", ",", "0.25", "-RSB-", "\\", "-RRB-", "according", "to", "the", "number", "of", "interaction", "threads", "."]], "ner": [[], [], [[58, 58, "a"], [71, 72, "p"]], [[85, 86, "a"], [92, 93, "a"], [100, 102, "a"], [114, 117, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [10, 10, "v"], [25, 25, "v"]], [], [[58, 58, "a"], [67, 68, "a"], [71, 72, "p"], [76, 79, "v"]], [[85, 86, "a"], [89, 89, "v"], [92, 93, "p"], [96, 96, "p"], [97, 97, "v"], [100, 102, "p"], [116, 117, "a"]], [[162, 162, "v"], [164, 164, "v"]]], "predicted_relations": [[], [], [[71, 72, 58, 58, "USED-FOR"]], [], []]}
{"doc_key": "1903.00827-f7915333-8b37-40fa-928e-de9fec6f72e9", "sentences": [["In", "MuJoCo", "environments", ",", "we", "adopt", "fully", "connected", "networks", "with", "hidden", "sizes", "of", "-LRB-", "256", ",", "256", ",", "128", "-RRB-", "and", "-LRB-", "256", ",", "128", "-RRB-", "to", "build", "the", "actor", "and", "critic", "respectively", "."], ["And", "we", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "a", "mini-batch", "size", "of", "128", "."], ["Other", "hyper-parameters", "keep", "the", "same", "settings", "of", "agents", "on", "L2R", "task", "."]], "ner": [[[6, 8, "a"], [10, 11, "p"], [18, 18, "v"], [24, 24, "v"]], [[38, 39, "p"], [51, 52, "p"], [54, 54, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [6, 8, "a"], [14, 14, "v"], [16, 16, "v"], [18, 18, "v"], [22, 22, "v"], [24, 24, "v"]], [[38, 39, "p"], [43, 45, "v"], [51, 52, "p"], [54, 54, "v"]], []], "predicted_relations": [[[10, 11, 6, 8, "USED-FOR"]], [], []]}
{"doc_key": "1910.10223-349a5cb4-bd42-47ec-9480-89db86418a88", "sentences": [["For", "all", "experiments", ",", "we", "use", "\\", "-LRB-", "b_\\gamma", "=", "l_\\gamma", "=", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mu", "=", "10^", "-LCB-", "-1", "-RCB-", "\\", "-RRB-", "."], ["\\", "-LRB-", "p", "-LRB-", "\\pi", "\\vert", "x_2", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "r", "-LRB-", "\\pi", "-RRB-", "\\", "-RRB-", "are", "both", "modeled", "as", "Gaussian", "distributions", "of", "unit", "variance", "."], ["The", "latter", "has", "a", "mean", "of", "zero", "and", "\\", "-LRB-", "E_\\pi", "\\", "-RRB-", "estimates", "the", "mean", "of", "the", "first", "."], ["We", "use", "the", "reparameterization", "trick", "-LSB-", "28", "-RSB-", "to", "obtain", "low", "variance", "estimates", "of", "the", "gradient", "."], ["Depending", "on", "the", "dataset", ",", "we", "implement", "the", "negative", "log-likelihood", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "rec", "-RCB-", "-RCB-", "\\", "-RRB-", "with", "a", "\\", "-LRB-", "l_2\\", "-RRB-", "loss", "-LRB-", "sprites", "-RRB-", ",", "a", "perceptual", "loss", "-LSB-", "24", "-RSB-", "-LRB-", "norb", "-RRB-", "or", "a", "perceptual", "loss", "together", "with", "a", "discriminator", "loss", "as", "in", "-LSB-", "10", "-RSB-", ",", "weighted", "by", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "-LRB-", "remaining", "datasets", "-RRB-", "."]], "ner": [[], [], [[63, 63, "p"], [74, 74, "p"], [65, 65, "v"], [63, 63, "a"], [74, 74, "a"], [72, 77, "c"]], [[82, 83, "a"]], [[104, 105, "a"], [133, 134, "a"], [148, 149, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 15, "v"]], [], [[65, 65, "v"]], [[82, 83, "a"]], [[133, 134, "a"], [139, 139, "a"], [148, 149, "a"], [160, 163, "v"]]], "predicted_relations": [[], [], [[63, 63, 63, 63, "USED-FOR"], [74, 74, 63, 63, "USED-FOR"], [74, 74, 74, 74, "USED-FOR"], [72, 77, 65, 65, "USED-FOR"]], [], []]}
{"doc_key": "1910.10307-ca06b821-389f-40c5-a209-f50b4e1285ae", "sentences": [["To", "train", "OSVM", "classifiers", "for", "detection", "and", "finding", "the", "OODL", ",", "we", "used", "the", "rbf", "kernel", "and", "training", "error", "\\", "-LRB-", "\\textit", "-LCB-", "nu", "-RCB-", "=0.001\\", "-RRB-", "."], ["The", "rbf", "kernel", "gave", "us", "the", "best", "results", "in", "comparison", "to", "other", "kernels", "such", "as", "linear", "or", "poly", "."], ["We", "used", "temperature", "scale", "\\", "-LRB-", "T=1000\\", "-RRB-", "for", "the", "ODIN", "approach", "since", "it", "was", "deemed", "as", "the", "optimal", "value", "based", "in", "the", "original", "paper", "-LSB-", "17", "-RSB-", "."], ["The", "perturbation", "magnitude", "\\", "-LRB-", "\\varepsilon", "\\", "-RRB-", "for", "our", "approach", "and", "ODIN", "was", "optimized", "to", "minimize", "FPR", "at", "\\", "-LRB-", "95\\", "%", "\\", "-RRB-", "TPR", "by", "having", "access", "to", "randomly", "selected", "\\", "-LRB-", "20\\", "%", "\\", "-RRB-", "of", "OOD", "datasets", "."], ["We", "used", "F-MNIST", "and", "TinyImageNet", "datasets", "to", "find", "the", "OODLs", "."], ["The", "OODL", "was", "fixed", "for", "every", "ID", "dataset", "and", "its", "associated", "model", "."], ["The", "OODL", "for", "the", "MNIST", "dataset", "was", "the", "second", "convolutional", "layer", "."], ["The", "OODLs", "for", "VGG-16", "trained", "on", "CIFAR-10", "and", "CIFAR-100", "were", "the", "second", "convolutional", "layer", "and", "the", "first", "max-polling", "layer", ",", "respectively", "."], ["The", "OODL", "for", "ResNet", "trained", "on", "CIFAR-10", "and", "CIFAR-100", "were", "the", "thirteenth", "and", "ninth", "residual", "layers", ",", "respectively", "."], ["Details", "of", "parameters", "for", "training", "models", "are", "in", "supplemental", "material", "."]], "ner": [[[2, 3, "a"], [15, 15, "p"], [14, 14, "v"], [23, 23, "p"], [25, 25, "v"]], [[30, 30, "p"], [29, 29, "v"], [43, 43, "v"], [45, 45, "v"]], [[53, 53, "p"], [53, 53, "v"]], [], [[120, 120, "a"], [122, 122, "a"]], [], [], [[157, 157, "a"], [160, 160, "a"], [162, 162, "a"]], [[182, 182, "a"], [184, 184, "a"], [179, 179, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [], [[49, 50, "p"], [53, 53, "v"], [57, 58, "a"]], [[86, 86, "a"], [88, 88, "a"], [97, 98, "v"], [110, 111, "v"]], [[120, 120, "a"], [122, 122, "a"]], [], [[146, 147, "a"]], [[157, 157, "a"], [160, 160, "a"], [162, 162, "a"], [171, 171, "a"]], [[179, 179, "a"], [182, 182, "a"], [184, 184, "a"], [189, 189, "v"]], []], "predicted_relations": [[[15, 15, 2, 3, "USED-FOR"], [14, 14, 15, 15, "USED-FOR"], [25, 25, 23, 23, "USED-FOR"]], [[29, 29, 30, 30, "USED-FOR"]], [[53, 53, 53, 53, "USED-FOR"], [53, 53, 53, 53, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1909.13550-29df2a33-9523-4903-b88e-169d026437a9", "sentences": [["batch", "size", "of", "256", "AdamW", "optimizer", "-LSB-", "19", "-RSB-", "with", "initial", "learn", "rate", "of", "\\", "-LRB-", "0.01", "\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "=", "0.9", ",", "\\beta", "_", "-LCB-", "2", "-RCB-", "=", "0.999", "\\", "-RRB-", "weight", "decay", "of", "\\", "-LRB-", "0.01", "\\", "-RRB-", "negative-log", "likelihood", "-LRB-", "cross", "entropy", "-RRB-", "loss", "reduce-on-plateau", "learn", "rate", "scheduler", "-LRB-", "patience", "of", "10", "epochs", "-RRB-", "with", "factor", "of", "\\", "-LRB-", "0.1", "\\", "-RRB-", "additional", "validation", "set", "is", "randomly", "extracted", "from", "the", "training", "set", "-LRB-", "5000", "samples", "-RRB-", "dropout", "with", "probability", "of", "\\", "-LRB-", "0.5", "\\", "-RRB-", "before", "the", "last", "linear", "layer", "was", "used", "in", "all", "models", "during", "training", "in", "MC", "dropout", ",", "\\", "-LRB-", "N", "=", "25", "\\", "-RRB-", "forward", "passes", "with", "dropout", "probability", "of", "\\", "-LRB-", "0.5", "\\", "-RRB-", "were", "performed"]], "ner": [[[4, 5, "a"], [10, 12, "p"], [16, 16, "v"], [44, 44, "v"], [28, 28, "v"], [36, 36, "v"], [0, 1, "a"], [39, 40, "a"], [47, 53, "a"], [54, 57, "a"], [59, 59, "p"], [61, 62, "v"], [65, 65, "p"], [69, 69, "v"], [72, 74, "a"], [86, 86, "a"], [109, 109, "a"], [121, 121, "a"], [88, 88, "p"], [122, 122, "p"], [92, 92, "v"], [126, 126, "v"], [108, 109, "a"], [113, 113, "p"], [115, 115, "v"], [121, 122, "p"], [92, 92, "v"], [126, 126, "v"]]], "relations": [[]], "predicted_ner": [[[0, 1, "p"], [3, 3, "v"], [4, 4, "a"], [11, 12, "p"], [16, 17, "v"], [28, 28, "v"], [36, 36, "v"], [39, 40, "p"], [44, 45, "v"], [53, 53, "a"], [61, 61, "v"], [62, 62, "p"], [69, 70, "v"], [83, 83, "v"], [86, 86, "a"], [92, 93, "v"], [108, 109, "a"], [115, 116, "v"], [118, 119, "a"], [126, 127, "v"]]], "predicted_relations": [[[10, 12, 4, 5, "USED-FOR"], [10, 12, 0, 1, "USED-FOR"], [16, 16, 10, 12, "USED-FOR"], [59, 59, 4, 5, "USED-FOR"], [59, 59, 0, 1, "USED-FOR"], [59, 59, 39, 40, "USED-FOR"], [59, 59, 47, 53, "USED-FOR"], [59, 59, 54, 57, "USED-FOR"], [59, 59, 72, 74, "USED-FOR"], [61, 62, 59, 59, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 113, 113, "USED-FOR"], [65, 65, 4, 5, "USED-FOR"], [65, 65, 0, 1, "USED-FOR"], [65, 65, 47, 53, "USED-FOR"], [65, 65, 54, 57, "USED-FOR"], [65, 65, 72, 74, "USED-FOR"], [88, 88, 4, 5, "USED-FOR"], [88, 88, 47, 53, "USED-FOR"], [88, 88, 54, 57, "USED-FOR"], [88, 88, 72, 74, "USED-FOR"], [122, 122, 47, 53, "USED-FOR"], [122, 122, 72, 74, "USED-FOR"], [122, 122, 86, 86, "USED-FOR"], [126, 126, 121, 122, "USED-FOR"], [113, 113, 39, 40, "USED-FOR"], [113, 113, 47, 53, "USED-FOR"], [113, 113, 54, 57, "USED-FOR"], [113, 113, 72, 74, "USED-FOR"], [115, 115, 113, 113, "USED-FOR"], [121, 122, 47, 53, "USED-FOR"], [121, 122, 72, 74, "USED-FOR"], [121, 122, 86, 86, "USED-FOR"], [121, 122, 109, 109, "USED-FOR"], [121, 122, 108, 109, "USED-FOR"], [126, 126, 121, 122, "USED-FOR"]]]}
{"doc_key": "1909.13302-538235d1-e6f6-4a4e-abdd-de10566f012f", "sentences": [["The", "detailed", "parameters", "of", "the", "model", "are", "as", "follows", ":", "Both", "of", "the", "source", "embedding", "and", "the", "target", "embeddings", "have", "512", "dimensions", "and", "use", "the", "same", "BPE", "vocabulary", "."], ["We", "share", "the", "weights", "of", "decoder", "'s", "input", "and", "output", "embeddings", "."], ["Both", "of", "the", "encoder", "and", "decoder", "have", "6", "multi-head", "layers", "and", "8", "attention", "heads", "."], ["The", "size", "of", "inner", "layer", "at", "each", "multi-head", "layer", "is", "2048", "."], ["We", "use", "Adam", "optimizer", "to", "train", "transformer", "model", "with", "the", "inverse", "squared", "root", "schedule", "which", "will", "decay", "the", "learning", "rate", "based", "on", "the", "inverse", "square", "root", "of", "the", "warm-up", "steps", "."], ["The", "learning", "rate", "initialize", "with", "\\", "-LRB-", "5", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "warm-up", "during", "the", "first", "4,000", "steps", "."], ["In", "order", "to", "train", "transformer", "adequately", ",", "we", "use", "a", "batch", "size", "of", "32,000", "tokens", "and", "fine-tune", "the", "model", "on", "labeled", "data", "for", "30,000", "steps", "."], ["Dropout", "is", "applied", "at", "a", "ratio", "of", "0.3", "."], ["The", "Loss", "function", "we", "use", "is", "the", "Edit-weighted", "MLE", "objective", "-LSB-", "18", "-RSB-", "and", "the", "factor", "\\", "-LRB-", "\\Lambda", "\\", "-RRB-", "is", "set", "to", "1.2", "."]], "ner": [[], [], [], [], [[70, 71, "a"], [86, 87, "p"]], [[100, 101, "p"]], [], [], [[164, 166, "a"], [175, 175, "p"], [181, 181, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[20, 20, "v"]], [], [[48, 48, "v"], [52, 52, "v"]], [[66, 66, "v"]], [[70, 70, "a"], [74, 75, "a"], [86, 87, "p"]], [[100, 101, "p"], [106, 106, "v"], [108, 110, "v"], [119, 119, "v"]], [[135, 135, "v"], [145, 145, "v"]], [[148, 148, "a"], [155, 155, "v"]], [[164, 166, "a"], [175, 175, "p"], [181, 181, "v"]]], "predicted_relations": [[], [], [], [], [[86, 87, 70, 71, "USED-FOR"]], [], [], [], [[175, 175, 164, 166, "USED-FOR"], [181, 181, 175, 175, "USED-FOR"]]]}
{"doc_key": "1912.11683-f933f74c-7d43-468d-a723-7d18981e27d7", "sentences": [["All", "our", "models", "are", "trained", "in", "PyTorch", "-LSB-", "28", "-RSB-", "."], ["We", "use", "the", "Adam", "optimizer", "-LSB-", "17", "-RSB-", "with", "default", "params", "and", "learning", "rates", "between", "1e-3", "and", "1e-4", "."], ["We", "anneal", "the", "learning", "rate", "once", "the", "loss", "curves", "start", "to", "plateau", "."]], "ner": [[[6, 6, "a"]], [[14, 15, "a"], [26, 26, "v"], [28, 28, "v"]], [[33, 34, "p"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"]], [[14, 14, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "v"]], [[33, 34, "p"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1912.11683-cd0eed0d-44dd-473e-951a-2ffa62448ea8", "sentences": [["We", "use", "the", "Runge-Kutta", "-LRB-", "RK-45", "-RRB-", "adaptive", "solver", "and", "the", "adjoint", "sensitivity", "method", "provided", "in", "-LSB-", "5", "-RSB-", "."], ["We", "set", "the", "relative", "error", "tolerance", "to", "zero", "and", "explore", "absolute", "error", "tolerances", "between", "1e-3", "and", "1e-5", "."]], "ner": [[[3, 8, "a"], [11, 13, "a"]], [[23, 25, "p"], [30, 32, "p"], [34, 34, "v"], [36, 36, "v"]]], "relations": [[], []], "predicted_ner": [[[11, 13, "a"]], [[27, 27, "v"], [34, 34, "v"], [36, 36, "v"]]], "predicted_relations": [[], [[34, 34, 30, 32, "USED-FOR"], [36, 36, 30, 32, "USED-FOR"]]]}
{"doc_key": "1912.11683-49a397f6-381f-423b-8301-08f0daf2dd1a", "sentences": [["The", "kidney", "segmentation", "experiments", "were", "conducted", "on", "a", "single", "NVIDIA", "DGX-1", "with", "8", "GPUs", "."], ["The", "salient", "object", "detection", "experiments", "on", "UNet", "and", "NodeUNet", "were", "conducted", "on", "a", "single", "NVIDIA", "DGX-1", "with", "8", "GPUs", ",", "and", "the", "experiments", "on", "NodeStack", "were", "conducted", "on", "4", "NVIDIA", "DGX-1", "nodes", "with", "32", "GPUs", "total", "."], ["We", "used", "the", "largest", "possible", "batch", "size", "given", "memory", "constraints", "."]], "ner": [[[9, 10, "a"]], [[29, 30, "a"], [44, 45, "a"], [21, 21, "a"], [23, 23, "a"], [39, 39, "a"]], [[57, 58, "a"], [55, 56, "p"]]], "relations": [[], [], []], "predicted_ner": [[[9, 10, "a"], [12, 12, "v"]], [[21, 21, "a"], [23, 23, "a"], [32, 32, "v"], [39, 39, "a"], [43, 43, "v"], [48, 48, "v"]], []], "predicted_relations": [[], [], [[55, 56, 57, 58, "USED-FOR"]]]}
{"doc_key": "1901.03991-3739a7d7-4ecc-40a4-9811-1a13978159bc", "sentences": [["DRAW", "We", "follow", "the", "approach", "described", "in", "-LSB-", "20", "-RSB-", "https", ":", "//github.com/ericjang/draw", "."], ["The", "model", "architecture", "as", "well", "as", "about", "the", "used", "objectives", "can", "be", "found", "in", "-LSB-", "20", "-RSB-", "."], ["We", "did", "not", "change", "any", "of", "the", "building", "blocks", "of", "draw", "and", "train", "the", "network", "as", "proposed", "with", "the", "Adam", "optimizer", ",", "the", "momentum", "set", "to", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", "."], ["The", "learning", "rate", "is", "set", "to", "0.0005", "."], ["Training", "converges", "after", "approximately", "300", "epoch", "."], ["An", "epoch", "corresponds", "to", "\\", "-LRB-", "\\frac", "-LCB-", "S_T", "-RCB-", "-LCB-", "S_B", "-RCB-", "\\", "-RRB-", "gradient", "updates", ",", "\\", "-LRB-", "S_T\\", "-RRB-", "denotes", "dataset", "size", "and", "\\", "-LRB-", "S_B\\", "-RRB-", "is", "the", "mini-batch", "size", "."], ["All", "shown", "samples", ",", "we", "generate", "from", "a", "normal", "distribution", "\\", "-LRB-", "z", "\\sim", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "0,1", "-RRB-", "\\", "-RRB-", "."], ["We", "take", "the", "same", "number", "of", "dimension", "for", "the", "latent", "space", "as", "suggested", "in", "the", "paper", ":", "\\", "-LRB-", "z", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "100", "-RCB-", "\\", "-RRB-", "."], ["In", "this", "experiment", "we", "enabled", "the", "attention", "mechanism", "and", "set", "the", "read", "and", "write", "window", "size", "to", "\\", "-LRB-", "3\\times", "3\\", "-RRB-", "and", "\\", "-LRB-", "5\\times", "5\\", "-RRB-", "respectively", "."], ["The", "number", "of", "glimpses", "or", "equivalently", "defined", "as", "time", "steps", ",", "is", "set", "to", "64", "."], ["For", "both", "recurrent", "networks", ",", "encoder", "and", "decoder", ",", "we", "choose", "the", "hidden", "vectors", "\\", "-LRB-", "h^", "-LCB-", "enc", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "h^", "-LCB-", "dec", "-RCB-", "\\", "-RRB-", "to", "have", "dimension", "256", "."]], "ner": [[[0, 0, "a"]], [], [[51, 52, "p"], [55, 55, "p"], [61, 61, "v"], [51, 52, "a"]], [[70, 70, "v"], [65, 66, "c"]], [], [], [], [[165, 165, "v"]], [[183, 185, "p"]], [[201, 203, "p"], [214, 214, "v"]], [[250, 250, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [], [[42, 42, "a"], [51, 51, "a"], [55, 55, "p"]], [[65, 66, "p"], [70, 70, "v"]], [[76, 76, "v"], [77, 77, "p"]], [], [[133, 133, "v"]], [], [[176, 177, "a"], [189, 190, "v"], [196, 196, "v"]], [[214, 214, "v"]], [[218, 219, "a"], [232, 235, "a"], [250, 250, "v"]]], "predicted_relations": [[], [], [[61, 61, 55, 55, "USED-FOR"]], [[65, 66, 70, 70, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1901.07821-e90d20a6-7342-42f8-9d37-f57ce4cee8a6", "sentences": [["where", "we", "use", "\\", "-LRB-", "\\sigma", "=", "2/L\\", "-RRB-", "."], ["Uniformly", "distributed", "noise", "\\", "-LRB-", "\\mathcal", "-LCB-", "U", "-RCB-", "-LRB-", "-\\tfrac", "-LCB-", "a", "-RCB-", "-LCB-", "2", "-RCB-", ",", "\\tfrac", "-LCB-", "a", "-RCB-", "-LCB-", "2", "-RCB-", "-RRB-", "\\", "-RRB-", "is", "added", "to", "the", "encoder", "output", "before", "it", "is", "passed", "on", "to", "the", "decoder", ",", "with", "\\", "-LRB-", "a", "=", "2", "/", "-LRB-", "L-1", "-RRB-", "\\", "-RRB-", "."]], "ner": [[], [[10, 12, "a"], [22, 22, "p"], [30, 30, "p"], [56, 56, "p"]]], "relations": [[], []], "predicted_ner": [[], []], "predicted_relations": [[], []]}
{"doc_key": "1905.04919-ab022952-6d98-4ef7-8cfc-6c9223ebf403", "sentences": [["In", "the", "searching", "stage", ",", "we", "train", "a", "small", "network", "stacked", "by", "8", "cells", "using", "BayesNAS", "with", "different", "\\", "-LRB-", "\\lambda", "_w\\", "-RRB-", "."], ["This", "network", "size", "is", "determined", "to", "fit", "into", "a", "single", "GPU", "."], ["Since", "we", "cache", "the", "feature", "maps", "in", "memory", ",", "we", "can", "only", "set", "batch", "size", "as", "18", "."], ["The", "optimizer", "we", "use", "is", "SGD", "optimizer", "with", "momentum", "0.9", "and", "fixed", "learning", "rate", "0.1", "."], ["Other", "training", "setups", "follow", "DARTS", "and", "SNAS", "-LRB-", "Appendix", "REF", "-RRB-", "."], ["The", "search", "takes", "about", "3", "hours", "on", "a", "single", "GPUAll", "the", "experiments", "were", "performed", "using", "NVIDIA", "TITAN", "V", "GPUs", "."]], "ner": [[[15, 15, "a"]], [], [], [[68, 68, "v"], [65, 67, "c"], [59, 60, "a"], [62, 62, "p"], [63, 63, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[12, 12, "v"], [15, 15, "a"]], [], [[52, 52, "v"]], [[59, 59, "a"], [63, 63, "v"], [66, 67, "p"], [68, 68, "v"]], [[74, 74, "a"], [76, 76, "a"]], [[86, 86, "v"]]], "predicted_relations": [[], [], [], [[62, 62, 59, 60, "USED-FOR"]], [], []]}
{"doc_key": "1905.04919-ed0e5069-e7d2-4ae6-9f36-7d6cc87c1954", "sentences": [["In", "the", "searching", "stage", ",", "we", "set", "batch", "size", "to", "32", "and", "learning", "rate", "to", "0.1", "."], ["We", "use", "the", "same", "optimizer", "as", "for", "proxy", "search", "."], ["The", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "of", "BayesNAS", "for", "each", "possible", "path", "is", "set", "to", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[7, 8, "a"], [12, 13, "a"]], [[21, 21, "a"]], [[34, 34, "a"]]], "relations": [[], [], []], "predicted_ner": [[[7, 8, "p"], [10, 10, "v"], [12, 13, "p"], [15, 15, "v"]], [], [[30, 30, "p"], [34, 34, "a"], [45, 47, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1905.04919-d457f23d-593d-4cf0-b4fd-2426a733a76f", "sentences": [["The", "network", "parameters", "are", "optimized", "using", "momentum", "SGD", ",", "with", "initial", "learning", "rate", "\\", "-LRB-", "\\eta", "_", "-LCB-", "\\mathbf", "-LCB-", "\\theta", "-RCB-", "-RCB-", "=", "0.1\\", "-RRB-", ",", "momentum", "0.9", ",", "and", "weight", "decay", "\\", "-LRB-", "1", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "batch", "size", "employed", "is", "16", "and", "the", "initial", "number", "of", "channels", "is", "16", "."]], "ner": [[[6, 7, "a"], [10, 12, "p"], [24, 24, "v"], [6, 6, "p"], [27, 27, "p"], [28, 28, "v"], [31, 32, "p"]], [[45, 46, "p"], [49, 49, "v"], [57, 57, "v"], [52, 55, "p"], [49, 49, "v"], [57, 57, "v"]]], "relations": [[], []], "predicted_ner": [[[6, 7, "a"], [11, 12, "p"], [24, 24, "v"], [27, 27, "p"], [28, 28, "v"], [31, 32, "p"], [35, 35, "v"]], [[45, 46, "p"], [49, 49, "v"], [57, 57, "v"]]], "predicted_relations": [[[10, 12, 6, 7, "USED-FOR"], [24, 24, 27, 27, "USED-FOR"], [6, 6, 6, 7, "USED-FOR"], [27, 27, 6, 7, "USED-FOR"], [31, 32, 6, 7, "USED-FOR"]], []]}
{"doc_key": "1905.04919-1c22d1a9-a49d-4f75-8a78-65d9213d7c7a", "sentences": [["The", "network", "is", "trained", "with", "batch", "size", "128", ",", "SGD", "optimizer", "with", "weight", "decay", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "momentum", "0.9", "and", "initial", "learning", "rate", "0.1", ",", "which", "is", "decayed", "using", "cosine", "annealing", "."]], "ner": [[[9, 10, "a"], [12, 13, "p"], [24, 24, "p"], [25, 25, "v"], [27, 29, "p"], [30, 30, "v"], [36, 37, "a"]]], "relations": [[]], "predicted_ner": [[[5, 6, "p"], [7, 7, "v"], [9, 9, "a"], [12, 13, "p"], [17, 19, "v"], [24, 24, "p"], [25, 25, "v"], [28, 29, "p"], [30, 30, "v"], [36, 37, "a"]]], "predicted_relations": [[[24, 24, 9, 10, "USED-FOR"], [25, 25, 27, 29, "USED-FOR"], [27, 29, 9, 10, "USED-FOR"], [30, 30, 27, 29, "USED-FOR"]]]}
{"doc_key": "1906.05381-ff050a4e-55f3-47a2-90ff-177e49c6d52a", "sentences": [["A", "PyTorch", "implementation", "is", "available", "-LRB-", "see", "acknowledgements", "-RRB-", "."], ["All", "experiments", "use", "the", "same", "hyperparameters", ",", "and", "many", "were", "set", "according", "to", "the", "best-performing", "seq2seq", "model", "in", "-LSB-", "15", "-RSB-", "."], ["The", "input", "and", "output", "sequence", "encoders", "are", "two-layer", "biLSTMs", "with", "\\", "-LRB-", "m=200\\", "-RRB-", "hidden", "units", "per", "layer", ",", "producing", "\\", "-LRB-", "m\\", "-RRB-", "dimensional", "embeddings", "."], ["The", "output", "decoder", "is", "a", "two-layer", "LSTM", "also", "with", "\\", "-LRB-", "m=200\\", "-RRB-", "."], ["Dropout", "is", "applied", "with", "probability", "0.5", "to", "each", "LSTM", "and", "symbol", "embedding", "."], ["A", "greedy", "decoder", "is", "effective", "due", "to", "SCAN", "'s", "determinism", "-LSB-", "15", "-RSB-", "."]], "ner": [[[1, 1, "a"]], [], [], [[65, 65, "a"]], [[77, 77, "p"], [78, 78, "v"], [81, 81, "a"], [73, 73, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[25, 26, "a"]], [[40, 40, "a"], [44, 44, "v"], [46, 47, "p"], [54, 54, "p"]], [[65, 65, "a"], [70, 70, "v"]], [[73, 73, "a"], [78, 78, "v"], [81, 81, "a"]], []], "predicted_relations": [[], [], [], [], [[77, 77, 81, 81, "USED-FOR"], [77, 77, 73, 73, "USED-FOR"]], []]}
{"doc_key": "1906.05381-0a0e73bf-15b5-4cfd-b8b9-cca7c2423dd3", "sentences": [["Networks", "are", "meta-trained", "for", "10,000", "episodes", "with", "the", "ADAM", "optimizer", "-LSB-", "14", "-RSB-", "."], ["The", "learning", "rate", "is", "reduced", "from", "0.001", "to", "0.0001", "halfway", ",", "and", "gradients", "with", "a", "\\", "-LRB-", "l_2\\", "-RRB-", "-norm", "greater", "than", "50", "are", "clipped", "."], ["With", "my", "PyTorch", "implementation", ",", "it", "takes", "less", "than", "1", "hour", "to", "train", "meta", "seq2seq", "on", "SCAN", "using", "one", "NVIDIA", "Titan", "X", "GPU", "-LRB-", "regular", "seq2seq", "trains", "in", "less", "than", "30", "minutes", "-RRB-", "."], ["All", "models", "were", "trained", "five", "times", "with", "different", "random", "initializations", "and", "random", "meta-training", "episodes", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[8, 9, "a"]], [[15, 16, "p"], [20, 20, "v"], [22, 22, "v"], [23, 23, "c"], [36, 36, "v"]], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 4, "v"], [8, 8, "a"]], [[15, 16, "p"], [20, 20, "v"], [22, 22, "v"], [36, 36, "v"]], [[49, 49, "v"], [54, 54, "a"], [56, 56, "a"], [58, 58, "v"], [65, 65, "a"], [70, 70, "v"]], [[78, 78, "v"]], []], "predicted_relations": [[], [[23, 23, 22, 22, "USED-FOR"]], [], [], []]}
{"doc_key": "1906.03221-0931b83c-d834-43fc-aad1-e2e2e660518f", "sentences": [["Model", "hyperparameters", "were", "tuned", "on", "the", "development", "set", "."], ["We", "used", "the", "Adagrad", "optimizer", "-LSB-", "7", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "0.15", ",", "decayed", "by", "0.97", "for", "every", "epoch", "after", "the", "4th", "epoch", "."], ["We", "used", "truncated", "BPTT", "-LSB-", "38", "-RSB-", "of", "length", "100", "and", "made", "use", "of", "input", "feeding", "-LSB-", "23", "-RSB-", "."], ["We", "summarize", "the", "hyperparameters", "of", "the", "RotoWire", "and", "MLB", "models", "in", "the", "Appendix", "."], ["All", "models", "were", "implemented", "on", "a", "fork", "of", "OpenNMT-py", "-LSB-", "18", "-RSB-", "."]], "ner": [[], [[12, 13, "a"], [23, 23, "v"], [25, 26, "p"], [27, 27, "v"]], [[38, 39, "a"], [44, 44, "p"], [45, 45, "v"], [50, 51, "a"]], [], [[78, 78, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"], [20, 21, "p"], [23, 23, "v"], [27, 27, "v"], [33, 33, "v"]], [[39, 39, "a"], [45, 45, "v"]], [[62, 62, "a"], [64, 64, "a"]], [[78, 78, "a"]]], "predicted_relations": [[], [[23, 23, 25, 26, "USED-FOR"], [25, 26, 12, 13, "USED-FOR"], [27, 27, 25, 26, "USED-FOR"]], [[44, 44, 38, 39, "USED-FOR"], [44, 44, 50, 51, "USED-FOR"], [45, 45, 44, 44, "USED-FOR"]], [], []]}
{"doc_key": "1908.09936-2a06315f-20da-4637-a389-e545c27001c4", "sentences": [["We", "have", "as", "trainable", "parameters", "the", "parameters", "of", "our", "Bregman", "module\u2013with", "the", "exception", "of", "the", "step", "size", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "\u2013the", "threshold", "\\", "-LRB-", "\\tau", "\\", "-RRB-", ",", "and", "the", "Bi-LSTM", "parameters", "."], ["For", "the", "initialization", "of", "the", "Bi-LSTMs", ",", "we", "used", "Xavier", "-LSB-", "5", "-RSB-", ",", "and", "a", "recurrent", "dropout", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "-LSB-", "4", "-RSB-", "."], ["They", "have", "all", "an", "input", "size", "of", "400", ",", "and", "a", "hidden", "size", "of", "200", "."], ["The", "Bregman", "module", "was", "initalized", "with", "random", "orthonormal", "matrices", "-LSB-", "16", "-RSB-", ",", "and", "with", "an", "input", "size", "of", "512", ",", "output", "size", "of", "1", ",", "and", "a", "depth", "of", "10", "."], ["The", "threshold", "is", "initialized", "to", "\\", "-LRB-", "\\tau", "=", "0.75\\", "-RRB-", ",", "and", "we", "use", "Adam", "-LSB-", "7", "-RSB-", "as", "our", "optimizer", "."], ["We", "trained", "the", "model", "for", "50", "epochs", ",", "with", "an", "early", "termination", "of", "10", "epochs", "."], ["We", "maintained", "the", "maximum", "number", "of", "hypernyms", "fixed", "at", "9", ",", "the", "depth", "of", "the", "Wordnet", "graph", "at", "2", ",", "and", "the", "features", "at", "10", "."]], "ner": [[[9, 10, "a"], [15, 16, "p"], [23, 23, "p"], [32, 32, "a"], [9, 10, "a"], [23, 23, "p"]], [[37, 37, "p"], [44, 44, "v"], [51, 52, "p"], [56, 56, "v"], [37, 37, "p"]], [[66, 67, "p"], [69, 69, "v"], [73, 74, "p"], [76, 76, "v"], [66, 67, "p"]], [[79, 80, "a"], [94, 95, "p"], [79, 80, "a"], [94, 95, "p"], [97, 97, "v"], [99, 100, "p"], [102, 102, "v"], [106, 106, "p"], [108, 108, "v"], [84, 86, "v"], [108, 108, "v"], [108, 108, "v"]], [[111, 111, "p"], [111, 111, "p"], [119, 119, "v"], [125, 125, "a"]], [[146, 146, "v"], [146, 146, "v"], [139, 139, "a"], [147, 147, "a"], [138, 138, "v"], [143, 144, "p"], [146, 146, "v"]], [[161, 161, "p"], [173, 173, "v"], [152, 155, "a"], [158, 158, "v"], [161, 165, "a"], [167, 167, "v"], [171, 171, "a"], [173, 173, "v"], [173, 173, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[32, 32, "a"]], [[40, 40, "a"], [44, 44, "a"], [51, 52, "a"], [56, 56, "v"]], [[69, 69, "v"], [76, 76, "v"]], [[79, 80, "a"], [97, 97, "v"], [102, 102, "v"], [108, 108, "v"]], [[119, 119, "v"], [125, 125, "a"]], [[136, 136, "a"], [138, 138, "v"], [139, 139, "p"], [146, 146, "v"], [147, 147, "p"]], [[158, 158, "v"], [167, 167, "v"], [173, 173, "v"]]], "predicted_relations": [[[15, 16, 9, 10, "USED-FOR"], [15, 16, 9, 10, "USED-FOR"], [23, 23, 9, 10, "USED-FOR"], [23, 23, 9, 10, "USED-FOR"], [23, 23, 9, 10, "USED-FOR"], [23, 23, 9, 10, "USED-FOR"]], [], [[69, 69, 73, 74, "USED-FOR"], [76, 76, 73, 74, "USED-FOR"]], [[102, 102, 106, 106, "USED-FOR"], [108, 108, 106, 106, "USED-FOR"], [108, 108, 106, 106, "USED-FOR"], [108, 108, 106, 106, "USED-FOR"]], [], [[143, 144, 139, 139, "USED-FOR"], [143, 144, 147, 147, "USED-FOR"]], [[161, 161, 152, 155, "USED-FOR"], [161, 161, 161, 165, "USED-FOR"], [161, 161, 171, 171, "USED-FOR"], [158, 158, 161, 161, "USED-FOR"], [167, 167, 161, 161, "USED-FOR"]]]}
{"doc_key": "1906.01543-e2f55f0a-4b3f-424b-bdc5-7e075636047d", "sentences": [["All", "input", "text", "is", "lower-cased", "and", "tokenised", ",", "numbers", "with", "5", "or", "more", "digits", "get", "their", "digits", "replaced", "by", "a", "wildcard", "symbol", "#", ",", "while", "words", "longer", "than", "16", "characters", "are", "replaced", "by", "a", "wildcard", "token", "LONGWORD", "."], ["Sentence", "boundary", "tokens", "<", "S", ">", "and", "<", "/S", ">", "are", "added", "to", "each", "sentence", "."], ["The", "vocabulary", "consists", "of", "the", "unigrams", "that", "occur", "at", "least", "10", "times", "in", "a", "random", "1M", "subset", "of", "the", "Reddit", "training", "set", "\u2013this", "results", "in", "a", "total", "of", "105K", "unigrams\u2013", "plus", "the", "200K", "most", "frequent", "bigrams", "in", "the", "same", "random", "subset", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[10, 10, "v"], [28, 28, "v"]], [], [[64, 64, "v"], [69, 69, "v"], [73, 73, "a"], [82, 82, "v"], [86, 86, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1906.01543-09979c45-0867-42eb-a1ec-1ba8c4a31dc8", "sentences": [["The", "following", "training", "setup", "refers", "to", "the", "final", "Reddit", "model", ",", "illustrated", "in", "Figure", "REF", ",", "and", "used", "in", "fine-tuning", "."], ["The", "model", "is", "trained", "by", "SGD", "setting", "the", "initial", "learning", "rate", "to", "0.03", ",", "and", "then", "decaying", "the", "learning", "rate", "by", "0.3x", "every", "1M", "training", "steps", "after", "the", "first", "2.5M", "steps", "."], ["Similar", "to", "learning", "rate", "scaling", "by", "the", "batch", "size", "used", "in", "prior", "work", "-LSB-", "18", "-RSB-", ",", "-LSB-", "12", "-RSB-", ",", "we", "scale", "the", "unigram", "and", "bigram", "embedding", "gradients", "by", "the", "batch", "size", "."], ["The", "batch", "size", "is", "500", ",", "and", "attention", "projection", "dimensionality", "is", "64", "."]], "ner": [[], [[26, 26, "a"], [29, 31, "p"], [33, 33, "v"], [42, 42, "v"], [43, 51, "c"]], [[60, 61, "p"], [84, 85, "p"], [55, 57, "a"]], [[88, 89, "p"], [91, 91, "v"], [94, 96, "p"], [98, 98, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 9, "a"]], [[26, 26, "a"], [30, 31, "p"], [33, 33, "v"], [39, 40, "p"], [42, 42, "v"], [44, 44, "v"], [50, 50, "v"]], [[55, 56, "p"], [60, 61, "p"], [84, 85, "p"]], [[88, 89, "p"], [91, 91, "v"], [98, 98, "v"]]], "predicted_relations": [[], [[29, 31, 26, 26, "USED-FOR"], [33, 33, 29, 31, "USED-FOR"], [43, 51, 33, 33, "USED-FOR"], [43, 51, 42, 42, "USED-FOR"]], [], [[91, 91, 88, 89, "USED-FOR"], [98, 98, 94, 96, "USED-FOR"]]]}
{"doc_key": "1906.01502-e4ca43fa-2ed9-43f3-bdac-88ae7edf7dba", "sentences": [["All", "models", "were", "fine-tuned", "with", "a", "batch", "size", "of", "32", ",", "and", "a", "maximum", "sequence", "length", "of", "128", "for", "3", "epochs", "."], ["We", "used", "a", "learning", "rate", "of", "\\", "-LRB-", "3\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "with", "learning", "rate", "warmup", "during", "the", "first", "\\", "-LRB-", "10\\", "%", "\\", "-RRB-", "of", "steps", ",", "and", "linear", "decay", "afterwards", "."], ["We", "also", "applied", "\\", "-LRB-", "10\\", "%", "\\", "-RRB-", "dropout", "on", "the", "last", "layer", "."], ["No", "parameter", "tuning", "was", "performed", "."], ["We", "used", "the", "BERT-Base", ",", "Multilingual", "Cased", "checkpoint", "from", "https", ":", "//github.com/google-research/bert", "."]], "ner": [[], [[25, 26, "a"], [40, 41, "a"], [40, 42, "a"], [56, 57, "a"]], [[69, 69, "a"]], [], [[84, 87, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 7, "p"], [9, 9, "v"], [17, 17, "v"], [19, 19, "v"], [20, 20, "p"]], [[25, 26, "p"], [30, 36, "v"], [48, 49, "v"], [56, 57, "a"]], [[65, 66, "v"], [69, 69, "a"]], [], [[84, 84, "a"], [86, 88, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1906.01363-54d8e7c8-df69-41e5-b65e-78e1cc02a475", "sentences": [["We", "did", "a", "train", ":", "validation", ":", "test", "split", "as", "70:20:10", ",", "stratified", "on", "the", "basis", "of", "the", "number", "of", "classes", "corresponding", "to", "each", "input", "."], ["Adam", "optimizer", "with", "a", "learning", "rate", "of", "5x\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "is", "used", "."], ["Training", "is", "done", "on", "batches", ",", "with", "a", "batch", "size", "of", "64", ",", "and", "is", "continued", "for", "600", "epochs", "."], ["The", "model", "used", "for", "testing", "is", "the", "one", "saved", "at", "the", "epoch", "with", "the", "highest", "validation", "accuracy", "."]], "ner": [[[3, 8, "a"], [10, 10, "v"]], [[26, 27, "a"], [30, 31, "p"]], [[52, 53, "a"], [62, 62, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[26, 27, "a"], [30, 31, "p"], [35, 37, "v"]], [[52, 53, "p"], [55, 55, "v"], [61, 61, "v"], [62, 62, "p"]], [[71, 71, "v"]]], "predicted_relations": [[], [[30, 31, 26, 27, "USED-FOR"]], [], []]}
{"doc_key": "1905.03721-bd18a0b3-40ca-4c5a-acec-0fd4f42109d4", "sentences": [["All", "RNNs", "used", "as", "encoder", "or", "decoder", "are", "2-layer", "LSTMs", "with", "300-dimensional", "hidden", "states", "."], ["Action", "predictor", "and", "price", "decoder", "networks", "have", "the", "same", "network", "architecture", ",", "a", "4-layer", "fully-connected", "network", "with", "ReLU", "activation", "functions", "."], ["We", "also", "applied", "a", "dropout", "with", "a", "rate", "of", "0.3", "to", "all", "parts", "of", "our", "architecture", "."]], "ner": [[[1, 1, "a"], [8, 8, "v"], [9, 9, "a"], [11, 11, "v"]], [[29, 30, "a"], [28, 28, "v"], [32, 32, "v"]], [[40, 40, "a"], [43, 43, "p"], [45, 45, "v"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [8, 8, "v"], [9, 9, "a"], [11, 11, "v"], [11, 13, "p"]], [[28, 28, "v"], [29, 30, "a"], [32, 32, "a"]], [[40, 40, "a"], [45, 45, "v"]]], "predicted_relations": [[], [], [[43, 43, 40, 40, "USED-FOR"]]]}
{"doc_key": "1905.03721-1633c23a-a0b8-47ce-bac7-0fce3cf08b1b", "sentences": [["Parameters", "of", "the", "models", "are", "optimised", "using", "Adam", "with", "the", "learning", "rate", "set", "to", "1e-3", "in", "first", "20", "epochs", "and", "then", "decayed", "to", "1e-4", "for", "another", "320", "epochs", "."], ["The", "batch", "size", "is", "set", "to", "128", "in", "all", "experiments", "."]], "ner": [[[7, 7, "a"], [10, 11, "p"], [14, 14, "v"], [15, 18, "c"], [23, 23, "v"], [24, 27, "c"]], [[30, 31, "p"], [35, 35, "v"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "a"], [10, 11, "p"], [14, 14, "v"], [17, 17, "v"], [18, 18, "p"], [23, 23, "v"], [26, 26, "v"], [27, 27, "p"]], [[30, 31, "p"], [35, 35, "v"], [36, 38, "c"]]], "predicted_relations": [[[10, 11, 7, 7, "USED-FOR"], [14, 14, 10, 11, "USED-FOR"], [15, 18, 14, 14, "USED-FOR"], [15, 18, 23, 23, "USED-FOR"], [24, 27, 23, 23, "USED-FOR"]], []]}
{"doc_key": "1905.03721-1e95f460-c184-44a6-8584-15dfd4f422af", "sentences": [["Except", "for", "hierarchical", "dialogue", "encoder", "and", "the", "language", "decoder", "which", "are", "trained", "together", ",", "we", "trained", "other", "modules", "separately", "during", "the", "supervised", "learning", "process", "."], ["Afterwards", ",", "for", "RL", ",", "we", "only", "optimised", "the", "action", "predictor", "and", "price", "decoder", "parameters", "for", "5000", "episodes", "using", "a", "learning", "rate", "of", "1e-4", "."]], "ner": [[[2, 4, "a"], [7, 8, "a"], [21, 23, "a"]], [[28, 28, "a"], [34, 35, "a"], [45, 46, "p"], [48, 48, "v"]]], "relations": [[], []], "predicted_ner": [[], [[41, 41, "v"], [45, 46, "p"], [48, 48, "v"]]], "predicted_relations": [[], [[45, 46, 28, 28, "USED-FOR"], [45, 46, 34, 35, "USED-FOR"], [48, 48, 45, 46, "USED-FOR"]]]}
{"doc_key": "1907.04666-a4c6cba4-f6b4-43b8-80e7-8613042b248a", "sentences": [["We", "describe", "here", "the", "hyperparameters", "used", "to", "train", "the", "models", "."], ["The", "autoencoders", "are", "constituted", "of", "one", "layer", "of", "100", "LSTM", "neurons", "for", "the", "encoder", "and", "the", "decoder", "."], ["For", "the", "KISSME", "version", ",", "the", "encodings", "are", "then", "projected", "into", "a", "50-dimensional", "space", ",", "and", "the", "distance", "matrix", ",", "which", "thus", "has", "also", "dimension", "50", ",", "was", "updated", "with", "the", "closed-form", "every", "30", "epochs", "."], ["These", "parameters", "were", "determined", "after", "preliminary", "tests", "where", "deeper", "architectures", "and", "higher", "dimensional", "spaces", "were", "tested", "."], ["Models", "are", "trained", "with", "20", "similar", "pairs", "for", "each", "time", "slot", "and", "the", "same", "total", "number", "of", "dissimilar", "pairs", "for", "a", "total", "of", "960", "training", "pairs", "coming", "from", "12", "different", "days", "of", "data", "."], ["The", "training", "was", "stopped", "based", "on", "the", "loss", "computed", "on", "the", "validation", "set", "which", "contains", "three", "days", "of", "data", "i.e.", ",", "72", "sequences", "."], ["The", "testing", "set", "is", "composed", "of", "15", "days", "or", "360", "sequences", "."], ["The", "data", "in", "the", "training", "set", "were", "rescaled", "between", "-1", "and", "1", "and", "the", "same", "parameters", "were", "applied", "on", "the", "validation", "and", "testing", "sets", "."], ["A", "learning", "rate", "of", "0.001", "was", "used", "and", "divided", "by", "10", "if", "the", "loss", "did", "not", "decrease", "anymore", "during", "10", "epochs", "."], ["A", "batch", "size", "of", "50", ",", "a", "margin", "of", "1", "for", "the", "contrastive", "loss", "and", "of", "0.5", "for", "the", "cosine", "loss", "were", "chosen", "."], ["We", "also", "observed", "that", "changing", "to", "zero", "30", "%", "of", "the", "values", "of", "the", "training", "sequences", "sliglty", "improved", "the", "results", "as", "suggested", "in", "-LSB-", "27", "-RSB-", "."]], "ner": [[], [[19, 21, "v"]], [[41, 42, "v"], [31, 31, "a"], [41, 41, "v"], [41, 41, "v"], [54, 54, "v"]], [], [[86, 86, "v"], [105, 105, "v"], [109, 114, "c"]], [[137, 138, "v"]], [[149, 150, "v"]], [[161, 161, "v"], [163, 163, "v"]], [[181, 181, "v"]], [[203, 203, "v"], [208, 208, "v"], [215, 215, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"], [16, 16, "v"], [19, 19, "v"], [20, 20, "a"]], [[31, 31, "a"], [41, 41, "v"], [54, 54, "v"], [62, 62, "v"]], [], [[86, 86, "v"], [105, 105, "v"], [110, 110, "v"]], [[131, 131, "v"], [137, 137, "v"]], [[146, 146, "v"], [149, 149, "v"]], [[161, 161, "v"], [163, 163, "v"]], [[178, 179, "p"], [181, 181, "v"], [187, 187, "v"], [196, 196, "v"], [197, 197, "p"]], [[200, 201, "p"], [203, 203, "v"], [208, 208, "v"], [211, 212, "a"], [215, 215, "v"], [218, 219, "a"]], [[229, 229, "v"], [230, 231, "v"]]], "predicted_relations": [[], [], [], [], [[109, 114, 86, 86, "USED-FOR"], [109, 114, 105, 105, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "1910.02366-05cca19e-897f-47df-9f0f-364b14bcef00", "sentences": [["We", "treat", "the", "filters", "as", "the", "neurons", "to", "split", "for", "convolutional", "neural", "networks", "."], ["For", "example", ",", "consider", "a", "convolutional", "layer", "with", "\\", "-LRB-", "n_", "-LCB-", "out", "-RCB-", "\\times", "n_", "-LCB-", "in", "-RCB-", "\\times", "k", "\\times", "k\\", "-RRB-", "parameters", ",", "where", "\\", "-LRB-", "n_", "-LCB-", "out", "-RCB-", "\\", "-RRB-", "denotes", "the", "number", "of", "output", "channels", "and", "\\", "-LRB-", "n_", "-LCB-", "in", "-RCB-", "\\", "-RRB-", "the", "number", "of", "input", "channels", "and", "\\", "-LRB-", "k\\", "-RRB-", "the", "filter", "size", "."], ["We", "treat", "it", "as", "\\", "-LRB-", "n_", "-LCB-", "out", "-RCB-", "\\", "-RRB-", "neurons", ",", "and", "each", "neuron", "has", "a", "parameter", "of", "size", "\\", "-LRB-", "n_", "-LCB-", "in", "-RCB-", "\\times", "k", "\\times", "k\\", "-RRB-", "."], ["To", "apply", "our", "methods", ",", "we", "start", "with", "a", "small", "variant", "of", "the", "MobileNet", "and", "VGG19", ",", "and", "gradually", "grow", "the", "network", "by", "splitting", "the", "-LRB-", "convolutional", "-RRB-", "neurons", "with", "the", "most", "negative", "splitting", "indexes", "following", "Algorithm", "REF", "."], ["For", "MobileNet", ",", "we", "construct", "the", "initial", "network", "by", "keeping", "the", "size", "of", "the", "first", "convolution", "layer", "as", "the", "same", "-LRB-", "=32", "-RRB-", "as", "the", "original", "MobileNet", "and", "setting", "the", "number", "of", "depthwise", "and", "pointwise", "channels", "to", "be", "16", "."], ["For", "VGG19", ",", "we", "set", "the", "number", "of", "channels", "of", "the", "initial", "network", "to", "be", "16", "for", "all", "layers", "."]], "ner": [[[10, 12, "a"]], [[51, 54, "p"], [65, 68, "p"], [75, 76, "p"], [34, 34, "v"], [36, 36, "v"], [72, 72, "v"]], [[107, 107, "v"], [109, 109, "v"]], [[125, 125, "a"], [127, 127, "a"], [148, 149, "a"]], [[152, 152, "a"], [177, 177, "a"], [172, 172, "v"], [181, 186, "p"], [189, 189, "v"], [189, 189, "v"]], [[206, 206, "v"], [192, 192, "a"], [197, 203, "p"], [206, 206, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[34, 34, "p"], [36, 36, "p"]], [[107, 107, "p"]], [[125, 125, "a"], [127, 127, "a"]], [[152, 152, "a"], [172, 172, "v"], [177, 177, "a"], [189, 189, "v"]], [[192, 192, "a"], [206, 206, "v"]]], "predicted_relations": [[], [[72, 72, 65, 68, "USED-FOR"]], [], [], [[181, 186, 152, 152, "USED-FOR"], [181, 186, 177, 177, "USED-FOR"]], [[197, 203, 192, 192, "USED-FOR"]]]}
{"doc_key": "1910.02366-91b04673-e188-4446-9e23-d22679a3e1d8", "sentences": [["We", "start", "with", "a", "very", "narrow", "network", "and", "progressively", "grow", "it", "using", "splitting", "steepest", "descent", "."], ["We", "build", "our", "initial", "narrow", "network", "based", "on", "the", "DS-CNN", "architecture", "proposed", "in", "-LSB-", "28", "-RSB-", ",", "by", "reducing", "the", "number", "of", "channels", "in", "each", "layer", "to", "16", "."], ["The", "backbone", "DS-CNN", "model", "consists", "of", "one", "regular", "convolution", "layer", "and", "five", "depthwise", "and", "pointwise", "convolution", "layers", "-LSB-", "9", "-RSB-", "."], ["We", "refer", "the", "reader", "to", "-LSB-", "28", "-RSB-", "for", "more", "information", "."], ["At", "each", "splitting", "stage", ",", "we", "increase", "the", "number", "of", "channels", "by", "a", "percentage", "of", "30", "%", "using", "the", "approach", "described", "in", "Algorithm", "REF", "."], ["We", "use", "the", "same", "hyper-parameters", "for", "training", "and", "evaluation", "as", "in", "-LSB-", "28", "-RSB-", "."]], "ner": [[[12, 14, "a"]], [[25, 26, "a"]], [], [], [], [[107, 107, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[25, 25, "a"], [43, 43, "v"]], [[47, 48, "a"], [51, 51, "v"], [56, 56, "v"]], [], [[93, 94, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1912.00042-bdfeaf50-053f-478c-94f1-21c6103f6889", "sentences": [["We", "train", "on", "ImageNet32", "and", "ImageNet64", "for", "\\", "-LRB-", "200,000\\", "-RRB-", "iterations", "with", "mini", "batches", "of", "size", "64", ",", "and", "a", "learning", "rate", "of", "0.0001", "using", "the", "Adam", "optimizer", "-LSB-", "21", "-RSB-", "."], ["The", "high-resolution", "image", "\\", "-LRB-", "x_", "-LCB-", "hr", "-RCB-", "\\", "-RRB-", "either", "the", "original", "\\", "-LRB-", "32", "\\times", "32\\", "-RRB-", "or", "\\", "-LRB-", "64", "\\times", "64\\", "-RRB-", "original", "input", "images", "."], ["The", "flow", "architecture", "is", "build", "with", "\\", "-LRB-", "L=2\\", "-RRB-", "levels", "and", "\\", "-LRB-", "K=8\\", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[3, 3, "a"], [5, 5, "a"], [27, 28, "a"], [21, 22, "p"], [24, 24, "v"]], [], [[65, 66, "a"], [72, 72, "p"], [72, 72, "v"], [78, 78, "p"], [78, 78, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [9, 9, "v"], [17, 17, "v"], [21, 22, "p"], [24, 24, "v"], [27, 27, "a"]], [[49, 49, "v"], [51, 51, "v"], [56, 56, "v"], [58, 58, "v"]], [[72, 72, "v"], [78, 78, "v"]], []], "predicted_relations": [[[21, 22, 3, 3, "USED-FOR"], [21, 22, 5, 5, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [], [[72, 72, 65, 66, "USED-FOR"], [72, 72, 72, 72, "USED-FOR"], [72, 72, 72, 72, "USED-FOR"], [78, 78, 65, 66, "USED-FOR"], [78, 78, 78, 78, "USED-FOR"], [78, 78, 72, 72, "USED-FOR"], [78, 78, 78, 78, "USED-FOR"]], []]}
{"doc_key": "1902.09631-87518038-1fa3-4240-b3af-78664c976dd7", "sentences": [["Optimization", "was", "performed", "with", "the", "adam", "-LSB-", "20", "-RSB-", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.0002\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1=0.5\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.9\\", "-RRB-", "."], ["Gradient", "descent", "was", "alternated", "between", "generator", "and", "discriminator", ",", "with", "the", "discriminator", "receiving", "real", "and", "generated", "images", "in", "distinct", "batches", "."]], "ner": [[[12, 13, "p"], [17, 17, "v"], [23, 23, "v"], [29, 29, "v"]], []], "relations": [[], []], "predicted_ner": [[[5, 5, "a"], [12, 13, "p"], [17, 17, "v"], [23, 23, "v"], [29, 29, "v"]], [[32, 33, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1912.07183-c1d36516-dfe8-4852-8a75-334f4d41d117", "sentences": [["Our", "training", "setup", "is", "similar", "to", "Edge-connect", "-LSB-", "17", "-RSB-", "."], ["PyTorch", "is", "used", "for", "implementation", "."], ["All", "models", "are", "trained", "using", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "images", "with", "a", "batch", "size", "of", "eight", "."], ["The", "Adam", "optimiser", "with", "\\", "-LRB-", "\\beta", "_1", "=", "0\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2", "=", "0.9\\", "-RRB-", "is", "used", "."], ["The", "initial", "learning", "rate", "of", "generator", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["It", "is", "divided", "by", "10", "when", "the", "generator", "loss", "value", "stops", "decreasing", "."], ["In", "total", ",", "the", "learning", "rate", "is", "divided", "by", "10", "twice", "."], ["As", "we", "used", "a", "WGAN", ",", "the", "learning", "rate", "of", "the", "discriminator", "is", "five", "times", "that", "of", "generator", "."], ["In", "large", "datasets", "the", "convergence", "appears", "within", "200,000", "steps", ",", "while", "in", "small", "datasets", "the", "final", "convergence", "appears", "within", "85,000", "steps", "."]], "ner": [[], [], [], [[37, 38, "a"], [45, 45, "v"], [53, 53, "v"], [53, 53, "v"]], [[59, 61, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[11, 11, "a"]], [[24, 24, "v"], [26, 26, "v"], [31, 32, "p"], [34, 34, "v"]], [[43, 45, "v"], [53, 53, "v"]], [[60, 61, "p"], [69, 72, "v"]], [[80, 80, "v"]], [[93, 94, "p"], [98, 98, "v"]], [[105, 105, "a"], [108, 109, "p"], [114, 114, "v"]], [[127, 127, "v"], [139, 139, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "1905.10464-5005c734-07cc-40c0-88c3-7f1bef9573e3", "sentences": [["We", "trained", "the", "word2vec", "modelWe", "train", "using", "https", ":", "//github.com/tmikolov/word2vec", "."], ["using", "the", "CBOW", "algorithm", "with", "window", "size", "of", "10", ",", "negative", "sampling", "of", "10", ",", "and", "minimum", "count", "of", "10", ";", "the", "GloVe", "modelWe", "train", "using", "https", ":", "//github.com/stanfordnlp/GloVe", "."], ["with", "windows", "size", "of", "10", "and", "minimum", "count", "of", "10", ";", "and", "the", "FastText", "modelWe", "train", "using", "https", ":", "//github.com/facebookresearch/fastText", "."], ["using", "the", "CBOW", "algorithm", "with", "word", "n-gram", "of", "5", ",", "window", "size", "of", "5", ",", "and", "negative", "sampling", "of", "10", "."]], "ner": [[[3, 3, "a"], [9, 9, "a"]], [[14, 14, "p"], [13, 13, "v"], [16, 17, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"], [21, 22, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"], [27, 28, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"], [33, 33, "a"], [39, 39, "a"], [16, 17, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"], [27, 28, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"], [14, 14, "p"], [13, 13, "v"], [16, 17, "p"], [21, 22, "p"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"]], [[45, 45, "v"], [50, 50, "v"], [45, 45, "v"], [50, 50, "v"], [47, 48, "p"], [45, 45, "v"], [50, 50, "v"], [45, 45, "v"], [50, 50, "v"], [47, 48, "p"], [45, 45, "v"], [50, 50, "v"], [54, 54, "a"], [45, 45, "v"], [50, 50, "v"]], [[65, 65, "p"], [64, 64, "v"], [72, 73, "p"], [81, 81, "v"], [78, 79, "p"], [81, 81, "v"], [81, 81, "v"], [72, 73, "p"], [81, 81, "v"], [81, 81, "v"], [65, 65, "p"], [64, 64, "v"], [67, 68, "p"], [70, 70, "v"], [75, 75, "v"], [72, 73, "p"], [70, 70, "v"], [75, 75, "v"], [78, 79, "p"], [81, 81, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[13, 14, "a"], [19, 19, "v"], [24, 24, "v"], [30, 30, "v"]], [[45, 45, "v"], [50, 50, "v"]], [[64, 65, "a"], [70, 70, "v"], [75, 75, "v"], [81, 81, "v"]]], "predicted_relations": [[], [[13, 13, 14, 14, "USED-FOR"], [13, 13, 14, 14, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [13, 13, 14, 14, "USED-FOR"], [13, 13, 14, 14, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"], [30, 30, 27, 28, "USED-FOR"]], [[45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"]], [[64, 64, 65, 65, "USED-FOR"], [64, 64, 65, 65, "USED-FOR"], [64, 64, 65, 65, "USED-FOR"], [64, 64, 65, 65, "USED-FOR"]]]}
{"doc_key": "1903.09171-1ed175bc-6ff8-421d-8c76-88b9c254099c", "sentences": [["To", "initialize", "the", "model", "structure", ",", "the", "only", "information", "required", "is", "the", "number", "and", "types", "of", "inputs", "and", "outputs", "together", "with", "their", "corresponding", "dimensions", "."], ["In", "our", "case", ",", "we", "can", "define", "\\", "-LRB-", "I=\\lbrace", "i_0\\rbrace", "\\", "-RRB-", "and", "\\", "-LRB-", "O=\\lbrace", "o_0", ",", "o_1", ",", "o_2\\rbrace", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "i_0=", "-LRB-", "v_", "-LCB-", "i_0", "-RCB-", ",", "t_", "-LCB-", "i_o", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "\\", "-LRB-", "|v_", "-LCB-", "i_0", "-RCB-", "|", "=", "28\\times", "28=784\\", "-RRB-", "and", "\\", "-LRB-", "t_", "-LCB-", "i_0", "-RCB-", "=", "\\text", "-LCB-", "Numeric", "-RCB-", "\\", "-RRB-", "."], ["\\", "-LRB-", "o_0=", "-LRB-", "\\psi", "_0", ",", "f_", "-LCB-", "o_0", "-RCB-", "-RRB-", "\\", "-RRB-", "where", "\\", "-LRB-", "|\\psi", "_0^0|=32\\", "-RRB-", ",", "and", "\\", "-LRB-", "t_", "-LCB-", "\\psi", "_0^0", "-RCB-", "=\\text", "-LCB-", "Numeric", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "o_1=", "-LRB-", "\\psi", "_1", ",", "f_", "-LCB-", "o_1", "-RCB-", "-RRB-", "\\", "-RRB-", "where", "\\", "-LRB-", "|\\psi", "_1^0|=10\\", "-RRB-", ",", "and", "\\", "-LRB-", "t_", "-LCB-", "\\psi", "_1^0", "-RCB-", "=\\text", "-LCB-", "Discrete", "-RCB-", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "o_2=", "-LRB-", "\\psi", "_2", ",", "f_", "-LCB-", "o_2", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "|\\psi", "_2^0|=28\\times", "28=784\\", "-RRB-", "and", "\\", "-LRB-", "t_", "-LCB-", "\\psi", "_2^0", "-RCB-", "=\\text", "-LCB-", "Samples", "-RCB-", "\\", "-RRB-", "."], ["\\", "-LRB-", "f_", "-LCB-", "o_0", "-RCB-", "=f_", "-LCB-", "o_1", "-RCB-", "=f_", "-LCB-", "o_2", "-RCB-", "=\\Lambda", "\\", "-RRB-", "."]], "ner": [[[3, 4, "a"], [12, 18, "p"]], [], [], [[206, 218, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [], []], "predicted_relations": [[[12, 18, 3, 4, "USED-FOR"]], [], [], []]}
{"doc_key": "1902.02502-9901dab9-6d5d-4609-b750-5b95620c81b9", "sentences": [["Latent", "representations", "\\", "-LRB-", "s_", "-LCB-", "k", "-RCB-", "\\", "-RRB-", "can", "be", "updated", "by", "either", "gradient", "descent", "with", "a", "learnable", "learning", "rate", "or", "an", "RNN", "which", "imitate", "the", "behavior", "of", "gradient", "descent", "."], ["For", "the", "sake", "of", "notational", "simplicity", ",", "outputs", "of", "the", "neural", "networks", "\\", "-LRB-", "f_", "-LCB-", "\\phi", "-RCB-", "-LRB-", "s_k", "-RRB-", "_m\\", "-RRB-", "and", "\\", "-LRB-", "g_", "-LCB-", "\\psi", "-RCB-", "-LRB-", "s_k", "-RRB-", "\\", "-RRB-", "are", "denoted", "by", "\\", "-LRB-", "f_", "-LCB-", "k", ",", "m", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "g_k\\", "-RRB-", ",", "respectively", "."], ["If", "using", "gradient", "descent", "as", "the", "update", "rule", ",", "latent", "representations", "\\", "-LRB-", "s_k\\", "-RRB-", "with", "\\", "-LRB-", "1", "\\le", "k", "<", "K\\", "-RRB-", "are", "updated", "by", "\\", "-LRB-", "s_k^", "-LCB-", "-LRB-", "t+1", "-RRB-", "-RCB-", "=", "s_k^", "-LCB-", "-LRB-", "t", "-RRB-", "-RCB-", "+", "\\eta", "_s", "\\sum", "_", "-LCB-", "m", "-RCB-", "\\Big", "-LRB-", "\\gamma", "_", "-LCB-", "m", ",", "k", "-RCB-", "^", "-LCB-", "-LRB-", "t", "-RRB-", "-RCB-", "\\frac", "-LCB-", "\\partial", "\\log", "-LCB-", "p_", "-LCB-", "m", ",", "k", "-RCB-", "-RCB-", "-RCB-", "-LCB-", "\\partial", "g_k", "-RCB-", "\\frac", "-LCB-", "\\partial", "g_k", "-RCB-", "-LCB-", "\\partial", "s_k", "-RCB-", "\\\\+", "\\sum", "_", "-LCB-", "k^", "-LCB-", "\\prime", "-RCB-", "\\ge", "k", "-RCB-", "-LCB-", "\\gamma", "_", "-LCB-", "m", ",", "k^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "^", "-LCB-", "-LRB-", "t", "-RRB-", "-RCB-", "\\frac", "-LCB-", "\\partial", "\\log", "-LCB-", "\\pi", "_", "-LCB-", "m", ",", "k^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "-RCB-", "-RCB-", "-LCB-", "\\partial", "f_", "-LCB-", "k", ",", "m", "-RCB-", "-RCB-", "\\frac", "-LCB-", "\\partial", "f_", "-LCB-", "k", ",", "m", "-RCB-", "-RCB-", "-LCB-", "\\partial", "s_k", "-RCB-", "-RCB-", "\\Big", "-RRB-", "\\bigg", "|_", "-LCB-", "s_k", "=", "s_k^", "-LCB-", "-LRB-", "t", "-RRB-", "-RCB-", "-RCB-", "\\", "-RRB-"]], "ner": [[[24, 24, "a"]], [], []], "relations": [[], [], []], "predicted_ner": [[[15, 16, "a"], [24, 24, "a"], [30, 31, "a"]], [], [[91, 92, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1902.02441-4ff62c1e-88b5-433f-9e35-03e71d6dd24a", "sentences": [["Due", "to", "limited", "compute", "resources", ",", "a", "full", "hyperparameter", "search", "was", "not", "feasible", "."], ["A", "few", "parameters", "were", "evaluated", "during", "training", "for", "24", "hours", "each", "."], ["Discount", "factors", "between", "0.95", "and", "0.99", "were", "evaluated", "."], ["Trials", "showed", "the", "agent", "learned", "to", "walk", "faster", "using", "a", "value", "range", "of", "-LSB-", "0.96", ",", "0.976", "-RSB-", "."], ["Different", "rates", "of", "learning", "rate", "per", "step", "were", "evaluated", "."], ["Evaluating", "mini-batch", "sizes", "from", "32", "to", "128", "showed", "that", "a", "higher", "value", "was", "more", "beneficial", "."]], "ner": [[[8, 9, "a"]], [], [[29, 29, "v"], [31, 31, "v"]], [[45, 46, "p"]], [[57, 60, "p"]], [[65, 66, "p"], [68, 68, "v"], [70, 70, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[22, 22, "v"]], [[26, 27, "p"], [29, 29, "v"], [31, 31, "v"]], [[49, 49, "v"], [51, 51, "v"]], [[57, 58, "p"]], [[68, 68, "v"], [70, 70, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1908.11503-c87f2360-3459-482e-89b7-badd9373a462", "sentences": [["Our", "aggregate", "network", "applies", "2", "search", "depth", "-LRB-", "i.e.", ",", "2-hops", "-RRB-", "with", "output", "dimension", "of", "1024", "and", "512", ",", "respectively", "."], ["We", "perform", "batch", "normalization", "after", "each", "output", "layer", ",", "followed", "with", "ReLU", "activation", "function", "."], ["As", "for", "multi-head", "attention", "module", ",", "two", "dense", "layers", "respectively", "followed", "by", "tanh", "and", "LeakyReLU", "-LSB-", "43", "-RSB-", "activations", "are", "developed", "for", "both", "class-level", "and", "instance-level", "attention", "."], ["In", "the", "relation", "kernel", "module", ",", "we", "use", "a", "two-layer", "MLP", "with", "batch", "normalization", "and", "ReLU", "activation", "for", "adjacency", "matrix", "building", ",", "whose", "input", "and", "output", "dimensions", "are", "consistent", "with", "the", "output", "of", "the", "aggregate", "network", "and", "adjacency", "matrix", "size", ",", "respectively", "."], ["GCN", "module", "is", "composed", "of", "2", "graph", "convolutional", "layers", "with", "output", "channel", "dimensionality", "of", "512", "and", "128", ",", "respectively", "."], ["Our", "whole", "TGG", "model", "is", "trained", "end-to-end", "via", "ADAM", "-LSB-", "20", "-RSB-", "optimizer", "with", "learning", "rate", "0.001", "and", "weight", "decay", "0.0005", "."], ["The", "batch", "size", "is", "set", "to", "be", "128", "for", "all", "datasets", "and", "we", "use", "validation", "sets", "for", "early", "stopping", "."], ["Both", "\\", "-LRB-", "\\lambda", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_2\\", "-RRB-", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "are", "set", "to", "be", "0.5", "."], ["We", "implement", "our", "TGG", "by", "PyTorchhttps", ":", "//pytorch.org/", "and", "the", "source", "code", "of", "our", "work", "is", "available", "at", ":", "https", ":", "//github.com/zcrwind/tgg-pytorch", "."]], "ner": [[[18, 18, "v"]], [[33, 33, "a"], [24, 25, "a"]], [[51, 51, "a"], [49, 49, "a"], [39, 40, "a"]], [[80, 80, "a"], [77, 78, "a"], [67, 68, "a"], [74, 75, "a"]], [[108, 108, "a"], [118, 120, "p"], [122, 122, "v"], [124, 124, "v"]], [[136, 136, "a"], [142, 143, "p"], [144, 144, "v"], [146, 147, "p"], [148, 148, "v"]], [[157, 157, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "v"], [16, 16, "v"], [18, 18, "v"]], [[24, 25, "a"], [33, 33, "a"]], [[43, 43, "v"], [49, 49, "a"], [51, 51, "a"]], [[75, 75, "a"], [77, 78, "a"], [80, 81, "a"]], [[108, 108, "a"], [113, 113, "v"], [122, 122, "v"], [124, 124, "v"]], [[130, 131, "a"], [136, 136, "a"], [142, 143, "p"], [144, 144, "v"], [146, 147, "p"], [148, 148, "v"]], [[151, 152, "p"], [157, 157, "v"], [158, 160, "c"]], [[173, 174, "p"], [179, 180, "p"]], [[192, 192, "v"]], [[197, 197, "a"]]], "predicted_relations": [[], [], [], [], [[118, 120, 108, 108, "USED-FOR"], [122, 122, 118, 120, "USED-FOR"], [124, 124, 118, 120, "USED-FOR"]], [[142, 143, 136, 136, "USED-FOR"], [144, 144, 146, 147, "USED-FOR"], [146, 147, 136, 136, "USED-FOR"], [148, 148, 146, 147, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1911.07559-04054834-cf39-4fa5-8287-cf71fc1abc53", "sentences": [["We", "train", "the", "FFA-Net", "in", "RGB", "channels", "and", "augment", "the", "training", "dataset", "with", "randomly", "rotated", "by", "90,180,270", "degrees", "and", "horizontal", "flip", "."], ["The", "2", "hazy-image", "patches", "with", "the", "size", "\\", "-LRB-", "240\\times", "240\\", "-RRB-", "are", "extracted", "as", "FFA-Net", "\u2019", "s", "input", "."], ["The", "whole", "network", "is", "trained", "for", "\\", "-LRB-", "5\\times", "10^5\\", "-RRB-", ",", "\\", "-LRB-", "1\\times", "10^6\\", "-RRB-", "steps", "on", "indoor", "and", "outdoor", "images", "respectively", "."], ["We", "use", "Adam", "optimizer", ",", "where", "\\", "-LRB-", "\\beta", "1\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "2\\", "-RRB-", "take", "the", "default", "values", "of", "0.9", "and", "0.999", ",", "respectively", "."]], "ner": [[[3, 3, "a"]], [[37, 37, "a"]], [], [[69, 70, "a"], [75, 76, "p"], [91, 91, "v"], [81, 82, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[23, 23, "v"], [32, 32, "v"], [37, 37, "a"]], [[51, 51, "v"], [57, 57, "v"]], [[69, 69, "a"], [89, 89, "v"], [91, 91, "v"]]], "predicted_relations": [[], [], [], [[75, 76, 69, 70, "USED-FOR"], [81, 82, 69, 70, "USED-FOR"]]]}
{"doc_key": "1911.07559-8e67f360-8c80-4d7e-afef-39c8ab51fcd3", "sentences": [["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "we", "adopt", "the", "cosine", "annealing", "strategy", "-LSB-", "7", "-RSB-", "to", "adjust", "the", "learning", "rate", "from", "the", "initial", "value", "to", "0", "by", "following", "the", "cosine", "function", "."], ["Assume", "the", "total", "number", "of", "batches", "is", "\\", "-LRB-", "T\\", "-RRB-", ",", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "is", "the", "initial", "earning", "rate", ",", "then", "at", "batch", "\\", "-LRB-", "t\\", "-RRB-", ",", "the", "learning", "rate", "\\", "-LRB-", "\\eta", "_", "-LCB-", "t", "-RCB-", "\\", "-RRB-", "is", "computed", "as", ":", "\\", "-LRB-", "\\eta", "_", "-LCB-", "t", "-RCB-", "=\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "2", "-RCB-", "-LRB-", "1+\\cos", "-LRB-", "\\frac", "-LCB-", "t\\pi", "-RCB-", "-LCB-", "T", "-RCB-", "-RRB-", "-RRB-", "\\eta", "\\qquad", "\\mathrm", "-LCB-", "-LRB-", "9", "-RRB-", "-RCB-", "\\", "-RRB-"]], "ner": [[[20, 22, "a"], [2, 3, "p"], [29, 30, "p"], [36, 36, "v"], [40, 41, "a"], [1, 3, "p"]], [[75, 76, "p"], [45, 48, "p"], [52, 52, "v"], [112, 112, "v"], [57, 57, "v"], [79, 79, "v"], [92, 92, "v"], [116, 116, "v"]]], "relations": [[], []], "predicted_ner": [[[2, 3, "p"], [10, 13, "v"], [29, 30, "p"], [36, 36, "v"]], [[75, 76, "p"]]], "predicted_relations": [[[29, 30, 20, 22, "USED-FOR"]], []]}
{"doc_key": "1909.06887-8d15f678-0aed-46f2-8c8d-3dd6fd4e1111", "sentences": [["To", "learn", "our", "descriptor", ",", "we", "use", "one", "\\", "-LRB-", "S^2\\", "-RRB-", "convolution", "layers", "and", "three", "\\", "-LRB-", "\\operatorname", "-LCB-", "SO", "-RCB-", "-LRB-", "3", "-RRB-", "\\", "-RRB-", "convolution", "layers", "with", "constant", "number", "of", "channels", ",", "40", ",", "while", "the", "bandwidths", "is", "set", "to", "24", "for", "the", "first", "three", "layer", "and", "4", "for", "the", "last", "one", ",", "which", "results", "in", "a", "descriptor", "with", "512", "entries", "."], ["The", "architecture", "of", "our", "decoder", "is", "made", "of", "4", "fully-connected", "layers", ",", "with", "ReLU", "non-linearities", "on", "the", "first", "three", "layers", "and", "tanh", "on", "the", "final", "output", "layer", "."], ["The", "network", "is", "trained", "with", "mini-bacthes", "of", "size", "32", "by", "using", "ADAM", "-LSB-", "14", "-RSB-", "."], ["The", "starting", "learning", "rate", "is", "set", "to", "0.001", "and", "is", "decayed", "every", "4000", "iterations", "."], ["We", "train", "the", "network", "for", "14", "epochs", "."]], "ner": [[[31, 33, "p"], [35, 35, "v"], [39, 39, "p"], [43, 43, "v"], [50, 50, "v"], [31, 33, "p"], [35, 35, "v"], [39, 39, "p"], [43, 43, "v"], [50, 50, "v"]], [[73, 73, "v"], [73, 73, "v"]], [[104, 104, "a"], [106, 106, "v"]], [[110, 112, "p"], [116, 116, "v"], [121, 122, "v"]], [[129, 129, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 7, "v"], [15, 15, "v"], [23, 23, "v"], [35, 35, "v"], [43, 43, "v"], [47, 47, "v"], [50, 50, "v"], [54, 54, "v"], [62, 62, "v"]], [[73, 73, "v"], [78, 78, "a"], [83, 83, "v"], [86, 86, "a"]], [[98, 98, "a"], [101, 101, "v"], [104, 104, "a"]], [[111, 112, "p"], [116, 116, "v"], [121, 121, "v"]], [[129, 129, "v"], [130, 130, "p"]]], "predicted_relations": [[[35, 35, 31, 33, "USED-FOR"], [35, 35, 39, 39, "USED-FOR"], [35, 35, 31, 33, "USED-FOR"], [35, 35, 39, 39, "USED-FOR"], [43, 43, 31, 33, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 31, 33, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [35, 35, 31, 33, "USED-FOR"], [35, 35, 39, 39, "USED-FOR"], [35, 35, 31, 33, "USED-FOR"], [35, 35, 39, 39, "USED-FOR"], [43, 43, 31, 33, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 31, 33, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1905.10073-1197763f-7753-4d56-bb87-bc163863199d", "sentences": [["We", "used", "the", "Adam", "optimizer", "-LSB-", "20", "-RSB-", "with", "the", "first", "momentum", "set", "to", "0.9", "and", "the", "second", "momentum", "set", "to", "0.999", "."], ["Weight", "decay", "was", "set", "to", "\\", "-LRB-", "5", "*", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "the", "convolutions", "and", "to", "\\", "-LRB-", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "for", "the", "decision", "trees", "."], ["The", "batch", "size", "was", "set", "to", "400", "and", "each", "batch", "was", "always", "balanced", "in", "terms", "of", "available", "classes", "."], ["This", "means", "that", "in", "each", "batch", "each", "class", "was", "represented", "40", "times", "."], ["The", "initial", "learning", "rate", "was", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "and", "reduced", "by", "\\", "-LRB-", "10^", "-LCB-", "-1", "-RCB-", "\\", "-RRB-", "after", "each", "100", "epochs", "until", "it", "reached", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "we", "continued", "the", "training", "for", "additional", "1000", "epochs", "and", "selected", "the", "best", "result", "."], ["For", "data", "augmentation", "we", "used", "random", "noise", "in", "the", "range", "of", "0-30", "%", "of", "the", "image", "resolution", "."]], "ner": [[[3, 4, "a"], [10, 11, "p"], [14, 14, "v"], [17, 18, "p"], [21, 21, "v"]], [[38, 40, "c"], [51, 54, "c"]], [[57, 58, "p"], [62, 62, "v"]], [], [[89, 91, "p"]], [], [[168, 173, "v"], [158, 159, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [14, 14, "v"], [21, 21, "v"]], [[23, 24, "p"], [30, 30, "v"], [45, 48, "v"], [53, 54, "a"]], [[57, 58, "p"], [62, 62, "v"]], [[85, 85, "v"]], [[90, 91, "p"], [97, 100, "v"], [108, 111, "v"], [116, 116, "v"], [117, 117, "p"], [123, 126, "v"]], [[132, 133, "p"], [137, 140, "v"], [149, 149, "v"], [150, 150, "p"]], [[168, 169, "v"]]], "predicted_relations": [[[17, 18, 3, 4, "USED-FOR"], [21, 21, 17, 18, "USED-FOR"]], [], [[62, 62, 57, 58, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1905.10073-4e204894-4c59-4560-8b77-50fdb879a40d", "sentences": [["We", "used", "the", "Adam", "optimizer", "-LSB-", "20", "-RSB-", "with", "the", "first", "momentum", "set", "to", "0.9", "and", "the", "second", "momentum", "set", "to", "0.999", "."], ["Weight", "decay", "was", "set", "to", "\\", "-LRB-", "5", "*", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "the", "convolutions", "and", "to", "\\", "-LRB-", "10^", "-LCB-", "-10", "-RCB-", "\\", "-RRB-", "for", "the", "decision", "trees", "."], ["The", "batch", "size", "was", "set", "to", "50", "with", "the", "same", "batch", "balancing", "approach", "as", "for", "the", "MNIST", "dataset", "."], ["For", "CIFAR", "this", "means", "each", "batch", "consisted", "of", "five", "examples", "per", "class", "."], ["The", "initial", "learning", "rate", "was", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "and", "reduced", "by", "\\", "-LRB-", "10^", "-LCB-", "-1", "-RCB-", "\\", "-RRB-", "after", "each", "500", "epochs", "until", "it", "reached", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "we", "continued", "the", "training", "for", "additional", "1000", "epochs", "and", "selected", "the", "best", "result", "."], ["For", "data", "augmentation", "we", "used", "random", "cropping", "of", "\\", "-LRB-", "24", "\\times", "24\\", "-RRB-", "patches", ",", "random", "color", "offsets", ",", "random", "color", "distortion", ",", "flipping", "the", "image", "horizontally", "and", "vertically", "as", "well", "as", "random", "noise", "in", "the", "range", "of", "0-20", "%", "of", "the", "image", "resolution", "."], ["Additionally", ",", "we", "overlayed", "patches", "of", "the", "same", "class", "with", "an", "intensity", "of", "up", "to", "20", "%", "."]], "ner": [[[3, 4, "a"], [10, 11, "p"], [14, 14, "v"], [17, 18, "p"], [21, 21, "v"]], [[38, 40, "c"], [51, 54, "c"]], [[57, 58, "p"], [62, 62, "v"], [63, 73, "c"]], [], [[89, 91, "p"], [114, 117, "c"]], [], [[158, 159, "a"], [162, 163, "p"], [173, 175, "p"], [177, 179, "p"], [181, 186, "p"], [190, 191, "p"], [196, 201, "v"]], [[206, 211, "p"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [14, 14, "v"], [21, 21, "v"]], [[23, 24, "p"], [30, 30, "v"], [45, 48, "v"], [53, 54, "a"]], [[57, 58, "p"], [62, 62, "v"], [72, 73, "a"]], [[76, 76, "a"], [83, 83, "v"]], [[90, 91, "p"], [97, 100, "v"], [108, 111, "v"], [116, 116, "v"], [117, 117, "p"], [123, 126, "v"]], [[132, 133, "p"], [137, 140, "v"], [149, 149, "v"], [150, 150, "p"]], [[167, 167, "v"], [169, 169, "v"], [196, 197, "v"]], [[218, 219, "v"]]], "predicted_relations": [[[14, 14, 17, 18, "USED-FOR"], [17, 18, 3, 4, "USED-FOR"], [21, 21, 17, 18, "USED-FOR"]], [], [[62, 62, 57, 58, "USED-FOR"], [63, 73, 62, 62, "USED-FOR"]], [], [], [], [[162, 163, 158, 159, "USED-FOR"], [173, 175, 158, 159, "USED-FOR"], [177, 179, 158, 159, "USED-FOR"], [181, 186, 158, 159, "USED-FOR"], [196, 201, 190, 191, "USED-FOR"]], []]}
{"doc_key": "1905.10095-53133a88-5995-470f-9454-0d4856fa83d2", "sentences": [["Network", "architecture", "."], ["The", "number", "of", "shared", "and", "specific", "graph", "convolutional", "layers", "are", "both", "1", ",", "shared", "hidden", "size", "is", "64", ",", "and", "specific", "hidden", "size", "is", "16", "."], ["Initialization", "."], ["The", "node", "feature", "matrix", "can", "be", "initialized", "randomly", ",", "or", "by", "other", "embedding", "methods", ",", "we", "initialize", "it", "as", "the", "identity", "matrix", "."], ["Gradient", "normalization", "."], ["We", "normalize", "the", "gradient", "of", "shared", "parameter", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\Theta", "-RCB-", "_s\\", "-RRB-", "of", "each", "domain", ",", "and", "then", "use", "the", "normalized", "gradient", "to", "calculating", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "."], ["The", "normalized", "gradient", "of", "domain", "\\", "-LRB-", "d\\", "-RRB-", "is", "\\", "-LRB-", "\\mathbf", "-LCB-", "G", "-RCB-", "_d", "/", "\\left", "-LRB-", "\\left\\Vert", "\\mathbf", "-LCB-", "G", "-RCB-", "_d", "\\right\\Vert", "_2", "\\cdot", "L_d", "\\right", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "\\mathbf", "-LCB-", "G", "-RCB-", "_d", "=", "\\frac", "-LCB-", "\\partial", "L_d\\left", "-LRB-", "\\mathbf", "-LCB-", "\\Theta", "-RCB-", "_s", ",", "\\mathbf", "-LCB-", "\\Theta", "-RCB-", "_d\\right", "-RRB-", "-RCB-", "-LCB-", "\\partial", "\\mathbf", "-LCB-", "\\Theta", "-RCB-", "_s", "-RCB-", "\\", "-RRB-", "is", "the", "unnormalized", "gradient", "."], ["Other", "hyper-parameters", "."], ["The", "number", "of", "negative", "samples", "is", "2", ";", "the", "embedding", "dimension", "is", "16", ";", "the", "dropout", "of", "shared", "graph", "convolutional", "layers", "is", "0.3", "and", "that", "is", "0.1", "of", "specific", "graph", "convolutional", "layers", ";", "the", "batch", "size", "is", "256", "and", "we", "train", "the", "model", "for", "a", "maximum", "of", "10", "epochs", "using", "Adam", "."]], "ner": [[[0, 1, "a"]], [[14, 14, "v"], [14, 14, "v"], [20, 20, "v"], [27, 27, "v"], [27, 27, "v"]], [[29, 29, "a"]], [], [[54, 55, "a"]], [], [], [], [[173, 174, "a"]], [[202, 202, "v"], [202, 202, "v"], [188, 188, "v"], [182, 182, "v"], [188, 188, "v"], [198, 198, "v"], [202, 202, "v"], [213, 213, "v"], [223, 223, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[14, 14, "v"], [20, 20, "v"], [27, 27, "v"]], [], [], [], [], [], [], [], [[182, 182, "v"], [188, 188, "v"], [198, 198, "v"], [202, 202, "v"], [210, 211, "p"], [213, 213, "v"], [223, 223, "v"], [224, 224, "p"], [226, 226, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1905.10095-5c444575-5579-4c4a-be04-5078b5f6a577", "sentences": [["MF", "."], ["It", "is", "implemented", "using", "LibMFhttps", ":", "//www.csie.ntu.edu.tw/", "cjlin/libmf/", "."], ["DeepWalk", "."], ["The", "length", "of", "context", "window", "is", "5", ";", "the", "length", "of", "random", "walk", "is", "20", ";", "the", "number", "of", "walks", "per", "node", "is", "50", "."], ["LINE", "."], ["The", "number", "of", "negative", "samples", "is", "2.", "node2vec", "."], ["The", "length", "of", "context", "window", "is", "5", ";", "the", "length", "of", "random", "walk", "is", "20", ";", "the", "number", "of", "walks", "per", "node", "is", "50", ";", "the", "number", "of", "negative", "samples", "is", "2", ";", "\\", "-LRB-", "p\\", "-RRB-", "is", "1", "and", "\\", "-LRB-", "q\\", "-RRB-", "is", "0.25", "."], ["GCN", "."], ["The", "number", "of", "graph", "convolutional", "layers", "is", "1.", "mGCN", "."], ["The", "initial", "general", "representation", "size", "is", "64", ",", "other", "parameter", "settings", "are", "the", "same", "as", "-LSB-", "21", "-RSB-", ",", "and", "we", "train", "the", "model", "for", "a", "maximum", "of", "20", "epochs", "using", "Adam", "."], ["DMGE", "-LRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "-RRB-", "."], ["Considering", "that", "both", "domains", "are", "important", ",", "we", "set", "the", "weight", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "to", "0.5", ";", "the", "other", "parameter", "settings", "are", "the", "same", "as", "DMGE", "."]], "ner": [[[0, 0, "a"]], [], [[11, 11, "a"]], [[14, 17, "p"], [19, 19, "v"], [22, 25, "p"], [27, 27, "v"], [30, 34, "p"], [36, 36, "v"], [14, 17, "p"], [19, 19, "v"], [22, 25, "p"], [27, 27, "v"], [30, 34, "p"], [36, 36, "v"]], [[38, 38, "a"]], [[41, 44, "p"], [46, 46, "v"], [47, 47, "a"], [41, 44, "p"], [46, 46, "v"]], [[50, 53, "p"], [55, 55, "v"], [58, 61, "p"], [63, 63, "v"], [66, 70, "p"], [72, 72, "v"], [75, 78, "p"], [80, 80, "v"], [50, 53, "p"], [55, 55, "v"], [58, 61, "p"], [63, 63, "v"], [66, 70, "p"], [72, 72, "v"], [75, 78, "p"], [80, 80, "v"], [84, 84, "p"], [87, 87, "v"], [91, 91, "p"], [94, 94, "v"], [87, 87, "v"]], [[96, 96, "a"]], [[105, 105, "v"], [99, 103, "p"], [105, 105, "v"], [106, 106, "a"]], [[136, 136, "v"], [136, 136, "v"], [109, 112, "p"], [114, 114, "v"]], [[141, 141, "a"], [145, 145, "p"]], [[167, 167, "v"], [167, 167, "v"], [177, 177, "a"], [163, 163, "p"], [167, 167, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [], [[11, 11, "a"]], [[19, 19, "v"], [27, 27, "v"], [36, 36, "v"]], [], [[47, 47, "a"]], [[55, 55, "v"], [63, 63, "v"], [72, 72, "v"], [80, 80, "v"], [87, 87, "v"], [94, 94, "v"]], [[96, 96, "a"]], [[106, 106, "a"]], [[114, 114, "v"], [136, 136, "v"], [137, 137, "p"], [139, 139, "a"]], [[141, 141, "a"], [145, 145, "p"]], [[163, 163, "p"], [167, 167, "v"], [177, 177, "a"]]], "predicted_relations": [[], [], [], [[19, 19, 22, 25, "USED-FOR"], [19, 19, 22, 25, "USED-FOR"], [27, 27, 22, 25, "USED-FOR"], [27, 27, 22, 25, "USED-FOR"], [36, 36, 22, 25, "USED-FOR"], [36, 36, 22, 25, "USED-FOR"], [19, 19, 22, 25, "USED-FOR"], [19, 19, 22, 25, "USED-FOR"], [27, 27, 22, 25, "USED-FOR"], [27, 27, 22, 25, "USED-FOR"], [36, 36, 22, 25, "USED-FOR"], [36, 36, 22, 25, "USED-FOR"]], [], [], [[55, 55, 58, 61, "USED-FOR"], [55, 55, 58, 61, "USED-FOR"], [63, 63, 58, 61, "USED-FOR"], [63, 63, 58, 61, "USED-FOR"], [72, 72, 58, 61, "USED-FOR"], [72, 72, 58, 61, "USED-FOR"], [80, 80, 91, 91, "USED-FOR"], [55, 55, 58, 61, "USED-FOR"], [55, 55, 58, 61, "USED-FOR"], [63, 63, 58, 61, "USED-FOR"], [63, 63, 58, 61, "USED-FOR"], [72, 72, 58, 61, "USED-FOR"], [72, 72, 58, 61, "USED-FOR"], [80, 80, 91, 91, "USED-FOR"], [87, 87, 84, 84, "USED-FOR"], [87, 87, 91, 91, "USED-FOR"], [94, 94, 91, 91, "USED-FOR"], [87, 87, 84, 84, "USED-FOR"], [87, 87, 91, 91, "USED-FOR"]], [], [], [[114, 114, 109, 112, "USED-FOR"]], [], []]}
{"doc_key": "1911.09839-d36b261c-8d10-491f-a099-2daa2ff24564", "sentences": [["The", "latent", "parameter", "\\", "-LRB-", "z_i\\", "-RRB-", "at", "\\", "-LRB-", "i", "\\in", "\\lbrace", "1", ",", "\\ldots", ",", "m\\rbrace", "\\", "-RRB-", "has", "the", "fixed", "value", "\\", "-LRB-", "e_i\\", "-RRB-", "in", "\\", "-LRB-", "\\lbrace", "0,1\\rbrace", "^m\\", "-RRB-", "that", "has", "1", "at", "the", "\\", "-LRB-", "i\\", "-RRB-", "-th", "position", "and", "0", "everywhere", "else", "."], ["Formally", ",", "this", "means", "that", "the", "prior", "\\", "-LRB-", "P", "-LRB-", "z_", "-LCB-", "1", ":", "m", "-RCB-", "-RRB-", "\\", "-RRB-", "is", "the", "Dirac", "distribution", "at", "\\", "-LRB-", "-LRB-", "e_1", ",", "e_2", ",", "\\ldots", ",", "e_m", "-RRB-", "\\", "-RRB-", "."], ["The", "random", "variable", "\\", "-LRB-", "x_j\\", "-RRB-", "at", "\\", "-LRB-", "j", "\\in", "\\lbrace", "1", ",", "\\ldots", ",", "n\\rbrace", "\\", "-RRB-", "consists", "of", "two", "parts", ",", "\\", "-LRB-", "x_j^S", "\\in", "\\mathcal", "-LCB-", "X", "-RCB-", "_S\\", "-RRB-", "for", "the", "latent", "state", "and", "\\", "-LRB-", "x_j^O", "\\in", "\\mathcal", "-LCB-", "X", "-RCB-", "_O\\", "-RRB-", "for", "the", "observed", "value", "."], ["Thus", ",", "\\", "-LRB-", "x_j", "=", "-LRB-", "x_j^S", ",", "x_j^O", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathcal", "-LCB-", "X", "-RCB-", "=", "\\mathcal", "-LCB-", "X", "-RCB-", "_S", "\\times", "\\mathcal", "-LCB-", "X", "-RCB-", "_O\\", "-RRB-", "."], ["The", "probability", "distribution", "\\", "-LRB-", "P_\\phi", "-LRB-", "x_j", "\\", ",", "|\\", ",", "x_", "-LCB-", "1", ":", "j-1", "-RCB-", ",", "z_i", "-RRB-", "\\", "-RRB-", "is", "parameterised", "by", "\\", "-LRB-", "\\phi", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^p\\", "-RRB-", "for", "some", "\\", "-LRB-", "p\\", "-RRB-", ",", "and", "has", "the", "form", "\\", "-LRB-", "P_\\phi", "-LRB-", "x_j", "\\", ",", "|\\", ",", "x_", "-LCB-", "1", ":", "j-1", "-RCB-", ",", "z_i", "-RRB-", "=", "P_\\phi", "-LRB-", "x_j^O", "\\", ",", "|\\", ",", "x_j^S", ",", "z_i", "-RRB-", "P_\\phi", "-LRB-", "x_j^S", "\\", ",", "|\\", ",", "x_", "-LCB-", "1", ":", "j-1", "-RCB-", "^S", ",", "z_i", "-RRB-", ".\\", "-RRB-", "Typically", ",", "\\", "-LRB-", "P_\\phi", "\\", "-RRB-", "is", "defined", "using", "a", "neural", "network", ",", "and", "\\", "-LRB-", "\\phi", "\\", "-RRB-", "denotes", "the", "weights", "of", "the", "network", "."]], "ner": [[], [[73, 74, "a"]], [], [], [[286, 287, "a"], [184, 184, "p"], [207, 207, "p"], [228, 228, "p"], [245, 245, "p"], [256, 256, "p"], [279, 279, "p"], [292, 292, "p"], [180, 181, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[37, 37, "v"], [47, 47, "v"]], [], [[112, 112, "v"]], [], []], "predicted_relations": [[], [], [], [], [[228, 228, 180, 181, "USED-FOR"], [292, 292, 286, 287, "USED-FOR"]]]}
{"doc_key": "1907.03548-c8e06086-a64b-4a8e-b6d8-4d85443dbc5c", "sentences": [["In", "an", "end-to-end", "training", "manner", ",", "we", "updated", "the", "weights", "of", "all", "networks", "using", "the", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "the", "batch", "size", "of", "training", "was", "8", "."], ["All", "networks", "were", "trained", "up", "to", "100", "epochs", ",", "where", "the", "learning", "rate", "was", "fixed", "in", "the", "first", "60", "epochs", "and", "then", "linearly", "reduced", "to", "\\", "-LRB-", "1e^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."], ["In", "the", "early", "phase", ",", "the", "synthetic", "images", "were", "blurry", ",", "so", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "shape", "-RCB-", "\\", "-RRB-", "was", "set", "to", "0", "at", "the", "beginning", "and", "linearly", "increased", "to", "100", "at", "60", "epoch", "."], ["In", "the", "end", ",", "we", "used", "the", "model", "trained", "at", "the", "100th", "epoch", "to", "perform", "on", "testing", "data", "."]], "ner": [[[15, 16, "a"], [19, 21, "p"], [34, 35, "p"], [39, 39, "v"], [20, 21, "p"]], [[48, 48, "p"], [60, 60, "p"], [47, 47, "v"], [52, 53, "p"], [63, 64, "c"], [47, 47, "v"]], [[107, 107, "v"], [99, 99, "v"], [100, 102, "c"], [107, 107, "v"], [108, 110, "c"]], []], "relations": [[], [], [], []], "predicted_ner": [[[15, 15, "a"], [20, 21, "p"], [25, 27, "v"], [34, 35, "p"], [39, 39, "v"]], [[47, 47, "v"], [48, 48, "p"], [52, 53, "p"], [59, 59, "v"], [60, 60, "p"], [68, 70, "v"]], [[89, 93, "p"], [99, 99, "v"], [107, 107, "v"], [109, 109, "v"], [110, 110, "p"]], [[123, 123, "v"]]], "predicted_relations": [[[19, 21, 15, 16, "USED-FOR"], [34, 35, 15, 16, "USED-FOR"], [20, 21, 15, 16, "USED-FOR"]], [[47, 47, 48, 48, "USED-FOR"], [47, 47, 60, 60, "USED-FOR"], [47, 47, 48, 48, "USED-FOR"], [47, 47, 60, 60, "USED-FOR"]], [[100, 102, 107, 107, "USED-FOR"], [100, 102, 99, 99, "USED-FOR"], [100, 102, 107, 107, "USED-FOR"], [108, 110, 107, 107, "USED-FOR"], [108, 110, 99, 99, "USED-FOR"], [108, 110, 107, 107, "USED-FOR"]], []]}
{"doc_key": "1905.00561-ef0232fa-7724-4f3b-8e75-363ae95e2d6d", "sentences": [["Models", ":", "R", "-LRB-", "2+1", "-RRB-", "D-d", "-LSB-", "14", "-RSB-", "Source", "code", ":", "https", ":", "//github.com/dutran/R2Plus1D", "is", "the", "fundamental", "architecture", "used", "for", "pre-training", ",", "where", "\\", "-LRB-", "d\\", "-RRB-", "denotes", "model", "depth", "=", "\\", "-LRB-", "\\lbrace", "18", ",", "34", ",", "101", ",", "152\\rbrace", "\\", "-RRB-", "."], ["As", "in", "-LSB-", "29", "-RSB-", ",", "we", "construct", "models", "of", "depth", "\\", "-LRB-", ">", "\\", "34\\", "-RRB-", "by", "replacing", "simple", "temporal", "blocks", "with", "bottleneck", "blocks", "for", "computational", "feasibility", "."], ["We", "direct", "the", "reader", "to", "the", "supplementary", "material", "for", "details", "."]], "ner": [[[2, 6, "a"], [6, 6, "p"], [27, 27, "p"], [36, 36, "v"], [38, 38, "v"], [40, 40, "v"], [42, 42, "v"]], [[61, 61, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"]], [[60, 61, "v"]], []], "predicted_relations": [[[6, 6, 2, 6, "USED-FOR"]], [], []]}
{"doc_key": "1905.00561-0117a767-91bd-4afc-ba35-2f1da8ee4efe", "sentences": [["Training", "Details", ":", "Video", "frames", "are", "down-sampled", "to", "a", "resolution", "of", "\\", "-LRB-", "128\\times", "171\\", "-RRB-", "and", "each", "video", "clip", "is", "generated", "by", "cropping", "a", "random", "patch", "of", "size", "\\", "-LRB-", "112\\times", "112\\", "-RRB-", "from", "a", "frame", "."], ["Video", "clips", "of", "either", "8", "or", "32", "frames", "are", "used", "in", "our", "experiments", ",", "and", "temporal", "jittering", "is", "also", "applied", "to", "the", "input", "."], ["Synchronous", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "is", "used", "to", "train", "our", "models", "on", "128", "GPUs", "across", "16", "machines", "using", "caffe2", "-LSB-", "9", "-RSB-", "."], ["When", "32", "frames", "per", "input", "video", "clip", "are", "considered", ",", "each", "GPU", "processes", "6", "videos", "at", "a", "time", "-LRB-", "due", "to", "memory", "constraints", "-RRB-", ",", "while", "16", "videos", "are", "processed", "at", "a", "time", "when", "8", "frames", "per", "video", "clip", "are", "considered", "."], ["Batch", "normalization", "-LRB-", "BN", "-RRB-", "is", "applied", "to", "all", "convolutional", "layers", "and", "the", "statistics", "-LSB-", "33", "-RSB-", "are", "computed", "on", "each", "GPU", "."], ["All", "pre-training", "experiments", "process", "\\", "-LRB-", "490M\\", "-RRB-", "videos", "in", "total", "."], ["Learning", "rate", "is", "set", "following", "the", "linear", "scaling", "procedure", "proposed", "in", "-LSB-", "27", "-RSB-", "with", "a", "warmup", "."], ["An", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.192\\", "-RRB-", "is", "used", "which", "is", "divided", "by", "2", "at", "equal", "steps", "such", "that", "the", "total", "number", "of", "learning", "rate", "reductions", "is", "13", "over", "the", "course", "of", "training", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], [], [], [[164, 165, "p"]], [[189, 189, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[14, 14, "v"], [32, 32, "v"]], [[42, 42, "v"], [44, 44, "v"]], [[62, 68, "a"], [76, 76, "v"], [79, 79, "v"], [82, 82, "a"]], [[88, 88, "v"], [100, 100, "v"], [113, 113, "v"], [121, 121, "v"]], [[129, 133, "a"]], [[158, 158, "v"]], [[164, 165, "p"]], [[184, 185, "p"], [189, 189, "v"], [197, 197, "v"], [207, 208, "p"], [211, 211, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "1904.02823-3dc7e77e-b5c1-4506-87df-708eb4bf6ca6", "sentences": [["We", "use", "fully", "convolutional", "VGG-style", "networks", "for", "CIFAR-10", "and", "SVHN", ",", "and", "ResNet", "for", "CIFAR-100", "."], ["All", "of", "them", "use", "the", "ADAM", "optimizer", "-LSB-", "25", "-RSB-", "as", "suggested", "by", "Hubara", "et", "al", ".", "-LSB-", "21", "-RSB-", "."], ["For", "the", "BNN", "trained", "with", "distribution", "loss", "-LRB-", "BNN-DL", "-RRB-", ",", "we", "compute", "the", "loss", "with", "the", "activations", "prior", "to", "each", "binarized", "activation", "function", "-LRB-", "\\", "-LRB-", "i.e.\\", "-RRB-", ",", "\\", "-LRB-", "Sign\\", "-RRB-", "function", "that", "uses", "\\", "-LRB-", "HardTanh\\", "-RRB-", "for", "gradient", "computation", "-RRB-", "."], ["Unless", "noted", "otherwise", ",", "we", "set", "the", "coefficient", "\\", "-LRB-", "k_\\epsilon", "\\", "-RRB-", "to", "be", "1", ",", "0.25", "and", "0.25", "for", "\\", "-LRB-", "L_D\\", "-RRB-", ",", "\\", "-LRB-", "L_S\\", "-RRB-", "and", "\\", "-LRB-", "L_M\\", "-RRB-", ",", "respectively", ",", "and", "set", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "to", "be", "2", "."], ["To", "show", "the", "statistical", "significance", ",", "all", "the", "experiments", "for", "CIFAR-10", "and", "SVHN", "are", "averaged", "over", "five", "experiments", "with", "different", "parameter", "initialization", "seeds", "."], ["The", "details", "of", "the", "network", "structure", "and", "training", "scheme", "for", "each", "dataset", "is", "as", "follows", ":"]], "ner": [[[4, 5, "a"], [12, 12, "a"]], [[21, 22, "a"]], [[42, 43, "a"]], [[130, 130, "v"], [100, 100, "v"], [102, 102, "v"], [125, 125, "p"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [7, 7, "a"], [9, 9, "a"], [12, 12, "a"], [14, 14, "a"]], [[21, 21, "a"]], [[39, 39, "a"], [51, 51, "a"]], [[98, 98, "v"], [100, 100, "v"], [102, 102, "v"], [125, 125, "p"], [130, 130, "v"]], [[142, 142, "a"], [144, 144, "a"], [148, 148, "v"]], []], "predicted_relations": [[], [], [], [[130, 130, 125, 125, "USED-FOR"]], [], []]}
{"doc_key": "1911.01678-03188d30-54f8-4378-90b6-ccd85d465803", "sentences": [["\\", "-LRB-", "\\bullet", "\\", "-RRB-", "DEFT", ":", "This", "is", "a", "recently", "released", "dataset", "for", "DE", "-LSB-", "26", "-RSB-", "."], ["DEFT", "consists", "of", "two", "categories", "of", "definitions", ":", "a", "-RRB-", "Contracts", ":", "involving", "2,433", "sentences", "from", "the", "2017", "SEC", "contract", "filing", "with", "537", "definitional", "and", "1906", "non-definitional", "sentences", "."], ["Besides", "terms", "and", "definitions", ",", "this", "corpus", "has", "an", "additional", "type", "qualifier", "."], ["It", "indicates", "the", "words/phrases", "specifying", "the", "conditions", ",", "dates", "or", "locations", "in", "which", "the", "definitions", "are", "valid", "for", "the", "terms", "."], ["We", "also", "use", "the", "BIO", "tagging", "schema", "for", "this", "type", "."], ["2", "-RRB-", "Textbook", ":", "involving", "21,303", "sentences", "from", "the", "publicly", "available", "textbooks", "in", "different", "domains", ",", "including", "biology", ",", "history", ",", "and", "physics", "."], ["This", "corpus", "contains", "5,964", "definitional", "and", "15,339", "non-definitional", "sentences", "."]], "ner": [[[5, 5, "a"]], [[19, 19, "a"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [14, 14, "a"]], [[22, 22, "v"], [32, 32, "v"], [41, 41, "v"], [44, 44, "v"]], [], [], [], [[98, 98, "v"]], [[120, 120, "v"], [123, 123, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1911.01678-8dae4925-f4b6-44cc-b69e-2fe2faa78726", "sentences": [["For", "all", "the", "datasets", ",", "we", "use", "the", "standard", "data", "splits", "to", "ensure", "a", "comparable", "comparison", "with", "the", "prior", "work", "."], ["We", "fine", "tune", "the", "model", "parameters", "on", "the", "validation", "set", "of", "the", "DEFT", "Contract", "dataset", "and", "fix", "the", "detected", "parameters", "to", "train", "and", "evaluate", "the", "models", "on", "the", "other", "datasets", "for", "consistency", "."], ["The", "parameters", "we", "found", "include", ":", "50", "dimensions", "for", "the", "POS", "embeddings", ";", "200", "dimensions", "for", "the", "LSTM", "and", "GCN", "hidden", "vectors", "and", "all", "the", "feed", "forward", "neural", "networks", "in", "the", "model", ";", "\\", "-LRB-", "a=1", ",", "b=1", ",", "c=1", ",", "\\alpha", "=1", ",", "\\beta", "=10", ",", "\\gamma", "=1\\", "-RRB-", "and", "\\", "-LRB-", "\\eta", "=1\\", "-RRB-", "for", "the", "trade-off", "parameters", ";", "\\", "-LRB-", "U=3\\", "-RRB-", "for", "the", "latent", "labels", "in", "the", "semantic", "consistency", "module", ";", "and", "the", "learning", "rate", "of", "0.003", "for", "the", "Adam", "optimizer", "."], ["We", "use", "the", "pre-trained", "word", "embeddings", "GloVe", "with", "300", "dimensions", "from", "-LSB-", "24", "-RSB-", "to", "initialize", "the", "model", "."], ["Finally", ",", "to", "assess", "how", "well", "our", "model", "could", "benefit", "from", "the", "pre-trained", "contextualized", "word", "embeddings", ",", "we", "also", "perform", "an", "additional", "experiment", "where", "BERT", "-LSB-", "7", "-RSB-", "is", "used", "to", "initialize", "the", "word", "embeddings", "in", "the", "model", "."]], "ner": [[[13, 13, "p"]], [[33, 35, "a"]], [[64, 65, "a"], [61, 61, "p"], [68, 68, "p"], [60, 60, "v"], [71, 75, "a"], [61, 61, "p"], [68, 68, "p"], [67, 67, "v"], [112, 113, "a"], [89, 89, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [91, 91, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [93, 93, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [95, 95, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [98, 98, "p"], [99, 99, "v"], [101, 101, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [107, 107, "p"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [102, 102, "v"], [108, 108, "v"], [121, 127, "a"], [117, 117, "p"], [117, 117, "v"], [137, 138, "a"], [131, 132, "p"], [134, 134, "v"], [61, 61, "p"], [68, 68, "p"]], [[149, 149, "p"], [149, 149, "p"], [146, 146, "a"], [149, 149, "p"], [148, 148, "v"]], [[183, 183, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[33, 35, "a"]], [[60, 60, "v"], [67, 67, "v"], [71, 71, "a"], [73, 73, "a"], [79, 82, "a"], [117, 117, "v"], [131, 132, "p"], [134, 134, "v"], [137, 137, "a"]], [[148, 148, "v"]], [[166, 166, "a"], [183, 183, "a"]]], "predicted_relations": [[], [], [[61, 61, 64, 65, "USED-FOR"], [61, 61, 71, 75, "USED-FOR"], [68, 68, 64, 65, "USED-FOR"], [68, 68, 71, 75, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [60, 60, 68, 68, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [60, 60, 68, 68, "USED-FOR"], [60, 60, 89, 89, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [60, 60, 68, 68, "USED-FOR"], [61, 61, 64, 65, "USED-FOR"], [61, 61, 71, 75, "USED-FOR"], [68, 68, 64, 65, "USED-FOR"], [68, 68, 71, 75, "USED-FOR"], [67, 67, 61, 61, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [67, 67, 61, 61, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [67, 67, 89, 89, "USED-FOR"], [67, 67, 91, 91, "USED-FOR"], [67, 67, 93, 93, "USED-FOR"], [67, 67, 61, 61, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [89, 89, 64, 65, "USED-FOR"], [89, 89, 71, 75, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [91, 91, 64, 65, "USED-FOR"], [91, 91, 71, 75, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [93, 93, 64, 65, "USED-FOR"], [93, 93, 71, 75, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [95, 95, 64, 65, "USED-FOR"], [95, 95, 71, 75, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [98, 98, 64, 65, "USED-FOR"], [98, 98, 71, 75, "USED-FOR"], [98, 98, 112, 113, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 91, 91, "USED-FOR"], [99, 99, 93, 93, "USED-FOR"], [99, 99, 95, 95, "USED-FOR"], [99, 99, 98, 98, "USED-FOR"], [99, 99, 101, 101, "USED-FOR"], [99, 99, 107, 107, "USED-FOR"], [101, 101, 64, 65, "USED-FOR"], [101, 101, 71, 75, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [107, 107, 64, 65, "USED-FOR"], [107, 107, 71, 75, "USED-FOR"], [107, 107, 112, 113, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [89, 89, 89, 89, "USED-FOR"], [89, 89, 91, 91, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 95, 95, "USED-FOR"], [89, 89, 98, 98, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 107, 107, "USED-FOR"], [89, 89, 61, 61, "USED-FOR"], [89, 89, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [91, 91, 89, 89, "USED-FOR"], [91, 91, 91, 91, "USED-FOR"], [91, 91, 93, 93, "USED-FOR"], [91, 91, 95, 95, "USED-FOR"], [91, 91, 98, 98, "USED-FOR"], [91, 91, 101, 101, "USED-FOR"], [91, 91, 107, 107, "USED-FOR"], [91, 91, 61, 61, "USED-FOR"], [91, 91, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [93, 93, 89, 89, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 95, 95, "USED-FOR"], [93, 93, 98, 98, "USED-FOR"], [93, 93, 101, 101, "USED-FOR"], [93, 93, 107, 107, "USED-FOR"], [93, 93, 68, 68, "USED-FOR"], [96, 96, 89, 89, "USED-FOR"], [96, 96, 91, 91, "USED-FOR"], [96, 96, 93, 93, "USED-FOR"], [96, 96, 95, 95, "USED-FOR"], [96, 96, 98, 98, "USED-FOR"], [96, 96, 101, 101, "USED-FOR"], [96, 96, 107, 107, "USED-FOR"], [102, 102, 89, 89, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 95, 95, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"], [102, 102, 107, 107, "USED-FOR"], [108, 108, 89, 89, "USED-FOR"], [108, 108, 91, 91, "USED-FOR"], [108, 108, 93, 93, "USED-FOR"], [108, 108, 95, 95, "USED-FOR"], [108, 108, 98, 98, "USED-FOR"], [108, 108, 101, 101, "USED-FOR"], [108, 108, 107, 107, "USED-FOR"], [117, 117, 64, 65, "USED-FOR"], [117, 117, 71, 75, "USED-FOR"], [117, 117, 112, 113, "USED-FOR"], [117, 117, 121, 127, "USED-FOR"], [117, 117, 89, 89, "USED-FOR"], [117, 117, 91, 91, "USED-FOR"], [117, 117, 95, 95, "USED-FOR"], [117, 117, 98, 98, "USED-FOR"], [117, 117, 101, 101, "USED-FOR"], [117, 117, 107, 107, "USED-FOR"], [117, 117, 117, 117, "USED-FOR"], [131, 132, 112, 113, "USED-FOR"], [61, 61, 64, 65, "USED-FOR"], [61, 61, 71, 75, "USED-FOR"], [68, 68, 64, 65, "USED-FOR"], [68, 68, 71, 75, "USED-FOR"]], [[149, 149, 146, 146, "USED-FOR"], [149, 149, 146, 146, "USED-FOR"], [149, 149, 146, 146, "USED-FOR"], [148, 148, 149, 149, "USED-FOR"], [148, 148, 149, 149, "USED-FOR"], [148, 148, 149, 149, "USED-FOR"]], []]}
{"doc_key": "1906.00654-57d89d1f-9bab-4b73-bb1c-e39d6e0ff955", "sentences": [["For", "all", "experiments", ",", "we", "optimize", "our", "models", "using", "Adam", "-LSB-", "21", "-RSB-", "."], ["The", "batch", "size", "is", "set", "to", "100", ",", "and", "there", "are", "10", "-", "15", "batches", "per", "epoch", "for", "each", "task", "."], ["To", "train", "the", "classifier", ",", "we", "use", "an", "initial", "learning", "rate", "equal", "to", "5e-4", "and", "we", "train", "it", "for", "300", "epochs", "by", "minimizing", "the", "cross-entropy", "loss", "for", "each", "task", "."], ["Moreover", ",", "in", "order", "to", "train", "the", "generator", ",", "we", "use", "an", "initial", "learning", "rate", "of", "1e-3", "and", "train", "it", "for", "1700", "epochs", "for", "each", "task", "."], ["The", "autoencoder", "loss", "is", "the", "binary", "cross-entropy", "for", "each", "time-frequency", "bin", "between", "the", "original", "spectrogram", "and", "the", "reconstruction", "."], ["The", "loss", "for", "the", "variational", "autoencoder", "is", "the", "sum", "of", "binary", "cross-entropy", "and", "KL-Divergence", "between", "the", "modeled", "distribution", "and", "unit", "Gaussian", "."]], "ner": [[[9, 9, "a"]], [[15, 16, "p"], [20, 20, "v"], [28, 30, "p"], [25, 27, "v"]], [[43, 45, "p"], [48, 48, "v"], [55, 55, "p"], [54, 54, "v"], [38, 38, "c"], [59, 60, "a"]], [[77, 79, "p"], [87, 87, "p"], [86, 86, "v"], [72, 72, "c"]], [[97, 98, "a"]], [[121, 122, "a"], [124, 124, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"]], [[15, 16, "p"], [20, 20, "v"], [25, 27, "v"]], [[44, 45, "p"], [48, 48, "v"], [54, 54, "v"], [55, 55, "p"], [59, 60, "a"]], [[78, 79, "p"], [81, 81, "v"], [86, 86, "v"]], [[93, 94, "a"], [97, 98, "a"]], [[115, 116, "a"], [121, 122, "a"]]], "predicted_relations": [[], [[25, 27, 28, 30, "USED-FOR"]], [[48, 48, 43, 45, "USED-FOR"], [48, 48, 55, 55, "USED-FOR"], [54, 54, 55, 55, "USED-FOR"]], [[86, 86, 87, 87, "USED-FOR"]], [], []]}
{"doc_key": "1904.00824-91c86d27-e38a-45c0-82a3-a3e724fc2568", "sentences": [["RA", "."], ["Six", "classes", "shown", "in", "Figure", "REF", "are", "used", "for", "this", "experiment", "on", "training", "images", "synthesized", "using", "local", "BRDFs", "with", "environment", "maps", "for", "reflection", "approximation", "."], ["In", "order", "to", "train", "the", "object", "detector", "we", "used", "\\", "-LRB-", "12K\\", "-RRB-", "frames", "."], ["We", "set", "\\", "-LRB-", "batch\\_size", "=", "8\\", "-RRB-", ",", "from", "which", "we", "determine", "the", "number", "of", "steps", "per", "epoch", "\\", "-LRB-", "steps", "=", "1500\\", "-RRB-", "."], ["Training", "is", "stopped", "when", "no", "further", "improvement", "takes", "place", "."], ["For", "RA", "the", "process", "was", "stopped", "after", "55", "epochs", "."]], "ner": [[[0, 0, "a"]], [], [], [[48, 48, "v"], [58, 58, "p"], [63, 63, "p"], [65, 65, "v"]], [], [[79, 79, "a"], [86, 86, "p"], [85, 85, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[2, 2, "v"]], [[38, 38, "v"]], [[48, 48, "v"], [65, 65, "v"]], [], [[85, 85, "v"], [86, 86, "p"]]], "predicted_relations": [[], [], [], [[65, 65, 63, 63, "USED-FOR"]], [], [[85, 85, 86, 86, "USED-FOR"]]]}
{"doc_key": "1904.00824-7d578570-d09c-40fd-8fc7-e52da07e7042", "sentences": [["DR", "."], ["In", "the", "second", "experiment", "we", "trained", "another", "detector", "on", "the", "DR", "images", "."], ["A", "simple", "indoor", "scene", "is", "randomized", "in", "order", "to", "apply", "domain", "randomization", "to", "our", "data", "set", "as", "described", "in", "Section", "."], ["For", "synthesis", "of", "frames", "we", "also", "used", "local", "shading", "."], ["We", "train", "the", "object", "detector", "with", "\\", "-LRB-", "38K\\", "-RRB-", "images", "and", "we", "set", "\\", "-LRB-", "batch\\_size", "=", "8\\", "-RRB-", "leading", "to", "4750", "steps", "per", "epoch", "."], ["This", "task", "was", "terminated", "after", "39", "epochs", "."]], "ner": [[], [], [[25, 26, "a"]], [], [[49, 50, "a"], [64, 64, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"]], [], [], [[54, 54, "v"], [64, 64, "v"], [68, 68, "v"]], [[78, 78, "v"], [79, 79, "p"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1910.08914-b1a53eb4-0d76-4ffb-af1f-f2149c145207", "sentences": [["We", "use", "the", "Adam", "-LSB-", "16", "-RSB-", "optimizer", "with", "momentum", "parameters", "\\", "-LRB-", "\\beta", "_1=0.5", ",", "\\beta", "_2=0.999\\", "-RRB-", "."], ["We", "update", "one", "step", "for", "either", "\\", "-LRB-", "G\\", "-RRB-", "or", "\\", "-LRB-", "D\\", "-RRB-", "alternatively", ",", "and", "batch", "size", "is", "set", "to", "8", "."], ["Either", "the", "first", "or", "the", "second", "training", "stage", "lasts", "100", "epochs", "with", "an", "initial", "learning", "rate", "\\", "-LRB-", "lr_G=0.0001\\", "-RRB-", "for", "the", "generator", "and", "\\", "-LRB-", "lr_D=0.0004\\", "-RRB-", "for", "the", "discriminator", ",", "while", "the", "third", "stage", "lasts", "50", "epochs", "with", "initial", "learning", "rates", "\\", "-LRB-", "lr_G=0.00001\\", "-RRB-", "and", "\\", "-LRB-", "lr_D=0.00004\\", "-RRB-", "."], ["The", "learning", "rates", "decay", "at", "the", "halfway", "point", "of", "each", "stage", "."], ["The", "entire", "training", "process", "takes", "about", "seven", "days", "on", "eight", "GeForce", "GTX", "1080Ti", "GPUs", "."]], "ner": [[[3, 3, "a"], [9, 10, "p"], [14, 14, "v"], [17, 17, "v"]], [[38, 39, "a"]], [[59, 60, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [9, 10, "p"]], [[22, 22, "v"], [33, 33, "p"], [38, 39, "p"], [43, 43, "v"]], [[54, 54, "v"], [55, 55, "p"], [59, 60, "p"], [71, 71, "v"], [82, 82, "v"], [83, 83, "p"], [86, 87, "p"]], [[99, 100, "p"]], [[116, 116, "v"], [119, 119, "v"]]], "predicted_relations": [[[9, 10, 3, 3, "USED-FOR"], [14, 14, 9, 10, "USED-FOR"], [17, 17, 9, 10, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1902.01382-c56be682-c6f2-4f6d-b548-20998605a616", "sentences": [["Third", ",", "we", "consider", "a", "semi-supervised", "setting", "where", "we", "also", "leverage", "monolingual", "data", "on", "the", "target", "side", "using", "the", "standard", "back-translation", "training", "protocol", "-LSB-", "31", "-RSB-", ":", "we", "train", "a", "backward", "MT", "system", ",", "which", "we", "use", "to", "translate", "monolingual", "target", "sentences", "to", "the", "source", "language", "."], ["Then", ",", "we", "merge", "the", "resulting", "pairs", "of", "noisy", "-LRB-", "back-translated", "-RRB-", "source", "sentences", "with", "the", "original", "target", "sentences", "and", "add", "them", "as", "additional", "parallel", "data", "for", "training", "source-to-target", "MT", "system", "."], ["Since", "monolingual", "data", "is", "available", "for", "both", "languages", ",", "we", "train", "backward", "MT", "systems", "in", "both", "directions", "and", "repeat", "the", "back-translation", "process", "iteratively", "-LSB-", "14", "-RSB-", ",", "-LSB-", "19", "-RSB-", "."], ["We", "consider", "up", "to", "two", "back-translation", "iterations", "."], ["At", "each", "iteration", "we", "generate", "back-translations", "using", "beam", "search", ",", "which", "has", "been", "shown", "to", "perform", "well", "in", "low-resource", "settings", "-LSB-", "8", "-RSB-", ";", "we", "use", "a", "beam", "width", "of", "5", "and", "individually", "tune", "the", "length-penalty", "on", "the", "dev", "set", "."]], "ner": [[], [], [], [], [[148, 148, "v"], [145, 146, "c"], [153, 153, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[114, 114, "v"]], [[125, 126, "a"], [145, 146, "p"], [148, 148, "v"]]], "predicted_relations": [[], [], [], [], [[145, 146, 148, 148, "USED-FOR"], [145, 146, 153, 153, "USED-FOR"]]]}
{"doc_key": "1904.04764-4734a003-67bd-4934-a4f8-033fc8c759f8", "sentences": [["We", "train", "the", "end-to-end", "TTS", "system", "with", "a", "high-quality", "American", "English", "speech", "database", "used", "in", "2011", "Blizzard", "Challenge", ",", "which", "has", "16", "hours", "of", "speech", "recorded", "by", "a", "single", "female", "speaker", "."], ["We", "train", "these", "models", "for", "200,000", "iterations", "with", "a", "batch", "size", "of", "128", "distributed", "across", "4", "GPUs", "with", "synchronous", "updates", ",", "using", "\\", "-LRB-", "L1\\", "-RRB-", "loss", "and", "Adam", "optimizer", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "exponentially", "decayed", "to", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "after", "\\", "-LRB-", "50,000\\", "-RRB-", "iterations", "."], ["In", "this", "study", ",", "we", "use", "factored", "parser", "-LSB-", "14", "-RSB-", "of", "the", "Stanford", "Parser", "-LSB-", "27", "-RSB-", "to", "extract", "syntactic", "trees", "."]], "ner": [[[4, 5, "a"]], [[41, 42, "p"], [44, 44, "v"], [76, 77, "p"], [38, 38, "p"], [103, 103, "p"], [37, 37, "v"], [101, 101, "v"], [60, 61, "a"], [66, 66, "v"], [72, 72, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[3, 5, "a"], [21, 21, "v"]], [[37, 37, "v"], [41, 42, "p"], [44, 44, "v"], [47, 47, "v"], [60, 60, "a"], [76, 77, "p"], [81, 85, "v"], [92, 96, "v"], [101, 101, "v"]], []], "predicted_relations": [[], [[76, 77, 60, 61, "USED-FOR"], [103, 103, 60, 61, "USED-FOR"], [37, 37, 38, 38, "USED-FOR"], [101, 101, 103, 103, "USED-FOR"], [72, 72, 76, 77, "USED-FOR"]], []]}
{"doc_key": "1904.04775-f6d86439-6fe3-4d5c-b0f2-636230b1625b", "sentences": [["We", "use", "Tacotron2", "-LSB-", "9", "-RSB-", "as", "TTS", "model", ",", "include", "WaveNet", "as", "vocoder", "for", "all", "experiments", "."], ["We", "use", "one-hot", "feature", "as", "input", ",", "which", "contains", "phonemes", ",", "punctuation", "and", "the", "blank", "between", "two", "adjacent", "words", "."], ["The", "model", "output", "is", "an", "80-channel", "Mel", "spectrum", "-LRB-", "12.5", "ms", "frame", "shift", ",", "50", "ms", "frame", "length", "-RRB-", ",", "one", "frame", "at", "a", "time", "."], ["The", "model", "structure", "of", "the", "discriminator", "has", "been", "shown", "in", "Fig.REF", ",", "which", "has", "1536-dim", "input", ",", "512-dim", "hidden", "size", ",", "and", "1-dim", "output", "."]], "ner": [[[2, 2, "a"], [11, 11, "a"]], [[20, 21, "a"], [23, 23, "p"]], [[40, 40, "c"]], [[69, 69, "a"], [79, 79, "p"], [78, 78, "v"], [81, 81, "v"], [82, 83, "c"], [86, 86, "v"], [87, 87, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 8, "a"], [11, 11, "a"]], [[34, 34, "v"]], [[43, 43, "v"], [47, 48, "v"], [52, 53, "v"], [58, 58, "v"]], [[78, 78, "v"], [81, 81, "v"], [86, 86, "v"]]], "predicted_relations": [[], [[23, 23, 20, 21, "USED-FOR"]], [], [[78, 78, 79, 79, "USED-FOR"], [82, 83, 78, 78, "USED-FOR"]]]}
{"doc_key": "1904.04775-75a7b968-ec3d-43dc-94d7-64cc384e9536", "sentences": [["All", "models", "are", "trained", "with", "a", "batch", "size", "of", "128", "sequences", "."], ["We", "train", "these", "models", "using", "the", "Adam", "optimizer", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "."], ["The", "learning", "rate", "is", "exponentially", "decayed", "from", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "after", "50,000", "iterations", "."], ["The", "TF", "model", "trained", "with", "100,000", "steps", "is", "set", "to", "be", "the", "baseline", "model", "."], ["In", "SS", ",", "TF-GAN", "and", "SS-GAN", "training", ",", "we", "adopt", "the", "TF", "model", "trained", "with", "50,000", "steps", "as", "the", "pre-trained", "model", ",", "and", "train", "it", "for", "another", "50,000", "steps", "with", "these", "algorithms", "."], ["The", "scheduled", "sampling", "strategy", "is", "to", "use", "real", "data", "with", "a", "linear", "decay", ",", "from", "probability", "1", "to", "0.5", ",", "in", "the", "first", "50,000", "steps", "."], ["We", "set", "the", "initial", "learning", "rate", "\\", "-LRB-", "lr_g", "=", "10^", "-LCB-", "-3", "-RCB-", ",", "lr_d", "=", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "adversarial", "weight", "\\", "-LRB-", "\\alpha", "=", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "GAN-based", "algorithms", "."], ["The", "range", "of", "the", "required", "discriminator", "accuracy", "is", "set", "to", "\\", "-LRB-", "75\\", "%", "\\sim", "97\\", "%", "\\", "-RRB-", "."]], "ner": [[[6, 7, "a"], [6, 7, "p"], [9, 9, "v"]], [[18, 19, "a"], [24, 24, "v"], [30, 30, "v"]], [[34, 35, "a"]], [], [], [[110, 111, "a"], [125, 125, "v"], [127, 127, "v"]], [[139, 140, "a"], [138, 140, "p"], [172, 173, "a"], [143, 143, "p"], [150, 150, "p"], [163, 163, "p"]], [[180, 181, "p"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 7, "p"], [9, 9, "v"]], [[18, 18, "a"]], [[34, 35, "p"], [42, 45, "v"], [51, 54, "v"], [58, 58, "v"]], [[66, 66, "v"]], [[77, 77, "a"], [79, 79, "a"], [81, 81, "a"], [91, 91, "v"], [103, 103, "v"]], [[120, 121, "p"], [125, 125, "v"], [127, 127, "v"], [132, 132, "v"]], [[139, 140, "p"], [143, 143, "p"], [145, 148, "v"], [150, 150, "p"], [152, 155, "v"], [159, 160, "p"], [163, 163, "p"], [165, 168, "v"]], [[187, 188, "v"], [190, 191, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[138, 140, 139, 140, "USED-FOR"], [143, 143, 139, 140, "USED-FOR"], [150, 150, 139, 140, "USED-FOR"]], []]}
{"doc_key": "1903.05807-dc999692-129e-4fc2-abcd-b3e92b7c38db", "sentences": [["We", "train", "our", "model", "for", "50", "epochs", "with", "batch", "size", "32", "."], ["We", "use", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "with", "initial", "learning", "rate", "0.01", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "0.9", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "0.999", "."], ["Batch", "normalization", "-LSB-", "9", "-RSB-", "is", "applied", "before", "activation", "functions", "in", "all", "layers", "except", "the", "last", "layer", "."], ["Leaky", "ReLU", "with", "a", "fixed", "leakiness", "parameter", "0.2", "is", "used", "as", "activation", "functions", "."], ["Dropout", "-LSB-", "20", "-RSB-", "with", "keep", "ratio", "0.7", "is", "applied", "on", "last", "three", "fully-connected", "layers", "."]], "ner": [[], [[14, 15, "a"], [20, 22, "p"], [23, 23, "v"], [30, 30, "v"], [37, 37, "v"]], [[39, 40, "a"]], [[57, 58, "a"], [62, 63, "p"], [64, 64, "v"]], [[71, 71, "a"], [76, 77, "p"], [78, 78, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "v"], [6, 6, "p"], [8, 9, "p"], [10, 10, "v"]], [[14, 14, "a"], [21, 22, "p"], [23, 23, "v"], [30, 30, "v"], [37, 37, "v"]], [[39, 40, "a"]], [[57, 58, "a"], [62, 63, "p"], [64, 64, "v"]], [[71, 71, "a"], [76, 77, "p"], [78, 78, "v"], [83, 83, "v"]]], "predicted_relations": [[], [[20, 22, 14, 15, "USED-FOR"]], [], [[62, 63, 57, 58, "USED-FOR"]], [[76, 77, 71, 71, "USED-FOR"]]]}
{"doc_key": "1910.12129-e3c4c40d-e0a1-4df0-b7d2-251632658e0e", "sentences": [["Even", "though", "on", "the", "small", "datasets", "we", "work", "with", "we", "do", "not", "necessarily", "expect", "the", "Transformer", "model", "to", "perform", "better", "than", "recurrent", "neural", "networks", ",", "we", "chose", "this", "model", "for", "its", "significantly", "faster", "training", ",", "without", "sacrificing", "the", "performance", "."], ["For", "our", "experiments", "a", "small", "2-layer", "Transformer", "with", "8", "heads", "proved", "to", "be", "sufficient", "."], ["The", "input", "tokens", "are", "encoded", "into", "embeddings", "of", "size", "256", ",", "and", "the", "target", "sequences", "were", "truncated", "to", "60", "tokens", "."], ["The", "model", "performed", "best", "with", "dropout", "values", "of", "0.2", "."], ["For", "training", "of", "the", "Transformer", "models", "we", "used", "the", "Adam", "optimizer", "with", "a", "custom", "learning", "rate", "schedule", "including", "a", "brief", "linear", "warm-up", "and", "a", "cosine", "decay", "."]], "ner": [[[15, 16, "a"]], [], [[56, 57, "p"], [59, 64, "v"], [68, 69, "p"], [71, 74, "v"]], [[81, 82, "p"], [84, 84, "v"]], [[95, 96, "a"], [100, 102, "p"], [105, 111, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[15, 16, "a"], [28, 28, "a"]], [[48, 48, "v"]], [[64, 64, "v"], [73, 73, "v"]], [[77, 77, "a"], [81, 81, "p"], [84, 84, "v"]], [[90, 91, "a"], [95, 95, "a"], [106, 107, "a"], [110, 111, "a"]]], "predicted_relations": [[], [], [[59, 64, 68, 69, "USED-FOR"]], [[84, 84, 81, 82, "USED-FOR"]], []]}
{"doc_key": "1906.09925-f213bb68-f32f-48db-aaca-6ece03b862fb", "sentences": [["We", "employ", "a", "variety", "of", "masks", "based", "on", "the", "dependencies", "we", "want", "to", "capture", "in", "the", "dataset", "."], ["We", "use", "three", "different", "kinds", "of", "the", "mask", "in", "our", "evaluation", "-LRB-", "mask", "A1", "and", "B1", "for", "mask", "1", ",", "mask", "A2", "and", "B2", "for", "mask", "2", ",", "mask", "A3", "and", "B3", "for", "mask", "3", "-RRB-", ".The", "masks", "1", ",", "2", "and", "3", "for", "filter", "dimension", "5", "is", "shown", "in", "Fig", "."], ["REF", "-LRB-", "c", ",", "d", ",", "e", "-RRB-", "respectively", ",", "where", "the", "middle", "element", "in", "Fig", "."], ["REF", "-LRB-", "c", ",", "d", ",", "e", "-RRB-", "is", "0", "for", "mask", "A", "and", "1", "for", "mask", "B", "."]], "ner": [[], [[25, 25, "a"], [30, 30, "a"], [35, 35, "a"], [38, 38, "a"], [43, 43, "a"], [46, 46, "a"], [51, 51, "a"], [30, 33, "p"], [30, 31, "v"], [38, 41, "p"], [38, 39, "v"], [46, 49, "p"], [46, 47, "v"]], [], [[98, 98, "a"], [103, 103, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[20, 20, "v"], [58, 58, "v"], [60, 60, "v"], [64, 64, "v"]], [], [[96, 96, "v"], [101, 101, "v"]]], "predicted_relations": [[], [[30, 33, 25, 25, "USED-FOR"], [30, 33, 30, 30, "USED-FOR"], [30, 33, 35, 35, "USED-FOR"], [30, 33, 38, 38, "USED-FOR"], [30, 33, 43, 43, "USED-FOR"], [30, 33, 46, 46, "USED-FOR"], [30, 33, 51, 51, "USED-FOR"], [30, 31, 30, 33, "USED-FOR"], [30, 31, 38, 41, "USED-FOR"], [30, 31, 46, 49, "USED-FOR"], [38, 41, 25, 25, "USED-FOR"], [38, 41, 30, 30, "USED-FOR"], [38, 41, 35, 35, "USED-FOR"], [38, 41, 38, 38, "USED-FOR"], [38, 41, 43, 43, "USED-FOR"], [38, 41, 46, 46, "USED-FOR"], [38, 41, 51, 51, "USED-FOR"], [38, 39, 38, 41, "USED-FOR"], [38, 39, 46, 49, "USED-FOR"], [46, 49, 25, 25, "USED-FOR"], [46, 49, 30, 30, "USED-FOR"], [46, 49, 35, 35, "USED-FOR"], [46, 49, 38, 38, "USED-FOR"], [46, 49, 43, 43, "USED-FOR"], [46, 49, 46, 46, "USED-FOR"], [46, 49, 51, 51, "USED-FOR"], [46, 47, 38, 41, "USED-FOR"], [46, 47, 46, 49, "USED-FOR"]], [], []]}
{"doc_key": "1909.06092-4f6c78f2-9255-4865-893e-66b6c6f452d0", "sentences": [["Augmented", "Bias", "Specifications", "."], ["We", "first", "augment", "the", "bias", "specifications", "using", "a", "similarity-specialized", "embedding", "space", "produced", "by", "-LSB-", "23", "-RSB-", "Available", "at", ":", "https", ":", "//tinyurl.com/y273cuvk", "."], ["based", "on", "the", "en", "fastText", "embeddings", "-LSB-", "1", "-RSB-", "."], ["For", "WEAT", "T8", ",", "we", "augment", "the", "target", "and", "attribute", "lists", "with", "\\", "-LRB-", "k=4\\", "-RRB-", "nearest", "neighbours", "of", "each", "term", "."], ["As", "the", "initial", "lists", "of", "WEAT", "T1", "are", "longer", "than", "those", "of", "T8", ",", "we", "use", "\\", "-LRB-", "k=2\\", "-RRB-", "with", "T1", "."], ["We", "train", "all", "debiasing", "models", "using", "bias", "specifications", "containing", "only", "the", "augmentation", "terms", "-LRB-", "i.e.", ",", "without", "the", "initial", "bias", "specification", "terms", "-RRB-", ";", "we", "use", "the", "initial", "terms", "for", "testing", "."]], "ner": [[], [], [[30, 32, "a"]], [[38, 39, "a"], [51, 51, "p"], [51, 51, "v"]], [[77, 77, "p"], [77, 77, "v"], [64, 65, "c"]], [[85, 86, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [], [[38, 39, "a"], [51, 51, "v"]], [[64, 64, "a"], [71, 71, "a"], [77, 77, "v"], [80, 80, "a"]], []], "predicted_relations": [[], [], [], [[51, 51, 38, 39, "USED-FOR"], [51, 51, 51, 51, "USED-FOR"], [51, 51, 51, 51, "USED-FOR"]], [[77, 77, 77, 77, "USED-FOR"], [77, 77, 77, 77, "USED-FOR"], [64, 65, 77, 77, "USED-FOR"]], []]}
{"doc_key": "1907.13196-0a2ac46e-d80c-4a3c-94f5-0b94f32a00fe", "sentences": [["Recognising", "that", "\\", "-LRB-", "W", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", "=", "0\\", "-RRB-", "-LRB-", "the", "distance", "between", "the", "same", "probability", "densities", "-RRB-", ",", "and", "\\", "-LRB-", "\\nabla", "_", "-LCB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-RCB-", "W", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", "=", "0\\", "-RRB-", "since", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "\\", "-RRB-", "minimises", "\\", "-LRB-", "W", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "we", "can", "simplify", "the", "Hessian", "approximation", "by", "writing", ":", "\\", "-LRB-", "W", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-RRB-", "\\approx", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "2", "-RCB-", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", "^", "-LCB-", "\\mathsf", "-LCB-", "T", "-RCB-", "-RCB-", "\\nabla", "^", "-LCB-", "2", "-RCB-", "_", "-LCB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-RCB-", "W", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", "-LRB-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "-", "\\mathbf", "-LCB-", "\\phi", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", ".\\", "-RRB-"]], "ner": [[]], "relations": [[]], "predicted_ner": [[]], "predicted_relations": [[]]}
{"doc_key": "1907.13268-f12f2127-cf80-4c2e-8c7f-eb719eb745c4", "sentences": [["For", "both", "synthetic", "and", "real", "experiments", ",", "our", "EMP-Net", "model", "is", "trained", "with", "a", "batch", "size", "of", "16", ",", "where", "every", "instance", "within", "a", "batch", "is", "a", "sequence", "of", "5", "consecutive", "frames", "resized", "to", "\\", "-LRB-", "120", "\\times", "160\\", "-RRB-", "."], ["The", "RGB", "and", "depth", "data", "were", "scaled", "to", "between", "\\", "-LRB-", "-LSB-", "0,1", "-RSB-", "\\", "-RRB-", "."], ["The", "buffer", "size", "of", "the", "SSMM", "is", "\\", "-LRB-", "b=4\\", "-RRB-", "and", "the", "number", "of", "extracted", "point-embeddings", "is", "\\", "-LRB-", "N_r=4800\\", "-RRB-", "."], ["The", "temperature", "parameter", "was", "tested", "with", "values", "between", "\\", "-LRB-", "\\tau", "=", "-LSB-", "10^", "-LCB-", "3", "-RCB-", ",10^", "-LCB-", "6", "-RCB-", "-RSB-", "\\", "-RRB-", ",", "where", "we", "found", "the", "model", "to", "be", "fairly", "invariant", "to", "this", "value", "."], ["In", "all", "of", "the", "experiments", "shown", "\\", "-LRB-", "\\tau", "=10^", "-LCB-", "5", "-RCB-", "\\", "-RRB-", "."], ["The", "embedding", "distance", "function", "is", "defined", "as", "the", "\\", "-LRB-", "L2\\", "-RRB-", "distance", ",", "\\", "-LRB-", "d_", "-LCB-", "\\phi", "-RCB-", "=\\left\\Vert", "a-b\\right\\Vert", "_2\\", "-RRB-", "."], ["\\", "-LRB-", "\\lambda", "_t=0.02\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_R=5\\", "-RRB-", "are", "chosen", "to", "maintain", "the", "same", "ratio", "as", "in", "-LSB-", "22", "-RSB-", "."], ["We", "use", "the", "ADAM", "optimiser", "-LSB-", "23", "-RSB-", ",", "using", "the", "default", "first", "and", "second", "moment", "terms", "of", "0.9", "and", "0.999", "values", "respectively", "."], ["We", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "and", "train", "for", "10", "epochs", "."]], "ner": [[[8, 9, "a"], [14, 15, "p"], [17, 17, "v"], [29, 29, "v"]], [], [[59, 60, "p"], [67, 67, "v"], [71, 74, "p"], [78, 78, "v"]], [[82, 83, "p"], [94, 94, "v"], [98, 98, "v"]], [[130, 130, "v"], [128, 128, "v"]], [[136, 138, "p"]], [[163, 163, "v"], [169, 169, "v"]], [[187, 188, "a"], [202, 202, "v"], [204, 204, "v"]], [[211, 212, "p"], [226, 226, "p"], [216, 216, "v"], [225, 225, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 9, "a"], [14, 15, "p"], [17, 17, "v"], [29, 29, "v"], [36, 36, "v"], [38, 38, "v"]], [[52, 54, "v"]], [[63, 63, "a"], [67, 67, "v"]], [], [], [], [[162, 163, "p"], [168, 169, "p"]], [[187, 187, "a"], [202, 202, "v"], [204, 204, "v"]], [[211, 212, "p"], [216, 219, "v"], [225, 225, "v"], [226, 226, "p"]]], "predicted_relations": [[[14, 15, 8, 9, "USED-FOR"]], [], [[67, 67, 59, 60, "USED-FOR"], [67, 67, 71, 74, "USED-FOR"], [78, 78, 71, 74, "USED-FOR"]], [], [], [], [], [], [[216, 216, 211, 212, "USED-FOR"], [216, 216, 226, 226, "USED-FOR"], [225, 225, 226, 226, "USED-FOR"]]]}
{"doc_key": "1901.06484-2358c3ed-75c8-4758-8177-aaef3f7e5b20", "sentences": [["The", "network", "depth", "is", "usually", "defined", "as", "the", "length", "of", "the", "longest", "path", "from", "the", "input", "to", "the", "output", "-LSB-", "17", "-RSB-", ",", "-LSB-", "30", "-RSB-", "."], ["According", "to", "the", "entire", "structure", "of", "the", "proposed", "model", ",", "the", "depth", "of", "our", "CSSFN", "network", "is", "given", "by", ":", "\\", "-LRB-", "D", "=", "n", "-LSB-", "1", "+", "m", "\\times", "-LRB-", "q", "+", "1", "-RRB-", "-RSB-", "+", "s", "+", "6", ",", "\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[], [[41, 42, "a"], [55, 55, "p"]]], "predicted_relations": [[], []]}
{"doc_key": "1901.06484-6c58879f-47f7-4cb8-8e90-b93e48334890", "sentences": [["where", "\\", "-LRB-", "s\\", "-RRB-", "denotes", "the", "depth", "of", "the", "upscale", "modula", "and", "depends", "on", "the", "specific", "value", "of", "the", "scaling", "factor", "\\", "-LRB-", "r\\", "-RRB-", "."], ["Specifically", ",", "\\", "-LRB-", "s", "=", "1\\", "-RRB-", "for", "\\", "-LRB-", "r", "=", "2\\", "-RRB-", "or", "\\", "-LRB-", "r", "=", "3\\", "-RRB-", ",", "and", "\\", "-LRB-", "s", "=", "2\\", "-RRB-", "for", "\\", "-LRB-", "r", "=", "4\\", "-RRB-", "."], ["The", "first", "\u201c", "1", "\u201d", "in", "-LRB-", "REF", "-RRB-", "corresponds", "to", "the", "compression", "layer", "at", "the", "beginning", "of", "each", "CSSFB", ",", "and", "the", "second", "one", "denotes", "the", "extension", "layer", "at", "the", "end", "of", "each", "CSSFU", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], [[68, 68, "v"], [84, 84, "a"], [89, 89, "v"], [99, 99, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1903.06482-b1ad61b1-589c-43ba-8bcf-50d441052315", "sentences": [["Both", "the", "depth", "and", "semantic", "predictions", "are", "jointly", "trained", "using", "groundtruth", "data", "."], ["In", "addition", "to", "the", "reconstruction", "losses", "discussed", "in", "the", "following", "sections", ",", "the", "variational", "setup", "requires", "a", "KL-divergence", "based", "loss", "on", "the", "latent", "space", "-LSB-", "20", "-RSB-", "."], ["In", "order", "to", "avoid", "a", "degrading", "latent", "space", ",", "we", "employ", "a", "KL", "annealing", "strategy", "-LSB-", "3", "-RSB-", ",", "-LSB-", "33", "-RSB-", "where", "we", "gradually", "increase", "the", "weights", "of", "the", "KL", "terms", "from", "0", "after", "2", "training", "epochs", "."], ["Finally", ",", "the", "weights", "of", "semantic", "vs.", "depth", "reconstruction", "losses", "are", "trained", "in", "an", "adaptive", "manner", "to", "account", "for", "task-dependent", "uncertainty", "-LSB-", "17", "-RSB-", "."], ["In", "all", "of", "our", "experiments", ",", "we", "train", "the", "whole", "network", "in", "an", "end-to-end", "manner", "using", "the", "Adam", "optimiser", "-LSB-", "19", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "ResNet-50", "is", "initialised", "using", "ImageNet", "pre-trained", "weights", ",", "and", "all", "other", "weights", "are", "initialised", "using", "He", "'s", "method", "-LSB-", "10", "-RSB-", "."]], "ner": [[], [[30, 32, "a"]], [[53, 55, "a"], [75, 78, "c"]], [], [[129, 131, "p"], [122, 123, "a"], [143, 144, "p"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[30, 30, "a"]], [[74, 74, "v"], [76, 76, "v"]], [], [[122, 122, "a"], [130, 131, "p"], [135, 138, "v"], [143, 144, "p"], [148, 151, "v"]], [[156, 156, "a"], [160, 160, "a"], [171, 173, "a"]]], "predicted_relations": [[], [], [], [], [[129, 131, 122, 123, "USED-FOR"], [143, 144, 122, 123, "USED-FOR"]], []]}
{"doc_key": "1903.06482-6cd9d222-3f7e-4b24-a69c-07096986fc03", "sentences": [["For", "depth", "images", ",", "as", "in", "-LSB-", "2", "-RSB-", ",", "the", "raw", "depth", "values", "\\", "-LRB-", "d\\", "-RRB-", "are", "first", "transformed", "via", "a", "hybrid", "parametrisation", "called", "proximity", ",", "\\", "-LRB-", "p=", "a/", "-LRB-", "a+d", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "a\\", "-RRB-", "is", "the", "average", "depth", "value", ",", "which", "is", "set", "to", "2m", "in", "all", "of", "our", "experiments", "."], ["In", "this", "way", ",", "we", "can", "handle", "raw", "depth", "values", "ranging", "from", "0", "to", "\\", "-LRB-", "+\\infty", "\\", "-RRB-", "and", "assign", "more", "precision", "to", "regions", "closer", "to", "the", "camera", "."], ["An", "\\", "-LRB-", "L_", "-LCB-", "1", "-RCB-", "\\", "-RRB-", "loss", "function", "together", "with", "data", "dependent", "Homoscedastic", "uncertainty", "-LSB-", "16", "-RSB-", "is", "used", "as", "the", "reconstruction", "error", ":", "\\", "-LRB-", "L_", "-LCB-", "\\phi", ",", "\\theta", "-RCB-", "\\left", "-LRB-", "d\\right", "-RRB-", "&", "=", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "N", "-RCB-", "\\left", "-LSB-", "\\frac", "-LCB-", "\\left|\\widetilde", "-LCB-", "p", "-RCB-", "_", "-LCB-", "i", "-RCB-", "-p_", "-LCB-", "i", "-RCB-", "\\right|", "-RCB-", "-LCB-", "b_", "-LCB-", "i", "-RCB-", "-RCB-", "+\\log", "\\left", "-LRB-", "b_", "-LCB-", "i", "-RCB-", "\\right", "-RRB-", "\\right", "-RSB-", ",", "\\", "-RRB-"]], "ner": [[[22, 22, "p"], [31, 31, "p"], [33, 33, "p"], [41, 41, "p"], [53, 53, "v"]], [], []], "relations": [[], [], []], "predicted_ner": [[[53, 53, "v"]], [[72, 72, "v"]], []], "predicted_relations": [[[53, 53, 22, 22, "USED-FOR"], [53, 53, 31, 31, "USED-FOR"], [53, 53, 33, 33, "USED-FOR"], [53, 53, 41, 41, "USED-FOR"]], [], []]}
{"doc_key": "1908.02391-dde3a819-da94-4e5f-943c-7c2fb795ca77", "sentences": [["We", "use", "Inception-V3", "as", "a", "backbone", "for", "our", "model", "."], ["In", "particular", ",", "we", "take", "the", "convolutional", "layers", "and", "initialize", "them", "with", "weights", "from", "a", "standard", "network", "pre-trained", "on", "ImageNet", "."], ["The", "final", "descriptors", "are", "further", "max-pooled", "and", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "normalized", "."], ["The", "descriptor", "size", "is", "\\", "-LRB-", "2,048\\", "-RRB-", "."], ["The", "model", "is", "trained", "using", "the", "ADAM", "optimizer", ",", "with", "the", "initial", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "with", "a", "learning", "rate", "decay", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "each", "\\", "-LRB-", "50\\textrm", "-LCB-", "k", "-RCB-", "\\", "-RRB-", "iterations", "."], ["The", "images", "for", "person", "re-ID", "are", "resized", "to", "\\", "-LRB-", "192", "\\times", "384\\", "-RRB-", "pixels", ",", "and", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "for", "Stanford", "Online", "Products", "."], ["At", "test", "time", ",", "we", "extract", "representations", "and", "compare", "them", "using", "dot", "product", "."]], "ner": [[[2, 2, "a"]], [], [], [], [[60, 61, "a"], [65, 67, "p"], [80, 82, "p"], [86, 86, "v"], [97, 97, "p"]], [], [[138, 139, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [8, 8, "a"]], [[29, 29, "a"]], [], [[51, 51, "v"]], [[60, 60, "a"], [66, 67, "p"], [70, 73, "v"], [80, 82, "p"], [86, 86, "v"]], [[109, 109, "v"], [111, 111, "v"], [118, 118, "v"], [120, 120, "v"]], []], "predicted_relations": [[], [], [], [], [[65, 67, 60, 61, "USED-FOR"], [80, 82, 60, 61, "USED-FOR"]], [], []]}
{"doc_key": "1907.01922-70db499b-e99b-45ed-b8c0-1b7400d47fc0", "sentences": [["In", "our", "proposed", "model", ",", "we", "used", "the", "encoder", "architecture", "in", "-LSB-", "3", "-RSB-", "as", "the", "backbone", "for", "both", "CNNs", "."], ["We", "adopted", "the", "initialization", "strategy", "of", "this", "work", "-LSB-", "7", "-RSB-", "to", "initialize", "the", "weights", "of", "all", "convolutional", "layers", "."], ["Moreover", ",", "we", "set", "the", "initial", "learning", "rate", "as", "\\", "-LRB-", "1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "periodically", "reduced", "it", "by", "multiplying", "with", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "and", "stopped", "the", "learning", "process", "after", "100", "epochs", "."], ["We", "employed", "the", "Adam", "optimizer", "-LSB-", "9", "-RSB-", "with", "the", "first", "momentum", "of", "0.9", ",", "the", "second", "momentum", "of", "0.999", ",", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "to", "minimize", "the", "loss", "-LRB-", "see", "Eq", "."], ["REF", "-RRB-", "of", "the", "whole", "network", "."], ["Our", "network", "was", "implemented", "using", "the", "Keras", "toolbox", "with", "a", "Tensorflow", "backend", "and", "we", "set", "the", "mini-batch", "size", "as", "one", "."]], "ner": [[[8, 9, "a"]], [[24, 25, "a"]], [[67, 67, "v"]], [[82, 83, "a"], [89, 90, "p"], [92, 92, "v"], [95, 96, "p"], [98, 98, "v"], [102, 103, "p"], [107, 107, "v"], [112, 112, "a"]], [], [[130, 131, "a"], [134, 135, "a"], [140, 141, "a"], [140, 141, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [], [[47, 48, "p"], [52, 54, "v"], [67, 67, "v"], [76, 76, "v"], [77, 77, "p"]], [[82, 82, "a"], [92, 92, "v"], [98, 98, "v"], [102, 103, "p"], [107, 107, "v"]], [], [[125, 125, "a"], [140, 141, "p"], [143, 143, "v"]]], "predicted_relations": [[], [], [], [[95, 96, 82, 83, "USED-FOR"], [98, 98, 95, 96, "USED-FOR"], [102, 103, 82, 83, "USED-FOR"], [107, 107, 102, 103, "USED-FOR"]], [], [[140, 141, 130, 131, "USED-FOR"], [140, 141, 134, 135, "USED-FOR"], [140, 141, 140, 141, "USED-FOR"]]]}
{"doc_key": "1907.01791-facd5db5-1c3a-42b1-9f7b-5e6c7e7cb1ef", "sentences": [["All", "our", "proposed", "models", "are", "trained", "with", "backpropagation", ",", "and", "gradient-based", "optimization", "is", "performed", "using", "Adam", "-LSB-", "16", "-RSB-", "."], ["In", "all", "experiments", ",", "we", "set", "the", "character", "LSTM", "hidden", "size", "to", "64", "and", "word", "embedding", "LSTM", "hidden", "size", "to", "128", "."], ["We", "use", "300-dimension", "GloVe", "vectors", "-LSB-", "27", "-RSB-", "for", "the", "benchmark", "datasets", "and", "in-house", "embeddings", "for", "the", "Alexa", "dataset", ",", "which", "are", "trained", "with", "Wikipedia", "data", "and", "live", "utterances", "spoken", "to", "Alexa", "."], ["Character", "embedding", "dimensions", "and", "dropout", "rate", "are", "set", "to", "100", "and", "0.5", "respectively", "."], ["Minimax", "optimization", "in", "adversarial", "training", "was", "implemented", "via", "the", "use", "of", "a", "gradient", "reversal", "layer", "-LSB-", "9", "-RSB-", ",", "-LSB-", "22", "-RSB-", "."], ["The", "models", "are", "implemented", "with", "the", "TensorFlow", "library", "-LSB-", "0", "-RSB-", "."]], "ner": [[[15, 15, "a"]], [], [[45, 45, "a"]], [[86, 86, "v"], [75, 76, "a"]], [[89, 90, "a"]], [[118, 118, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [15, 15, "a"]], [[28, 28, "a"], [32, 32, "v"], [36, 36, "a"], [40, 40, "v"]], [[44, 44, "v"], [45, 46, "a"], [59, 60, "a"]], [[79, 80, "p"], [84, 84, "v"], [86, 86, "v"]], [[101, 102, "a"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1907.01791-b82517e8-4b5f-4241-886f-5afd7bcd7e4d", "sentences": [["For", "benchmark", "data", ",", "the", "models", "are", "trained", "using", "an", "early-stop", "strategy", "with", "maximum", "epoch", "set", "to", "50", "and", "patience", "-LRB-", "i.e.", ",", "number", "of", "epochs", "with", "no", "improvement", "on", "the", "dev", "set", "for", "both", "SF", "and", "IC", "-RRB-", "to", "6", "."], ["In", "addition", ",", "the", "benchmark", "dataset", "has", "varied", "size", "vocabularies", "across", "its", "datasets", "."], ["To", "give", "equal", "importance", "to", "each", "of", "them", ",", "\\", "-LRB-", "\\alpha", "_i^j\\", "-RRB-", "-LRB-", "see", "Equation", "REF", "-RRB-", "is", "proportional", "to", "\\", "-LRB-", "1/n\\", "-RRB-", ",", "where", "\\", "-LRB-", "n\\", "-RRB-", "is", "the", "training", "set", "size", "of", "task", "\\", "-LRB-", "j\\", "-RRB-", "in", "group", "\\", "-LRB-", "i\\", "-RRB-", "."], ["We", "are", "able", "to", "train", "on", "CPUs", ",", "due", "to", "the", "low", "values", "of", "\\", "-LRB-", "n\\", "-RRB-", "."]], "ner": [[[10, 11, "a"], [13, 14, "p"], [17, 17, "v"], [19, 19, "p"], [40, 40, "v"]], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[17, 17, "v"], [25, 25, "p"], [37, 37, "a"], [40, 40, "v"]], [], [], []], "predicted_relations": [[[13, 14, 10, 11, "USED-FOR"], [17, 17, 13, 14, "USED-FOR"], [17, 17, 19, 19, "USED-FOR"], [19, 19, 10, 11, "USED-FOR"]], [], [], []]}
{"doc_key": "1907.01791-15676bef-0946-4a76-9f09-e0deefa889ea", "sentences": [["For", "Alexa", "data", ",", "optimal", "hyperparameters", "are", "determined", "on", "the", "80", "development", "skills", "and", "applied", "to", "the", "training", "and", "evaluation", "of", "the", "90", "test", "skills", "."], ["\\", "-LRB-", "\\alpha", "_i^j\\", "-RRB-", "is", "here", "set", "to", "1", "as", "all", "skills", "have", "\\", "-LRB-", "10,000\\", "-RRB-", "training", "utterances", "sampled", "from", "the", "respective", "developer-defined", "skill", "grammars", "-LSB-", "17", "-RSB-", "."], ["Here", ",", "training", "was", "done", "using", "GPU-enabled", "EC2", "instances", "-LRB-", "p2.8xlarge", "-RRB-", "."]], "ner": [[[1, 2, "a"]], [], []], "relations": [[], [], []], "predicted_ner": [[[10, 10, "v"], [22, 22, "v"]], [[35, 35, "v"], [42, 42, "v"]], [[64, 64, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1909.06515-1b7ab593-214c-4fbf-a791-2ae316ba37a2", "sentences": [["For", "the", "B\u00e9rard", "architecture", ",", "we", "use", "the", "Adam", "optimizer", "-LSB-", "22", "-RSB-", "with", "a", "learning", "rate", "of", "0.001", "."], ["For", "the", "smaller", "AST", "Librispeech", "task", ",", "we", "use", "a", "minibatch", "size", "of", "16000", "frames", "to", "help", "convergence", "."], ["For", "other", "tasks", ",", "we", "use", "a", "minibatch", "size", "of", "96,000", "frames", "except", "for", "the", "vggtransformer", "where", "we", "use", "72,000", "frames", "-LRB-", "to", "avoid", "memory", "issues", "-RRB-", "."], ["We", "also", "use", "delayed", "updates", "-LSB-", "23", "-RSB-", "in", "order", "to", "keep", "the", "same", "effective", "batch", "size", "and", "avoid", "GPU", "out-of-memory", "errors", "."], ["All", "experiments", "are", "conducted", "on", "8", "GPUs", "."], ["For", "other", "architectures", "than", "B\u00e9rard", ",", "we", "use", "ADADELTA", "-LSB-", "24", "-RSB-", "with", "a", "learning", "rate", "of", "1", "and", "we", "normalize", "the", "loss", "per", "utterance", "instead", "of", "per", "token", "."], ["These", "hyperparameters", "were", "chosen", "based", "on", "preliminary", "experimentation", "on", "the", "ASR", "Librispeech", "task", "."]], "ner": [[[8, 9, "a"], [15, 16, "p"], [18, 18, "v"], [15, 16, "p"]], [[30, 31, "a"], [33, 34, "v"]], [[46, 47, "a"], [40, 41, "p"], [49, 50, "v"], [58, 59, "v"], [54, 54, "c"]], [[70, 71, "a"]], [], [[112, 113, "p"], [106, 106, "a"], [112, 113, "p"], [115, 115, "v"]], [[138, 140, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [8, 8, "a"], [15, 16, "p"], [18, 18, "v"]], [[33, 33, "v"]], [[49, 49, "v"], [54, 54, "a"], [58, 58, "v"]], [[70, 71, "a"]], [[95, 95, "v"]], [[102, 102, "a"], [106, 106, "a"], [112, 113, "p"], [115, 115, "v"]], []], "predicted_relations": [[[15, 16, 8, 9, "USED-FOR"], [15, 16, 8, 9, "USED-FOR"]], [], [[54, 54, 49, 50, "USED-FOR"], [54, 54, 58, 59, "USED-FOR"]], [], [], [[112, 113, 106, 106, "USED-FOR"], [112, 113, 106, 106, "USED-FOR"]], []]}
{"doc_key": "1910.13676-0ff0a463-17ad-4721-8355-a8972d4cfe42", "sentences": [["As", "mentioned", "in", "section", "we", "use", "our", "modified", "version", "of", "Pointnet++", "for", "training", "and", "testing", "the", "effectiveness", "of", "synthetic", "data", "."], ["We", "train", "the", "model", "on", "point", "clouds", "with", "and", "without", "color", "information", "denoted", "as", "RGB-Di-", "*", "and", "Di-", "*", "respectively", "."], ["Here", "*", "represents", "the", "type", "of", "training", "dataset", ",", "i", "represents", "the", "number", "of", "training", "classes", "-LRB-", "excluding", "unlabelled", "class", "-RRB-", ",", "RGB", "stands", "for", "Red", ",", "Green", ",", "Blue", "channel", "of", "image", "and", "D", "stands", "for", "Depth", "information", "."], ["We", "trained", "all", "models", "until", "saturation", ",", "and", "used", "Adam", "optimizer", "with", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "learning", "rate", "decay", "of", "\\", "-LRB-", "0.7\\", "-RRB-", "."], ["All", "models", "are", "trained", "on", "a", "sample", "size", "of", "8192", "points", "per", "batch", "."]], "ner": [[], [], [], [[94, 95, "p"], [109, 110, "p"], [99, 99, "v"], [102, 102, "p"], [106, 106, "v"], [109, 111, "p"], [115, 115, "v"], [91, 92, "a"]], [[124, 125, "a"], [128, 130, "p"], [127, 127, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[10, 10, "a"]], [[24, 24, "a"]], [], [[91, 91, "a"], [94, 95, "p"], [99, 99, "v"], [102, 102, "p"], [106, 106, "v"], [109, 111, "p"], [115, 115, "v"]], [[127, 127, "v"]]], "predicted_relations": [[], [], [], [[109, 110, 91, 92, "USED-FOR"], [99, 99, 102, 102, "USED-FOR"], [102, 102, 91, 92, "USED-FOR"], [106, 106, 109, 110, "USED-FOR"], [106, 106, 109, 111, "USED-FOR"], [109, 111, 91, 92, "USED-FOR"]], [[128, 130, 124, 125, "USED-FOR"]]]}
{"doc_key": "1905.12349-3704f947-632a-4e3f-90d2-3888313cd374", "sentences": [["The", "ILSVRC", "2012", "classification", "dataset", "consists", "of", "1.28", "million", "images", "for", "training", ",", "and", "50,000", "images", "for", "validation", ",", "from", "1000", "different", "classes", "."], ["We", "train", "networks", "on", "the", "training", "set", "and", "report", "the", "top-1", "and", "top-5", "accuracy", "on", "the", "validation", "set", "."], ["We", "train", "our", "models", "using", "Pytorch", ",", "and", "optimization", "is", "performed", "using", "synchronous", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "algorithm", "with", "a", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "a", "batch", "size", "of", "256", "."], ["Following", "the", "MobileNets", ",", "setup", ",", "we", "use", "a", "initial", "learning", "rate", "of", "0.045", ",", "and", "a", "learning", "rate", "decay", "rate", "of", "0.98", "per", "epoch", "."]], "ner": [[[1, 4, "a"]], [], [[48, 48, "a"], [65, 65, "p"], [69, 69, "v"], [73, 74, "p"], [76, 76, "v"]], [[87, 89, "p"], [91, 91, "v"], [95, 98, "p"], [100, 100, "v"], [101, 102, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "v"], [14, 14, "v"], [20, 20, "v"]], [], [[46, 46, "a"], [48, 48, "a"], [55, 62, "a"], [65, 65, "p"], [69, 69, "v"], [73, 74, "p"], [76, 76, "v"]], [[80, 80, "a"], [88, 89, "p"], [91, 91, "v"], [95, 98, "p"], [100, 100, "v"]]], "predicted_relations": [[], [], [[65, 65, 48, 48, "USED-FOR"]], [[101, 102, 100, 100, "USED-FOR"]]]}
{"doc_key": "1905.12349-7bb1bac6-2406-4bc8-afab-b30268b79512", "sentences": [["The", "CIFAR-100", "dataset", "consists", "of", "colored", "natural", "images", "with", "\\", "-LRB-", "32", "\\times", "32\\", "-RRB-", "pixels", "."], ["The", "training", "and", "testing", "sets", "contain", "50000", "and", "10000", "images", ",", "respectively", "."], ["We", "train", "networks", "on", "the", "training", "set", "and", "report", "the", "average", "accuracy", "of", "three", "executions", "of", "the", "experiments", "on", "the", "testing", "set", "."]], "ner": [[[1, 2, "a"]], [[23, 23, "v"], [25, 25, "v"]], [[35, 36, "p"], [50, 51, "p"], [32, 32, "a"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [11, 11, "v"], [13, 13, "v"]], [[23, 23, "v"], [25, 25, "v"]], [[43, 43, "v"]]], "predicted_relations": [[], [], [[35, 36, 32, 32, "USED-FOR"]]]}
{"doc_key": "1905.12349-563b5945-e654-4e02-ad04-12b63a7800ae", "sentences": [["We", "train", "all", "these", "models", "using", "Pytorch", "and", "optimize", "them", "using", "synchronous", "SGD", "algorithm", "with", "the", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "the", "batch", "size", "of", "128", "."], ["All", "the", "models", "are", "trained", "in", "150", "epochs", "from", "scratch", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.01\\", "-RRB-", "and", "decreased", "by", "a", "factor", "of", "10", "every", "80", "epochs", "."]], "ner": [[[6, 6, "a"], [12, 13, "a"], [16, 16, "p"], [24, 25, "p"]], [[35, 35, "v"], [36, 36, "p"]], [[41, 43, "p"], [60, 60, "p"], [59, 59, "v"], [58, 58, "c"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"], [16, 16, "p"], [20, 20, "v"], [24, 25, "p"], [27, 27, "v"]], [[35, 35, "v"], [36, 36, "p"]], [[42, 43, "p"], [49, 49, "v"], [57, 57, "v"], [59, 59, "v"], [60, 60, "p"]]], "predicted_relations": [[[16, 16, 6, 6, "USED-FOR"], [16, 16, 12, 13, "USED-FOR"]], [[35, 35, 36, 36, "USED-FOR"]], [[59, 59, 60, 60, "USED-FOR"]]]}
{"doc_key": "1904.09764-45b391bd-0cd9-4bf2-9d1e-4c9a094a0dca", "sentences": [["We", "use", "CIFAR-100", "dataset", "-LSB-", "15", "-RSB-", "to", "perform", "the", "analysis", "."], ["The", "dataset", "contains", "60,000", "32x32", "color", "images", "in", "100", "different", "classes", "-LRB-", "600", "images", "per", "class", "-RRB-", "."], ["It", "is", "split", "into", "training", "set", "and", "test", "set", "with", "the", "ratio", "of", "5:1", "."], ["All", "models", "in", "this", "section", "are", "trained", "90", "epochs", "with", "random", "horizontal", "flip", "as", "data", "augmentation", "-LSB-", "16", "-RSB-", ",", "for", "preprocessing", ",", "we", "normalize", "the", "data", "using", "the", "channel", "means", "and", "standard", "deviations", "as", "in", "-LSB-", "16", "-RSB-", "."], ["The", "networks", "are", "updated", "with", "ADAGRAD", "-LSB-", "4", "-RSB-", "optimizer", "with", "learning", "rate", "set", "to", "0.1", "and", "decreases", "to", "0.01", "from", "45th", "epoch", "on", "wards", "."]], "ner": [[[2, 3, "a"]], [], [], [], [[90, 90, "a"], [96, 97, "p"], [100, 100, "v"], [104, 104, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 3, "a"]], [[15, 15, "v"], [16, 16, "v"], [20, 20, "v"], [24, 24, "v"]], [[43, 43, "v"]], [[52, 52, "v"]], [[90, 90, "a"], [96, 97, "p"], [100, 100, "v"], [104, 104, "v"], [106, 106, "v"]]], "predicted_relations": [[], [], [], [], [[96, 97, 90, 90, "USED-FOR"]]]}
{"doc_key": "1910.07747-fe17ca35-d76c-4801-b7cd-f2f00a1b7859", "sentences": [["Exponential", "linear", "units", "-LRB-", "ELU", "-RRB-", "were", "used", "as", "a", "nonlinear", "function", "in", "our", "network", "."], ["In", "addition", "to", "the", "two", "networks", ",", "i.e.", ",", "\\", "-LRB-", "T_\\text", "-LCB-", "g", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "T_\\text", "-LCB-", "l", "-RCB-", "\\", "-RRB-", ",", "we", "applied", "a", "batch", "normalization", "-LSB-", "32", "-RSB-", "."], ["blackFurthermore", ",", "we", "applied", "an", "\\", "-LRB-", "l_2\\", "-RRB-", "-regularization", "with", "a", "coefficient", "of", "black\\", "-LRB-", "0.1\\", "-RRB-", "and", "a", "dropout", "-LSB-", "33", "-RSB-", "with", "a", "rate", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "to", "prevent", "over-fitting", "."], ["We", "trained", "models", "by", "using", "a", "RAdam", "-LSB-", "34", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "by", "exponentially", "decreasing", "\\", "-LRB-", "0.99\\", "-RRB-", "per", "epoch", ",", "where", "the", "dimension", "of", "a", "mini-batch", "size", "was", "40", "."], ["Regarding", "the", "hyper-parameters", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", ",", "we", "chose", "\\", "-LRB-", "\\lbrace", "\\alpha", ",", "\\beta", ",", "\\gamma", "\\rbrace", "\\", "-RRB-", "as", "\\", "-LRB-", "\\lbrace", "0.5,0.3,0.5\\rbrace", "\\", "-RRB-", "for", "all", "cases", "."]], "ner": [[], [[46, 47, "a"]], [[64, 64, "p"], [68, 68, "v"], [72, 72, "a"], [78, 78, "p"], [82, 82, "v"], [82, 82, "v"], [82, 82, "v"]], [[101, 101, "p"], [94, 94, "a"], [100, 101, "p"], [112, 113, "p"], [116, 116, "v"], [126, 127, "a"], [123, 123, "p"], [129, 129, "v"]], [[133, 133, "a"], [136, 136, "p"], [142, 142, "p"], [148, 148, "p"]], [[175, 175, "v"], [175, 175, "v"], [163, 163, "p"], [175, 175, "v"], [175, 175, "v"], [165, 165, "p"], [175, 175, "v"], [167, 167, "p"], [175, 175, "v"], [175, 175, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[0, 5, "a"], [14, 14, "a"]], [[20, 20, "v"], [46, 47, "a"]], [[68, 68, "v"], [72, 72, "a"], [78, 78, "p"], [82, 82, "v"]], [[94, 94, "a"], [100, 101, "p"], [105, 108, "v"], [116, 116, "v"], [126, 127, "c"], [129, 129, "v"]], [[136, 136, "p"], [142, 142, "p"], [148, 148, "p"]], [[165, 165, "p"], [167, 167, "p"]]], "predicted_relations": [[], [], [[78, 78, 72, 72, "USED-FOR"]], [[101, 101, 94, 94, "USED-FOR"], [100, 101, 94, 94, "USED-FOR"], [112, 113, 94, 94, "USED-FOR"], [116, 116, 112, 113, "USED-FOR"], [116, 116, 123, 123, "USED-FOR"], [129, 129, 123, 123, "USED-FOR"]], [[136, 136, 133, 133, "USED-FOR"], [142, 142, 133, 133, "USED-FOR"], [148, 148, 133, 133, "USED-FOR"]], [[175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"], [175, 175, 165, 165, "USED-FOR"], [175, 175, 167, 167, "USED-FOR"]]]}
{"doc_key": "1911.12815-7ed7db98-9440-49f6-a959-b15249126e55", "sentences": [["We", "set", "\\", "-LRB-", "N_i=1,2,3\\", "-RRB-", "to", "get", "three", "distinct", "resolution", "configurations", "in", "each", "pipeline", "stage", "in", "our", "experiments", "."], ["For", "each", "stage", ",", "we", "train", "different", "NN", "models", "and", "each", "NN", "model", "is", "trained", "via", "stochastic", "gradient", "descent", "with", "the", "Adam", "optimizer", "using", "TensorFlow", "."], ["The", "weight", "precision", "\\", "-LRB-", "A_\\textit", "-LCB-", "R", "-RCB-", "\\", "-RRB-", "during", "training", "is", "set", "to", "be", "1\\", "-LRB-", "\\sim", "\\", "-RRB-", "7-bit", "."], ["The", "batch", "size", "is", "4096", ",", "and", "the", "projection", "step", "is", "performed", "every", "256", "iterations", "."], ["We", "train", "for", "a", "total", "of", "2\\", "-LRB-", "\\times", "10^4\\", "-RRB-", "iterations", "for", "each", "sub-ADC", "model", "and", "residue", "model", ",", "varying", "the", "learning", "rate", "from", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "across", "the", "iterations", "."]], "ner": [[], [[27, 28, "a"], [36, 38, "a"], [41, 42, "a"], [44, 44, "a"]], [[47, 48, "p"]], [[71, 72, "p"], [74, 74, "v"], [78, 79, "p"], [83, 84, "v"]], [[108, 109, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 8, "v"]], [[36, 38, "a"], [41, 41, "a"]], [[47, 48, "p"], [68, 68, "v"]], [[71, 72, "p"], [74, 74, "v"], [83, 83, "v"]], [[95, 95, "v"], [108, 109, "p"], [113, 116, "v"], [122, 125, "v"]]], "predicted_relations": [[], [], [], [[74, 74, 71, 72, "USED-FOR"]], []]}
{"doc_key": "1902.11109-62294742-5d5e-4d45-8a30-043cae8dd5af", "sentences": [["In", "experiments", ",", "we", "set", "word", "embedding", "dimension", ",", "model", "dimension", "and", "latent", "vector", "dimension", "all", "to", "128", "."], ["The", "number", "of", "attention", "layer", "\\", "-LRB-", "L=4\\", "-RRB-", ",", "number", "of", "heads", "\\", "-LRB-", "H=8\\", "-RRB-", "each", "with", "dimension", "\\", "-LRB-", "d_", "-LCB-", "h", "-RCB-", "=64\\", "-RRB-", "."], ["Consider", "the", "size", "of", "our", "dataset", "and", "vocabulary", "size", ",", "we", "set", "our", "model", "parameters", "to", "a", "relatively", "small", "value", "compared", "to", "Transformers", "."]], "ner": [[[9, 9, "a"], [5, 7, "p"], [17, 17, "v"], [9, 10, "p"], [17, 17, "v"], [12, 14, "p"], [17, 17, "v"]], [[20, 23, "p"], [26, 26, "v"], [29, 31, "p"], [34, 34, "v"], [45, 45, "v"]], [[61, 61, "a"]]], "relations": [[], [], []], "predicted_ner": [[[17, 17, "v"]], [[26, 26, "v"], [34, 34, "v"]], [[70, 70, "a"]]], "predicted_relations": [[[5, 7, 9, 9, "USED-FOR"], [9, 10, 9, 9, "USED-FOR"], [12, 14, 9, 9, "USED-FOR"]], [[26, 26, 20, 23, "USED-FOR"], [34, 34, 29, 31, "USED-FOR"]], []]}
{"doc_key": "1902.11109-30795c09-eae5-4d32-8a03-3621772ebe35", "sentences": [["All", "parameters", "are", "initialised", "from", "Gaussian", "Distribution", "\\", "-LRB-", "N", "-LRB-", "0", ",", "0.02", "-RRB-", "\\", "-RRB-", "."], ["We", "employ", "vanilla", "GAN", "to", "train", "our", "model", ",", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "5", "\\times", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "as", "we", "find", "a", "larger", "learning", "rate", "leads", "to", "instability", "very", "quickly", "."], ["Adam", "optimiser", "is", "employed", "with", "beta1", "equals", "0.5", "."]], "ner": [[[5, 6, "a"]], [[20, 21, "a"]], [[55, 56, "a"], [60, 60, "p"], [62, 62, "v"]]], "relations": [[], [], []], "predicted_ner": [[[11, 11, "v"], [13, 13, "v"]], [[20, 21, "a"], [27, 28, "p"], [36, 38, "v"], [47, 48, "p"]], [[55, 55, "a"], [60, 60, "a"], [62, 62, "v"]]], "predicted_relations": [[], [], [[60, 60, 55, 56, "USED-FOR"], [62, 62, 60, 60, "USED-FOR"]]]}
{"doc_key": "1910.12906-9ac28402-70f1-4a26-b53e-7b1883ddf97e", "sentences": [["For", "training", "STEP-Gen", ",", "we", "use", "a", "batch", "size", "of", "8", "and", "train", "for", "150", "epochs", "."], ["We", "use", "the", "Adam", "optimizer", "-LSB-", "25", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "which", "decreases", "to", "\\", "-LRB-", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "10", "-RCB-", "\\", "-RRB-", "-th", "of", "its", "current", "value", "after", "75", ",", "113", "and", "132", "epochs", "."], ["We", "also", "use", "a", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "and", "weight-decay", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[7, 8, "a"], [15, 15, "a"]], [[20, 21, "a"], [27, 29, "p"], [33, 33, "v"], [61, 61, "a"]], [[67, 67, "p"], [71, 71, "v"], [75, 75, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [7, 8, "p"], [10, 10, "v"], [14, 14, "v"], [15, 15, "p"]], [[20, 20, "a"], [28, 29, "p"], [33, 33, "v"], [56, 56, "v"], [58, 58, "v"], [60, 60, "v"], [61, 61, "p"]], [[71, 71, "v"], [75, 75, "a"], [80, 83, "v"]]], "predicted_relations": [[], [[27, 29, 20, 21, "USED-FOR"]], []]}
{"doc_key": "1910.12906-b911fc07-0241-4fb0-a0f0-6064454469e2", "sentences": [["For", "training", "STEP", ",", "we", "use", "a", "split", "of", "\\", "-LRB-", "7:2:1\\", "-RRB-", "for", "training", ",", "validation", "and", "testing", "sets", "."], ["We", "use", "a", "batch", "size", "of", "8", "and", "train", "for", "500", "epochs", "using", "the", "Adam", "optimizer", "-LSB-", "25", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "learning", "rate", "decreases", "to", "\\", "-LRB-", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "10", "-RCB-", "\\", "-RRB-", "-th", "of", "its", "current", "value", "after", "250", ",", "375", "and", "438", "epochs", "."], ["We", "also", "use", "a", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "and", "weight-decay", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["All", "our", "results", "were", "generated", "on", "an", "NVIDIA", "GeForce", "GTX", "1080", "Ti", "GPU", "."]], "ner": [[], [[35, 36, "a"], [43, 44, "p"], [48, 48, "v"]], [[52, 53, "p"], [70, 71, "c"]], [[84, 84, "p"], [88, 88, "v"], [92, 92, "p"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[11, 11, "v"]], [[24, 25, "p"], [27, 27, "v"], [31, 31, "v"], [32, 32, "p"], [35, 35, "a"], [43, 44, "p"], [48, 48, "v"]], [[52, 53, "p"], [73, 75, "v"], [77, 77, "v"], [78, 78, "p"]], [[88, 88, "v"], [92, 92, "a"], [97, 100, "v"]], []], "predicted_relations": [[], [[43, 44, 35, 36, "USED-FOR"]], [], [], []]}
{"doc_key": "1905.07473-fb98b620-6f6d-49ca-9927-706158216a0b", "sentences": [["We", "train", "separate", "2-layer", "LSTMs", "with", "a", "embedding", "input", "layer", "and", "a", "linear", "output-layer", "to", "both", "the", "fixed-", "and", "variable-", "copy", "tasks", "by", "minimizing", "the", "cross-entropy", "loss", "."], ["The", "embedding", "dimension", "is", "set", "to", "6", "and", "hidden", "and", "cell", "dimensions", "of", "the", "LSTM", "layers", "are", "set", "to", "50", "."], ["We", "train", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "using", "SGD", "using", "a", "batchsize", "of", "\\", "-LRB-", "S=64\\", "-RRB-", "and", "a", "fixed", "learning", "rate", "of", "\\", "-LRB-", "\\gamma", "=", "1.0\\", "-RRB-", "with", "fixed", "TBPTT", "\\", "-LRB-", "K", "\\in", "-LSB-", "5", ",", "10", ",", "15", ",", "20", ",", "30", "-RSB-", "\\", "-RRB-", "and", "our", "adaptive", "TBPTT", "method", "\\", "-LRB-", "\\delta", "\\in", "-LSB-", "0.9", ",", "0.5", ",", "0.1", "-RSB-", "\\", "-RRB-", ",", "\\", "-LRB-", "W", "=", "100\\", "-RRB-", ",", "\\", "-LRB-", "K_0", "=", "15\\", "-RRB-", "and", "\\", "-LRB-", "-LSB-", "K_", "-LCB-", "\\min", "-RCB-", ",", "K_", "-LCB-", "\\max", "-RCB-", "-RSB-", "=", "-LSB-", "2,100", "-RSB-", "\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "W", "=", "100\\", "-RRB-", ",", "\\", "-LRB-", "K_0", "=", "15\\", "-RRB-", "and", "\\", "-LRB-", "-LSB-", "K_", "-LCB-", "\\min", "-RCB-", ",", "K_", "-LCB-", "\\max", "-RCB-", "-RSB-", "=", "-LSB-", "2,100", "-RSB-", "\\", "-RRB-", "for", "Algorithm", "."]], "ner": [[[3, 4, "a"], [3, 3, "v"], [25, 26, "a"]], [[29, 30, "p"], [34, 34, "v"], [36, 43, "p"], [47, 47, "v"]], [[57, 57, "a"], [60, 60, "p"], [64, 64, "v"], [68, 70, "p"], [76, 76, "v"], [79, 80, "p"], [86, 86, "v"], [110, 110, "v"], [88, 88, "v"], [90, 90, "v"], [128, 128, "v"], [92, 92, "v"], [94, 94, "v"], [100, 101, "p"], [108, 108, "v"], [110, 110, "v"], [112, 112, "v"], [119, 119, "p"], [121, 121, "v"], [146, 146, "v"], [126, 126, "p"], [90, 90, "v"], [128, 128, "v"], [146, 146, "v"], [121, 121, "v"], [146, 146, "v"]], [[164, 164, "v"], [155, 155, "p"], [157, 157, "v"], [182, 182, "v"], [162, 162, "p"], [164, 164, "v"], [182, 182, "v"], [157, 157, "v"], [182, 182, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "a"], [25, 26, "a"]], [[29, 30, "p"], [34, 34, "v"], [42, 42, "a"], [47, 47, "v"]], [[53, 53, "p"], [57, 57, "a"], [60, 60, "p"], [64, 64, "v"], [69, 70, "p"], [74, 74, "p"], [76, 76, "v"], [80, 80, "a"], [83, 83, "p"], [100, 102, "a"], [105, 105, "p"], [121, 121, "v"], [126, 128, "v"], [146, 146, "v"]], [[155, 155, "p"], [157, 157, "v"], [162, 164, "v"], [182, 182, "v"]]], "predicted_relations": [[], [[34, 34, 29, 30, "USED-FOR"], [34, 34, 36, 43, "USED-FOR"], [47, 47, 29, 30, "USED-FOR"], [47, 47, 36, 43, "USED-FOR"]], [[60, 60, 57, 57, "USED-FOR"], [64, 64, 60, 60, "USED-FOR"], [64, 64, 68, 70, "USED-FOR"], [64, 64, 79, 80, "USED-FOR"], [68, 70, 57, 57, "USED-FOR"], [79, 80, 57, 57, "USED-FOR"], [86, 86, 79, 80, "USED-FOR"], [86, 86, 100, 101, "USED-FOR"], [110, 110, 100, 101, "USED-FOR"], [110, 110, 119, 119, "USED-FOR"], [88, 88, 79, 80, "USED-FOR"], [88, 88, 100, 101, "USED-FOR"], [88, 88, 119, 119, "USED-FOR"], [90, 90, 79, 80, "USED-FOR"], [90, 90, 100, 101, "USED-FOR"], [128, 128, 126, 126, "USED-FOR"], [92, 92, 79, 80, "USED-FOR"], [92, 92, 100, 101, "USED-FOR"], [92, 92, 119, 119, "USED-FOR"], [94, 94, 79, 80, "USED-FOR"], [94, 94, 100, 101, "USED-FOR"], [94, 94, 119, 119, "USED-FOR"], [100, 101, 57, 57, "USED-FOR"], [108, 108, 119, 119, "USED-FOR"], [110, 110, 100, 101, "USED-FOR"], [110, 110, 119, 119, "USED-FOR"], [112, 112, 100, 101, "USED-FOR"], [112, 112, 119, 119, "USED-FOR"], [112, 112, 126, 126, "USED-FOR"], [121, 121, 119, 119, "USED-FOR"], [121, 121, 126, 126, "USED-FOR"], [146, 146, 119, 119, "USED-FOR"], [146, 146, 126, 126, "USED-FOR"], [90, 90, 79, 80, "USED-FOR"], [90, 90, 100, 101, "USED-FOR"], [128, 128, 126, 126, "USED-FOR"], [146, 146, 119, 119, "USED-FOR"], [146, 146, 126, 126, "USED-FOR"], [121, 121, 119, 119, "USED-FOR"], [121, 121, 126, 126, "USED-FOR"], [146, 146, 119, 119, "USED-FOR"], [146, 146, 126, 126, "USED-FOR"]], [[164, 164, 162, 162, "USED-FOR"], [157, 157, 155, 155, "USED-FOR"], [157, 157, 162, 162, "USED-FOR"], [182, 182, 155, 155, "USED-FOR"], [182, 182, 162, 162, "USED-FOR"], [164, 164, 162, 162, "USED-FOR"], [182, 182, 155, 155, "USED-FOR"], [182, 182, 162, 162, "USED-FOR"], [157, 157, 155, 155, "USED-FOR"], [157, 157, 162, 162, "USED-FOR"], [182, 182, 155, 155, "USED-FOR"], [182, 182, 162, 162, "USED-FOR"]]]}
{"doc_key": "1905.07473-aae21909-77ef-4350-97b5-336147f199fc", "sentences": [["For", "both", "the", "PTB", "and", "Wiki2", "corpus", ",", "we", "train", "1-layer", "LSTMs", "with", "a", "word", "embedding", "layer", "input", "and", "a", "linear", "output", "layer", "."], ["The", "embedding", "dimension", ",", "hidden", "state", ",", "and", "cell", "state", "dimensions", "are", "all", "900", "for", "the", "PTB", "following", "-LRB-", "-RRB-", "and", "512", "for", "the", "Wiki2", "corpus", "following", "-LRB-", "-RRB-", "."], ["We", "use", "a", "batchsize", "of", "\\", "-LRB-", "S=32\\", "-RRB-", "and", "a", "fixed", "learning", "rate", "of", "\\", "-LRB-", "\\gamma", "=", "10\\", "-RRB-", "for", "fixed", "TBPTT", "\\", "-LRB-", "K", "\\in", "-LSB-", "10", ",", "50", ",", "100", ",", "200", ",", "300", "-RSB-", "\\", "-RRB-", "and", "our", "adaptive", "TBPTT", "method", "\\", "-LRB-", "\\delta", "\\in", "-LSB-", "0.9", ",", "0.5", ",", "0.1", "-RSB-", "\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "W", "=", "400\\", "-RRB-", ",", "\\", "-LRB-", "K_0", "=", "100\\", "-RRB-", "and", "\\", "-LRB-", "-LSB-", "K_", "-LCB-", "\\min", "-RCB-", ",", "K_", "-LCB-", "\\max", "-RCB-", "-RSB-", "=", "-LSB-", "10,400", "-RSB-", "\\", "-RRB-", "for", "Algorithm", "."]], "ner": [[[10, 11, "a"], [3, 3, "c"], [5, 6, "c"], [3, 3, "c"], [5, 6, "c"], [3, 3, "c"], [5, 6, "c"]], [[25, 26, "p"], [37, 37, "v"], [40, 40, "c"], [45, 45, "v"], [48, 49, "c"], [37, 37, "v"], [40, 40, "c"], [45, 45, "v"], [48, 49, "c"], [37, 37, "v"], [40, 40, "c"], [45, 45, "v"], [48, 49, "c"]], [[57, 57, "a"], [65, 67, "a"], [76, 77, "a"], [80, 80, "p"], [73, 73, "v"], [83, 83, "v"], [85, 85, "v"], [87, 87, "v"], [89, 89, "v"], [91, 91, "v"], [97, 98, "a"], [102, 102, "p"], [105, 105, "v"], [107, 107, "v"], [109, 109, "v"], [87, 87, "v"], [73, 73, "v"], [83, 83, "v"]], [[145, 145, "v"], [127, 127, "v"], [150, 150, "a"], [118, 118, "p"], [120, 120, "v"], [145, 145, "v"], [125, 125, "p"], [127, 127, "v"], [145, 145, "v"], [120, 120, "v"], [145, 145, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 6, "a"], [11, 11, "a"]], [[28, 29, "p"], [37, 37, "v"], [40, 40, "a"], [45, 45, "v"], [48, 49, "a"]], [[57, 57, "p"], [61, 61, "v"], [66, 67, "p"], [71, 71, "p"], [73, 73, "v"], [80, 80, "p"], [97, 99, "a"], [102, 102, "p"]], [[118, 118, "p"], [118, 120, "v"], [127, 127, "v"], [145, 145, "v"]]], "predicted_relations": [[], [[37, 37, 25, 26, "USED-FOR"], [45, 45, 25, 26, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [37, 37, 25, 26, "USED-FOR"], [45, 45, 25, 26, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [37, 37, 25, 26, "USED-FOR"], [45, 45, 25, 26, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"], [48, 49, 37, 37, "USED-FOR"], [48, 49, 45, 45, "USED-FOR"]], [[80, 80, 57, 57, "USED-FOR"], [80, 80, 65, 67, "USED-FOR"], [80, 80, 76, 77, "USED-FOR"], [83, 83, 80, 80, "USED-FOR"], [85, 85, 80, 80, "USED-FOR"], [87, 87, 80, 80, "USED-FOR"], [89, 89, 80, 80, "USED-FOR"], [102, 102, 97, 98, "USED-FOR"], [109, 109, 102, 102, "USED-FOR"], [87, 87, 80, 80, "USED-FOR"], [83, 83, 80, 80, "USED-FOR"]], [[127, 127, 118, 118, "USED-FOR"], [127, 127, 125, 125, "USED-FOR"], [120, 120, 118, 118, "USED-FOR"], [120, 120, 125, 125, "USED-FOR"], [127, 127, 118, 118, "USED-FOR"], [127, 127, 125, 125, "USED-FOR"], [120, 120, 118, 118, "USED-FOR"], [120, 120, 125, 125, "USED-FOR"]]]}
{"doc_key": "1906.04980-fbf8218b-ac59-49ef-bf54-e5cbe4c8e8ef", "sentences": [["Here", "we", "describe", "experimental", "details", "for", "unsupervised", "NMT", "setup", "."], ["We", "use", "the", "English", "tokenizer", "from", "Moses", "-LSB-", "19", "-RSB-", ",", "and", "use", "FastBPE", "-LRB-", "https", ":", "//github.com/glample/fastBPE", "-RRB-", "to", "split", "into", "subword", "units", ",", "with", "a", "vocabulary", "size", "of", "60000", "."], ["The", "architecture", "uses", "a", "4-layer", "transformer", "encoder", "and", "4-layer", "transformer", "decoder", ",", "where", "one", "layer", "is", "language", "specific", "for", "both", "the", "encoder", "and", "decoder", ",", "the", "rest", "are", "shared", "."], ["We", "use", "the", "standard", "hyperparameter", "settings", "recommended", "by", "-LSB-", "23", "-RSB-", "."], ["The", "models", "are", "initialised", "with", "random", "weights", ",", "and", "the", "input", "word", "embedding", "matrix", "is", "initialised", "using", "FastText", "vectors", "-LSB-", "3", "-RSB-", "trained", "on", "the", "concatenation", "of", "the", "\\", "-LRB-", "C\\", "-RRB-", "and", "\\", "-LRB-", "Q\\", "-RRB-", "corpora", "."], ["Initially", ",", "the", "auto-encoding", "loss", "and", "back-translation", "loss", "have", "equal", "weight", ",", "with", "the", "auto-encoding", "loss", "coefficient", "reduced", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "by", "100K", "steps", "and", "to", "0", "by", "300k", "steps", "."], ["We", "train", "using", "5M", "cloze", "questions", "and", "natural", "questions", ",", "and", "cease", "training", "when", "the", "BLEU", "scores", "between", "back-translated", "and", "input", "questions", "stops", "improving", ",", "usually", "around", "300K", "optimisation", "steps", "."], ["When", "generating", ",", "we", "decode", "greedily", ",", "and", "note", "that", "decoding", "with", "a", "beam", "size", "of", "5", "did", "not", "significantly", "change", "downstream", "QA", "performance", ",", "or", "greatly", "change", "the", "fluency", "of", "generations", "."]], "ner": [[], [[16, 16, "a"], [23, 23, "a"]], [[47, 48, "a"], [51, 52, "a"]], [], [[101, 101, "a"]], [[139, 139, "p"], [144, 144, "v"], [126, 127, "a"], [137, 138, "a"], [144, 144, "v"], [151, 151, "v"], [129, 130, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[16, 16, "a"], [23, 23, "a"], [40, 40, "v"]], [[55, 55, "v"]], [], [], [[126, 127, "a"], [129, 130, "a"], [144, 144, "v"], [147, 147, "v"], [151, 151, "v"], [153, 153, "v"]], [[159, 159, "v"], [183, 183, "v"]], [[203, 203, "v"]]], "predicted_relations": [[], [], [], [], [], [[139, 139, 126, 127, "USED-FOR"], [139, 139, 137, 138, "USED-FOR"], [139, 139, 129, 130, "USED-FOR"]], [], []]}
{"doc_key": "1905.11062-ccfef91e-3d00-441b-8a3b-fea0795ba882", "sentences": [["We", "use", "the", "Glorot", "uniform", "initializer", "-LSB-", "11", "-RSB-", "for", "the", "weights", "of", "encoder-decoder", "networks", "."], ["The", "codebook", "is", "initialized", "by", "the", "uniform", "unit", "scaling", "."], ["All", "models", "are", "trained", "using", "Adam", "optimizer", "-LSB-", "16", "-RSB-", "with", "learning", "rate", "3e-4", "and", "evaluate", "the", "performance", "after", "40000", "iterations", "with", "batch", "size", "32", "."], ["Early", "stopping", "at", "10000", "iterations", "is", "applied", "by", "soft", "VQ-VAE", "on", "SVHN", "and", "CIFAR-10", "datasets", "."]], "ner": [[[3, 5, "a"]], [], [[31, 32, "a"], [46, 46, "p"]], [[56, 56, "p"], [55, 55, "v"], [52, 53, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"]], [], [[31, 31, "a"], [37, 38, "p"], [39, 39, "v"], [45, 45, "v"], [48, 49, "p"], [50, 50, "v"]], [[55, 55, "v"], [60, 61, "a"], [63, 63, "a"], [65, 65, "a"]]], "predicted_relations": [[], [], [[46, 46, 31, 32, "USED-FOR"]], [[56, 56, 52, 53, "USED-FOR"], [55, 55, 56, 56, "USED-FOR"]]]}
{"doc_key": "1910.11552-3dc030e3-00ea-4c12-9548-bb6a00542999", "sentences": [["According", "to", "-LSB-", "15", "-RSB-", ",", "the", "selection", "of", "hyper", "parameters", "greatly", "influences", "the", "performance", "of", "the", "algorithms", "."], ["For", "LS-SVM", "with", "the", "popular", "Gaussian", "kernel", "-LRB-", "i.e.", ",", "\\", "-LRB-", "K", "-LRB-", "u", ",", "v", "-RRB-", "=", "-LCB-", "\\rm", "exp", "-RCB-", "-LRB-", "-\\delta", "||u-v||^", "-LCB-", "2", "-RCB-", "-RRB-", "\\", "-RRB-", "-RRB-", ",", "it", "mainly", "has", "two", "hyper", "parameters", "which", "are", "the", "cost", "parameter", "\\", "-LRB-", "C\\", "-RRB-", "-LRB-", "preventing", "the", "model", "from", "being", "too", "complex", "-RRB-", "and", "kernel", "parameter", "\\", "-LRB-", "\\delta", "\\", "-RRB-", "."], ["ELM", "using", "Gaussian", "kernel", ",", "has", "three", "hyper", "parameters", ",", "the", "cost", "parameter", "\\", "-LRB-", "C\\", "-RRB-", ",", "kernel", "parameter", "\\", "-LRB-", "\\delta", "\\", "-RRB-", "and", "number", "of", "nodes", "\\", "-LRB-", "L\\", "-RRB-", "."], ["For", "the", "proposed", "GNN", "with", "R-WDD", ",", "it", "also", "has", "three", "hyper", "parameters", "which", "are", "the", "regularizer", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", ",", "the", "parameter", "for", "GPS", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "and", "the", "number", "of", "neurons", "\\", "-LRB-", "L\\", "-RRB-", "."], ["In", "this", "paper", ",", "the", "value", "of", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "fixed", "to", "\\", "-LRB-", "0.05\\", "-RRB-", "."], ["Also", ",", "the", "number", "of", "nodes", "for", "ELM", "and", "the", "proposed", "GNN", "with", "R-WDD", "for", "binary", "and", "multi-classification", "problems", "are", "fixed", "to", "1000", "."]], "ner": [[], [[20, 20, "a"], [62, 63, "p"], [78, 79, "p"], [62, 63, "p"], [78, 79, "p"]], [[97, 98, "p"], [104, 105, "p"], [86, 86, "a"], [97, 98, "p"], [104, 105, "p"], [112, 114, "p"]], [[123, 125, "a"], [136, 136, "p"], [144, 146, "p"], [154, 156, "p"]], [[179, 179, "v"]], [[189, 189, "a"], [185, 187, "p"], [204, 204, "v"], [193, 195, "a"], [204, 204, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[20, 20, "a"], [56, 56, "v"], [82, 82, "p"]], [[92, 92, "v"], [108, 108, "p"]], [[123, 123, "a"], [125, 125, "a"], [130, 130, "v"], [139, 139, "p"], [146, 146, "a"], [149, 149, "p"]], [[171, 171, "p"], [179, 179, "v"]], [[193, 193, "a"], [195, 195, "a"], [204, 204, "v"]]], "predicted_relations": [[], [[62, 63, 20, 20, "USED-FOR"], [62, 63, 20, 20, "USED-FOR"]], [[97, 98, 86, 86, "USED-FOR"], [104, 105, 86, 86, "USED-FOR"], [97, 98, 86, 86, "USED-FOR"], [104, 105, 86, 86, "USED-FOR"], [112, 114, 86, 86, "USED-FOR"]], [[136, 136, 123, 125, "USED-FOR"], [144, 146, 123, 125, "USED-FOR"], [154, 156, 123, 125, "USED-FOR"]], [], [[185, 187, 189, 189, "USED-FOR"]]]}
{"doc_key": "1905.02244-35ccf60e-7fa3-4820-8444-f3625f92fde9", "sentences": [["We", "train", "our", "models", "using", "synchronous", "training", "setup", "on", "4x4", "TPU", "Pod", "-LSB-", "23", "-RSB-", "using", "standard", "tensorflow", "RMSPropOptimizer", "with", "0.9", "momentum", "."], ["We", "use", "the", "initial", "learning", "rate", "of", "0.1", ",", "with", "batch", "size", "4096", "-LRB-", "128", "images", "per", "chip", "-RRB-", ",", "and", "learning", "rate", "decay", "rate", "of", "0.01", "every", "3", "epochs", "."], ["We", "use", "dropout", "of", "0.8", ",", "and", "l2", "weight", "decay", "1e-5", "and", "the", "same", "image", "preprocessing", "as", "Inception", "-LSB-", "41", "-RSB-", "."], ["Finally", "we", "use", "exponential", "moving", "average", "with", "decay", "0.9999", "."], ["All", "our", "convolutional", "layers", "use", "batch-normalization", "layers", "with", "average", "decay", "of", "0.99", "."]], "ner": [[[18, 18, "a"], [21, 21, "p"], [20, 20, "v"]], [[26, 28, "p"], [30, 30, "v"], [33, 34, "p"], [35, 35, "v"], [44, 47, "p"], [49, 49, "v"], [46, 46, "p"]], [[56, 56, "a"], [58, 58, "v"], [61, 63, "a"], [64, 64, "v"], [63, 63, "p"]], [[79, 81, "a"], [83, 83, "p"], [84, 84, "v"]], [[95, 95, "p"], [91, 92, "a"], [94, 95, "p"], [97, 97, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [9, 11, "a"], [20, 20, "v"], [21, 21, "p"]], [[27, 28, "p"], [30, 30, "v"], [33, 34, "p"], [35, 35, "v"], [37, 37, "v"], [44, 47, "p"], [49, 49, "v"], [51, 51, "v"], [52, 52, "p"]], [[56, 56, "p"], [58, 58, "v"], [61, 63, "p"], [64, 64, "v"], [71, 71, "a"]], [[79, 81, "a"], [84, 84, "v"]], [[91, 91, "a"], [94, 95, "p"], [97, 97, "v"]]], "predicted_relations": [[[21, 21, 18, 18, "USED-FOR"]], [[35, 35, 26, 28, "USED-FOR"], [35, 35, 33, 34, "USED-FOR"], [49, 49, 46, 46, "USED-FOR"]], [[58, 58, 63, 63, "USED-FOR"], [64, 64, 63, 63, "USED-FOR"], [63, 63, 56, 56, "USED-FOR"], [63, 63, 61, 63, "USED-FOR"]], [[83, 83, 79, 81, "USED-FOR"], [84, 84, 83, 83, "USED-FOR"]], [[97, 97, 95, 95, "USED-FOR"], [97, 97, 94, 95, "USED-FOR"]]]}
{"doc_key": "1911.09071-6c4cf2ba-473e-4cdb-afa2-76a42079802c", "sentences": [["We", "trained", "at", "a", "batch", "size", "of", "4096", "using", "SGD", "with", "Nesterov", "momentum", "of", "0.9", "and", "weight", "decay", "of", "\\", "-LRB-", "8", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "performed", "evaluation", "using", "an", "exponential", "moving", "average", "of", "the", "training", "weights", "computed", "with", "decay", "factor", "0.9999", "."], ["The", "learning", "rate", "schedule", "consisted", "of", "10", "epochs", "of", "linear", "warmup", "to", "a", "maximum", "learning", "rate", "of", "1.6", ",", "followed", "by", "exponential", "decay", "at", "a", "rate", "of", "0.975", "per", "epoch", "."], ["For", "all", "conditions", "we", "randomly", "horizontally", "flipped", "images", "and", "performed", "standard", "Inception-style", "color", "augmentation", "."]], "ner": [[[9, 9, "a"], [4, 5, "p"], [7, 7, "v"], [12, 12, "p"], [14, 14, "v"], [16, 17, "p"], [34, 36, "a"], [43, 44, "p"], [45, 45, "v"], [23, 23, "v"]], [[48, 50, "a"], [54, 54, "p"], [53, 53, "v"], [60, 62, "p"], [64, 64, "v"], [74, 74, "v"]], [[89, 91, "a"]]], "relations": [[], [], []], "predicted_ner": [[[4, 5, "p"], [7, 7, "v"], [9, 9, "a"], [11, 12, "p"], [14, 14, "v"], [16, 17, "p"], [21, 21, "v"], [23, 26, "v"], [43, 44, "p"], [45, 45, "v"]], [[53, 53, "v"], [54, 54, "p"], [56, 57, "a"], [61, 62, "p"], [64, 64, "v"], [68, 69, "a"], [74, 74, "v"]], []], "predicted_relations": [[[4, 5, 9, 9, "USED-FOR"], [7, 7, 4, 5, "USED-FOR"], [7, 7, 12, 12, "USED-FOR"], [12, 12, 9, 9, "USED-FOR"], [16, 17, 9, 9, "USED-FOR"], [43, 44, 9, 9, "USED-FOR"], [43, 44, 34, 36, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"], [23, 23, 12, 12, "USED-FOR"], [23, 23, 16, 17, "USED-FOR"]], [[54, 54, 48, 50, "USED-FOR"], [53, 53, 54, 54, "USED-FOR"], [60, 62, 48, 50, "USED-FOR"], [64, 64, 60, 62, "USED-FOR"]], []]}
{"doc_key": "1909.13701-fbc7fbd4-47b9-4834-9bc5-49b29e74da00", "sentences": [["For", "all", "the", "experiments", "we", "use", "images", "resized", "to", "256\\", "-LRB-", "\\times", "\\", "-RRB-", "512", "-LRB-", "due", "to", "our", "limited", "memory", "size", "-RRB-", ",", "and", "hyper-parameters", "\\", "-LRB-", "\\lbrace", "w_1", ",", "w_2", ",", "w_3", ",", "\\lambda", "_", "-LCB-", "cyc", "-RCB-", ",", "\\lambda", "_", "-LCB-", "ste", "-RCB-", "\\rbrace", "=", "\\lbrace", "0.5", ",", "0.7", ",", "1", ",", "10", ",", "0.05\\rbrace", "\\", "-RRB-", "."], ["To", "accommodate", "the", "stereo", "pair", "requirement", ",", "our", "translation", "network", "is", "simply", "modified", "to", "have", "two", "exactly", "similar", "weight-sharing", "pipelines", ",", "each", "working", "on", "an", "image", "from", "the", "pair", "."], ["We", "use", "a", "buffer", "of", "50", "previously", "translated", "pairs", "to", "reduce", "model", "oscillations", "-LSB-", "3", "-RSB-", ",", "-LSB-", "25", "-RSB-", "."], ["All", "networks", "use", "Adam", "-LSB-", "15", "-RSB-", "solver", "with", "its", "parameters", "\\", "-LRB-", "\\lbrace", "\\beta", "_1", ",", "\\beta", "_2\\rbrace", "=\\lbrace", "0.5", ",", "0.999\\rbrace", "\\", "-RRB-", "."], ["We", "use", "a", "batch", "size", "of", "4", ",", "and", "keep", "a", "constant", "learning", "rate", "of", "0.0002", "for", "all", "the", "networks", "for", "the", "first-half", "of", "the", "training", "epochs", ",", "and", "then", "linearly", "decay", "it", "to", "zero", "over", "the", "second-half", "."]], "ner": [[[49, 49, "v"], [25, 25, "a"], [29, 29, "p"], [49, 49, "v"], [31, 31, "p"], [51, 51, "v"], [33, 33, "p"], [53, 53, "v"], [55, 55, "v"], [57, 57, "v"]], [], [], [[115, 115, "a"], [132, 132, "v"], [134, 134, "v"], [132, 132, "v"]], [[150, 151, "a"], [149, 149, "p"], [153, 153, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[14, 14, "v"], [35, 39, "p"], [41, 45, "p"]], [[69, 70, "a"], [76, 76, "v"]], [[96, 96, "v"]], [[115, 115, "a"]], [[141, 142, "p"], [144, 144, "v"], [150, 151, "p"], [153, 153, "v"], [154, 157, "c"], [172, 172, "v"]]], "predicted_relations": [[[29, 29, 25, 25, "USED-FOR"], [31, 31, 25, 25, "USED-FOR"], [33, 33, 25, 25, "USED-FOR"]], [], [], [], [[153, 153, 149, 149, "USED-FOR"]]]}
{"doc_key": "1911.04947-b092952e-f7db-452a-8eb5-4e8a1e1e3459", "sentences": [["The", "imitation", "learning", "model", "acts", "as", "a", "policy", "network", "during", "the", "next", "training", "phase", "which", "uses", "PPO", "."], ["A", "replica", "of", "the", "same", "network", "is", "created", "for", "value", "function", "estimation", ",", "with", "the", "output", "layer", "of", "size", "1", "instead", "of", "6", "."], ["We", "refrain", "from", "using", "the", "same", "CNN", "layers", "to", "approximate", "the", "value", "function", "as", "this", "creates", "aberration", "during", "the", "initial", "phase", "of", "learning", "and", "often", "leads", "to", "policy", "forgetting", "and", "degradation", "."], ["We", "also", "avoid", "using", "any", "regularization", "technique", "such", "as", "dropout", "while", "training", "using", "PPO", ",", "as", "this", "leads", "to", "significant", "increase", "in", "KL", "divergence", "between", "trained", "policies", "."]], "ner": [[[16, 16, "a"]], [], [], [[87, 87, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 3, "a"], [16, 16, "a"]], [[37, 37, "v"], [40, 40, "v"]], [[48, 48, "a"]], [[83, 83, "a"], [87, 87, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1911.05045-a9670d00-597b-45c4-909c-2292cda7b040", "sentences": [["In", "all", "the", "experiments", "we", "use", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "with", "0.9", "momentum", ",", "cross", "entropy", "loss", "as", "loss", "function", "and", "L2", "regularization", "."], ["All", "other", "training", "details", "are", "provided", "along", "with", "the", "open-sourced", "code", "-LRB-", "Section", "REF", "-RRB-", "."]], "ner": [[[14, 14, "p"], [13, 13, "v"], [16, 18, "a"], [23, 24, "a"]], []], "relations": [[], []], "predicted_ner": [[[6, 11, "a"], [13, 13, "v"], [14, 14, "p"], [16, 18, "a"], [23, 24, "a"]], []], "predicted_relations": [[[14, 14, 16, 18, "USED-FOR"]], []]}
{"doc_key": "1902.02401-f9c8de6f-8218-4eff-84ba-340e99a22e4d", "sentences": [["For", "our", "CNN", ",", "we", "use", "300-dimensional", "Word2Vec", "-LSB-", "10", "-RSB-", ",", "-LSB-", "11", "-RSB-", ",", "-LSB-", "12", "-RSB-", "word", "embeddings", "trained", "on", "GoogleNews", "datasethttps", ":", "//code.google.com/p/word2vec", ",", "and", "128", "feature", "maps", "with", "filter", "width", "-LCB-", "2", ",", "3", ",", "4", "-RCB-", "."], ["We", "set", "maximum", "word", "lengths", "of", "50", "and", "500", "for", "claims", "and", "documents", "respectively", ";", "these", "values", "are", "greater", "than", "the", "length", "for", "most", "claims", "and", "documents", "in", "the", "target", "train", "data", "."], ["For", "the", "BOW", "model", ",", "we", "keep", "the", "hyper-parameters", "and", "features", "the", "same", "as", "the", "baseline", "model", "-LSB-", "15", "-RSB-", "."], ["Our", "models", "are", "trained", "using", "the", "Adam", "optimizer", ",", "and", "\\", "-LRB-", "20\\", "%", "\\", "-RRB-", "of", "the", "training", "data", "is", "set", "aside", "as", "validation", "data", "."], ["In", "the", "models", "with", "a", "domain", "adaptation", "-LRB-", "DA", "-RRB-", "component", ",", "equal", "amounts", "of", "both", "source", "and", "target", "data", "are", "randomly", "selected", "at", "each", "epoch", "during", "training", "."], ["Finally", ",", "we", "fine-tune", "all", "the", "hyper-parameters", "of", "our", "models", "on", "validation", "data", "which", "contains", "equal", "amounts", "of", "source", "and", "target", "data", "."]], "ner": [[[7, 7, "a"], [2, 2, "a"], [33, 34, "p"], [36, 36, "v"], [38, 38, "v"], [40, 40, "v"]], [], [[78, 79, "a"]], [[103, 104, "a"]], [[129, 130, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "v"], [7, 7, "a"], [29, 29, "v"], [36, 36, "v"], [40, 40, "v"]], [[49, 49, "v"], [51, 51, "v"]], [[78, 79, "a"]], [[103, 103, "a"], [109, 110, "v"]], [], []], "predicted_relations": [[[33, 34, 7, 7, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1911.11536-7e285e72-ea2f-412f-b078-64bb2f4ca13a", "sentences": [["The", "best", "results", "were", "obtained", "with", "batch-size", "\\", "-LRB-", "b", "=", "128\\", "-RRB-", "and", "epochs", "\\", "-LRB-", "e", "=", "40\\", "-RRB-", "."], ["\\", "-LRB-", "Nadam\\", "-RRB-", "-LSB-", "13", "-RSB-", "is", "used", "as", "optimiser", "and", "the", "mean", "squared", "error", "-LRB-", "MSE", "-RRB-", "as", "loss-function", "."], ["When", "using", "bigger", "batch-sizes", ",", "unwanted", "jumps", "in", "the", "training", "loss", "were", "observed", "regularly", ",", "and", "when", "using", "smaller", "batch-sizes", ",", "overfitting", "occured", "early", "during", "training", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 6, "a"], [9, 9, "p"], [11, 11, "v"]], [[24, 24, "a"], [35, 37, "a"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "p"], [9, 9, "p"], [9, 11, "v"], [14, 14, "p"], [17, 17, "p"], [17, 19, "v"]], [], [[47, 47, "p"], [63, 63, "p"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1911.11763-a5310adb-49af-43bd-be45-0376b44d934f", "sentences": [["Model", "Parameters", ":", "The", "Keypoint", "Encoder", "MLP", "has", "5", "layers", ",", "mapping", "positions", "to", "dimensions", "of", "size", "\\", "-LRB-", "-LRB-", "32,64,128,256", ",", "D", "-RRB-", "\\", "-RRB-", ",", "yielding", "100k", "parameters", "."], ["Each", "layer", "has", "the", "three", "projection", "matrices", ",", "and", "an", "extra", "\\", "-LRB-", "-LCB-", "\\bf", "W", "-RCB-", "^O\\", "-RRB-", "to", "deal", "with", "the", "multi-head", "output", "."], ["The", "message", "update", "MLP", "has", "2", "layers", "and", "maps", "to", "dimensions", "\\", "-LRB-", "-LRB-", "2D", ",", "D", "-RRB-", "\\", "-RRB-", "."], ["Both", "MLPs", "use", "BatchNorm", "and", "ReLUs", "."], ["Each", "layer", "has", "0.66M", "parameters", "."], ["SuperGlue", "has", "18", "layers", ",", "with", "a", "total", "of", "12M", "parameters", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[4, 6, "a"], [9, 9, "p"], [8, 8, "v"], [11, 14, "p"], [9, 9, "p"], [9, 9, "p"]], [], [[63, 63, "p"], [58, 60, "a"], [63, 63, "p"], [62, 62, "v"], [63, 63, "p"]], [], [], [[94, 94, "p"], [94, 94, "p"], [91, 91, "a"], [94, 94, "p"], [93, 93, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "v"], [28, 28, "v"]], [[35, 35, "v"]], [[60, 60, "a"], [62, 62, "v"]], [[81, 81, "a"], [83, 83, "a"]], [[88, 88, "v"]], [[91, 91, "a"], [93, 93, "v"], [100, 100, "v"]], []], "predicted_relations": [[[9, 9, 4, 6, "USED-FOR"], [8, 8, 9, 9, "USED-FOR"], [8, 8, 11, 14, "USED-FOR"], [8, 8, 9, 9, "USED-FOR"], [8, 8, 9, 9, "USED-FOR"], [11, 14, 4, 6, "USED-FOR"], [9, 9, 4, 6, "USED-FOR"], [9, 9, 4, 6, "USED-FOR"]], [], [[63, 63, 58, 60, "USED-FOR"], [63, 63, 58, 60, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [63, 63, 58, 60, "USED-FOR"]], [], [], [[94, 94, 91, 91, "USED-FOR"], [94, 94, 91, 91, "USED-FOR"], [94, 94, 91, 91, "USED-FOR"], [93, 93, 94, 94, "USED-FOR"], [93, 93, 94, 94, "USED-FOR"], [93, 93, 94, 94, "USED-FOR"]], []]}
{"doc_key": "1905.07967-d3f5112e-0431-45bf-ab40-4f2f5042e9c6", "sentences": [["The", "dataset", "from", "section", "REF", "was", "split", "into", "training", "and", "test", "set", "with", "a", "\\", "-LRB-", "4:1\\", "-RRB-", "ratio", "."], ["As", "a", "result", ",", "3725", "images", "were", "used", "for", "training", "and", "931", "for", "testing", "."], ["The", "networks", "were", "trained", "with", "Tensorflow", "using", "an", "Nvidia", "GeForce", "GTX", "1080", "Ti", "graphics", "card", "."]], "ner": [[[1, 1, "a"], [18, 18, "a"], [18, 18, "p"], [16, 16, "v"]], [], [[40, 40, "a"], [43, 47, "a"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [16, 16, "v"]], [[24, 24, "v"], [31, 31, "v"]], []], "predicted_relations": [[[16, 16, 18, 18, "USED-FOR"]], [], []]}
{"doc_key": "1905.07826-a399873b-e4ad-41aa-b733-fcba6e4c59fb", "sentences": [["The", "model", "was", "built", "on", "tensorflow", "1.8", "framework", "and", "implemented", "using", "Python", "3.6", "."], ["The", "code", "is", "open-sourced", "and", "can", "be", "found", "at", "\\", "-LRB-", "github.com/hyuna915/video_segmentation\\", "-RRB-", "."], ["In", "addition", "to", "original", "code", "to", "pre-process", "image", ",", "isolate", "objects", ",", "construct", "U-Net", ",", "and", "SegNet", "graph", ",", "we", "used", "the", "davis-2017", "code", "repository", "for", "model", "evaluation", "and", "OSVOS", "code", "repository", "for", "constructing", "OSVOS", "layer", "."]], "ner": [[[5, 5, "a"], [6, 6, "v"], [11, 11, "a"], [12, 12, "v"]], [], [[50, 50, "a"], [57, 57, "a"], [62, 62, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[41, 41, "a"], [44, 45, "a"], [50, 50, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1905.07826-5e1e70d1-a54e-4c3a-90a7-68e3b31164da", "sentences": [["Our", "model", "was", "trained", "on", "N1-HighMem-8", "instance", ",", "with", "v8CPU", ",", "52", "GB", "memory", ",", "on", "Google", "Cloud", "Compute", "Platform", "."], ["We", "'ve", "also", "attached", "NVIDIA", "Tesla", "P100", "GPU", "with", "16GB", "memory", "to", "the", "virtual", "machine", "."], ["Due", "to", "the", "sheer", "amount", "of", "model", "structure/parameters", "we", "have", "experimented", "upon", ",", "in", "total", "5", "GPUs", "are", "used", "for", "this", "project", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [9, 9, "a"], [11, 12, "v"]], [[30, 30, "v"]], [[52, 52, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1911.08522-6a9db8c6-4f10-40f2-b870-1ff2a5503947", "sentences": [["For", "all", "the", "experiments", ",", "we", "use", "the", "GloVe", "word", "embedding", "of", "size", "300", "-LSB-", "8", "-RSB-", "."], ["The", "encoder", "and", "decoder", "are", "bidirectional", "LSTMs", "of", "3-layers", "with", "a", "state", "size", "of", "256", "."], ["The", "dimension", "of", "all", "hidden", "layers", "is", "256", "."], ["We", "initialized", "all", "weights", "with", "samples", "from", "a", "normal", "distribution", "with", "mean", "zero", "and", "a", "standard", "deviation", "of", "0.0001", "."], ["We", "minimize", "the", "loss", "function", "in", "Equation", "REF", "with", "the", "Adam", "optimizer", "-LSB-", "5", "-RSB-", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.005\\", "-RRB-", "."], ["We", "also", "applied", "regular", "dropout", "after", "the", "input", "and", "output", "of", "each", "LSTM", "with", "keep", "probability", "of", "\\", "-LRB-", "95.0\\", "%", "\\", "-RRB-", "for", "SMTD", "and", "\\", "-LRB-", "50.0\\", "%", "\\", "-RRB-", "for", "CamRest", "."], ["We", "identified", "the", "overwrite", "probability", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "by", "random", "search", "in", "\\", "-LRB-", "-LSB-", "0.01", ",", "5", "-RSB-", "\\", "-RRB-", "and", "fixed", "it", "at", "\\", "-LRB-", "0.1\\", "-RRB-", "after", "evaluating", "in", "the", "held-out", "validation", "dataset", "."]], "ner": [[[8, 10, "a"], [12, 12, "p"], [13, 13, "v"]], [[30, 30, "p"], [23, 24, "a"], [26, 26, "v"], [29, 30, "p"], [32, 32, "v"]], [[41, 41, "v"]], [], [[73, 74, "a"], [81, 82, "p"], [86, 86, "v"]], [[92, 93, "a"], [103, 104, "p"], [113, 113, "c"], [122, 122, "c"]], [[127, 128, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "v"]], [[24, 24, "a"], [29, 30, "p"], [32, 32, "v"]], [[41, 41, "v"]], [[55, 55, "v"], [61, 61, "v"]], [[73, 73, "a"], [81, 82, "p"], [86, 86, "v"]], [[93, 93, "a"], [101, 101, "a"], [108, 109, "v"], [113, 113, "a"], [117, 118, "v"], [122, 122, "a"]], [[141, 144, "v"], [153, 153, "v"]]], "predicted_relations": [[[12, 12, 8, 10, "USED-FOR"], [13, 13, 12, 12, "USED-FOR"]], [[30, 30, 23, 24, "USED-FOR"], [29, 30, 23, 24, "USED-FOR"]], [], [], [[81, 82, 73, 74, "USED-FOR"]], [[103, 104, 92, 93, "USED-FOR"]], []]}
{"doc_key": "1910.05577-e0f042b3-ce4a-4688-9923-190335a6af3f", "sentences": [["For", "the", "default", "setting", "on", "ImageNet", ",", "we", "use", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "random", "resized", "cropping", "and", "random", "horizontal", "flipping", "for", "data", "augmentation", "."], ["Then", "we", "standardize", "the", "data", "with", "mean", "and", "variance", "per", "channel", "."], ["We", "use", "a", "traditional", "cross-entropy", "loss", "to", "train", "all", "the", "networks", "with", "a", "batch", "size", "of", "256", "on", "8", "GPUs", "by", "SGD", ",", "a", "weight", "decay", "of", "0.0001", ",", "and", "a", "momentum", "of", "0.9", "for", "100", "epochs", "."], ["We", "start", "from", "a", "learning", "rate", "of", "0.1", "and", "decrease", "it", "by", "a", "factor", "of", "10", "every", "30", "epochs", "."], ["The", "last", "normalization", "layers", "in", "the", "module", "are", "zero-initialized", "to", "make", "the", "gates", "start", "from", "constants", "."], ["All", "the", "extra", "layers", "in", "Context-Gated", "Convolution", "have", "a", "learning", "rate", "ten", "times", "smaller", "than", "convolutional", "kernels", "."]], "ner": [[[5, 5, "a"], [14, 16, "a"], [18, 20, "a"]], [], [[41, 42, "a"], [58, 58, "a"], [61, 62, "p"], [68, 68, "p"], [73, 73, "p"]], [[79, 80, "p"], [79, 80, "p"], [93, 93, "p"]], [], [[121, 122, "p"], [121, 122, "p"], [117, 118, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [12, 12, "v"]], [], [[41, 42, "a"], [50, 51, "p"], [53, 53, "v"], [55, 55, "v"], [61, 62, "p"], [64, 64, "v"], [70, 70, "v"], [72, 72, "v"], [73, 73, "p"]], [[79, 80, "p"], [82, 82, "v"], [90, 90, "v"], [92, 92, "v"], [93, 93, "p"]], [], [[121, 122, "p"], [123, 123, "v"]]], "predicted_relations": [[], [], [[61, 62, 41, 42, "USED-FOR"], [61, 62, 58, 58, "USED-FOR"], [68, 68, 41, 42, "USED-FOR"], [68, 68, 58, 58, "USED-FOR"], [73, 73, 58, 58, "USED-FOR"]], [], [], [[121, 122, 117, 118, "USED-FOR"], [121, 122, 117, 118, "USED-FOR"]]]}
{"doc_key": "1910.05577-185992e1-f4dc-462a-87b1-9347b8b2aa05", "sentences": [["For", "the", "advanced", "setting", ",", "we", "also", "use", "mixup", "-LSB-", "55", "-RSB-", "for", "data", "augmentation", ",", "and", "we", "follow", "-LSB-", "22", "-RSB-", "to", "use", "learning", "rate", "warm-up", "in", "the", "first", "5", "epochs", "of", "training", "."], ["We", "train", "the", "networks", "with", "the", "cosine", "learning", "rate", "schedule", "-LSB-", "22", "-RSB-", "for", "120", "epochs", "."], ["The", "other", "hyper-parameters", "are", "set", "to", "be", "same", "with", "the", "default", "setting", "."]], "ner": [[[8, 8, "a"], [24, 26, "a"], [31, 31, "p"]], [[50, 50, "p"], [49, 49, "v"], [41, 44, "a"]], []], "relations": [[], [], []], "predicted_ner": [[[8, 8, "a"], [24, 26, "a"], [30, 30, "v"], [31, 31, "p"]], [[38, 38, "a"], [49, 49, "v"], [50, 50, "p"]], []], "predicted_relations": [[[31, 31, 24, 26, "USED-FOR"]], [[50, 50, 41, 44, "USED-FOR"], [49, 49, 50, 50, "USED-FOR"]], []]}
{"doc_key": "1910.05577-9bcbd659-3354-4d50-bd9d-e5307f9ac9b8", "sentences": [["For", "CIFAR-10", ",", "we", "use", "\\", "-LRB-", "32\\times", "32\\", "-RRB-", "random", "cropping", "with", "a", "padding", "of", "4", "and", "random", "horizontal", "flipping", "."], ["We", "use", "a", "batch", "size", "of", "128", "and", "train", "on", "1", "GPU", "."], ["We", "decrease", "the", "learning", "rate", "at", "the", "81st", "and", "122nd", "epochs", ",", "and", "halt", "training", "after", "164", "epochs", "."], ["For", "the", "ablation", "study", ",", "the", "result", "is", "an", "average", "of", "3", "runs", "."]], "ner": [[[1, 1, "a"], [10, 11, "a"], [14, 14, "a"], [18, 20, "a"]], [[25, 26, "a"]], [[38, 39, "a"], [49, 49, "a"]], [[66, 66, "p"], [65, 65, "v"], [56, 57, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"], [8, 8, "v"], [16, 16, "v"]], [[25, 26, "p"], [28, 28, "v"], [32, 32, "v"]], [[38, 39, "p"], [42, 42, "v"], [44, 44, "v"], [51, 51, "v"], [52, 52, "p"]], [[65, 65, "v"]]], "predicted_relations": [[], [], [], [[66, 66, 56, 57, "USED-FOR"], [65, 65, 66, 66, "USED-FOR"]]]}
{"doc_key": "1909.11287-62d1cc53-6d4b-49bc-8955-e00bc413215f", "sentences": [["Sequence", "to", "sequence", "."], ["For", "SEQ2SEQ", ",", "we", "adopt", "one", "layer", "LSTMs", "as", "encoder", "and", "decoder", "."], ["For", "Key-Value", "Retrieval", "dataset", ",", "hidden", "size", "is", "placed", "at", "512", "and", "the", "dropout", "rate", "is", "0.3", "."], ["On", "dataset", "bAbI", ",", "the", "hidden", "size", "and", "dropout", "rate", "are", "128", "and", "0.1", "for", "task", "3", ",", "256", "and", "0.1", "for", "task", "4", "and", "5", "."], ["Learning", "rates", "are", "set", "to", "0.001", "for", "bAbI", "and", "0.0001", "for", "DSTC", "2", "and", "Key-Value", "Retrieval", "dataset", "."], ["SEQ2SEQ", "+", "Attention", "."], ["We", "adopt", "the", "attention", "mechanism", "-LSB-", "12", "-RSB-", "commonly", "used", "in", "neural", "machine", "translation", "."], ["On", "dataset", "bAbI", ",", "hidden", "size", "and", "the", "dropout", "rate", "are", "256", "and", "0.1", "for", "task", "3", "and", "4", ",", "128", "and", "0.1", "for", "task", "5", "."], ["For", "Key-Value", "Retrieval", "dataset", ",", "hidden", "size", "and", "dropout", "rate", "are", "512", "and", "0.3", "."], ["On", "the", "DSTC", "2", "task", ",", "hidden", "size", "is", "set", "to", "353", "and", "word", "embedding", "size", "is", "300", "-LRB-", "same", "with", "original", "work", "-RRB-", "."], ["Mem2Seq", "."], ["Except", "128", "in", "task", "3", ",", "hidden", "size", "in", "other", "tasks", "is", "256", "."], ["The", "dropout", "rate", "is", "set", "to", "0.2", "in", "task", "3", ",", "4", "and", "Key-Value", "Retrieval", "dataset", ",", "0.1", "in", "task", "5", "and", "DSTC", "2", "dataset", "."], ["We", "adopt", "three", "hops", "in", "DSTC", "2", "and", "Key-Value", "Retrieval", "dataset", "."], ["HMNs", "with", "context-free", "only", "-LRB-", "HMNs-CFO", "-RRB-", "."], ["To", "test", "the", "performance", "of", "context-aware", "memory", ",", "we", "apply", "other", "context-free", "to", "encode", "dialogue", "history", "instead", "of", "context-aware", "memory", "in", "HMNs", "."], ["All", "the", "other", "structure", "and", "parameter", "settings", "are", "the", "same", "as", "HMNs", "in", "this", "model", "."]], "ner": [[], [], [[22, 23, "p"], [27, 27, "v"], [18, 20, "c"], [30, 31, "p"], [33, 33, "v"], [18, 20, "c"], [22, 23, "p"], [27, 27, "v"], [18, 20, "c"], [30, 31, "p"], [33, 33, "v"], [18, 20, "c"], [22, 23, "p"], [30, 31, "p"]], [[40, 41, "p"], [46, 46, "v"], [53, 53, "v"], [43, 44, "p"], [48, 48, "v"], [55, 55, "v"], [48, 48, "v"], [55, 55, "v"], [37, 37, "c"], [40, 41, "p"], [53, 53, "v"], [46, 46, "v"], [43, 44, "p"], [48, 48, "v"], [55, 55, "v"], [40, 41, "p"], [46, 46, "v"], [53, 53, "v"], [43, 44, "p"], [48, 48, "v"], [55, 55, "v"]], [[76, 78, "c"], [73, 74, "c"], [76, 78, "c"], [67, 67, "v"], [69, 69, "c"], [71, 71, "v"], [73, 78, "c"], [76, 78, "c"], [73, 74, "c"], [76, 78, "c"], [73, 74, "c"]], [[80, 82, "a"]], [], [[103, 104, "p"], [119, 119, "v"], [110, 110, "v"], [107, 108, "p"], [112, 112, "v"], [121, 121, "v"], [112, 112, "v"], [121, 121, "v"], [101, 101, "c"], [103, 104, "p"], [110, 110, "v"], [119, 119, "v"], [107, 108, "p"], [112, 112, "v"], [121, 121, "v"], [103, 104, "p"], [119, 119, "v"], [110, 110, "v"], [107, 108, "p"], [112, 112, "v"], [121, 121, "v"]], [[131, 132, "p"], [137, 137, "v"], [127, 129, "c"], [134, 135, "p"], [139, 139, "v"], [127, 129, "c"], [131, 132, "p"], [137, 137, "v"], [127, 129, "c"], [134, 135, "p"], [139, 139, "v"], [127, 129, "c"], [131, 132, "p"], [134, 135, "p"]], [[147, 148, "p"], [152, 152, "v"], [143, 144, "c"], [147, 148, "p"], [152, 152, "v"], [143, 144, "c"], [154, 156, "p"], [158, 158, "v"], [143, 144, "c"], [147, 148, "p"]], [[166, 166, "a"]], [[174, 175, "p"], [169, 169, "v"], [180, 180, "v"], [174, 175, "p"], [180, 180, "v"], [169, 169, "v"], [174, 175, "p"], [169, 169, "v"], [180, 180, "v"]], [[195, 197, "c"], [204, 205, "c"], [183, 184, "p"], [195, 197, "c"], [199, 199, "v"], [188, 188, "v"], [199, 199, "v"], [195, 197, "c"], [204, 205, "c"], [183, 184, "p"], [199, 199, "v"], [195, 197, "c"], [204, 205, "c"], [183, 184, "p"], [188, 188, "v"], [199, 199, "v"]], [[216, 218, "c"], [213, 214, "c"], [216, 218, "c"], [213, 218, "c"], [216, 218, "c"], [213, 214, "c"], [216, 218, "c"], [213, 214, "c"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[5, 5, "a"], [9, 9, "v"], [11, 11, "a"]], [[18, 20, "a"], [22, 23, "p"], [27, 27, "v"], [30, 31, "p"], [33, 33, "v"]], [[37, 37, "a"], [40, 41, "p"], [43, 44, "p"], [46, 46, "v"], [48, 48, "v"], [53, 53, "v"], [55, 55, "v"]], [[62, 63, "p"], [67, 67, "v"], [68, 69, "c"], [69, 69, "a"], [71, 71, "v"], [72, 78, "c"], [73, 74, "a"], [76, 78, "a"]], [[80, 82, "a"]], [[87, 88, "a"]], [[101, 101, "a"], [107, 108, "p"], [110, 110, "v"], [112, 112, "v"], [119, 119, "v"], [121, 121, "v"]], [[127, 129, "a"], [134, 135, "p"], [137, 137, "v"], [139, 139, "v"]], [[143, 144, "a"], [147, 148, "p"], [152, 152, "v"], [158, 158, "v"]], [[166, 166, "a"]], [[169, 169, "v"], [180, 180, "v"]], [[183, 184, "p"], [188, 188, "v"], [193, 193, "v"], [195, 197, "a"], [199, 199, "v"], [204, 205, "a"]], [[210, 210, "v"], [213, 214, "a"], [216, 218, "c"]], [[220, 220, "a"], [225, 225, "a"]], [[249, 249, "a"]], [[262, 262, "a"]]], "predicted_relations": [[], [], [[18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"], [18, 20, 27, 27, "USED-FOR"], [18, 20, 33, 33, "USED-FOR"]], [[48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [37, 37, 46, 46, "USED-FOR"], [37, 37, 46, 46, "USED-FOR"], [37, 37, 46, 46, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"]], [[76, 78, 71, 71, "USED-FOR"], [76, 78, 71, 71, "USED-FOR"], [73, 78, 71, 71, "USED-FOR"], [76, 78, 71, 71, "USED-FOR"], [76, 78, 71, 71, "USED-FOR"]], [], [], [[112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [101, 101, 110, 110, "USED-FOR"], [101, 101, 110, 110, "USED-FOR"], [101, 101, 110, 110, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"]], [[127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"], [127, 129, 137, 137, "USED-FOR"], [127, 129, 139, 139, "USED-FOR"]], [[152, 152, 154, 156, "USED-FOR"], [152, 152, 154, 156, "USED-FOR"]], [], [], [[195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [195, 197, 199, 199, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1909.11229-04c5a23b-1ebd-4083-8d82-677f7b3c9bf5", "sentences": [["We", "utilized", "the", "pose", "estimation", "toolbox", "called", "DeepLabCut", "-LSB-", "32", "-RSB-", ",", "-LSB-", "37", "-RSB-", ",", "-LSB-", "17", "-RSB-", ",", "and", "added", "MobileNetV2", "-LSB-", "43", "-RSB-", "and", "EfficientNet", "backbones", "-LSB-", "46", "-RSB-", "to", "the", "ResNets", "-LSB-", "12", "-RSB-", "that", "were", "present", ",", "as", "well", "as", "adding", "imgaug", "for", "data", "augmentation", "-LSB-", "18", "-RSB-", "."], ["The", "TensorFlow", "-LSB-", "0", "-RSB-", "-based", "network", "architectures", "could", "be", "easily", "exchanged", "while", "keeping", "data", "loading", ",", "training", ",", "and", "evaluation", "consistent", "."], ["The", "feature", "detectors", "in", "DeepLabCut", "consist", "of", "a", "backbone", "followed", "by", "deconvolutional", "layers", "to", "predict", "pose", "scoremaps", "and", "location", "refinement", "maps", "-LRB-", "offsets", "-RRB-", ",", "which", "can", "then", "be", "used", "for", "predicting", "the", "pose", "while", "also", "providing", "a", "confidence", "score", "."], ["As", "previously", ",", "for", "the", "ResNet", "backbones", "we", "utilize", "an", "output", "stride", "of", "16", "and", "then", "upsample", "the", "filter", "banks", "with", "deconvolutions", "by", "a", "factor", "of", "two", "to", "predict", "the", "heatmaps", "and", "location-refinement", "at", "1", "/", "8th", "of", "the", "original", "image", "size", "scale", "-LSB-", "17", "-RSB-", ",", "-LSB-", "32", "-RSB-", "."], ["For", "MobileNetV2", "-LSB-", "43", "-RSB-", ",", "we", "configured", "the", "output-stride", "as", "16", "-LRB-", "by", "changing", "the", "last", "stride", "2", "convolution", "to", "stride", "1", "-RRB-", "."]], "ner": [[[7, 7, "a"], [22, 22, "a"], [27, 27, "a"], [34, 34, "a"], [46, 46, "a"]], [[55, 55, "a"]], [[81, 81, "a"]], [[131, 131, "v"], [128, 129, "p"], [131, 131, "v"]], [[170, 170, "a"], [178, 178, "p"], [180, 180, "v"], [180, 180, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [22, 22, "a"], [27, 27, "a"], [34, 34, "a"], [46, 46, "a"]], [], [[81, 81, "a"]], [[123, 123, "a"], [131, 131, "v"], [144, 144, "v"], [152, 154, "v"]], [[170, 170, "a"], [180, 180, "v"], [191, 191, "v"]]], "predicted_relations": [[], [], [], [], [[178, 178, 170, 170, "USED-FOR"], [180, 180, 178, 178, "USED-FOR"], [180, 180, 178, 178, "USED-FOR"]]]}
{"doc_key": "1909.11229-bed04e61-8196-4521-9774-852b1ae6a595", "sentences": [["The", "baseline", "EfficientNet", "model", "was", "designed", "by", "Tan", "et", "al", "."], ["-LSB-", "46", "-RSB-", "through", "a", "neural", "architecture", "search", "to", "optimize", "for", "accuracy", "and", "inverse", "FLOPS", "."], ["From", "B0", "to", "B6", ",", "compound", "scaling", "is", "used", "to", "increase", "the", "width", ",", "depth", ",", "and", "resolution", "of", "the", "network", ",", "which", "directly", "corresponds", "to", "an", "increase", "in", "ImageNet", "performance", "-LSB-", "46", "-RSB-", "."], ["We", "used", "the", "AutoAugment", "pretrained", "checkpoints", "from", "TensorFlow", "as", "well", "as", "adapted", "the", "EfficientNet", "'s", "output-stride", "to", "16", "-LRB-", "by", "changing", "the", "-LRB-", "otherwise", "-RRB-", "last", "stride", "2", "convolution", "to", "stride", "1", "-RRB-", "."]], "ner": [[[2, 3, "a"]], [], [], [[77, 77, "p"], [79, 79, "v"], [65, 65, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[2, 3, "a"]], [], [[30, 30, "v"], [56, 56, "a"]], [[65, 65, "a"], [75, 75, "a"], [79, 79, "v"], [93, 93, "v"]]], "predicted_relations": [[], [], [], [[77, 77, 65, 65, "USED-FOR"], [79, 79, 77, 77, "USED-FOR"]]]}
{"doc_key": "1909.11229-0b903d05-5408-4878-a4a1-cec6b605b826", "sentences": [["The", "training", "loss", "is", "defined", "as", "the", "cross", "entropy", "loss", "for", "the", "scoremaps", "and", "the", "location", "refinement", "error", "via", "a", "Huber", "loss", "with", "weight", "\\", "-LRB-", "0.05\\", "-RRB-", "-LSB-", "32", "-RSB-", "."], ["The", "loss", "is", "minimized", "via", "ADAM", "with", "batch", "size", "8", "-LSB-", "20", "-RSB-", "."], ["For", "training", ",", "a", "cosine", "learning", "rate", "schedule", ",", "as", "in", "-LSB-", "22", "-RSB-", "with", "ADAM", "optimizer", "and", "batchsize", "8", "was", "used", ";", "we", "also", "performed", "augmentation", ",", "using", "imgaug", "-LSB-", "18", "-RSB-", ",", "with", "random", "cropping", "and", "rotations", "."], ["Initial", "learning", "rates", "and", "decay", "target", "points", "were", "cross-validated", "for", "MobileNetV2", "\\", "-LRB-", "0.35\\", "-RRB-", "and", "\\", "-LRB-", "1.0\\", "-RRB-", ",", "ResNet-50", ",", "EfficientNet", "B0", ",", "B3", ",", "and", "B5", "for", "the", "pretrained", "and", "from", "scratch", "models", "-LRB-", "see", "Supplementary", "Material", "-RRB-", "."], ["For", "each", "model", "that", "was", "not", "cross", "validated", "-LRB-", "MobileNetV2", "\\", "-LRB-", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "0.75\\", "-RRB-", ",", "ResNet-101", ",", "EfficientNet", "B1", ",", "B2", ",", "B4", ",", "B6", "-RRB-", ",", "the", "best", "performing", "training", "parameters", "from", "the", "most", "similar", "cross", "validated", "model", "was", "used", "-LRB-", "i.e", "."], ["the", "cross", "validated", "EfficientNet-B0", "schedule", "was", "used", "for", "EfficientNet-B1", ";", "see", "Supplementary", "Material", "-RRB-", "."], ["For", "MobileNetV2s", ",", "we", "trained", "the", "batch", "normalization", "layers", "too", "-LRB-", "this", "had", "little", "effect", "on", "task", "performance", "for", "MobileNetV2-\\", "-LRB-", "0.35\\", "-RRB-", "-RRB-", "."], ["Pretrained", "models", "were", "trained", "for", "30k", "iterations", "-LRB-", "as", "they", "converged", "-RRB-", ",", "while", "models", "from", "scratch", "were", "trained", "for", "180k", "iterations", "."], ["From", "scratch", "variants", "of", "the", "architectures", "used", "He-initialization", "-LSB-", "11", "-RSB-", ",", "while", "all", "pretrained", "networks", "were", "initialized", "from", "their", "ImageNet", "trained", "weights", "."]], "ner": [[[20, 21, "a"]], [[39, 40, "p"], [41, 41, "v"], [37, 37, "a"]], [[65, 65, "v"], [61, 61, "a"], [75, 75, "a"]], [], [], [], [], [], [[248, 248, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 9, "a"], [20, 21, "a"], [26, 26, "v"]], [[37, 37, "a"], [39, 40, "p"], [41, 41, "v"]], [[61, 61, "a"], [64, 64, "p"], [65, 65, "v"], [75, 75, "a"]], [[96, 96, "a"], [99, 99, "v"], [104, 104, "v"], [107, 107, "a"], [115, 115, "v"]], [[138, 138, "a"], [141, 141, "v"], [146, 146, "v"], [149, 149, "a"]], [[181, 181, "a"], [186, 186, "a"]], [[194, 194, "a"], [214, 214, "v"]], [[223, 223, "v"], [238, 238, "v"]], [[261, 261, "a"]]], "predicted_relations": [[], [[39, 40, 37, 37, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1904.02306-e50f2795-eb5a-4538-833d-994d57a092e1", "sentences": [["For", "the", "morphological", "tagger", ",", "we", "use", "the", "baseline", "implementation", "from", "P18-1247", "."], ["This", "implementation", "uses", "an", "input", "layer", "and", "linear", "layer", "dimension", "of", "128", "and", "a", "2-layer", "LSTM", "with", "a", "hidden", "layer", "dimension", "of", "256", "."], ["The", "Adam", "-LSB-", "18", "-RSB-", "optimizer", "is", "used", "for", "training", "and", "a", "dropout", "rate", "-LSB-", "32", "-RSB-", "of", "0.3", "is", "enforced", "during", "training", "."], ["The", "tagger", "was", "trained", "for", "10", "epochs", "."]], "ner": [[[8, 9, "a"]], [[17, 22, "p"], [24, 24, "v"], [27, 33, "p"], [35, 35, "v"]], [[49, 50, "p"], [55, 55, "v"], [49, 50, "a"]], [[66, 66, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[11, 11, "a"]], [[24, 24, "v"], [28, 28, "a"], [35, 35, "v"]], [[38, 38, "a"], [49, 50, "p"], [55, 55, "v"]], [[66, 66, "v"], [67, 67, "p"]]], "predicted_relations": [[], [[24, 24, 27, 33, "USED-FOR"]], [[49, 50, 49, 50, "USED-FOR"]], []]}
{"doc_key": "1904.02306-398882ef-8c89-414a-a64a-91a3973b95c6", "sentences": [["For", "the", "lemmatizer", ",", "we", "use", "a", "2-layer", "biLSTM", "encoder", "and", "a", "1-layer", "LSTM", "decoder", "with", "400", "hidden", "units", "."], ["The", "dimensions", "of", "character", "and", "tag", "embedding", "are", "200", "and", "40", ",", "respectively", "."], ["We", "enforce", "a", "dropout", "rate", "of", "0.4", "in", "the", "embedding", "and", "encoder", "LSTM", "layers", "."], ["The", "lemmatizer", "is", "also", "trained", "with", "Adam", "and", "the", "learning", "rate", "is", "0.001", "."], ["We", "halve", "the", "learning", "rate", "whenever", "the", "development", "log-likelihood", "increases", "and", "we", "perform", "early-stopping", "when", "the", "learning", "rate", "reaches", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["We", "apply", "gradient", "clipping", "with", "a", "maximum", "gradient", "norm", "of", "5", "."]], "ner": [[[7, 9, "a"], [17, 18, "p"], [16, 16, "v"]], [[28, 28, "v"], [25, 26, "p"], [30, 30, "v"]], [[37, 38, "p"], [40, 40, "v"]], [[55, 55, "a"], [58, 59, "p"], [61, 61, "v"], [58, 59, "p"]], [[66, 67, "p"], [79, 80, "p"], [76, 76, "a"], [66, 67, "p"], [79, 80, "p"], [87, 87, "v"]], [[94, 95, "a"], [98, 100, "p"], [102, 102, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [13, 13, "a"], [16, 16, "v"], [17, 18, "p"]], [[28, 28, "v"], [30, 30, "v"]], [[37, 38, "p"], [40, 40, "v"], [46, 46, "a"]], [[50, 50, "a"], [55, 55, "a"], [58, 59, "p"], [61, 61, "v"]], [[66, 67, "p"], [76, 76, "a"], [79, 80, "p"], [85, 87, "v"]], [[94, 95, "a"], [98, 100, "p"], [102, 102, "v"]]], "predicted_relations": [[[17, 18, 7, 9, "USED-FOR"]], [[28, 28, 25, 26, "USED-FOR"], [30, 30, 25, 26, "USED-FOR"]], [[40, 40, 37, 38, "USED-FOR"]], [[58, 59, 55, 55, "USED-FOR"], [58, 59, 55, 55, "USED-FOR"]], [[79, 80, 76, 76, "USED-FOR"], [79, 80, 76, 76, "USED-FOR"]], [[98, 100, 94, 95, "USED-FOR"], [102, 102, 98, 100, "USED-FOR"]]]}
{"doc_key": "1910.11161-8fc078fb-648d-426e-be3e-70c874fe9be3", "sentences": [["The", "four", "models", "including", "the", "proposed", "model", "-LRB-", "THRED", "-RRB-", "are", "all", "encoder-decoder", "models", "."], ["We", "use", "the", "bidirectional", "LSTM", "as", "the", "encoder", "part", "and", "the", "unidirectional", "LSTM", "as", "the", "decoder", "part", "."], ["All", "models", "have", "the", "dimensional", "size", "of", "500", "in", "the", "hidden", "layers", "."], ["The", "size", "of", "the", "latent", "variable", "\\", "-LRB-", "z\\", "-RRB-", "is", "\\", "-LRB-", "d_z=100\\", "-RRB-", "."], ["The", "size", "of", "the", "dense", "topic", "features", "in", "the", "-LRB-", "NMF", "-RRB-", "dense", "topic", "matrix", "is", "\\", "-LRB-", "d_t=40\\", "-RRB-", "."], ["For", "each", "dataset", ",", "we", "pick", "top", "20000", "frequent", "tokens", "to", "make", "the", "vocabulary", "."], ["We", "train", "the", "models", "with", "the", "learning", "rate", "of", "0.0002", "."], ["The", "best", "validated", "networks", "are", "saved", "in", "400000", "training", "epochs", "."], ["We", "also", "improve", "the", "results", "using", "Beam", "Search", "-LSB-", "18", "-RSB-", "which", "samples", "best-first", "candidate", "tokens", "at", "each", "inference", "step", "."], ["And", "we", "set", "the", "Beam", "number", "as", "5", "."]], "ner": [[], [[18, 19, "a"], [26, 27, "a"]], [[37, 38, "p"], [40, 40, "v"], [37, 38, "p"], [40, 40, "v"], [38, 38, "p"], [38, 38, "p"]], [[50, 51, "a"], [47, 47, "p"], [59, 59, "v"], [47, 47, "p"]], [[63, 63, "p"], [74, 76, "a"], [63, 63, "p"], [80, 80, "v"]], [], [[104, 105, "a"], [107, 107, "v"]], [], [[126, 127, "a"]], [[145, 146, "p"], [148, 148, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "v"]], [[19, 19, "a"], [27, 27, "a"]], [[40, 40, "v"]], [], [], [[90, 90, "v"]], [[104, 105, "p"], [107, 107, "v"]], [[116, 116, "v"], [117, 118, "p"]], [[126, 127, "a"]], [[145, 146, "p"], [148, 148, "v"]]], "predicted_relations": [[], [], [[40, 40, 37, 38, "USED-FOR"], [40, 40, 37, 38, "USED-FOR"], [40, 40, 38, 38, "USED-FOR"], [40, 40, 38, 38, "USED-FOR"], [40, 40, 37, 38, "USED-FOR"], [40, 40, 37, 38, "USED-FOR"], [40, 40, 38, 38, "USED-FOR"], [40, 40, 38, 38, "USED-FOR"]], [], [], [], [], [], [], [[148, 148, 145, 146, "USED-FOR"]]]}
{"doc_key": "1908.11024-c26fbe1c-8ca8-4ab3-a93d-9ad901471226", "sentences": [["Encoder/target", "network", ":", "In", "the", "classification", "experiment", "in", "Section", "REF", ",", "ResNet50", "was", "used", "as", "an", "encoder", "network", "and", "the", "reduced", "AlexNet", "was", "used", "as", "a", "target", "network", "."], ["The", "reduced", "AlexNet", "which", "consists", "of", "five", "convolutional", "layers", "and", "three", "FC", "layers", ",", "but", "the", "number", "of", "kernels", "in", "each", "layer", "are", "all", "reduced", "to", "about", "1/2", "to", "1/4", "of", "the", "ones", "in", "AlexNet", "-LSB-", "15", "-RSB-", "."], ["Here", "the", "size", "of", "convolutional", "kernels", "is", "set", "to", "3\\", "-LRB-", "\\times", "\\", "-RRB-", "3", "."], ["Then", ",", "in", "the", "object", "detection", "experiment", ",", "VGG16", "was", "used", "as", "an", "encoder", "network", "and", "SSD300", "-LSB-", "18", "-RSB-", "was", "used", "as", "a", "target", "network", "."], ["In", "the", "knowledge", "distillation", "experiment", "in", "Section", "REF", ",", "ResNet26", "was", "used", "as", "an", "encoder", "network", "and", "the", "reduced", "AlexNet", "was", "used", "as", "a", "target", "network", "."]], "ner": [[[11, 11, "a"], [20, 21, "a"]], [[30, 31, "a"], [45, 47, "p"]], [[77, 82, "v"], [70, 73, "p"]], [[92, 92, "a"], [100, 100, "a"]], [[129, 130, "a"], [120, 120, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[11, 11, "a"], [21, 21, "a"]], [[31, 31, "a"], [35, 35, "v"], [39, 39, "v"], [56, 56, "v"], [58, 58, "v"], [63, 63, "a"]], [[82, 82, "v"]], [[92, 92, "a"], [100, 100, "a"]], [[113, 115, "a"], [120, 120, "a"], [130, 130, "a"]]], "predicted_relations": [[], [[45, 47, 30, 31, "USED-FOR"]], [[77, 82, 70, 73, "USED-FOR"]], [], []]}
{"doc_key": "1908.11024-ebdd1fe1-aeb5-4aa8-86ab-26968e22d194", "sentences": [["Training", "details", ":", "Each", "numerical", "value", "in", "all", "experimental", "results", "is", "the", "average", "value", "of", "three", "trials", "."], ["Each", "iteration", "is", "2,000", "based", "on", "the", "batch", "size", "of", "64", ",", "and", "it", "performs", "up", "to", "50", "epochs", "."], ["Especially", ",", "in", "the", "case", "of", "the", "object", "detection", ",", "120", "epochs", "."], ["We", "employ", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "-LSB-", "30", "-RSB-", "with", "momentum", "0.9", "as", "an", "optimizer", "."], ["Also", "we", "used", "the", "TensorFlow", "library", "for", "model", "construction", "as", "well", "as", "training", "."]], "ner": [[], [], [], [[63, 63, "p"], [64, 64, "v"]], [[73, 73, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[15, 15, "v"]], [[21, 21, "v"], [25, 26, "p"], [28, 28, "v"], [35, 35, "v"], [36, 36, "p"]], [[48, 48, "v"], [49, 49, "p"]], [[53, 58, "a"], [64, 64, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1902.05300-e607bdd4-8560-493b-8f4c-9a61e8c1952d", "sentences": [["with", "\\", "-LRB-", "\\lambda", "=", "0.0001\\", "-RRB-", "."], ["The", "network", "is", "trained", "using", "the", "RMSProp", "algorithm", "-LRB-", "see", "for", "example", "http", ":", "//www.cs.toronto.edu/~", "tijmen/csc321/slides/lecture_slides_lec6.pdf", "as", "referred", "to", "in", "-RRB-", "with", "minibatch", "size", "100", ",", "learning", "rate", "\\", "-LRB-", "0.00002\\", "-RRB-", ",", "momentum", "0", ",", "and", "decay", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["The", "number", "of", "training", "epochs", "is", "100", "."]], "ner": [[[5, 5, "v"], [3, 3, "p"], [5, 5, "v"]], [[14, 15, "a"], [30, 31, "p"], [32, 32, "v"], [34, 35, "p"], [38, 38, "v"], [41, 41, "p"], [38, 38, "v"], [42, 42, "v"], [48, 48, "v"], [45, 45, "p"], [48, 48, "v"], [32, 32, "v"]], [[57, 57, "v"], [57, 57, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "p"], [5, 5, "v"]], [[14, 15, "a"], [30, 31, "p"], [32, 32, "v"], [34, 35, "p"], [38, 38, "v"], [41, 41, "p"], [45, 45, "p"], [48, 48, "v"]], [[54, 55, "p"], [57, 57, "v"]]], "predicted_relations": [[[5, 5, 3, 3, "USED-FOR"], [5, 5, 3, 3, "USED-FOR"]], [[30, 31, 14, 15, "USED-FOR"], [32, 32, 30, 31, "USED-FOR"], [38, 38, 30, 31, "USED-FOR"], [38, 38, 41, 41, "USED-FOR"], [41, 41, 14, 15, "USED-FOR"], [38, 38, 30, 31, "USED-FOR"], [38, 38, 41, 41, "USED-FOR"], [42, 42, 41, 41, "USED-FOR"], [45, 45, 14, 15, "USED-FOR"], [32, 32, 30, 31, "USED-FOR"]], []]}
{"doc_key": "1902.05300-73153b0a-8906-4c30-94be-ca9bd896a36c", "sentences": [["We", "used", "the", "same", "values", "for", "\\", "-LRB-", "\\alpha", ",", "\\beta", ",", "\\gamma", "\\", "-RRB-", "and", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "as", "in", ",", "in", "particular", ",", "\\", "-LRB-", "\\alpha", "=15\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=", "0.1\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "=", "0.0025\\", "-RRB-", "and", "\\", "-LRB-", "\\tau", "=1\\", "-RRB-", "."], ["The", "generator", "and", "the", "discriminator", "network", "were", "jointly", "trained", "by", "alternating", "gradient", "optimization", "."], ["In", "particular", ",", "the", "Adam", "optimizer", "was", "adopted", ",", "with", "initial", "learning", "rate", "\\", "-LRB-", "0.0001\\", "-RRB-", ",", "momentum", "\\", "-LRB-", "0.5\\", "-RRB-", ",", "and", "minibatch", "size", "25", "."], ["The", "learning", "rate", "was", "halved", "every", "5", "epochs", "."], ["We", "applied", "the", "same", "early", "stopping", "rule", "as", "given", "in", "their", "implementationhttps", ":", "//github.com/nebulaV/DAGAN", "."], ["This", "is", "based", "on", "measuring", "the", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "iMSE", "-RCB-", "-RCB-", "\\", "-RRB-", "loss", "between", "the", "training", "set", "and", "validation", "set", "."], ["We", "used", "the", "early", "stopping", "number", "10", "."], ["In", "total", "this", "resulted", "in", "15", "epochs", "of", "training", "."]], "ner": [[], [], [[77, 79, "p"], [82, 82, "v"], [85, 85, "p"], [88, 88, "v"], [92, 93, "p"], [94, 94, "v"]], [], [[109, 111, "a"]], [], [[153, 155, "p"], [156, 156, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "p"], [10, 10, "p"], [12, 12, "p"], [18, 18, "p"], [29, 29, "p"], [30, 30, "v"], [35, 35, "p"], [37, 37, "v"], [42, 42, "p"], [44, 44, "v"]], [[57, 58, "a"], [63, 65, "a"]], [[71, 71, "a"], [78, 79, "p"], [82, 82, "v"], [85, 85, "p"], [88, 88, "v"], [92, 93, "p"], [94, 94, "v"]], [[97, 98, "p"], [102, 102, "v"], [103, 103, "p"]], [[109, 111, "a"]], [], [[153, 155, "p"], [156, 156, "v"]], [[163, 163, "v"], [164, 164, "p"]]], "predicted_relations": [[], [], [[82, 82, 77, 79, "USED-FOR"], [82, 82, 85, 85, "USED-FOR"], [88, 88, 85, 85, "USED-FOR"], [88, 88, 92, 93, "USED-FOR"], [94, 94, 85, 85, "USED-FOR"], [94, 94, 92, 93, "USED-FOR"]], [], [], [], [[156, 156, 153, 155, "USED-FOR"]], []]}
{"doc_key": "1902.05300-7733d0ea-f129-47ca-ac1b-cfb707a0cd7d", "sentences": [["The", "network", "weights", "were", "initialized", "using", "He", "initialization", "and", "the", "Adam", "optimizer", "was", "used", "for", "training", "."], ["This", "optimizer", "takes", "as", "input", "a", "learning", "rate", "-LRB-", "step", "size", "-RRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "and", "two", "exponential", "decay", "parameters", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "related", "to", "a", "momentum", "term", "."], ["We", "refer", "to", "for", "further", "explanations", "of", "these", "parameters", "."], ["The", "network", "was", "trained", "with", "\\", "-LRB-", "\\alpha", "=", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "and", "batch", "size", "equal", "10", "."]], "ner": [[[6, 7, "a"]], [], [], [[86, 86, "v"], [92, 92, "v"], [95, 96, "p"], [76, 76, "v"], [98, 98, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "a"]], [[23, 24, "p"], [31, 31, "p"], [36, 36, "v"]], [], [[74, 74, "p"], [76, 79, "v"], [95, 96, "p"], [98, 98, "v"]]], "predicted_relations": [[], [], [], [[98, 98, 95, 96, "USED-FOR"]]]}
{"doc_key": "1902.05300-00a0e4e4-3f4d-41e4-93d2-ac23ea86c00c", "sentences": [["The", "network", "weights", "were", "provided", "by", "the", "authors", "of", "and", "obtained", "based", "on", "the", "training", "procedure", "as", "described", "in", "their", "paper", "."], ["The", "loss", "function", "used", "to", "train", "the", "networks", "is", "the", "\\", "-LRB-", "\\ell", "^2\\", "-RRB-", "difference", "between", "the", "network", "output", "and", "the", "ground", "truth", ",", "and", "the", "networks", "are", "trained", "using", "the", "stochastic", "gradient", "descent", "algorithm", "with", "momentum", "."], ["The", "learning", "rate", "varies", "from", "\\", "-LRB-", "0.01\\", "-RRB-", "to", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "whereas", "the", "momentum", "is", "set", "to", "\\", "-LRB-", "0.99\\", "-RRB-", ",", "and", "the", "minibatch", "size", "is", "equal", "to", "1", "."], ["During", "training", ",", "gradients", "are", "clipped", "to", "the", "interval", "\\", "-LRB-", "-LSB-", "-I_", "-LCB-", "\\mathrm", "-LCB-", "max", "-RCB-", "-RCB-", ",", "I_", "-LCB-", "\\mathrm", "-LCB-", "max", "-RCB-", "-RCB-", "-RSB-", "\\", "-RRB-", "with", "\\", "-LRB-", "I_", "-LCB-", "\\mathrm", "-LCB-", "max", "-RCB-", "-RCB-", "=", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", ",", "to", "prevent", "the", "divergence", "of", "the", "cost", "function", "."], ["The", "networks", "are", "trained", "for", "101", "epochs", ",", "and", "the", "code", "used", "to", "implement", "the", "networks", "is", "written", "in", "MatLab", "using", "the", "library", "MatConvNethttp", ":", "//www.vlfeat.org/matconvnet", "."]], "ner": [[], [[59, 59, "p"]], [[62, 63, "p"], [68, 68, "v"], [73, 73, "v"], [78, 78, "p"], [84, 84, "v"], [89, 90, "p"], [94, 94, "v"]], [[99, 99, "p"]], [[159, 159, "p"], [158, 158, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[34, 35, "p"], [54, 57, "a"]], [[62, 63, "p"], [68, 68, "v"], [73, 73, "v"], [78, 78, "p"], [84, 84, "v"], [89, 90, "p"], [94, 94, "v"]], [[137, 140, "v"]], [[158, 158, "v"], [159, 159, "p"], [176, 178, "a"]]], "predicted_relations": [[], [], [[73, 73, 78, 78, "USED-FOR"], [84, 84, 78, 78, "USED-FOR"], [84, 84, 89, 90, "USED-FOR"], [94, 94, 89, 90, "USED-FOR"]], [], [[158, 158, 159, 159, "USED-FOR"]]]}
{"doc_key": "1902.05300-6a8e9e4a-c048-46f8-85ff-f66fe88bba39", "sentences": [["with", "\\", "-LRB-", "\\epsilon", "=", "10^", "-LCB-", "-12", "-RCB-", "\\", "-RRB-", "."], ["The", "network", "parameters", "that", "minimize", "the", "loss", "function", "are", "determined", "using", "the", "inertial", "incremental", "proximal", "gradient", "-LRB-", "IIPG", "-RRB-", "optimizer", "-LRB-", "see", ",", "for", "details", "-RRB-", "."], ["Optimization", "is", "performed", "for", "1000", "epochs", ",", "with", "a", "step", "size", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["Training", "data", "is", "arranged", "into", "minibatches", "of", "size", "5", "."], ["In", "the", "original", "paper", ",", "the", "batch", "size", "was", "set", "to", "10", ",", "but", "due", "to", "memory", "limitations", "we", "had", "to", "adjust", "this", "."]], "ner": [[[3, 3, "p"]], [[24, 31, "a"]], [[48, 49, "p"], [44, 44, "p"], [43, 43, "v"]], [[68, 68, "v"]], [[76, 77, "p"], [84, 87, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 8, "v"]], [[24, 30, "a"]], [[43, 43, "v"], [44, 44, "p"], [53, 56, "v"]], [[68, 68, "v"]], [[76, 77, "p"], [81, 81, "v"]]], "predicted_relations": [[], [], [[43, 43, 44, 44, "USED-FOR"]], [], []]}
{"doc_key": "1902.05392-c836bc2a-1c6c-4587-873e-09ca4e5c0dc7", "sentences": [["where", "\\", "-LRB-", "N\\", "-RRB-", "is", "the", "number", "of", "images", "in", "the", "burst", ",", "\\", "-LRB-", "S\\", "-RRB-", "is", "the", "set", "of", "kernel", "sizes", ",", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "are", "the", "hyperparameters", "controlling", "the", "weight", "decay", ",", "\\", "-LRB-", "t\\", "-RRB-", "is", "the", "training", "step", ",", "and", "\\", "-LRB-", "\\lambda", "_1", "+", "\\lambda", "_2", "=", "1\\", "-RRB-", "."], ["Please", "note", "that", "during", "training", "we", "discard", "in-place", "addition", "of", "kernels", "to", "enable", "better", "convergence", "."], ["However", ",", "once", "the", "network", "is", "well", "trained", ",", "the", "in-place", "addition", "can", "help", "speed", "up", "inference", "."]], "ner": [[[41, 42, "a"], [38, 38, "p"], [27, 27, "v"], [33, 33, "v"]], [[72, 75, "a"]], []], "relations": [[], [], []], "predicted_ner": [[[27, 27, "p"], [33, 33, "p"], [41, 42, "p"], [56, 57, "p"], [59, 62, "p"]], [], []], "predicted_relations": [[[38, 38, 41, 42, "USED-FOR"], [27, 27, 38, 38, "USED-FOR"], [33, 33, 38, 38, "USED-FOR"]], [], []]}
{"doc_key": "1911.07034-37dae77e-a6aa-4b11-80f1-b1e82fff2827", "sentences": [["We", "train", "our", "LISA", "framework", "by", "following", "the", "training", "strategies", "of", "Mask", "R-CNN", "implemented", "on", "Facebook", "Detectron2", "-LSB-", "47", "-RSB-", "."], ["Specifically", ",", "we", "adopt", "the", "weights", "of", "ResNeXt-101-FPN", "-LSB-", "27", "-RSB-", ",", "-LSB-", "48", "-RSB-", "trained", "on", "ImageNet", "-LSB-", "6", "-RSB-", "to", "initialize", "the", "parameters", "of", "the", "backbone", "network", ",", "and", "train", "our", "framework", "on", "two", "GeForce", "GTX", "1080", "Ti", "GPUs", "-LRB-", "four", "images", "per", "GPU", "-RRB-", "for", "40\\", "-LRB-", "k\\", "-RRB-", "training", "iterations", "."], ["We", "set", "the", "base", "learning", "rate", "as", "1e-4", ",", "adopt", "a", "warm-up", "-LSB-", "10", "-RSB-", "strategy", "to", "linearly", "increase", "the", "learning", "rate", "to", "1e-3", "during", "the", "first", "1,000", "iterations", ",", "keep", "the", "learning", "rate", "as", "1e-3", ",", "and", "stop", "the", "learning", "after", "40\\", "-LRB-", "k\\", "-RRB-", "iterations", "."], ["We", "re-scale", "the", "input", "images", ",", "such", "that", "the", "longer", "side", "is", "less", "than", "1,333", "and", "the", "shorter", "side", "is", "less", "than", "800", "without", "changing", "the", "image", "aspect", "ratio", "."], ["Lastly", ",", "we", "randomly", "apply", "horizontal", "flips", "on", "the", "images", "for", "data", "augmentation", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[11, 12, "a"]], [[28, 28, "a"], [38, 38, "a"], [73, 74, "p"]], [[87, 87, "a"], [79, 81, "p"], [83, 83, "v"], [99, 99, "v"], [111, 111, "v"]], [[133, 152, "v"]], [[165, 166, "p"], [159, 160, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [11, 12, "a"], [16, 16, "a"]], [[28, 28, "a"], [38, 38, "a"], [54, 54, "a"], [56, 56, "v"], [63, 63, "v"], [69, 69, "v"], [71, 71, "p"]], [[83, 83, "v"], [87, 87, "a"], [96, 97, "p"], [99, 99, "v"], [103, 103, "v"], [108, 109, "p"], [111, 111, "v"], [118, 118, "v"], [120, 120, "p"]], [[138, 138, "v"], [146, 146, "v"]], [], []], "predicted_relations": [[], [], [[79, 81, 87, 87, "USED-FOR"], [83, 83, 79, 81, "USED-FOR"]], [], [], []]}
{"doc_key": "1905.04509-c2d634ef-d7df-4fc1-8a6b-5a25137b6443", "sentences": [["We", "train", "every", "model", "via", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "Nesterov", "momentum", "of", "weight", "0.9", "without", "dampening", "."], ["We", "use", "a", "cosine", "shape", "learning", "rate", "schedule", "-LSB-", "6", "-RSB-", "which", "starts", "from", "\\", "-LRB-", "0.1\\", "-RRB-", "and", "decreases", "gradually", "to", "0", "throughout", "the", "training", "."], ["We", "set", "a", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "except", "for", "the", "spatial", "shifting", "biases", "\\", "-LRB-", "\\mathbf", "-LCB-", "b", "-RCB-", "\\", "-RRB-", "in", "which", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "is", "used", "instead", "."], ["During", "the", "training", ",", "we", "call", "dealloc", "and", "realloc", "at", "each", "epoch", "for", "the", "half", "of", "the", "total", "epochs", "."], ["This", "is", "mainly", "for", "two", "reasons", ":", "-LRB-", "a", "-RRB-", "usually", ",", "most", "of", "dealloc", "is", "done", "before", "that", "time", ",", "and", "-LRB-", "b", "-RRB-", "we", "found", "this", "makes", "the", "training", "less", "sensitive", "on", "the", "choice", "of", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "."], ["When", "a", "spatial", "bias", "is", "re-initialized", ",", "we", "sample", "a", "point", "from", "\\", "-LRB-", "-LSB-", "-1.5", ",", "1.5", "-RSB-", "\\times", "-LSB-", "-1.5", ",", "1.5", "-RSB-", "\\", "-RRB-", "pixels", "uniformly", "."]], "ner": [[[12, 13, "p"], [16, 16, "v"]], [], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 10, "a"], [12, 13, "a"], [16, 16, "v"]], [[36, 36, "v"], [42, 42, "v"], [43, 45, "c"]], [[50, 51, "p"], [55, 58, "v"], [80, 83, "v"]], [[96, 96, "a"], [104, 104, "v"]], [[114, 114, "v"], [149, 149, "p"]], [[170, 170, "v"], [176, 176, "v"]]], "predicted_relations": [[[16, 16, 12, 13, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1904.02210-667caed9-8b4d-4b1f-8dd8-730fde7bcb19", "sentences": [["We", "used", "80-dimensional", "log", "Mel", "filterbank", "features", "with", "3-dimensional", "pitch", "features", "."], ["We", "tuned", "hyperparameters", "for", "these", "models", "using", "one", "Aymara", "reading.CMU", "Wilderness", "reading", "ID", ":", "AYMSBU", "."], ["We", "found", "that", "a", "4", "layer", "encoder", ",", "1", "layer", "decoder", "with", "768", "for", "the", "encoder", "hidden", "size", "and", "projections", ",", "decoder", "hidden", "size", ",", "and", "attention", "hidden", "size", "yielded", "equal-best", "results", "with", "deeper", "models", "."], ["These", "settings", "were", "then", "used", "for", "training", "the", "models", "used", "in", "our", "experiments", "."]], "ner": [[[2, 10, "a"]], [], [[32, 38, "a"], [43, 45, "p"], [40, 40, "v"], [47, 47, "p"], [40, 40, "v"], [49, 51, "p"], [40, 40, "v"], [54, 56, "p"], [40, 40, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "v"], [8, 8, "v"]], [[19, 19, "v"], [20, 20, "a"], [26, 26, "a"]], [[32, 32, "v"], [36, 36, "v"], [40, 40, "v"]], []], "predicted_relations": [[], [], [[43, 45, 32, 38, "USED-FOR"], [40, 40, 43, 45, "USED-FOR"], [40, 40, 47, 47, "USED-FOR"], [47, 47, 32, 38, "USED-FOR"], [40, 40, 43, 45, "USED-FOR"], [40, 40, 47, 47, "USED-FOR"], [49, 51, 32, 38, "USED-FOR"], [40, 40, 43, 45, "USED-FOR"], [40, 40, 47, 47, "USED-FOR"], [54, 56, 32, 38, "USED-FOR"], [40, 40, 43, 45, "USED-FOR"], [40, 40, 47, 47, "USED-FOR"]], []]}
{"doc_key": "1910.08470-bd9c2f2e-0437-448b-a430-1ece416bb71d", "sentences": [["As", "mentioned", "above", ",", "we", "use", "the", "Darkening", "video", "sequence", "for", "training", "the", "model", "and", "the", "Light", "Switch", "video", "for", "testing", "."], ["All", "models", "are", "trained", "with", "the", "same", "parameters", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "lr=0.001\\", "-RRB-", "and", "is", "reduced", "by", "a", "factor", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "if", "the", "model", "does", "not", "improve", "for", "2", "epochs", "."], ["The", "training", "process", "ends", "after", "5", "epochs", "of", "no", "improvements", "."], ["For", "optimisation", ",", "the", "Adam", "optimiser", "-LSB-", "28", "-RSB-", "is", "selected", "with", "betas", "\\", "-LRB-", "b_1=0.9\\", "-RRB-", "and", "\\", "-LRB-", "b_2=0.999\\", "-RRB-", "."], ["Finally", ",", "the", "batch", "size", "is", "set", "to", "1", "."]], "ner": [[], [], [[32, 34, "p"], [38, 38, "v"]], [], [[76, 77, "a"], [84, 84, "p"], [87, 87, "v"], [92, 92, "v"]], [[98, 99, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[33, 34, "p"], [38, 38, "v"], [49, 49, "v"], [58, 58, "v"], [59, 59, "p"]], [[66, 66, "v"], [67, 67, "p"]], [[76, 76, "a"], [87, 87, "v"], [92, 92, "v"]], [[98, 99, "p"], [103, 103, "v"]]], "predicted_relations": [[], [], [[38, 38, 32, 34, "USED-FOR"]], [], [[84, 84, 76, 77, "USED-FOR"], [87, 87, 84, 84, "USED-FOR"], [92, 92, 84, 84, "USED-FOR"]], []]}
{"doc_key": "1910.08486-a9cf4396-8cab-4239-ba24-cb54bc7d65c1", "sentences": [["We", "initialize", "word", "embeddings", "with", "128-d", "vectors", "and", "fine-tune", "them", "during", "training", "."], ["Concepts", "share", "the", "same", "embeddings", "with", "the", "words", "."], ["The", "vocabulary", "size", "was", "set", "to", "150k", "for", "both", "the", "source", "and", "target", "text", "."], ["The", "hidden", "state", "size", "was", "set", "to", "256", "."], ["The", "vocabulary", "size", "is", "increased", "from", "around", "602", "to", "2216", "concepts", "w.r.t", "the", "different", "number", "-LRB-", "\\", "-LRB-", "k=1", ",", "\\cdots", ",", "5\\", "-RRB-", "-RRB-", "of", "concept", "candidates", "for", "each", "word", "."], ["Note", "that", "the", "generated", "concepts", "with", "UNKs", "were", "subsequently", "deleted", "."], ["Our", "code", "is", "available", "on", "https", ":", "//github.com/wprojectsn/codes", ",", "and", "the", "vocabularies", "and", "candidate", "concepts", "are", "also", "included", "."]], "ner": [[[2, 3, "a"], [5, 5, "v"]], [], [[23, 24, "p"], [28, 28, "v"], [32, 35, "c"]], [[38, 40, "p"], [44, 44, "v"]], [[47, 48, "p"], [55, 55, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"]], [], [[28, 28, "v"]], [[38, 40, "p"], [44, 44, "v"]], [[53, 53, "v"], [55, 55, "v"], [68, 68, "v"]], [[84, 84, "a"]], []], "predicted_relations": [[], [], [[28, 28, 23, 24, "USED-FOR"], [32, 35, 28, 28, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1910.08486-d9d94368-800b-4f29-b188-2d3f53042b7f", "sentences": [["We", "trained", "our", "models", "on", "a", "single", "GTX", "TITAN", "GPU", "machine", "."], ["We", "used", "the", "Adagrad", "optimizer", "with", "a", "batch", "size", "of", "64", "to", "minimize", "the", "loss", "."], ["The", "initial", "learning", "rate", "and", "the", "accumulator", "value", "were", "set", "to", "0.15", "and", "0.1", ",", "respectively", "."], ["We", "used", "gradient", "clipping", "with", "a", "maximum", "gradient", "norm", "of", "2", "."], ["At", "the", "time", "of", "decoding", ",", "the", "summaries", "were", "produced", "through", "a", "beam", "search", "of", "size", "8", "."], ["The", "hyper-parameter", "settings", "were", "\\", "-LRB-", "\\lambda", "=", "0.99\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "=0.1\\", "-RRB-", ",", "\\", "-LRB-", "\\pi", "=", "2.92\\", "-RRB-", "on", "DUC-2004", "and", "\\", "-LRB-", "\\pi", "=1.68\\", "-RRB-", "on", "Gigaword", "."], ["We", "trained", "our", "concept", "pointer", "generator", "for", "450k", "iterations", "yielded", "the", "best", "performance", ",", "then", "took", "the", "optimization", "using", "RL", "rewards", "for", "RG-L", "at", "95K", "iterations", "on", "DUC-2004", "and", "at", "50K", "iterations", "on", "Gigaword", "."], ["We", "took", "the", "distance-supervised", "training", "at", "5K", "iterations", "on", "DUC-2004", "and", "at", "6.5K", "iterations", "on", "Gigaword", "."]], "ner": [[], [[15, 16, "a"], [19, 20, "p"], [22, 22, "v"], [20, 20, "p"]], [[29, 31, "p"], [39, 39, "v"], [34, 35, "p"], [41, 41, "v"], [41, 41, "v"]], [[51, 53, "p"], [55, 55, "v"]], [[69, 70, "a"], [72, 72, "p"], [73, 73, "v"]], [[89, 89, "v"], [96, 96, "v"], [76, 77, "a"], [83, 83, "v"], [89, 89, "v"], [96, 96, "v"], [99, 99, "c"], [104, 104, "v"], [107, 107, "c"], [99, 99, "c"], [107, 107, "c"], [99, 99, "c"], [107, 107, "c"]], [[136, 136, "c"], [142, 142, "c"], [112, 114, "a"], [117, 117, "p"], [134, 134, "p"], [140, 140, "p"], [116, 116, "v"], [128, 129, "a"], [117, 117, "p"], [134, 134, "p"], [140, 140, "p"], [133, 133, "v"], [136, 136, "c"], [139, 139, "v"], [142, 142, "c"], [117, 117, "p"], [134, 134, "p"], [140, 140, "p"], [136, 136, "c"], [142, 142, "c"]], [[153, 153, "c"], [159, 159, "c"], [151, 151, "p"], [157, 157, "p"], [151, 151, "p"], [157, 157, "p"], [153, 153, "c"], [159, 159, "c"], [147, 148, "a"], [151, 151, "p"], [157, 157, "p"], [150, 150, "v"], [156, 156, "v"], [153, 153, "c"], [156, 156, "v"], [159, 159, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[15, 15, "a"], [19, 20, "p"], [22, 22, "v"]], [[30, 31, "p"], [34, 35, "p"], [39, 39, "v"], [41, 41, "v"]], [[47, 48, "a"], [51, 53, "p"], [55, 55, "v"]], [[69, 70, "c"], [73, 73, "v"]], [[81, 81, "p"], [83, 83, "v"], [88, 88, "p"], [89, 89, "v"], [96, 96, "v"], [99, 99, "a"], [104, 104, "v"], [107, 107, "a"]], [[112, 114, "a"], [116, 116, "v"], [131, 131, "a"], [133, 133, "v"], [136, 136, "c"], [139, 139, "v"], [142, 142, "a"]], [[150, 150, "v"], [153, 153, "a"], [156, 156, "v"], [159, 159, "a"]]], "predicted_relations": [[], [[22, 22, 20, 20, "USED-FOR"], [20, 20, 15, 16, "USED-FOR"]], [], [[55, 55, 51, 53, "USED-FOR"]], [[72, 72, 69, 70, "USED-FOR"], [73, 73, 72, 72, "USED-FOR"]], [[99, 99, 89, 89, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 104, 104, "USED-FOR"], [107, 107, 104, 104, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 104, 104, "USED-FOR"], [107, 107, 104, 104, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 89, 89, "USED-FOR"], [99, 99, 104, 104, "USED-FOR"], [107, 107, 104, 104, "USED-FOR"]], [[136, 136, 133, 133, "USED-FOR"], [136, 136, 139, 139, "USED-FOR"], [134, 134, 128, 129, "USED-FOR"], [140, 140, 128, 129, "USED-FOR"], [116, 116, 117, 117, "USED-FOR"], [116, 116, 117, 117, "USED-FOR"], [116, 116, 117, 117, "USED-FOR"], [134, 134, 128, 129, "USED-FOR"], [140, 140, 128, 129, "USED-FOR"], [133, 133, 134, 134, "USED-FOR"], [133, 133, 140, 140, "USED-FOR"], [133, 133, 134, 134, "USED-FOR"], [133, 133, 140, 140, "USED-FOR"], [133, 133, 134, 134, "USED-FOR"], [133, 133, 140, 140, "USED-FOR"], [136, 136, 133, 133, "USED-FOR"], [136, 136, 139, 139, "USED-FOR"], [139, 139, 134, 134, "USED-FOR"], [139, 139, 140, 140, "USED-FOR"], [139, 139, 134, 134, "USED-FOR"], [139, 139, 140, 140, "USED-FOR"], [139, 139, 134, 134, "USED-FOR"], [139, 139, 140, 140, "USED-FOR"], [134, 134, 128, 129, "USED-FOR"], [140, 140, 128, 129, "USED-FOR"], [136, 136, 133, 133, "USED-FOR"], [136, 136, 139, 139, "USED-FOR"]], [[153, 153, 150, 150, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [153, 153, 150, 150, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [150, 150, 151, 151, "USED-FOR"], [150, 150, 151, 151, "USED-FOR"], [150, 150, 151, 151, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [153, 153, 150, 150, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [153, 153, 156, 156, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"]]]}
{"doc_key": "1910.13136-df4435c2-5a6e-48c6-9916-e20693a0855a", "sentences": [["For", "the", "training", "process", ",", "4", "\\", "-LRB-", "\\times", "\\", "-RRB-", "1080Ti", "GPUs", "are", "used", ";", "and", "the", "test", "is", "carried", "on", "with", "a", "single", "GPU", "."], ["The", "Adam", "solver", "is", "used", "with", "parameters", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=", "0.9", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=", "0.999", ",", "and", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "=", "\\", "-LRB-", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "."], ["The", "batch", "size", "is", "set", "to", "32", ",", "with", "the", "learning", "rate", "is", "set", "to", "0.001", "."], ["The", "model", "is", "trained", "on", "the", "generated", "dataset", "for", "80", "epochs", "."], ["During", "the", "test", "process", ",", "it", "takes", "0.27", "seconds", "on", "average", "to", "fuse", "an", "image", "pairs", "of", "size", "520", "\\", "-LRB-", "\\times", "\\", "-RRB-", "520", "."]], "ner": [[], [[28, 29, "a"], [40, 40, "v"], [48, 48, "v"]], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [11, 11, "v"]], [[28, 29, "a"], [40, 40, "v"], [48, 48, "v"], [59, 61, "v"]], [[67, 68, "p"], [72, 72, "v"], [76, 77, "p"], [81, 81, "v"]], [[92, 92, "v"], [93, 93, "p"]], [[102, 102, "v"], [113, 113, "v"], [119, 119, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1907.12949-fc67696d-117b-4e80-8f49-f35ed5dc7f1d", "sentences": [["Images", "were", "resized", "to", "128x96", "pixels", "in", "order", "to", "smooth", "noise", "and", "reduce", "both", "training", "time", "and", "memory", "requirements", "."], ["Joint", "annotation", "was", "performed", "using", "a", "custom-built", "annotation", "tool", ",", "publicly", "available", "onlinehttps", ":", "//github.com/roccopietrini/pyPointAnnotator", "."], ["To", "build", "the", "ground-truth", "masks", ",", "we", "selected", "\\", "-LRB-", "r\\", "-RRB-", "equal", "to", "6", "pixels", "."]], "ner": [[[4, 5, "v"]], [], [[46, 46, "p"], [50, 51, "v"]]], "relations": [[], [], []], "predicted_ner": [[[4, 4, "v"]], [], [[50, 50, "v"]]], "predicted_relations": [[], [], [[50, 51, 46, 46, "USED-FOR"]]]}
{"doc_key": "1907.12949-c3bc6d98-5248-4f48-ae59-ca04ffad0b83", "sentences": [["For", "training", "the", "detection", "and", "regression", "network", ",", "we", "set", "an", "initial", "learning", "rate", "of", "0.01", "with", "a", "learning", "decay", "of", "10", "%", "every", "10", "epochs", ",", "and", "a", "momentum", "of", "0.98", "."], ["We", "used", "a", "batch", "size", "of", "16", "and", "for", "both", "the", "networks", "the", "number", "of", "epochs", "was", "set", "to", "100", "."], ["We", "selected", "the", "best", "model", "as", "the", "one", "that", "maximized", "the", "accuracy", "on", "the", "validation", "set", "-LRB-", "training/validation", "split", "=", "0.3", "-RRB-", "."]], "ner": [[[11, 13, "p"], [15, 15, "v"], [18, 19, "p"], [29, 29, "p"], [31, 31, "v"]], [[36, 37, "p"], [39, 39, "v"], [46, 48, "p"], [52, 52, "v"]], [[68, 69, "a"], [71, 72, "p"], [74, 74, "v"]]], "relations": [[], [], []], "predicted_ner": [[[12, 13, "p"], [15, 15, "v"], [18, 19, "p"], [21, 22, "v"], [24, 24, "v"], [25, 25, "p"], [31, 31, "v"]], [[36, 37, "p"], [39, 39, "v"], [48, 48, "p"], [52, 52, "v"]], [[74, 74, "v"]]], "predicted_relations": [[], [], [[71, 72, 68, 69, "USED-FOR"], [74, 74, 71, 72, "USED-FOR"]]]}
{"doc_key": "1910.05069-a8c84a89-35ef-4561-9c9b-3cd090661416", "sentences": [["We", "leveraged", "a", "BFS", "method", "to", "search", "valid", "logical", "forms", "for", "questions", "in", "training", "data", "."], ["The", "buffer", "size", "in", "BFS", "is", "set", "to", "1000", "."], ["Both", "embedding", "and", "hidden", "sizes", "in", "the", "model", "are", "set", "to", "\\", "-LRB-", "300D\\", "-RRB-", ",", "and", "no", "pretrained", "embeddings", "are", "loaded", "for", "initialization", ",", "and", "the", "positional", "encodings", "are", "randomly", "initialized", "and", "learnable", "."], ["The", "head", "number", "of", "multi-head", "attention", "is", "6", "and", "activation", "function", "inside", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "FFN", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "is", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "Gelu", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "-LSB-", "12", "-RSB-", "."], ["We", "used", "Adam", "-LSB-", "14", "-RSB-", "to", "optimize", "the", "loss", "function", "defined", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "where", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "1.5\\", "-RRB-", ",", "and", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "training", "batch", "size", "is", "128", "for", "6", "epochs", "."], ["And", "we", "also", "employed", "learning", "rate", "warmup", "within", "the", "first", "\\", "-LRB-", "1\\", "%", "\\", "-RRB-", "steps", "and", "linear", "decay", "within", "the", "rest", "."], ["The", "source", "codes", "are", "available", "at", "https", ":", "//github.com/taoshen58/MaSP", "."], ["More", "details", "of", "our", "implementation", "are", "described", "in", "Appendix"]], "ner": [[[3, 4, "a"]], [[17, 18, "p"], [24, 24, "v"]], [[33, 33, "a"], [39, 39, "v"], [39, 39, "v"]], [[62, 66, "p"], [68, 68, "v"], [89, 89, "v"]], [[102, 102, "a"], [109, 110, "a"]], [[121, 121, "p"], [129, 129, "v"], [133, 134, "a"], [133, 134, "p"]], [[154, 154, "v"], [148, 150, "a"], [148, 150, "p"], [152, 152, "v"]], [[161, 162, "a"], [161, 162, "p"], [161, 163, "a"], [173, 173, "p"], [175, 176, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"]], [[20, 20, "a"], [24, 24, "v"]], [[39, 39, "v"]], [[68, 68, "v"]], [[102, 102, "a"]], [[121, 121, "p"], [129, 129, "v"], [133, 134, "p"], [140, 143, "v"]], [[148, 150, "p"], [152, 152, "v"], [154, 154, "v"], [155, 155, "p"]], [[169, 170, "v"], [175, 176, "a"]], [], []], "predicted_relations": [[], [], [], [], [], [[129, 129, 133, 134, "USED-FOR"]], [[154, 154, 148, 150, "USED-FOR"], [148, 150, 148, 150, "USED-FOR"], [152, 152, 148, 150, "USED-FOR"]], [[173, 173, 161, 162, "USED-FOR"], [173, 173, 161, 163, "USED-FOR"]], [], []]}
{"doc_key": "1905.02019-e7c4ed99-c3ba-471e-900a-d9f26d989a25", "sentences": [["When", "\\", "-LRB-", "HiddenSize", "=", "150\\", "-RRB-", ",", "\\", "-LRB-", "Dropout", "=", "0.2\\", "-RRB-", "is", "a", "good", "choice", "."], ["Increase", "will", "lead", "to", "high", "variance", "model", "and", "decrease", "will", "lead", "to", "over-fitting", "in", "early", "stage", "Increase", "\\", "-LRB-", "HiddenSize\\", "-RRB-", "from", "150", "to", "250", "does", "n't", "improve", "the", "performance", "much", "."], ["\\", "-LRB-", "EmbeddingSize", "=", "100\\", "-RRB-", "has", "a", "reasonable", "good", "performance", "."], ["Increase", "embedding", "size", "from", "100", "to", "200", "does", "n't", "affect", "model", "performance", "much", "."]], "ner": [[[3, 3, "a"], [10, 10, "a"], [12, 12, "v"]], [[38, 38, "a"]], [[53, 53, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "v"], [12, 12, "v"]], [[41, 41, "v"], [43, 43, "v"]], [[55, 55, "v"]], [[67, 67, "v"], [69, 69, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1905.01995-7fd94dfa-1af0-457d-8b76-35e33b63e7c4", "sentences": [["The", "model", "word", "embeddings", "are", "initialized", "with", "the", "300-dimensional", "pre-trained", "vectors", "provided", "by", "Glove", "-LSB-", "58", "-RSB-", "."], ["We", "update", "network", "weights", "by", "using", "the", "Adam", "-LSB-", "59", "-RSB-", "optimizer", "with", "learning", "rate", "0.001", "."], ["The", "hidden", "layers", "of", "Bi-LSTM", "and", "Bi-GRU", "have", "size", "100", "."], ["In", "the", "semantic", "matching", "model", ",", "Dropout", "is", "set", "to", "0.1", "."]], "ner": [[[13, 13, "a"]], [[25, 25, "a"], [31, 32, "p"], [33, 33, "v"]], [[39, 39, "a"], [44, 44, "v"], [41, 41, "a"], [44, 44, "v"]], [[52, 52, "a"], [56, 56, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "v"], [13, 13, "a"]], [[25, 25, "a"], [31, 32, "p"], [33, 33, "v"]], [[39, 39, "a"], [41, 41, "a"], [44, 44, "v"]], [[52, 52, "p"], [56, 56, "v"]]], "predicted_relations": [[], [[31, 32, 25, 25, "USED-FOR"]], [], []]}
{"doc_key": "1905.01995-52025994-d8e6-4325-a880-03b47320ac9f", "sentences": [["We", "evaluate", "our", "method", "on", "the", "SimpleQuestions", "dataset", "which", "contains", "N", "=", "21.687", "questions", "and", "the", "corresponding", "triples", "."], ["For", "each", "question", "we", "follow", "the", "procedure", "described", "in", "Section", "REF", "to", "find", "whether", "adding", "char-level", "encoding", "or", "adding", "self-attention", "mechanism", "will", "help", "the", "matching", "of", "question", "and", "target", "fact", ",", "and", "which", "scoring", "method", "can", "get", "the", "answer", "of", "the", "question", "more", "accurately", "."]], "ner": [[[6, 7, "a"]], [[34, 35, "a"], [38, 39, "a"], [52, 53, "a"]]], "relations": [[], []], "predicted_ner": [[[3, 3, "a"], [6, 7, "a"], [12, 12, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "1903.00138-72efe2c9-4a74-4ac9-a4c1-4f04b0cba40c", "sentences": [["For", "the", "transformer", "model", ",", "we", "use", "token", "embeddings", "and", "hidden", "size", "of", "dimension", "512", ",", "and", "the", "encoder", "and", "decoder", "have", "6", "layers", "and", "8", "attention", "heads", "."], ["For", "the", "inner", "layer", "in", "the", "positionwise", "feed-forward", "network", ",", "we", "use", "4096", "."], ["Similar", "to", "previous", "models", "we", "set", "the", "dropout", "to", "0.2", "."], ["A", "50,000", "vocabulary", "for", "the", "input", "and", "output", "tokens", "are", "collected", "from", "the", "training", "data", "."], ["In", "total", ",", "this", "model", "has", "97M", "parameters", "."]], "ner": [[[2, 3, "a"], [7, 8, "p"], [10, 11, "p"], [14, 14, "v"], [22, 22, "v"], [26, 27, "p"], [25, 25, "v"]], [[31, 37, "p"], [41, 41, "v"]], [[50, 50, "p"], [52, 52, "v"]], [[56, 62, "p"], [55, 55, "v"]], [[73, 74, "a"], [77, 77, "p"], [76, 76, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 3, "a"], [13, 13, "p"], [14, 14, "v"], [22, 22, "v"], [25, 25, "v"]], [[36, 37, "a"], [41, 41, "v"]], [[50, 50, "p"], [52, 52, "v"]], [[55, 55, "v"]], [[76, 76, "v"]]], "predicted_relations": [[[10, 11, 2, 3, "USED-FOR"]], [], [[52, 52, 50, 50, "USED-FOR"]], [], [[77, 77, 73, 74, "USED-FOR"], [76, 76, 77, 77, "USED-FOR"]]]}
{"doc_key": "1903.00138-56419bba-ab67-4e77-9bba-ef082fd40f61", "sentences": [["Models", "are", "optimized", "with", "Nesterov", "\u2019", "s", "Accelerated", "Gradient", "-LSB-", "21", "-RSB-", "."], ["We", "set", "the", "learning", "rate", "with", "0.002", ",", "the", "weight", "decay", "0.5", ",", "the", "patience", "0", ",", "the", "momentum", "0.99", "and", "minimum", "learning", "rate", "10-4", "."], ["During", "training", ",", "we", "evaluate", "the", "performance", "on", "the", "development", "set", "for", "every", "epoch", "."]], "ner": [[[4, 8, "a"]], [[16, 17, "p"], [35, 36, "p"], [19, 19, "v"], [22, 23, "p"], [24, 24, "v"], [27, 27, "p"], [19, 19, "v"], [24, 24, "v"], [28, 28, "v"], [32, 32, "v"], [31, 31, "p"], [32, 32, "v"], [34, 36, "p"], [37, 37, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[4, 8, "a"]], [[16, 17, "p"], [19, 19, "v"], [22, 23, "p"], [24, 24, "v"], [27, 27, "p"], [32, 32, "v"], [35, 36, "p"], [37, 37, "v"]], []], "predicted_relations": [[], [[24, 24, 22, 23, "USED-FOR"], [24, 24, 22, 23, "USED-FOR"], [28, 28, 27, 27, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [32, 32, 35, 36, "USED-FOR"], [32, 32, 31, 31, "USED-FOR"], [32, 32, 34, 36, "USED-FOR"], [32, 32, 35, 36, "USED-FOR"], [32, 32, 31, 31, "USED-FOR"], [32, 32, 34, 36, "USED-FOR"], [37, 37, 35, 36, "USED-FOR"], [37, 37, 31, 31, "USED-FOR"], [37, 37, 34, 36, "USED-FOR"]], []]}
{"doc_key": "1903.00138-5f3e43ac-f895-4d8d-948c-da4cb5206c40", "sentences": [["Almost", "the", "same", "architecture", "and", "hyper-parameters", "are", "used", "when", "pre-training", "using", "unlabeled", "data", ",", "except", "the", "\\", "-LRB-", "\\Lambda", "\\", "-RRB-", "parameter", "for", "edit-weighted", "loss", "."], ["We", "set", "\\", "-LRB-", "\\Lambda", "=3\\", "-RRB-", "when", "we", "train", "the", "denoising", "auto-encoder", ",", "and", "set", "\\", "-LRB-", "\\Lambda", "\\in", "-LSB-", "1", ",", "1.8", "-RSB-", "\\", "-RRB-", "when", "we", "train", "GEC", "models", "."]], "ner": [[[18, 18, "p"], [18, 18, "p"]], [[37, 38, "a"], [30, 30, "p"], [44, 44, "p"], [31, 31, "v"], [56, 57, "a"], [30, 30, "p"], [44, 44, "p"], [47, 47, "v"], [49, 49, "v"], [49, 49, "v"]]], "relations": [[], []], "predicted_ner": [[[18, 18, "p"], [23, 24, "a"]], [[31, 31, "v"], [44, 44, "p"], [49, 49, "v"], [56, 56, "a"]]], "predicted_relations": [[], [[44, 44, 37, 38, "USED-FOR"], [31, 31, 30, 30, "USED-FOR"], [31, 31, 30, 30, "USED-FOR"], [44, 44, 37, 38, "USED-FOR"], [47, 47, 44, 44, "USED-FOR"], [47, 47, 44, 44, "USED-FOR"]]]}
{"doc_key": "1903.00138-6caa4c36-b90f-4e52-81b8-fffb6911a8ec", "sentences": [["During", "decoding", ",", "we", "use", "a", "beam-size", "of", "12", "and", "normalize", "model", "scores", "by", "length", "."], ["We", "do", "not", "use", "reranking", "when", "evaluating", "the", "CoNLL-2014", "data", "sets", "."], ["But", "we", "rerank", "the", "top", "12", "hypothesizes", "using", "the", "language", "model", "trained", "on", "Common", "Crawl", "-LSB-", "16", "-RSB-", "for", "the", "JFLEG", "test", "sets", "."]], "ner": [[[8, 8, "v"]], [], [[33, 33, "v"], [37, 38, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "p"], [8, 8, "v"]], [[24, 24, "a"]], [[33, 33, "v"], [41, 42, "a"], [48, 48, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1902.03538-d747666b-08ef-499d-bb77-ee6c41a1d7f8", "sentences": [["For", "adversarial", "training", ",", "we", "apply", "the", "PGD", "-LSB-", "31", "-RSB-", "attack", "to", "find", "adversarial", "samples", "."], ["Unless", "otherwise", "specified", ",", "we", "set", "the", "perturbation", "magnitude", "\\", "-LRB-", "\\Delta", "\\", "-RRB-", "to", "be", "76", "for", "MNIST", "and", "4", "for", "the", "other", "three", "datasets", "."], ["-LRB-", "The", "color", "scale", "of", "each", "channel", "is", "between", "0", "and", "255", ".", "-RRB-"], ["Following", "the", "settings", "in", "-LSB-", "31", "-RSB-", ",", "we", "set", "PGD", "attack", "iteration", "numbers", "\\", "-LRB-", "n\\", "-RRB-", "to", "be", "16", "for", "MNIST", "and", "7", "for", "the", "other", "three", "datasets", "."], ["We", "follow", "-LSB-", "29", "-RSB-", "to", "set", "PGD", "attack", "step", "size", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "to", "be", "\\", "-LRB-", "\\min", "-LRB-", "\\Delta", "+4,1.25\\Delta", "-RRB-", "/n\\", "-RRB-", "."], ["We", "train", "ATMC", "for", "50", ",", "150", ",", "150", ",", "80", "epochs", "on", "MNIST", ",", "CIFAR10", ",", "CIFAR100", "and", "SVHN", "respectively", "."]], "ner": [[], [[24, 25, "p"], [33, 33, "v"], [35, 35, "c"], [37, 37, "v"], [40, 42, "c"], [35, 35, "c"], [40, 42, "c"], [35, 35, "c"]], [], [[68, 69, "a"], [80, 80, "c"], [85, 87, "c"], [68, 71, "p"], [78, 78, "v"], [80, 80, "c"], [82, 82, "v"], [85, 87, "c"], [80, 80, "c"]], [[96, 97, "a"], [112, 112, "v"], [96, 99, "p"]], [[130, 130, "c"], [130, 130, "c"], [119, 119, "a"], [128, 128, "p"], [121, 121, "v"], [130, 130, "c"], [123, 123, "v"], [125, 125, "v"], [132, 132, "c"], [123, 123, "v"], [125, 125, "v"], [134, 134, "c"], [127, 127, "v"], [136, 136, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"]], [[28, 28, "p"], [33, 33, "v"], [34, 35, "c"], [37, 37, "v"], [41, 41, "v"]], [[53, 53, "v"], [55, 55, "v"]], [[74, 74, "p"], [78, 78, "v"], [79, 80, "c"], [82, 82, "v"], [86, 86, "v"]], [[102, 102, "p"], [111, 111, "p"]], [[119, 119, "a"], [121, 121, "v"], [123, 123, "v"], [127, 127, "v"], [128, 128, "p"], [130, 130, "a"], [132, 132, "c"], [134, 134, "c"], [136, 136, "a"]]], "predicted_relations": [[], [[33, 33, 24, 25, "USED-FOR"], [37, 37, 24, 25, "USED-FOR"]], [], [[68, 71, 68, 69, "USED-FOR"]], [[96, 99, 96, 97, "USED-FOR"]], [[128, 128, 119, 119, "USED-FOR"], [121, 121, 128, 128, "USED-FOR"], [123, 123, 128, 128, "USED-FOR"], [125, 125, 128, 128, "USED-FOR"], [123, 123, 128, 128, "USED-FOR"], [125, 125, 128, 128, "USED-FOR"], [127, 127, 128, 128, "USED-FOR"]]]}
{"doc_key": "1909.02322-15822853-9de0-4a9b-9e34-881533c2045c", "sentences": [["For", "all", "experiments", ",", "our", "model", "used", "word", "embeddings", "with", "128", "dimensions", ",", "pretrained", "using", "GloVe", "-LSB-", "32", "-RSB-", "."], ["We", "set", "the", "dimensions", "of", "all", "hidden", "vectors", "to", "256", "and", "the", "batch", "size", "to", "8", "."], ["For", "decoding", "summaries", ",", "we", "use", "a", "length-normalized", "beam", "search", "with", "beam", "size", "of", "5", "."], ["We", "applied", "dropout", "-LSB-", "38", "-RSB-", "at", "a", "rate", "of", "0.5", "."], ["The", "model", "was", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "21", "-RSB-", "with", "default", "parameters", "and", "\\", "-LRB-", "l_2\\", "-RRB-", "constraint", "-LSB-", "16", "-RSB-", "of", "2", "."], ["We", "performed", "early", "stopping", "based", "on", "model", "performance", "on", "the", "development", "set", "."], ["Our", "model", "is", "implemented", "in", "PyTorchOur", "code", "can", "be", "downloaded", "from", "xxx.yyy.zzz", ".."]], "ner": [[[15, 15, "a"]], [], [], [[55, 55, "a"], [61, 61, "p"], [63, 63, "v"]], [[71, 72, "a"], [89, 89, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [10, 10, "v"], [11, 11, "p"], [15, 15, "a"]], [[29, 29, "v"], [32, 33, "p"], [35, 35, "v"]], [[45, 46, "a"], [48, 49, "p"], [51, 51, "v"]], [[55, 55, "a"], [63, 63, "v"]], [[66, 66, "a"], [71, 71, "a"], [89, 89, "v"]], [[93, 94, "a"]], [[105, 105, "a"], [109, 109, "a"]]], "predicted_relations": [[], [], [], [[61, 61, 55, 55, "USED-FOR"]], [], [], []]}
{"doc_key": "1902.08830-dd534acd-524b-4402-b5b4-a7f1bf46a885", "sentences": [["Across", "all", "simulations", "we", "trained", "BCF", "to", "induce", "\\", "-LRB-", "K=40\\", "-RRB-", "categories", "and", "\\", "-LRB-", "G=50\\", "-RRB-", "feature", "types", "which", "are", "shared", "across", "categories", "."], ["We", "ran", "the", "Gibbs", "sampler", "for", "1,000", "iterations", ",", "and", "report", "the", "final", "most", "likely", "representation", "."], ["We", "trained", "BayesCat", "on", "the", "same", "input", "stimuli", "as", "BCF", ",", "with", "the", "following", "parameters", ":", "the", "number", "of", "categories", "was", "set", "to", "\\", "-LRB-", "K=40\\", "-RRB-", ",", "and", "the", "hyperparameters", "to", "\\", "-LRB-", "\\alpha", "=0.7", ",", "\\beta", "=0.1\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\gamma", "=0.1\\", "-RRB-", "."], ["From", "the", "learnt", "representations", ",", "we", "induced", "\\", "-LRB-", "G=50\\", "-RRB-", "global", "feature", "types", "as", "described", "above", "."], ["Again", "results", "are", "reported", "as", "averages", "over", "10", "runs", "of", "1,000", "iterations", "of", "the", "Gibbs", "sampler", "."], ["The", "co-occurrence", "model", "induces", "\\", "-LRB-", "K=40\\", "-RRB-", "categories", ",", "and", ",", "subsequently", ",", "\\", "-LRB-", "G=5\\", "-RRB-", "feature", "types", "for", "each", "category", "."]], "ner": [[[5, 5, "a"], [10, 10, "p"], [10, 10, "v"], [16, 16, "p"], [16, 16, "v"], [10, 10, "p"], [10, 10, "v"], [10, 10, "p"], [10, 10, "v"], [16, 16, "p"]], [[29, 30, "a"]], [[52, 52, "a"], [68, 68, "p"], [68, 68, "v"], [45, 45, "a"], [68, 68, "p"], [68, 68, "v"], [77, 77, "p"], [78, 78, "v"], [80, 80, "p"], [81, 81, "v"], [88, 88, "v"], [87, 87, "p"], [81, 81, "v"], [88, 88, "v"], [68, 68, "p"], [68, 68, "v"]], [[100, 100, "p"], [100, 100, "v"], [100, 100, "p"]], [], [[132, 132, "p"], [132, 132, "v"], [142, 142, "p"], [132, 132, "p"], [132, 132, "v"], [127, 128, "a"], [132, 132, "p"], [132, 132, "v"], [142, 142, "p"], [142, 142, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [10, 10, "v"], [16, 16, "v"]], [[29, 30, "a"], [32, 32, "v"]], [[45, 45, "a"], [52, 52, "a"], [68, 68, "v"], [77, 77, "p"], [81, 81, "v"], [87, 87, "p"], [88, 88, "v"]], [[100, 100, "v"]], [[116, 116, "v"], [119, 119, "v"], [123, 124, "a"]], [[127, 128, "a"], [132, 132, "v"], [142, 142, "v"]]], "predicted_relations": [[[10, 10, 5, 5, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [16, 16, 10, 10, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [16, 16, 10, 10, "USED-FOR"], [16, 16, 10, 10, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [10, 10, 5, 5, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [10, 10, 5, 5, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 16, 16, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"]], [], [[68, 68, 52, 52, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 45, 45, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 77, 77, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 52, 52, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 45, 45, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 77, 77, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [77, 77, 45, 45, "USED-FOR"], [78, 78, 68, 68, "USED-FOR"], [78, 78, 68, 68, "USED-FOR"], [78, 78, 77, 77, "USED-FOR"], [78, 78, 80, 80, "USED-FOR"], [78, 78, 68, 68, "USED-FOR"], [80, 80, 52, 52, "USED-FOR"], [80, 80, 45, 45, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [81, 81, 77, 77, "USED-FOR"], [81, 81, 80, 80, "USED-FOR"], [81, 81, 87, 87, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [88, 88, 80, 80, "USED-FOR"], [88, 88, 87, 87, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [81, 81, 77, 77, "USED-FOR"], [81, 81, 80, 80, "USED-FOR"], [81, 81, 87, 87, "USED-FOR"], [81, 81, 68, 68, "USED-FOR"], [88, 88, 80, 80, "USED-FOR"], [88, 88, 87, 87, "USED-FOR"], [68, 68, 52, 52, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 45, 45, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 77, 77, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"]], [[100, 100, 100, 100, "USED-FOR"], [100, 100, 100, 100, "USED-FOR"], [100, 100, 100, 100, "USED-FOR"], [100, 100, 100, 100, "USED-FOR"]], [], [[132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 127, 128, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [142, 142, 127, 128, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 127, 128, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 127, 128, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [142, 142, 127, 128, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"], [142, 142, 132, 132, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"], [142, 142, 132, 132, "USED-FOR"], [142, 142, 132, 132, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"]]]}
{"doc_key": "1912.09551-c889afb9-19e9-4f31-8313-bde92e2d98ec", "sentences": [["We", "have", "extracted", "the", "CONV-5", "image", "feature", "of", "the", "pre-trained", "VGG-19", "CNN", "model", "for", "the", "LSTM", "+", "Q+", "I+", "Attention", "baseline", "model", "."], ["Since", "submission", ",", "we", "have", "updated", "our", "model", "and", "used", "the", "CONV-5", "image", "feature", "of", "the", "pre-trained", "Resnet-152", "CNN", "model", "for", "MCB", "to", "get", "state", "of", "the", "art", "result", "."], ["We", "trained", "the", "differential", "attention", "model", "using", "joint", "loss", "in", "an", "end-to-end", "manner", "."], ["We", "have", "used", "RMSPROP", "optimizer", "to", "update", "the", "model", "parameter", "and", "configured", "hyper-parameter", "values", "to", "be", "as", "follows", ":", "learning", "rate", "=0.0004", ",", "batch", "size", "=", "200", ",", "alpha", "=", "0.99", "and", "epsilon=1e-8", "to", "train", "the", "classification", "network", "."], ["In", "order", "to", "train", "a", "triplet", "model", ",", "we", "have", "used", "RMSPROP", "to", "optimize", "the", "triplet", "model", "model", "parameter", "and", "configure", "hyper-parameter", "values", "to", "be", ":", "learning", "rate", "=0.001", ",", "batch", "size", "=", "200", ",", "alpha", "=", "0.9", "and", "epsilon=1e-8", "."], ["We", "have", "used", "learning", "rate", "decay", "to", "decrease", "the", "learning", "rate", "on", "every", "epoch", "by", "a", "factor", "given", "by", ":", "\\", "-LRB-", "Decay\\_factor=exp\\left", "-LRB-", "\\frac", "-LCB-", "log", "-LRB-", "0.1", "-RRB-", "-RCB-", "-LCB-", "a", "*", "b", "-RCB-", "\\right", "-RRB-", "\\", "-RRB-"]], "ner": [[[10, 12, "a"]], [[40, 42, "a"]], [], [[70, 70, "a"], [86, 87, "p"], [88, 88, "v"], [90, 91, "p"], [93, 93, "v"], [95, 95, "p"], [97, 97, "v"], [99, 99, "p"], [99, 99, "v"]], [[117, 117, "a"], [132, 133, "p"], [134, 134, "v"], [136, 137, "p"], [139, 139, "v"], [141, 141, "p"], [143, 143, "v"], [145, 145, "p"], [145, 145, "v"]], [[150, 151, "p"], [156, 157, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [10, 12, "a"]], [[34, 34, "a"], [40, 42, "a"], [44, 44, "a"]], [[56, 58, "a"], [60, 61, "a"]], [[70, 70, "a"], [86, 87, "p"], [90, 91, "p"], [93, 93, "v"], [97, 97, "v"], [103, 104, "a"]], [[111, 112, "a"], [117, 117, "a"], [132, 133, "p"], [136, 137, "p"], [139, 139, "v"], [141, 141, "p"], [143, 143, "v"]], [[150, 152, "a"], [156, 157, "p"], [175, 175, "v"]]], "predicted_relations": [[], [], [], [[86, 87, 70, 70, "USED-FOR"], [88, 88, 86, 87, "USED-FOR"], [88, 88, 95, 95, "USED-FOR"], [90, 91, 70, 70, "USED-FOR"], [93, 93, 90, 91, "USED-FOR"], [93, 93, 99, 99, "USED-FOR"], [95, 95, 70, 70, "USED-FOR"], [99, 99, 70, 70, "USED-FOR"], [99, 99, 86, 87, "USED-FOR"], [99, 99, 90, 91, "USED-FOR"], [99, 99, 95, 95, "USED-FOR"], [99, 99, 99, 99, "USED-FOR"]], [[132, 133, 117, 117, "USED-FOR"], [134, 134, 132, 133, "USED-FOR"], [134, 134, 141, 141, "USED-FOR"], [136, 137, 117, 117, "USED-FOR"], [139, 139, 136, 137, "USED-FOR"], [139, 139, 145, 145, "USED-FOR"], [141, 141, 117, 117, "USED-FOR"], [143, 143, 145, 145, "USED-FOR"], [145, 145, 117, 117, "USED-FOR"], [145, 145, 132, 133, "USED-FOR"], [145, 145, 136, 137, "USED-FOR"], [145, 145, 141, 141, "USED-FOR"], [145, 145, 145, 145, "USED-FOR"]], []]}
{"doc_key": "1912.09551-126a22d8-7027-4ae9-8bbd-9be3ecf489c6", "sentences": [["where", "value", "of", "a=1500", "and", "b=1250", "is", "set", "empirically", "."], ["The", "selection", "of", "training", "controlling", "factor", "-LRB-", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "-RRB-", "has", "a", "major", "role", "during", "training", "."], ["If", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "=1", "means", "updating", "the", "triplet", "and", "classification", "network", "parameter", "at", "the", "same", "rate", "."], ["If", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "\\", "-LRB-", "\\gg", "\\", "-RRB-", "1", "means", "updating", "the", "triplet", "net", "more", "frequently", "as", "compare", "to", "the", "classification", "net", "."], ["Since", "triplet", "loss", "decreases", "much", "lower", "then", "classification", "loss", ",", "we", "fixed", "the", "value", "of", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "\\", "-LRB-", "\\gg", "\\", "-RRB-", "1", "that", "is", "a", "fixed", "value", "of", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "=10", "."]], "ner": [[], [[13, 15, "a"], [19, 19, "p"]], [[33, 33, "p"], [36, 36, "v"]], [[53, 53, "p"], [61, 61, "v"]], [[93, 93, "p"], [110, 110, "p"], [101, 101, "v"], [113, 113, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "v"], [5, 5, "v"]], [], [], [[61, 61, "v"], [65, 66, "a"], [73, 74, "a"]], [[77, 78, "a"], [83, 84, "a"], [101, 101, "v"]]], "predicted_relations": [[], [], [[36, 36, 33, 33, "USED-FOR"]], [], [[113, 113, 110, 110, "USED-FOR"]]]}
{"doc_key": "1906.08031-710021b4-d80f-4cf9-9413-585c7d082adb", "sentences": [["Theoretically", "Derived", "Learning", "Rates", "."], ["The", "determination", "of", "the", "learning", "rate", "has", "a", "significant", "impact", "on", "the", "convergence", "of", "optimization", "algorithms", "."], ["Various", "scheduling", "schemes", "come", "up", ",", "e.g", "."], ["-LSB-", "25", "-RSB-", ",", "-LSB-", "37", "-RSB-", ",", "as", "the", "later", "additionally", "suggests", "a", "way", "for", "obtaining", "an", "empirical", "upper", "bound", "on", "the", "learning", "rate", "."], ["In", "section", "REF", ",", "multiple", "learning", "rates", "\\", "-LRB-", "\\eta", "^", "*", "_c\\", "-RRB-", "are", "suggested", "for", "minimizing", "the", "regret", "bound", "-LRB-", "REF", "-RRB-", ",", "as", "\\", "-LRB-", "c\\in", "\\lbrace", "N", ",", "R\\rbrace", "\\", "-RRB-", "represents", "normal", "and", "reduction", "cells", "respectively", "."], ["For", "example", ",", "for", "CIFAR10", "with", "50", "%", ":50", "%", "train-validation", "split", ",", "50", "search", "epochs", ",", "gradient", "clipping", "of", "1", ",", "6", "normal", "cells", "and", "2", "reduction", "cells", "both", "of", "8", "experts", "for", "each", "forecaster", ",", "-LRB-", "REF", "-RRB-", "yields", "\\", "-LRB-", "\\eta", "^", "*", "_N=\\", "-RRB-", "7.5e-4", "and", "\\", "-LRB-", "\\eta", "^", "*", "_R=\\", "-RRB-", "1.3e-3", "."]], "ner": [[[0, 3, "a"]], [[9, 10, "p"]], [], [[53, 54, "p"]], [[94, 95, "c"]], [[146, 146, "v"], [121, 122, "c"], [155, 155, "v"], [125, 126, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[9, 10, "p"]], [], [[53, 54, "p"]], [], [[102, 102, "a"], [104, 105, "v"], [111, 111, "v"], [112, 113, "p"], [118, 118, "v"], [120, 120, "v"], [124, 124, "v"], [129, 129, "v"], [146, 146, "v"], [155, 155, "v"]]], "predicted_relations": [[], [], [], [], [], [[121, 122, 146, 146, "USED-FOR"], [121, 122, 155, 155, "USED-FOR"], [125, 126, 146, 146, "USED-FOR"]]]}
{"doc_key": "1907.05794-bdbd8f36-3c9d-46bf-bbac-6396911e23e0", "sentences": [["We", "train", "ACTNET", "on", "a", "subset", "of", "Google", "Landmarks", "dataset", "-LRB-", "GLD", "-RRB-", "-LSB-", "37", "-RSB-", ",", "which", "contains", "1", "million", "images", "depicting", "15K", "unique", "landmarks", "-LRB-", "classes", "-RRB-", "."], ["In", "GLD", "the", "number", "of", "images", "per", "class", "is", "highly", "unbalanced", ",", "some", "classes", "contain", "thousands", "of", "images", ",", "while", "for", "around", "8K", "classes", "only", "20", "or", "fewer", "images", "are", "present", "."], ["Furthermore", ",", "the", "GLD", "contains", "a", "non-negligible", "fraction", "of", "images", "unrelated", "to", "the", "landmarks", "."], ["For", "this", "reason", ",", "we", "preprocess", "the", "GLD", "using", "the", "RVDW", "global", "descriptor", "and", "SIFT", "based", "RANSAC", "-LSB-", "31", "-RSB-", ",", "to", "obtain", "a", "clean", "dataset", "containing", "200K", "images", "belonging", "to", "2K", "classes", "."], ["Finally", ",", "we", "remove", "all", "images", "that", "overlap", "with", "the", "test", "datasets", "."], ["We", "refer", "this", "clean", "dataset", "as", "Google", "Landmarks", "Retrieval", "dataset", "-LRB-", "GLRD", "-RRB-", "."]], "ner": [[[2, 2, "a"]], [], [], [[87, 89, "a"], [91, 93, "a"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 12, "a"], [19, 20, "v"], [23, 23, "v"]], [[52, 52, "v"], [55, 55, "v"]], [], [[87, 87, "a"], [93, 93, "a"], [102, 102, "a"], [104, 104, "v"], [108, 108, "v"]], [], [[130, 136, "a"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1912.06598-29643008-e448-4477-b0ea-1599371f7023", "sentences": [["For", "cache-based", "models", ",", "we", "fix", "the", "size", "of", "the", "two", "caches", "to", "100", "words", "each", "."], ["The", "scoring", "feed-forward", "network", "has", "hidden", "dimensions", "1000", "and", "500", "and", "the", "gate", "feed-forward", "network", "has", "hidden", "dimensions", "500", "and", "200", ",", "following", "the", "configurations", "reported", "in", "-LSB-", "8", "-RSB-", "."], ["The", "cache", "word", "embeddings", "are", "shared", "with", "the", "Transformer", "decoder", "."], ["During", "training", "we", "provide", "the", "real", "topic", "of", "the", "target", "sentence", "for", "half", "of", "the", "training", "data", ",", "and", "for", "the", "other", "half", "we", "provide", "the", "topic", "projected", "from", "the", "source", ",", "in", "order", "for", "the", "model", "to", "learn", "from", "but", "not", "be", "over-reliant", "on", "gold", "-LRB-", "source", "-RRB-", "topics", "."], ["During", "training", "we", "also", "use", "the", "real", "target", "side", "sentences", "to", "load", "the", "dynamic", "cache", "."], ["At", "inference", "time", ",", "the", "topic", "is", "a", "projection", "from", "source", "to", "target", "and", "the", "dynamic", "cache", "is", "loaded", "with", "words", "from", "previously", "translated", "sentences", "."]], "ner": [[[1, 2, "a"], [7, 11, "p"], [13, 14, "v"]], [[22, 23, "p"], [33, 34, "p"], [24, 26, "v"], [18, 20, "c"], [35, 37, "v"], [29, 31, "c"]], [[56, 57, "a"]], [[64, 69, "a"], [85, 89, "a"], [65, 65, "a"], [85, 85, "a"]], [[116, 119, "a"]], [[131, 131, "a"], [146, 150, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[10, 10, "v"], [13, 13, "v"]], [[19, 20, "a"], [24, 24, "v"], [26, 26, "v"], [29, 31, "a"], [35, 35, "v"], [37, 37, "v"]], [], [[71, 71, "v"]], [], []], "predicted_relations": [[], [[24, 26, 33, 34, "USED-FOR"], [18, 20, 24, 26, "USED-FOR"], [18, 20, 35, 37, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1903.05285-22cd1951-fe25-493a-b80b-a1fcf4e812c7", "sentences": [["We", "use", "ShiftResNet-20", "and", "ShiftResNet-56", "with", "expansion", "rate", "6", "as", "two", "representatives", "for", "ablation", "study", "."], ["We", "train", "these", "networks", "by", "two", "GPUs", "with", "mini-batch", "128", "and", "base", "learning", "rate", "0.1", "."], ["As", "the", "same", "with", "-LSB-", "36", "-RSB-", ",", "the", "learning", "rate", "decays", "by", "a", "factor", "of", "10", "after", "32k", "and", "48k", "iterations", ",", "and", "the", "training", "stops", "after", "64k", "iterations", "."], ["Specifically", ",", "we", "stop", "the", "training", "of", "SSL", "after", "48k", "iterations", "in", "order", "to", "fix", "the", "learned", "shift", "pattern", "."], ["For", "data", "augmentation", ",", "only", "horizontal", "flipping", "and", "random", "cropping", "are", "adopted", "."], ["We", "use", "L2", "regularization", "to", "shift", "values", "in", "the", "following", "experiments", "since", "we", "find", "that", "the", "result", "of", "L2", "regularization", "is", "slightly", "better", "than", "L1", "."]], "ner": [[[2, 2, "a"], [4, 4, "a"]], [[24, 24, "a"], [25, 25, "v"], [27, 29, "a"], [28, 29, "p"], [30, 30, "v"]], [[41, 42, "p"], [48, 48, "v"], [50, 50, "v"], [52, 52, "v"], [60, 60, "v"]], [[72, 72, "v"]], [[84, 85, "a"], [88, 89, "v"], [91, 92, "v"]], [[98, 99, "a"], [114, 115, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [6, 7, "p"], [8, 8, "v"], [10, 10, "v"]], [[21, 21, "v"], [24, 24, "p"], [25, 25, "v"], [30, 30, "v"]], [[41, 42, "p"], [48, 48, "v"], [50, 50, "v"], [52, 52, "v"], [60, 60, "v"]], [[70, 70, "a"], [72, 72, "v"]], [], [[98, 99, "a"], [114, 115, "a"], [120, 120, "a"]]], "predicted_relations": [[], [[28, 29, 24, 24, "USED-FOR"], [28, 29, 27, 29, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1903.05285-8b89581b-2248-41f8-b2c2-220de78f38c3", "sentences": [["In", "the", "experiments", "on", "ImageNet", ",", "we", "use", "SGD", "to", "train", "the", "networks", "with", "mini-batch", "1024", ",", "weight", "decay", "0.00004", "and", "momentum", "0.9", "."], ["Training", "is", "started", "by", "a", "learning", "rate", "0.6", "with", "linear", "decaying", "policy", "and", "is", "stopped", "after", "480", "epochs", ",", "while", "the", "training", "of", "SSL", "is", "stopped", "after", "240", "epochs", "."], ["The", "entire", "training", "iteration", "is", "comparable", "with", "-LSB-", "31", "-RSB-", ",", "-LSB-", "21", "-RSB-", ",", "-LSB-", "29", "-RSB-", ",", "-LSB-", "25", "-RSB-", "."], ["For", "data", "augmentation", ",", "we", "scale", "the", "short-side", "of", "images", "to", "256", "and", "adopt", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "random", "crop", "as", "well", "as", "horizontal", "flip", "to", "augment", "the", "training", "dataset", "."], ["Also", ",", "to", "further", "rich", "the", "training", "images", ",", "more", "image", "of", "distortions", "are", "provided", "as", "used", "in", "Inception", "training", "-LSB-", "32", "-RSB-", ",", "-LSB-", "9", "-RSB-", "."], ["But", "it", "will", "be", "withdrawn", "in", "last", "several", "epochs", "."], ["At", "the", "validation", "phase", ",", "we", "only", "center", "crop", "the", "feeding", "resized", "images", "to", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "and", "present", "the", "results", "with", "single-view", "approach", "."]], "ner": [[[8, 8, "a"], [14, 14, "p"], [15, 15, "v"], [17, 18, "p"], [19, 19, "v"], [21, 21, "p"], [22, 22, "v"]], [[29, 30, "p"], [31, 31, "v"]], [], [[78, 79, "a"], [84, 86, "p"], [88, 88, "v"], [96, 97, "p"], [101, 102, "p"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "a"], [14, 14, "p"], [15, 15, "v"], [17, 18, "p"], [19, 19, "v"], [21, 21, "p"], [22, 22, "v"]], [[29, 30, "p"], [31, 31, "v"], [40, 40, "v"], [41, 41, "p"], [47, 47, "a"], [51, 51, "v"], [52, 52, "p"]], [], [[88, 88, "v"], [94, 94, "v"]], [], [[144, 144, "v"]], [[164, 164, "v"]]], "predicted_relations": [[[14, 14, 8, 8, "USED-FOR"], [15, 15, 21, 21, "USED-FOR"], [17, 18, 8, 8, "USED-FOR"], [19, 19, 17, 18, "USED-FOR"], [19, 19, 21, 21, "USED-FOR"], [21, 21, 8, 8, "USED-FOR"]], [], [], [[84, 86, 78, 79, "USED-FOR"], [88, 88, 84, 86, "USED-FOR"], [96, 97, 78, 79, "USED-FOR"]], [], [], []]}
{"doc_key": "1906.01861-e1fa5faa-ff71-463c-ab2b-479cf924873c", "sentences": [["GraphRNN", "and", "GraphRNN-S", "were", "trained", "using", "a", "single", "GPU", "for", "96000", "iterations", "with", "batch", "size", "32", "."], ["For", "the", "molecular", "dataset", ",", "considering", "its", "relatively", "large", "dataset", "size", ",", "we", "increased", "the", "number", "of", "iterations", "to", "1536000", "."]], "ner": [[[0, 0, "a"], [2, 2, "a"], [11, 11, "p"], [10, 10, "v"], [13, 14, "p"], [15, 15, "v"], [2, 2, "a"], [11, 11, "p"], [10, 10, "v"]], [[34, 34, "p"], [36, 36, "v"], [19, 20, "c"], [34, 34, "p"]]], "relations": [[], []], "predicted_ner": [[[0, 0, "a"], [2, 2, "a"], [10, 10, "v"], [13, 14, "p"], [15, 15, "v"]], [[36, 36, "v"]]], "predicted_relations": [[[11, 11, 2, 2, "USED-FOR"], [11, 11, 2, 2, "USED-FOR"], [10, 10, 11, 11, "USED-FOR"], [10, 10, 11, 11, "USED-FOR"], [11, 11, 2, 2, "USED-FOR"], [11, 11, 2, 2, "USED-FOR"], [10, 10, 11, 11, "USED-FOR"], [10, 10, 11, 11, "USED-FOR"]], [[36, 36, 34, 34, "USED-FOR"], [36, 36, 34, 34, "USED-FOR"], [19, 20, 36, 36, "USED-FOR"]]]}
{"doc_key": "1906.01861-7d7a8be8-fa1a-4390-ae78-7c8bcf779cfe", "sentences": [["For", "the", "convenience", "of", "implementation", ",", "we", "started", "the", "generation", "process", "from", "seed", "subgraphs", "with", "the", "number", "of", "nodes", "\\", "-LRB-", "N_", "-LCB-", "\\min", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "synthetic", "graph", "datasets", ",", "we", "trained", "our", "models", "using", "a", "single", "GPU", "for", "100", "epochs", "with", "batch", "size", "32", ",", "and", "we", "used", "\\", "-LRB-", "r=2\\", "-RRB-", "and", "\\", "-LRB-", "N_", "-LCB-", "\\min", "-RCB-", "=", "10\\", "-RRB-", "."], ["For", "the", "molecular", "dataset", ",", "we", "trained", "our", "models", "using", "2", "GPUs", "for", "20", "epochs", "with", "batch", "size", "256", ",", "and", "we", "used", "\\", "-LRB-", "r=7\\", "-RRB-", "and", "\\", "-LRB-", "N_", "-LCB-", "\\min", "-RCB-", "=", "5\\", "-RRB-", "."], ["For", "the", "ego", "dataset", ",", "we", "trained", "our", "models", "using", "2", "GPUs", "for", "25", "epochs", ",", "and", "we", "used", "\\", "-LRB-", "r=2\\", "-RRB-", "and", "\\", "-LRB-", "N_", "-LCB-", "\\min", "-RCB-", "=", "12\\", "-RRB-", "."], ["We", "used", "batch", "size", "4", "for", "GRAM", "and", "batch", "size", "8", "for", "GRAM-A", ",", "GRAM-B", ",", "and", "GRAM-AB", "."], ["For", "the", "protein", "dataset", ",", "we", "trained", "our", "models", "using", "2", "GPUs", "for", "25", "epochs", ",", "and", "we", "used", "\\", "-LRB-", "r=2\\", "-RRB-", "and", "\\", "-LRB-", "N_", "-LCB-", "\\min", "-RCB-", "=", "12\\", "-RRB-", "."], ["We", "used", "batch", "size", "4", "for", "GRAM", "and", "batch", "size", "32", "for", "GRAM-A", ",", "GRAM-B", ",", "and", "GRAM-AB", "."], ["Due", "to", "the", "code", "dependencies", ",", "Tesla", "P100", "was", "used", "for", "DeepGMG", ",", "GraphRNN", ",", "and", "GraphRNN-S", ",", "and", "Tesla", "V100", "was", "used", "for", "GRAM", "and", "its", "variants", "."], ["Empirically", ",", "the", "choice", "between", "the", "two", "gave", "no", "significant", "difference", "in", "computation", "time", "for", "our", "cases", "."]], "ner": [[], [[30, 32, "a"], [65, 65, "v"], [46, 47, "p"], [46, 47, "p"], [46, 47, "p"], [46, 47, "p"]], [[70, 71, "a"], [103, 103, "v"], [84, 85, "p"], [84, 85, "p"], [84, 85, "p"], [84, 85, "p"]], [[108, 109, "a"], [137, 137, "v"], [137, 137, "v"]], [[146, 146, "a"], [152, 152, "a"], [154, 154, "a"], [157, 157, "a"], [142, 143, "p"], [148, 149, "p"], [144, 144, "v"], [152, 152, "a"], [142, 143, "p"], [148, 149, "p"], [150, 150, "v"], [154, 154, "a"], [142, 143, "p"], [148, 149, "p"], [150, 150, "v"], [157, 157, "a"], [142, 143, "p"], [148, 149, "p"], [150, 150, "v"]], [[190, 190, "v"], [161, 162, "a"], [190, 190, "v"]], [[199, 199, "a"], [205, 205, "a"], [207, 207, "a"], [210, 210, "a"], [195, 196, "p"], [201, 202, "p"], [197, 197, "v"], [205, 205, "a"], [195, 196, "p"], [201, 202, "p"], [207, 207, "a"], [195, 196, "p"], [201, 202, "p"], [210, 210, "a"], [195, 196, "p"], [201, 202, "p"]], [[236, 236, "a"], [223, 223, "a"], [225, 225, "a"], [228, 228, "a"], [228, 228, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[40, 40, "v"], [43, 43, "v"], [44, 44, "p"], [46, 47, "p"], [48, 48, "v"], [55, 55, "v"], [65, 65, "v"]], [[70, 71, "a"], [78, 78, "v"], [81, 81, "v"], [82, 82, "p"], [84, 85, "p"], [86, 86, "v"], [93, 93, "v"], [103, 103, "v"]], [[108, 109, "a"], [116, 116, "v"], [119, 119, "v"], [120, 120, "p"], [127, 127, "v"], [137, 137, "v"]], [[142, 143, "p"], [144, 144, "v"], [148, 149, "p"], [150, 150, "v"]], [[169, 169, "v"], [172, 172, "v"], [173, 173, "p"], [180, 180, "v"], [190, 190, "v"]], [[195, 196, "p"], [197, 197, "v"], [198, 199, "c"], [201, 202, "p"], [203, 203, "v"]], [[218, 219, "a"], [223, 223, "a"], [225, 225, "a"], [228, 228, "a"], [231, 232, "a"]], [[247, 247, "v"]]], "predicted_relations": [[], [[46, 47, 30, 32, "USED-FOR"], [46, 47, 30, 32, "USED-FOR"], [46, 47, 30, 32, "USED-FOR"], [46, 47, 30, 32, "USED-FOR"]], [[84, 85, 70, 71, "USED-FOR"], [84, 85, 70, 71, "USED-FOR"], [84, 85, 70, 71, "USED-FOR"], [84, 85, 70, 71, "USED-FOR"]], [], [[148, 149, 146, 146, "USED-FOR"], [144, 144, 142, 143, "USED-FOR"], [144, 144, 142, 143, "USED-FOR"], [144, 144, 142, 143, "USED-FOR"], [144, 144, 142, 143, "USED-FOR"], [148, 149, 146, 146, "USED-FOR"], [148, 149, 146, 146, "USED-FOR"], [148, 149, 146, 146, "USED-FOR"]], [], [[201, 202, 199, 199, "USED-FOR"], [197, 197, 195, 196, "USED-FOR"], [197, 197, 195, 196, "USED-FOR"], [197, 197, 195, 196, "USED-FOR"], [197, 197, 195, 196, "USED-FOR"], [201, 202, 199, 199, "USED-FOR"], [201, 202, 199, 199, "USED-FOR"], [201, 202, 199, 199, "USED-FOR"]], [], []]}
{"doc_key": "1906.01861-324edaec-84b4-4001-abae-75da5f2b2501", "sentences": [["In", "evaluation", ",", "we", "reported", "an", "average", "of", "3", "runs", "for", "each", "score", "."], ["To", "calculate", "GK-MMD", "score", "for", "the", "molecular", "dataset", ",", "we", "used", "100", "samples", "from", "the", "generated", "graphs", "and", "100", "samples", "from", "the", "test", "set", "for", "fast", "evaluation", "."], ["We", "reported", "an", "average", "of", "10", "runs", "."]], "ner": [[], [[16, 17, "a"], [26, 26, "p"], [33, 33, "p"], [25, 25, "v"], [32, 32, "v"], [29, 30, "c"], [25, 25, "v"], [32, 32, "v"], [36, 37, "c"]], []], "relations": [[], [], []], "predicted_ner": [[[8, 8, "v"]], [[25, 25, "v"], [32, 32, "v"]], [[47, 47, "v"]]], "predicted_relations": [[], [[26, 26, 16, 17, "USED-FOR"], [33, 33, 16, 17, "USED-FOR"], [25, 25, 26, 26, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"], [29, 30, 25, 25, "USED-FOR"], [29, 30, 32, 32, "USED-FOR"], [29, 30, 25, 25, "USED-FOR"], [29, 30, 32, 32, "USED-FOR"], [25, 25, 26, 26, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"]], []]}
{"doc_key": "1907.06713-e69c022b-f470-4b52-8108-70ec7ddf668d", "sentences": [["Our", "implementation", "is", "based", "on", "the", "Tensorpack", "framework", "-LSB-", "33", "-RSB-", "."], ["We", "used", "the", "re-implemented", "version", "of", "Mask", "R-CNN", "in", "Tensorpack", "as", "the", "baseline", ",", "which", "shows", "better", "mask", "\\", "-LRB-", "AP\\", "-RRB-", "than", "the", "original", "paper", "."], ["The", "pretrained", "model", "is", "publicly", "available", "from", "the", "Tensorpack", "model", "zoo", "."], ["Image", "centric", "training", "-LSB-", "13", "-RSB-", "is", "applied", "so", "that", "the", "images", "are", "resized", "to", "800", "pixels", "on", "the", "shorter", "edge", ",", "1333", "on", "the", "longer", "edge", ",", "without", "changing", "the", "aspect", "ratio", "."], ["Each", "image", "has", "512", "sampled", "RoIs", ",", "and", "their", "positive", "to", "negatives", "ratio", "is", "1:3", "."], ["We", "use", "8", "Titan", "RTX", "GPUs", "in", "training", "and", "single", "image", "per", "GPU", "for", "360000", "iterations", "."], ["The", "learning", "rate", "is", "0.02", ",", "weight", "decay", "is", "0.0001", ",", "and", "momentum", "is", "0.9", "."], ["Other", "configurations", "are", "the", "same", "as", "Mask", "R-CNN", "."], ["The", "RPN", "is", "trained", "separately", "and", "do", "not", "share", "the", "weights", "with", "Mask", "R-CNN", "."], ["In", "addition", ",", "all", "ablation", "studies", "are", "tested", "based", "on", "the", "ResNet-50-FPN", "backbone", "for", "faster", "training/testing", "speed", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 7, "a"]], [[18, 19, "a"]], [], [[51, 53, "a"]], [[94, 99, "v"], [89, 90, "p"]], [[106, 106, "p"], [116, 116, "p"]], [[132, 132, "v"], [119, 120, "p"], [124, 125, "p"], [130, 130, "p"]], [[140, 141, "a"]], [[155, 156, "a"]], [[169, 169, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 7, "a"]], [[19, 19, "a"]], [], [[66, 66, "v"], [73, 73, "v"]], [[88, 88, "v"], [99, 99, "v"]], [[103, 103, "v"], [115, 115, "v"]], [[119, 120, "p"], [122, 122, "v"], [124, 125, "p"], [127, 127, "v"], [132, 132, "v"]], [[140, 141, "a"]], [[144, 144, "a"], [155, 156, "a"]], [[169, 169, "a"]], []], "predicted_relations": [[], [], [], [], [[94, 99, 89, 90, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "1909.08981-0b4ec0fb-8e93-46fa-91a3-cb01aa3ab5fc", "sentences": [["Our", "baseline", "model", "contains", "38,780", "embeddings", "in", "a", "32D", "space", ",", "generated", "by", "discretizing", "13,233", "unique", "variable", "labels", ",", "with", "20", "bins", "per", "continuous", "variable", "."], ["We", "utilize", "a", "GRU", "-LSB-", "16", "-RSB-", "of", "depth", "1", "with", "a", "sigmoid", "output", "activation", ",", "layer", "normalization", "applied", "to", "all", "linear", "projections", "-LSB-", "17", "-RSB-", ",", "dropout", "regularization", "-LSB-", "18", "-RSB-", "-LRB-", "\\", "-LRB-", "p=0.5\\", "-RRB-", "-RRB-", "on", "both", "the", "aggregated", "embedding", "and", "the", "hidden", "states", ",", "as", "well", "as", "a", "weight", "decay", "coefficient", "of", "0.001", "-LSB-", "19", "-RSB-", "."], ["We", "assess", "the", "effect", "of", "using", "summation", ",", "simple", "averaging", "and", "a", "masked", "softmax", "-LRB-", "over", "a", "separate", "token", "weight", "vector", "-RRB-", "as", "aggregation", "functions", "on", "model", "performance", "."], ["We", "note", "that", "the", "risk", "of", "unnormalized", "aggregation", ",", "such", "as", "summation", ",", "is", "that", "the", "model", "learns", "to", "count", "the", "number", "of", "readings", "taken", "in", "an", "hour", "and", "correlate", "this", "with", "patient", "outcome", "."]], "ner": [[], [[29, 29, "a"], [42, 43, "a"], [53, 54, "a"], [61, 61, "p"], [61, 61, "v"], [78, 80, "a"], [80, 80, "p"], [82, 82, "v"]], [[93, 93, "a"], [95, 96, "a"], [99, 100, "a"]], [[127, 127, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"], [4, 4, "v"], [8, 8, "v"], [14, 14, "v"], [20, 20, "v"]], [[29, 29, "a"], [35, 35, "v"], [38, 40, "a"], [53, 54, "a"], [82, 82, "v"]], [[100, 100, "a"]], []], "predicted_relations": [[], [[61, 61, 42, 43, "USED-FOR"], [61, 61, 53, 54, "USED-FOR"], [61, 61, 61, 61, "USED-FOR"], [61, 61, 61, 61, "USED-FOR"]], [], []]}
{"doc_key": "1903.07402-fd6960fb-47b7-4beb-a2a3-4ad4f865d7d7", "sentences": [["The", "data", "set", "generated", "as", "in", "section", "2", "are", "of", "small", "batches", "-LRB-", "we", "call", "them", "batch", "units", "-RRB-", "which", "are", "able", "to", "fit", "in", "GPU", "memory", ",", "but", "larger", "batch", "size", "provides", "better", "performance", "for", "Transformer", ",", "\u201c", "tokens_optm", "\u201d", "is", "applied", "to", "support", "large", "batch", "sizes", ",", "the", "training", "script", "will", "forward", "and", "backward", "many", "batch", "units", ",", "and", "update", "parameters", "with", "an", "optimizer", "step", "until", "it", "has", "collected", "gradient", "with", "more", "than", "\u201c", "tokens_optm", "\u201d", "number", "of", "tokens", "on", "the", "target", "side", "."]], "ner": [[[36, 36, "a"], [39, 39, "p"], [76, 76, "p"], [78, 84, "v"]]], "relations": [[]], "predicted_ner": [[[39, 39, "a"], [76, 76, "a"]]], "predicted_relations": [[[39, 39, 36, 36, "USED-FOR"]]]}
{"doc_key": "1906.05721-199a3404-8e42-4c4d-b22c-103644f9dabd", "sentences": [["MobileNet", "and", "MNasNet", "models", "are", "trained", "in", "TensorFlow", "using", "asynchronous", "training", "on", "GPU", "using", "the", "standard", "RMSPropOptimizer", "with", "both", "decay", "and", "momentum", "set", "to", "0.9", "."], ["We", "use", "16", "GPU", "asynchronous", "workers", ",", "and", "a", "batch", "size", "of", "96", "."], ["We", "use", "an", "initial", "learning", "rate", "of", "0.045", ",", "and", "learning", "rate", "decay", "rate", "of", "0.98", "per", "epoch", "."], ["All", "the", "convolutional", "layers", "use", "batch", "normalization", "with", "average", "decay", "of", "0.99", "."], ["Using", "the", "floating-point", "checkpoints", ",", "we", "then", "train", "models", "with", "8-bit", "representation", "of", "weights", "and", "activations", "by", "using", "quantization-aware", "training", "-LSB-", "33", "-RSB-", ",", "-LSB-", "3", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "learning", "rate", "decay", "of", "0.9", "per", "epoch", "."], ["Since", "we", "only", "classify", "two", "classes", "in", "Visual", "Wake", "Words", "dataset", ",", "we", "shrink", "the", "last", "convolutional", "layer", "in", "MobileNet", "V2", "and", "MNasNet", "models", "."]], "ner": [[[0, 0, "a"], [2, 2, "a"], [16, 16, "a"], [19, 19, "p"], [24, 24, "v"], [21, 21, "p"], [24, 24, "v"], [24, 24, "v"]], [], [[52, 52, "p"], [44, 45, "p"], [50, 51, "p"], [50, 52, "p"], [56, 57, "c"]], [[68, 68, "p"], [64, 65, "a"], [67, 68, "p"], [70, 70, "v"]], [[115, 115, "p"], [117, 117, "v"], [117, 117, "v"], [90, 91, "a"], [101, 102, "p"], [113, 114, "p"], [113, 115, "p"], [117, 117, "v"], [118, 119, "c"]], [[140, 140, "a"], [143, 143, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [2, 2, "a"], [19, 19, "p"], [24, 24, "v"]], [[28, 28, "v"], [35, 36, "p"], [38, 38, "v"]], [[44, 45, "p"], [47, 47, "v"], [50, 53, "p"], [55, 55, "v"]], [[64, 65, "a"], [70, 70, "v"]], [[82, 82, "v"], [101, 102, "p"], [106, 108, "v"], [113, 115, "p"], [117, 117, "v"]], [[125, 125, "v"], [128, 131, "a"], [140, 141, "a"], [143, 143, "a"]]], "predicted_relations": [[[19, 19, 0, 0, "USED-FOR"], [19, 19, 2, 2, "USED-FOR"], [19, 19, 16, 16, "USED-FOR"], [21, 21, 0, 0, "USED-FOR"], [21, 21, 2, 2, "USED-FOR"], [21, 21, 16, 16, "USED-FOR"]], [], [], [[70, 70, 68, 68, "USED-FOR"], [70, 70, 67, 68, "USED-FOR"]], [[115, 115, 90, 91, "USED-FOR"], [101, 102, 90, 91, "USED-FOR"]], []]}
{"doc_key": "1906.05795-07c8c293-a428-4bf9-9d5b-f2eb9c3b9b86", "sentences": [["Different", "methods", "have", "been", "used", "for", "the", "model", "training", "and", "optimization", "."], ["Firstly", ",", "all", "the", "channels", "described", "previously", "are", "concatenated", "into", "one", "fully-connected", "network", ",", "dealing", "with", "all", "the", "obtained", "feature", "maps", "concurrently", "."], ["Secondly", ",", "all", "the", "activation", "layers", "used", "are", "PReLU", ",", "initialized", "with", "he_normal", "-LSB-", "13", "-RSB-", ",", "-LSB-", "31", "-RSB-", "."], ["Thirdly", ",", "the", "dropout", "has", "been", "parametrized", "according", "to", "the", "strategy", "of", "the", "annealing", "dropout", ",", "from", "a", "rate", "of", "0.5", "to", "a", "rate", "of", "0.0", "after", "100", "epochs", "."], ["Concerning", "the", "losses", ",", "we", "used", "the", "categorical_crossentropy", "or", "binary_crossentropy", "for", "the", "classification", "model", ",", "and", "mean_squared_error", "for", "the", "auto-encoder", "structure", "."], ["Adadelta", "was", "used", "for", "optimization", "with", "an", "initial", "learning", "rate", "of", "1.0", "."]], "ner": [[], [[23, 24, "a"]], [[43, 43, "a"]], [[59, 59, "a"], [70, 70, "a"], [81, 81, "v"], [82, 84, "c"]], [[93, 93, "a"], [95, 95, "a"], [102, 102, "a"]], [[115, 117, "p"], [119, 119, "v"], [108, 108, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[22, 22, "v"]], [[43, 43, "a"], [47, 47, "a"]], [[59, 59, "a"], [70, 70, "a"], [76, 76, "v"], [81, 81, "v"], [83, 83, "v"], [84, 84, "p"]], [[93, 93, "a"], [95, 95, "a"]], [[108, 108, "a"], [116, 117, "p"], [119, 119, "v"]]], "predicted_relations": [[], [], [], [[82, 84, 81, 81, "USED-FOR"]], [], [[115, 117, 108, 108, "USED-FOR"]]]}
{"doc_key": "1910.13890-84a0948a-87d1-4a41-9338-dfdaa32e476f", "sentences": [["All", "models", "are", "implemented", "using", "gated", "recurrent", "units", "-LRB-", "GRU", "-RRB-", "-LSB-", "10", "-RSB-", ",", "and", "have", "a", "single-layer", "bi-RNN", "encoder", "."], ["The", "source", "sides", "of", "the", "data", "used", "for", "training", "all", "NMT", "models", ",", "and", "the", "target", "sides", "of", "the", "data", "used", "in", "training", "the", "subword-level", "NMT", "models", "are", "segmented", "using", "BPE", "with", "16,000", "merge", "rules", "."], ["We", "implement", "all", "decoders", "using", "a", "comparable", "number", "of", "GRU", "parameters", ",", "including", "3-layer", "stacked-GRU", "subword", "and", "character-level", "decoders", ",", "where", "the", "attention", "is", "computed", "after", "the", "1st", "layer", "-LSB-", "3", "-RSB-", "and", "a", "3-layer", "hierarchical", "decoder", "which", "implements", "the", "attention", "mechanism", "after", "the", "2nd", "layer", "."], ["All", "models", "use", "an", "embedding", "dimension", "and", "GRU", "size", "of", "512", "."], ["LMM", "uses", "the", "same", "hierarchical", "GRU", "architecture", ",", "where", "the", "middle", "layer", "is", "augmented", "using", "4", "multi-layer", "perceptrons", "with", "256", "hidden", "units", "."], ["We", "use", "a", "lemma", "vector", "dimension", "of", "150", ",", "10", "inflectional", "features", "-LRB-", "See", "\u00a7REF", "for", "experiments", "conducted", "to", "tune", "the", "feature", "dimensions", "-RRB-", "and", "set", "the", "regularization", "constant", "to", "\\", "-LRB-", "\\rho", "=0.4\\", "-RRB-", "."], ["All", "models", "are", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "17", "-RSB-", "with", "a", "batch", "size", "of", "100", ",", "dropout", "rate", "of", "0.2", ",", "learning", "rate", "of", "0.0004", "and", "learning", "rate", "decay", "of", "0.8", ",", "applied", "when", "the", "perplexity", "does", "not", "decrease", "at", "a", "given", "epoch.Perplexity", "is", "the", "exponentiated", "average", "negative", "log-likelihood", "per", "segment", "-LRB-", "BPE", ",", "or", "character", "-RRB-", "that", "a", "model", "assigns", "to", "a", "dataset", "."], ["It", "corresponds", "to", "the", "model", "'s", "average", "surprisal", "per", "time", "step", "."], ["Translations", "are", "generated", "with", "beam", "search", "with", "a", "beam", "size", "of", "5", ",", "where", "the", "hierarchical", "models", "implement", "the", "hierarchical", "beam", "search", "algorithm", "-LSB-", "1", "-RSB-", "."]], "ner": [[[12, 12, "v"]], [[52, 52, "a"], [54, 54, "v"]], [], [[115, 115, "v"], [112, 113, "p"], [115, 115, "v"]], [[117, 117, "a"]], [[147, 147, "v"], [149, 149, "v"], [173, 173, "v"]], [[230, 230, "a"], [182, 183, "a"], [192, 192, "v"], [197, 197, "v"], [202, 202, "v"], [208, 208, "v"]], [], [[266, 266, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 10, "a"], [19, 19, "a"]], [[52, 52, "a"], [54, 54, "v"]], [[67, 67, "a"], [72, 72, "a"]], [[112, 112, "a"], [115, 115, "v"]], [[132, 132, "v"], [136, 136, "v"], [137, 138, "p"]], [[147, 147, "v"], [149, 149, "v"], [167, 168, "p"], [173, 173, "v"]], [[182, 182, "a"], [189, 190, "p"], [192, 192, "v"], [194, 195, "p"], [197, 197, "v"], [199, 200, "p"], [202, 202, "v"], [204, 206, "p"], [208, 208, "v"]], [], [[259, 260, "a"], [263, 264, "p"], [266, 266, "v"], [274, 277, "a"]]], "predicted_relations": [[], [], [], [[115, 115, 112, 113, "USED-FOR"], [115, 115, 112, 113, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1901.04547-f27bc111-faf4-4de8-b4ae-efe1fee84ffa", "sentences": [["We", "use", "ADAM", "to", "optimize", "the", "networks", "in", "Algorithm", "REF", ",", "with", "the", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "apply", "weight", "decay", "constraining", "the", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "-norm", "of", "the", "weight", "parameters", "of", "the", "network", ",", "where", "the", "hyper-parameter", "for", "the", "decay", "is", "empirically", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["To", "prevent", "the", "networks", "from", "overfitting", ",", "we", "train", "at", "max", "1000", "iterations", "per", "round", ",", "and", "at", "max", "3", "epochs", "for", "the", "samples", "in", "current", "experience", "memory", "."], ["In", "addition", ",", "we", "only", "keep", "examples", "from", "the", "ten", "most", "recent", "rounds", "of", "optimization", "."]], "ner": [[[2, 2, "a"], [13, 14, "p"]], [[27, 28, "a"], [47, 47, "p"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"], [13, 14, "p"], [18, 21, "v"]], [[27, 28, "a"], [57, 60, "v"]], [[75, 75, "v"], [76, 76, "p"], [83, 83, "v"]], [[102, 102, "v"]]], "predicted_relations": [[[13, 14, 2, 2, "USED-FOR"]], [], [], []]}
{"doc_key": "1901.04547-9715a6cd-48bf-4f8a-930b-0a320d2a158b", "sentences": [["For", "MCTS", ",", "the", "number", "of", "repetitions", "of", "simulation", "is", "10", "."], ["The", "minimax-backup", "parameter", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "C_", "-LCB-", "puct", "-RCB-", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "1.0\\", "-RRB-", "."], ["The", "parameter", "for", "exploration", "extent", "is", "\\", "-LRB-", "\\epsilon", "=0.25\\", "-RRB-", "."]], "ner": [[[1, 1, "a"], [4, 8, "p"], [10, 10, "v"]], [[25, 25, "v"], [41, 41, "v"]], [[45, 48, "p"], [53, 53, "v"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [10, 10, "v"]], [[13, 14, "p"], [17, 17, "p"], [25, 25, "v"], [30, 33, "a"], [41, 41, "v"]], [[53, 53, "v"]]], "predicted_relations": [[[4, 8, 1, 1, "USED-FOR"]], [], [[53, 53, 45, 48, "USED-FOR"]]]}
{"doc_key": "1904.08301-dded42fc-50dd-4271-a496-4a17e23ac883", "sentences": [["We", "initialize", "all", "parameters", "of", "the", "model", "randomly", "."], ["Embedding", "vectors", "of", "dimension", "128", "are", "drawn", "from", "\\", "-LRB-", "U", "-LRB-", "0.05,0.05", "-RRB-", "\\", "-RRB-", "and", "the", "LSTM", "weights", "-LRB-", "neurons", ":", "128", "-RRB-", "and", "weights", "of", "the", "feed", "forward", "output", "layers", "are", "sampled", "from", "a", "Glorot", "uniform", "distribution", "-LSB-", "17", "-RSB-", "."], ["For", "future", "work", ",", "initializing", "the", "embedding", "layer", "with", "pre-trained", "vectors", "could", "further", "increase", "the", "performance", "."], ["In", "this", "work", ",", "however", ",", "we", "learn", "all", "parameters", "from", "the", "given", "data", "."], ["We", "fit", "our", "model", "using", "Adam", "-LSB-", "25", "-RSB-", "-LRB-", "learning", "rate", ":", "0.001", "-RRB-", "on", "the", "training", "data", "over", "20", "epochs", "with", "mini", "batches", "of", "size", "16", "."], ["We", "apply", "early", "stopping", "according", "to", "the", "maximum", "Pearson", "'s", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "-LRB-", "with", "regard", "to", "Smatch", "F1", "-RRB-", "on", "the", "development", "data", "."], ["\\", "-LRB-", "\\rho", "=\\frac", "-LCB-", "\\sum", "^n", "_", "-LCB-", "i=1", "-RCB-", "-LRB-", "x_i", "-", "\\bar", "-LCB-", "x", "-RCB-", "-RRB-", "-LRB-", "y_i", "-", "\\bar", "-LCB-", "y", "-RCB-", "-RRB-", "-RCB-", "-LCB-", "\\sqrt", "-LCB-", "\\sum", "^n", "_", "-LCB-", "i=1", "-RCB-", "-LRB-", "x_i", "-", "\\bar", "-LCB-", "x", "-RCB-", "-RRB-", "^2", "-RCB-", "\\sqrt", "-LCB-", "\\sum", "^n", "_", "-LCB-", "i=1", "-RCB-", "-LRB-", "y_i", "-", "\\bar", "-LCB-", "y", "-RCB-", "-RRB-", "^2", "-RCB-", "-RCB-", "\\", "-RRB-", "quantifies", "the", "linear", "relationship", "between", "predicted", "scores", "-LRB-", "\\", "-LRB-", "x_1", ",", "...", ",", "x_n\\", "-RRB-", "-RRB-", "and", "true", "scores", "-LRB-", "\\", "-LRB-", "y_1", ",", "...", ",", "y_n\\", "-RRB-", "-RRB-", "."]], "ner": [[], [[46, 48, "a"]], [], [], [[90, 90, "a"], [95, 96, "p"], [98, 98, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[12, 12, "p"], [13, 13, "v"], [19, 19, "p"], [27, 27, "a"], [32, 32, "v"], [46, 46, "a"]], [], [], [[88, 88, "a"], [90, 90, "a"], [95, 96, "p"], [98, 98, "v"], [105, 105, "v"], [106, 106, "p"], [112, 112, "v"]], [[116, 117, "a"], [133, 134, "a"]], []], "predicted_relations": [[], [], [], [], [[95, 96, 90, 90, "USED-FOR"]], [], []]}
{"doc_key": "1904.08105-5efab2b6-c6a2-4cfa-be20-b2705b158616", "sentences": [["Two", "Bi-LSTM", "layers", "with", "800", "cells", "each", "form", "the", "RNN", "."], ["To", "avoid", "overfitting", ",", "a", "dropout", "with", "the", "rate", "of", "\\", "-LRB-", "0.3\\", "-RRB-", "is", "used", "between", "and", "after", "the", "layers", "."], ["In", "addition", ",", "the", "gradients", "of", "the", "LSTMs", "are", "clipped", "to", "a", "value", "of", "1", "."], ["Thereby", "gradient", "exploding", "is", "avoided", "."]], "ner": [[[1, 1, "a"]], [[16, 16, "a"]], [[45, 45, "p"], [47, 47, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[0, 0, "v"], [1, 1, "a"], [4, 4, "v"], [9, 9, "a"]], [[16, 16, "a"], [23, 23, "v"]], [[40, 40, "a"], [47, 47, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1912.05510-3089b7a4-e710-479a-aff6-c14744a2fabe", "sentences": [["For", "the", "discrete", "action", "environment", "-LRB-", "Tetris", "and", "VizDoom", "-RRB-", ",", "the", "RL", "algorithm", "used", "is", "deep", "Q-learning", "-LSB-", "24", "-RSB-", "with", "a", "target", "Q", "network", "."], ["For", "the", "Humanoid", "domains", ",", "we", "use", "TRPO", "-LSB-", "33", "-RSB-", "."], ["For", "Tetris", "and", "the", "Humanoid", "domains", ",", "the", "policies", "are", "parameterized", "by", "fully", "connected", "neural", "networks", ",", "while", "VizDoom", "uses", "a", "convolutional", "network", "."], ["The", "encoders", "and", "decoders", "of", "the", "VAEs", "used", "for", "VizDoom", "and", "Humanoid", "experiments", "are", "implemented", "as", "fully", "connected", "networks", "over", "the", "same", "buffer", "observations", "as", "above", "."], ["The", "coefficient", "for", "the", "KL-divergence", "term", "in", "the", "VAE", "loss", "was", "0.1", "and", "1.0", "for", "the", "VizDoom", "and", "Humanoid", "experiments", ",", "respectively", "."]], "ner": [[], [[34, 34, "a"]], [], [], [[98, 98, "a"], [94, 95, "p"], [101, 101, "v"], [103, 103, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "a"], [17, 17, "a"]], [[34, 34, "a"]], [[40, 40, "a"], [57, 57, "a"]], [[72, 72, "a"]], [[98, 99, "a"], [101, 101, "v"], [103, 103, "v"], [106, 106, "a"]]], "predicted_relations": [[], [], [], [], [[94, 95, 98, 98, "USED-FOR"], [101, 101, 94, 95, "USED-FOR"], [103, 103, 94, 95, "USED-FOR"]]]}
{"doc_key": "1912.05421-8d04c10a-7338-4f60-994f-bb08de644c4c", "sentences": [["The", "goal", "of", "our", "experiments", "is", "not", "to", "set", "new", "benchmarks", "for", "predicting", "number", "and", "geographic", "word", "classes", "in", "text", ",", "but", "instead", "to", "demonstrate", "that", "the", "NSLM", "approach", "can", "be", "used", "to", "improve", "popular", "neural", "models", "of", "language", "by", "enhancing", "the", "inductive", "bias", "."], ["Thus", ",", "we", "adopt", "a", "standard", "language", "model", "architecture", "as", "our", "primary", "baseline", ",", "an", "RNN", "with", "LSTM", "cells", "and", "hyper-parameters", "corresponding", "to", "medium", "650", "dimensional", "models", "-LSB-", "25", "-RSB-", "."], ["All", "models", "converged", "within", "20", "training", "epochs", "."], ["During", "training", ",", "the", "softmax", "is", "computed", "using", "the", "full", "vocabulary", ",", "except", "for", "the", "Wikitext-103", "model", "which", "uses", "a", "sampled-softmax", "-LSB-", "8", "-RSB-", "with", "a", "sampling", "rate", "of", "2,500", "."], ["Distributions", "used", "by", "the", "micro-models", "are", "learned", "on", "the", "training", "sets", "."]], "ner": [[], [[60, 63, "a"], [65, 65, "p"], [68, 71, "v"]], [], [[104, 104, "a"], [110, 111, "p"], [113, 113, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[27, 28, "a"]], [[60, 60, "a"]], [[80, 80, "v"], [81, 82, "p"]], [[88, 88, "a"], [99, 99, "a"], [104, 104, "a"], [110, 111, "p"], [113, 113, "v"]], []], "predicted_relations": [[], [[65, 65, 60, 63, "USED-FOR"]], [], [[110, 111, 104, 104, "USED-FOR"]], []]}
{"doc_key": "1912.05421-9e1fb74e-91f1-4a71-9ba8-9c6e88390e3e", "sentences": [["-LSB-", "leftmargin=", "*", "-RSB-", "A", "traditional", "LSTM", "-LRB-", "NNLM", "-RRB-", "is", "used", "to", "assign", "probabilities", "to", "word", "classes", "over", "the", "vocabulary", "\\", "-LRB-", "V_W\\", "-RRB-", "-LRB-", "Eq", "."], ["REF", "-RRB-", "."], ["A", "hierarchical", "NNLM", "-LRB-", "HNLM", "-RRB-", "is", "used", "to", "assign", "probabilities", "to", "both", "word", "classes", "and", "members", "of", "the", "class", "vocabulary", "\\", "-LRB-", "V_C\\", "-RRB-", "-LRB-", "Eq", "."], ["REF", "-RRB-", "."], ["This", "evaluates", "how", "the", "benefit", "of", "working", "with", "smaller", "vocabularies", "for", "numbers", "and", "geographic", "locations", "may", "offset", "potentially", "poor", "accuracy", "of", "class", "probability", "estimates", "."], ["Character", "RNNs", "-LRB-", "CRNN", "-RRB-", "are", "used", "to", "assign", "probabilities", "to", "word", "lass", "tokens", "by", "predicting", "one", "character", "of", "a", "token", "at", "a", "time", "."], ["Separate", "CRNNs", "were", "trained", "for", "each", "class", "and", "probability", "was", "assigned", "to", "each", "token", "using", "the", "chain", "rule", "-LSB-", "9", "-RSB-", "."], ["Neural", "cache", "models", "-LSB-", "6", "-RSB-", "consider", "locality", "in", "language", "model", "results", "by", "up-weighting", "the", "probability", "of", "target", "words", "for", "repetitions", "in", "a", "historical", "window", "."], ["Neural-cache", "was", "applied", "to", "the", "three", "other", "neural", "baselines", "."], ["Step", "size", ",", "ensembling", "factor", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "Cache", "-RCB-", "\\", "-RRB-", "and", "temperature", "\\", "-LRB-", "\\theta", "_", "-LCB-", "Cache", "-RCB-", "\\", "-RRB-", "were", "set", "to", "500", ",", "0.25", "and", "0.75", ",", "respectively", ",", "after", "tuning", "on", "the", "validation", "set", "."]], "ner": [[], [], [], [], [], [], [], [[134, 136, "a"]], [], [[170, 171, "p"], [198, 198, "v"], [200, 200, "v"], [202, 202, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 9, "a"]], [], [[33, 36, "a"]], [], [], [[87, 91, "a"], [103, 103, "v"]], [[113, 113, "a"]], [[134, 136, "a"]], [[160, 160, "a"], [165, 165, "v"]], [[173, 174, "p"], [177, 181, "p"], [185, 185, "p"], [188, 192, "p"], [198, 198, "v"], [200, 200, "v"], [202, 202, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1912.05457-17db6dc5-07b6-4133-bcad-454a4dbf401b", "sentences": [["The", "batch", "size", "of", "the", "tested", "data", "is", "set", "as", "64", "."], ["The", "number", "of", "steps", "of", "historical", "data", "incorporated", "in", "the", "GMN", "model", "will", "have", "an", "influence", "on", "the", "prediction", "performance", "."], ["Hence", ",", "the", "GMNs", "with", "6-steps", ",", "8-steps", ",", "and", "10-steps", "of", "historical", "data", "are", "tested", "in", "the", "experiments", ",", "i.e", "."], ["the", "\\", "-LRB-", "n\\", "-RRB-", "in", "Equations", "REF", "and", "REF", "are", "set", "as", "6", ",", "8", ",", "and", "10", "."], ["In", "the", "following", "sections", ",", "we", "denoted", "these", "GMN", "models", "as", "GMN-6", ",", "GMN-8", ",", "and", "GMN-10", ",", "respectively", "."], ["The", "corresponding", "SGMN", "models", "with", "different", "steps", "are", "denoted", "as", "SGMN-6", ",", "SGMN-8", ",", "and", "SGMN-10", ",", "respectively", "."], ["The", "decay", "parameter", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "is", "set", "as", "0.9", "in", "the", "experiments", "."], ["For", "the", "RNN-based", "baseline", "models", ",", "including", "GRU", ",", "GRU-I", ",", "GRU-D", ",", "LSTM", ",", "LSTM-I", ",", "and", "LSTM-M", ",", "their", "input", "sequences", "all", "have", "10", "time", "steps", "."]], "ner": [[], [[22, 23, "a"], [13, 18, "p"]], [[38, 38, "v"], [40, 40, "v"], [43, 43, "v"]], [[68, 68, "v"], [70, 70, "v"], [73, 73, "v"]], [[86, 86, "v"], [88, 88, "v"], [91, 91, "v"]], [[105, 105, "v"], [107, 107, "v"], [110, 110, "v"]], [[115, 116, "a"], [119, 119, "p"], [125, 125, "v"]], [[155, 155, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "p"], [10, 10, "v"]], [[22, 23, "a"]], [[36, 36, "a"]], [[58, 58, "p"], [68, 68, "v"], [70, 70, "v"], [73, 73, "v"]], [[83, 84, "a"], [86, 86, "a"], [88, 88, "a"], [91, 91, "a"]], [[97, 97, "a"], [105, 105, "a"], [110, 110, "a"]], [[115, 116, "p"], [119, 119, "p"], [125, 125, "v"]], [[137, 137, "a"], [139, 139, "a"], [141, 141, "a"], [143, 143, "a"], [145, 145, "a"], [148, 148, "a"], [155, 155, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[119, 119, 115, 116, "USED-FOR"]], []]}
{"doc_key": "1904.00198-cda93e13-0c6c-4883-a8ec-7bb630630bef", "sentences": [["As", "for", "network", "settings", ",", "the", "normal", "setups", "of", "ResNet", "on", "CIFAR-10", "-LSB-", "15", "-RSB-", "are", "used", ",", "since", "CIFAR-10", "has", "similar", "input", "as", "our", "approach", "."], ["The", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "is", "applied", "to", "train", "the", "models", ",", "with", "softmax", "loss", "function", "."], ["15", "percents", "of", "the", "training", "examples", "are", "randomly", "handout", "for", "verification", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.001", ",", "and", "reduced", "after", "80", ",", "120", ",", "160", ",", "180", "epochs", "."], ["200", "epochs", "are", "used", "in", "total", ",", "and", "the", "batch", "size", "is", "128", "."], ["Therefore", ",", "there", "are", "about", "15000", "iterations", "during", "one", "single", "epoch", "in", "total", "."]], "ner": [[[9, 9, "a"]], [], [], [[65, 65, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"], [11, 11, "a"], [19, 19, "a"]], [[28, 33, "a"], [42, 42, "a"]], [[46, 46, "v"]], [[60, 61, "p"], [65, 65, "v"], [70, 70, "v"], [76, 76, "v"], [77, 77, "p"]], [[79, 79, "v"], [80, 80, "p"], [88, 89, "p"], [91, 91, "v"]], [[98, 98, "v"], [101, 101, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1909.09505-25445f2a-bd3a-47af-96e2-17c548ae694c", "sentences": [["The", "output", "normalized", "from", "\\", "-LRB-", "-1\\", "-RRB-", "to", "1", "was", "multiplied", "by", "a", "coefficient", "and", "converted", "into", "translation", "gains", ",", "rotation", "angles", ",", "and", "curvature", "gains", "as", "follows", "."], ["To", "set", "the", "range", "of", "the", "translation", "gains", "within", "0.86", "and", "1.26", ",", "the", "coefficient", "for", "the", "output", "of", "the", "translation", "gains", "was", "set", "to", "0.2", ",", "and", "then", "1.06", "was", "added", "."], ["For", "the", "rotation", "angle", ",", "the", "output", "multiplied", "by", "180", "and", "modulo", "360", "was", "used", "."], ["To", "set", "the", "range", "of", "the", "curvature", "gains", "within", "\\", "-LRB-", "-0.1333\\", "-RRB-", "and", "0.1333", ",", "the", "coefficient", "for", "the", "curvature", "gains", "output", "was", "set", "to", "0.1333", "."], ["Here", ",", "the", "positive", "and", "negative", "values", "indicate", "that", "the", "curvature", "is", "applied", "in", "the", "clockwise", "and", "counterclockwise", "directions", ",", "respectively", "."]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 9, "v"]], [[39, 39, "v"], [41, 41, "v"], [55, 55, "v"], [59, 59, "v"]], [[72, 72, "v"], [75, 75, "v"]], [[90, 90, "v"], [93, 93, "v"], [105, 105, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1909.09505-fbcaad80-0062-48ba-8022-1edf40bbf3c8", "sentences": [["In", "RL", ",", "the", "learning", "time", "is", "generally", "inversely", "proportional", "to", "the", "CPU", "performance", "."], ["By", "using", "a", "PC", "equipped", "with", "an", "Intel", "Core", "i7-8750H", "CPU", ",", "the", "learning", "time", "of", "these", "models", "was", "approximately", "2", "h.", "Additionally", ",", "the", "online", "execution", "time", "of", "the", "network", "was", "approximately", "0.301", "ms", "per", "frame", ",", "which", "is", "only", "1.81", "%", "of", "the", "duration", "of", "a", "frame", "in", "a", "60", "frames-per-secound", "environment", "."], ["This", "execution", "time", "is", "less", "enough", "to", "run", "the", "trained", "agent", "in", "practical", "VR", "contents", "with", "very", "low", "overhead", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [[35, 35, "v"], [48, 48, "v"], [56, 57, "v"], [66, 66, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1901.07124-8a7b64fa-a877-460f-909b-d15d544fb97f", "sentences": [["To", "train", "the", "network", "we", "randomly", "split", "the", "training", "set", "of", "GTSRB", "into", "two", "sets", ",", "35309", "images", "for", "training", "and", "3900", "for", "validation", "."], ["For", "testing", "we", "use", "the", "provided", "test", "set", "that", "holds", "12630", "images", "."], ["We", "crop", "and", "resize", "all", "images", "to", "50\\", "-LRB-", "\\times", "\\", "-RRB-", "50", "."]], "ner": [[[8, 11, "a"]], [[31, 32, "a"]], [[39, 41, "a"]]], "relations": [[], [], []], "predicted_ner": [[[11, 11, "a"], [13, 13, "v"], [16, 16, "v"], [21, 21, "v"]], [[35, 35, "v"]], [[45, 45, "v"], [50, 50, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1901.07124-9bcea759-22f2-43ea-a986-649a6be83158", "sentences": [["For", "the", "STN/ICSTN", "module", ",", "denoting", "convolution", "layers", "with", "\\", "-LRB-", "c\\", "-RRB-", "channels", "as", "\\", "-LRB-", "C", "-LRB-", "c", "-RRB-", "\\", "-RRB-", ",", "ReLU", "activations", "as", "\\", "-LRB-", "R\\", "-RRB-", ",", "and", "max-pooling", "layers", "as", "\\", "-LRB-", "P\\", "-RRB-", ",", "our", "network", "is", ":", "\\", "-LRB-", "C", "-LRB-", "4", "-RRB-", "RC", "-LRB-", "8", "-RRB-", "RPC", "-LRB-", "16", "-RRB-", "RPC", "-LRB-", "32", "-RRB-", "RPC", "-LRB-", "1024", "-RRB-", "\\", "-RRB-", "."], ["All", "convolutional", "layers", "use", "7\\", "-LRB-", "\\times", "\\", "-RRB-", "7", "kernels", "."], ["We", "apply", "max-pooling", "over", "each", "channel", "of", "the", "last", "feature", "map", "to", "produce", "one", "feature", "vector", "of", "size", "1024", "."], ["We", "then", "apply", "a", "fully", "connected", "layer", "with", "48", "neurons", "and", "ReLU", "activations", ",", "followed", "by", "another", "fully", "connected", "layer", "that", "maps", "to", "transformation", "parameters", "\u2013", "translation", ",", "scale", ",", "and", "rotation", "in", "our", "experiments", "."]], "ner": [[[2, 3, "a"], [6, 7, "p"], [49, 49, "v"], [13, 13, "c"], [53, 53, "v"], [13, 13, "c"], [57, 57, "v"], [13, 13, "c"], [61, 61, "v"], [13, 13, "c"], [65, 65, "v"], [13, 13, "c"], [24, 25, "a"], [33, 34, "a"]], [[80, 80, "p"]], [[100, 100, "v"]], [[106, 108, "p"], [119, 121, "p"], [110, 110, "v"], [111, 111, "c"], [113, 114, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[24, 25, "a"], [33, 33, "a"], [65, 65, "v"]], [[79, 79, "v"]], [[84, 84, "a"], [95, 95, "v"], [100, 100, "v"]], [[110, 110, "v"], [113, 114, "a"]]], "predicted_relations": [[[6, 7, 2, 3, "USED-FOR"], [6, 7, 24, 25, "USED-FOR"]], [], [], [[106, 108, 113, 114, "USED-FOR"], [119, 121, 113, 114, "USED-FOR"]]]}
{"doc_key": "1901.07124-039ac8f8-2d40-4f20-90a7-6db7fd287c19", "sentences": [["For", "the", "classification", "network", ",", "we", "use", "a", "simple", "network", "with", "a", "single", "hidden", "layer", "with", "128", "neurons", "and", "ReLU", "activations", "."], ["We", "choose", "a", "simple", "architecture", "on", "purpose", "in", "order", "to", "prevent", "the", "network", "relying", "on", "the", "increased", "capacity", "of", "a", "large", "classification", "network", "and", "learn", "spatial", "invariance", "and", "effectively", "ignoring", "the", "STN", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[16, 17, "v"], [19, 20, "v"]], [], []], "relations": [[], [], []], "predicted_ner": [[[16, 16, "v"], [19, 19, "a"]], [[53, 53, "a"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1901.07124-4487e1ad-2c5e-4d0b-bc02-86de04b937a9", "sentences": [["We", "use", "ADAM", "-LSB-", "19", "-RSB-", "as", "the", "optimizer", ",", "and", "choose", "10\\", "-LRB-", "^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "10\\", "-LRB-", "^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "as", "the", "learning", "rates", "for", "the", "STN/ICSTN", "modules", "and", "the", "classifier", "respectively", "."], ["We", "train", "the", "models", "from", "scratch", "with", "a", "batch", "size", "of", "64", ",", "and", "set", "the", "maximum", "number", "of", "iterations", "to", "300k", "."], ["We", "use", "early", "stopping", "if", "the", "model", "shows", "no", "improvement", "on", "the", "validation", "split", "within", "the", "last", "80k", "iterations", "."]], "ner": [[[2, 2, "a"]], [[50, 51, "p"], [53, 53, "v"], [58, 61, "p"], [63, 63, "v"]], [[67, 68, "p"], [82, 83, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [31, 32, "p"]], [[50, 51, "p"], [53, 53, "v"], [63, 63, "v"]], [[67, 68, "a"], [82, 82, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1908.11834-0249c89f-4208-4856-acf6-fd1f40ea7c95", "sentences": [["Optimization", "We", "use", "ADADELTA", "-LSB-", "36", "-RSB-", "with", "default", "hyper-parameters", "-LRB-", "rho=9e-1", ",", "eps=1e-6", ",", "weight", "decay=0", "-RRB-", "to", "minimize", "the", "aforementioned", "loss", "function", "."], ["Gradients", "are", "estimated", "using", "mini-batches", "with", "512", "images", "that", "are", "randomly", "sampled", "from", "training", "set", "."], ["We", "train", "6", "epochs", "in", "total", "."], ["We", "initialize", "the", "learning", "rate", "to", "\\", "-LRB-", "1.0\\", "-RRB-", "for", "the", "first", "4", "epochs", ",", "\\", "-LRB-", "0.1\\", "-RRB-", "for", "the", "fifth", "epoch", "and", "\\", "-LRB-", "0.01\\", "-RRB-", "for", "the", "sixth", "epoch", "."], ["All", "experiments", "are", "performed", "on", "a", "Ubuntu", "machine", "with", "4", "NVIDIA", "TITAN", "Xp", "graphics", "cards", ",", "each", "with", "12GB", "memory", "."]], "ner": [[[3, 3, "a"], [11, 11, "p"], [11, 11, "v"], [13, 13, "p"], [13, 13, "v"], [15, 16, "p"], [16, 16, "v"], [22, 23, "a"]], [], [], [[56, 56, "v"], [66, 66, "v"], [75, 75, "v"], [51, 52, "a"], [56, 56, "v"], [66, 66, "v"], [75, 75, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[31, 31, "v"]], [[43, 43, "v"], [44, 44, "p"]], [[51, 52, "p"], [56, 56, "v"], [61, 61, "v"], [62, 62, "p"], [66, 66, "v"], [75, 75, "v"]], [[91, 91, "v"], [100, 100, "v"]]], "predicted_relations": [[[11, 11, 3, 3, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [11, 11, 15, 16, "USED-FOR"], [13, 13, 3, 3, "USED-FOR"], [13, 13, 11, 11, "USED-FOR"], [13, 13, 13, 13, "USED-FOR"], [13, 13, 15, 16, "USED-FOR"], [15, 16, 3, 3, "USED-FOR"], [16, 16, 11, 11, "USED-FOR"], [16, 16, 13, 13, "USED-FOR"], [16, 16, 15, 16, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1910.00054-2b8d2272-e640-4673-96c1-2c0b323a3afc", "sentences": [["For", "a", "fair", "comparison", ",", "all", "the", "MIL-", "*", "models", "have", "the", "same", "parameter", "configuration", "as", "MILNET", "-LRB-", "Section", "5.3", "in", "-LSB-", "1", "-RSB-", "-RRB-", "."], ["For", "all", "models", "using", "word", "embeddings", "-LRB-", "i.e.", ",", "Seg-", "*", ",", "Rev-", "*", ",", "MIL-", "*", "-RRB-", ",", "we", "initialize", "the", "word", "embeddings", "using", "300-dimensional", "-LRB-", "\\", "-LRB-", "k=300\\", "-RRB-", "-RRB-", "pre-trained", "word2vec", "embeddings", "-LSB-", "21", "-RSB-", "."], ["For", "the", "CNNs", "we", "use", "kernels", "of", "size", "3", ",", "4", ",", "and", "5", "words", ",", "100", "feature", "maps", "per", "kernel", ",", "stride", "of", "size", "1", ",", "and", "max-over-time", "pooling", "to", "get", "fixed-size", "segment", "encodings", "-LRB-", "resulting", "in", "\\", "-LRB-", "\\ell", "=300\\", "-RRB-", "-RRB-", "."], ["For", "the", "forward", "and", "backward", "GRUs", "we", "use", "hidden", "vectors", "with", "50", "dimensions", "-LRB-", "\\", "-LRB-", "n=2", "\\cdot", "50", "=", "100\\", "-RRB-", "-RRB-", ",", "while", "for", "the", "attention", "mechanism", "we", "use", "vectors", "of", "100", "dimensions", "-LRB-", "\\", "-LRB-", "m=100\\", "-RRB-", "-RRB-", "."], ["We", "use", "dropout", "-LRB-", "with", "rate", "0.5", "-RRB-", "on", "the", "word", "embeddings", "and", "the", "internal", "GRU", "states", "."], ["We", "use", "L2", "regularization", "for", "the", "softmax", "classifier", "."]], "ner": [[[16, 16, "a"], [19, 19, "v"]], [[59, 60, "a"]], [[67, 67, "a"], [75, 75, "v"], [78, 78, "v"], [82, 85, "p"]], [[115, 115, "a"], [137, 138, "a"]], [[157, 157, "p"], [158, 158, "v"], [158, 158, "v"], [154, 154, "a"]], [[172, 173, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 9, "a"], [16, 16, "a"]], [[35, 36, "a"], [38, 39, "a"], [41, 42, "a"], [51, 51, "v"], [55, 55, "v"], [59, 59, "a"]], [[67, 67, "a"], [73, 73, "v"], [75, 75, "v"], [78, 78, "v"], [81, 81, "v"], [90, 90, "v"], [93, 94, "a"], [106, 106, "v"]], [[115, 115, "a"], [121, 121, "v"], [130, 130, "v"], [137, 138, "a"], [143, 143, "v"], [148, 148, "v"]], [[154, 154, "a"], [158, 158, "v"]], [[172, 173, "a"], [176, 177, "a"]]], "predicted_relations": [[], [], [[82, 85, 67, 67, "USED-FOR"]], [], [[157, 157, 154, 154, "USED-FOR"]], []]}
{"doc_key": "1910.00054-4cebbc54-2a95-46ed-bf6f-413a0c75b9e3", "sentences": [["For", "the", "*", "-BoW", "classifiers", ",", "the", "review", "text", "is", "encoded", "as", "a", "bag-of-words", "vector", "including", "n-grams", "-LRB-", "for", "n=1", ",", "2", ",", "and", "3", "-RRB-", "and", "each", "term", "is", "weighted", "using", "the", "Term", "Frequency-Inverse", "Document", "Frequency", "-LRB-", "TF-IDF", "-RRB-", "statistic", "-LSB-", "20", "-RSB-", "."], ["For", "the", "Rev-", "*", "and", "MIL-", "*", "classifiers", ",", "we", "use", "the", "same", "model", "parameter", "configuration", "as", "in", "Section", "REF", "."], ["We", "initialize", "the", "word", "embeddings", "using", "300-dimensional", "pre-trained", "word2vec", "embeddings", "."]], "ner": [[], [], [[74, 75, "a"], [72, 72, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 3, "a"], [24, 24, "v"]], [[47, 48, "a"], [50, 51, "a"]], [[72, 72, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1907.02413-ec6f8100-1773-47cf-a9a2-a627b56e2323", "sentences": [["To", "evaluate", "on", "OCT", "datasets", ",", "all", "models", "were", "first", "trained", "on", "Cirrus", "for", "4500", "iterations", "."], ["Then", "on", "Spectralis", ",", "the", "trained", "models", "were", "first", "fine-tuned", "on", "the", "training", "set", "for", "200", "iterations", ",", "then", "evaluated", "on", "the", "test", "sets", "."], ["When", "training", "on", "the", "Cirrus", "and", "Spectralis", "datasets", ",", "to", "increase", "data", "diversity", ",", "in", "each", "iteration", "\\", "-LRB-", "12\\sim", "18\\", "-RRB-", "slices", "were", "randomly", "chosen", "to", "form", "a", "batch", "from", "the", "30", "central", "slices", "of", "the", "input", "image", "."]], "ner": [[[12, 12, "a"], [15, 15, "p"]], [[19, 19, "a"], [33, 33, "p"], [32, 32, "v"]], [[46, 46, "a"], [48, 48, "a"]]], "relations": [[], [], []], "predicted_ner": [[[12, 12, "a"], [14, 14, "v"]], [[19, 19, "a"], [32, 32, "v"]], [[46, 46, "a"], [48, 48, "a"], [61, 62, "v"], [74, 74, "v"]]], "predicted_relations": [[[15, 15, 12, 12, "USED-FOR"]], [[33, 33, 19, 19, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"]], []]}
{"doc_key": "1907.02413-bc255fc0-a889-46e7-9769-68796fa628ce", "sentences": [["On", "the", "CRC-MSI", "dataset", ",", "there", "is", "significant", "domain", "gap", "between", "the", "training", "and", "test", "images", "."], ["Hence", "2", "%", "of", "the", "original", "test", "images", "were", "moved", "to", "the", "training", "set", "-LRB-", "these", "2domain", "gap", "."], ["In", "particular", ",", "all", "models", "were", "trained", "on", "the", "training", "set", "for", "one", "epoch", "-LRB-", "LR=0.01", "-RRB-", ",", "and", "then", "fine-tuned", "on", "the", "tuning", "set", "for", "two", "epochs", "-LRB-", "LR=0.01", ",", "0.004", "-RRB-", "."]], "ner": [[[2, 3, "a"]], [[29, 30, "c"]], [[40, 40, "a"], [51, 51, "p"], [65, 65, "p"], [51, 51, "v"], [65, 65, "v"], [45, 46, "c"], [67, 67, "v"], [59, 60, "c"]]], "relations": [[], [], []], "predicted_ner": [[[2, 3, "a"]], [[18, 19, "v"]], [[48, 48, "v"], [62, 62, "v"], [67, 67, "v"]]], "predicted_relations": [[], [], [[51, 51, 51, 51, "USED-FOR"], [65, 65, 51, 51, "USED-FOR"], [65, 65, 65, 65, "USED-FOR"], [45, 46, 51, 51, "USED-FOR"], [67, 67, 65, 65, "USED-FOR"], [59, 60, 51, 51, "USED-FOR"], [59, 60, 65, 65, "USED-FOR"]]]}
{"doc_key": "1907.00710-99eba4d3-7236-4633-b0d9-de9df2d8264e", "sentences": [["We", "use", "the", "Python-based", "natural", "language", "toolkit", "NLTK", "to", "perform", "tokenization", "."], ["Entities", "in", "dialog", "sessions", "are", "recognized", "via", "heuristic", "rules", "plus", "database", "entries", "."], ["All", "counts", ",", "time", "and", "reference", "numbers", "are", "replaced", "with", "the", "\\", "-LRB-", "\\left", "<", "\\text", "-LCB-", "value\\_count", "-RCB-", "\\right", ">", "\\", "-RRB-", ",", "\\", "-LRB-", "\\left", "<", "\\text", "-LCB-", "value\\_time", "-RCB-", "\\right", ">", "\\", "-RRB-", "and", "\\", "-LRB-", "\\left", "<", "\\text", "-LCB-", "domain\\_reference", "-RCB-", "\\right", ">", "\\", "-RRB-", "tokens", "respectively", "."], ["To", "reduce", "data", "sparsity", "further", ",", "all", "tokens", "are", "transformed", "to", "lowercase", "letters", "."], ["The", "stop", "words", "are", "chosen", "using", "tf\u2013idf", "-LSB-", "47", "-RSB-", "."], ["The", "number", "of", "topics", "\\", "-LRB-", "K\\", "-RRB-", "is", "set", "to", "20", "."], ["All", "tokens", "that", "appear", "less", "than", "5", "times", "in", "the", "corpus", "are", "replaced", "with", "the", "\\", "-LRB-", "\\left", "<", "\\text", "-LCB-", "UNK", "-RCB-", "\\right", ">", "\\", "-RRB-", "token", "."], ["We", "follow", "the", "-LCB-", "S", ",", "U", ",", "S", "'", "-RCB-", "utterance", "\u201c", "triples", "\u201d", "structure", "as", "-LSB-", "2", "-RSB-", "in", "our", "experiments", ",", "which", "means", "we", "aim", "to", "generate", "the", "system", "utterance", "S", "'", "by", "observing", "the", "former", "1", "turn", "of", "system", "utterance", "S", "and", "user", "utterance", "U", "."]], "ner": [[[7, 7, "a"]], [], [], [], [[97, 97, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"]], [], [], [], [[97, 97, "a"]], [[113, 113, "v"]], [[121, 121, "v"]], [[183, 183, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1901.03447-d1a882d6-301b-4f20-9e50-4a673c512f77", "sentences": [["Our", "method", "can", "be", "viewed", "as", "a", "way", "of", "training", "a", "network", "containing", "both", "encoders", "and", "a", "generator", ",", "such", "that", "the", "generator", "is", "effectively", "a", "portion", "of", "a", "GAN", "."], ["The", "network", "accepts", "a", "source", "texture", "\\", "-LRB-", "S\\", "-RRB-", "as", "input", "."], ["A", "global", "encoder", "\\", "-LRB-", "E^g", "-LRB-", "S", "-RRB-", "\\", "-RRB-", "encodes", "\\", "-LRB-", "S\\", "-RRB-", "into", "a", "latent", "vector", "\\", "-LRB-", "z^g\\", "-RRB-", ",", "which", "can", "also", "be", "viewed", "as", "a", "latent", "tensor", "with", "spatial", "size", "\\", "-LRB-", "1\\times", "1\\", "-RRB-", "."], ["A", "local", "encoder", "\\", "-LRB-", "E^l", "-LRB-", "S", "-RRB-", "\\", "-RRB-", "encodes", "the", "source", "texture", "into", "a", "latent", "tensor", "\\", "-LRB-", "z^l\\", "-RRB-", ",", "which", "has", "a", "spatial", "size", "that", "is", "a", "factor", "\\", "-LRB-", "m\\", "-RRB-", "smaller", "than", "the", "size", "of", "the", "input", "texture", ":", "we", "use", "\\", "-LRB-", "m", "=", "4\\", "-RRB-", "."], ["The", "generator", "\\", "-LRB-", "G", "-LRB-", "z^l", ",", "z^g", "-RRB-", "\\", "-RRB-", "ningcolorconcatenates", "\\", "-LRB-", "z^l\\", "-RRB-", "and", "\\", "-LRB-", "z^g\\", "-RRB-", ",", "and", "can", "decode", "these", "latent", "tensors", "back", "into", "a", "texture", "patch", ",", "so", "that", "ideally", "\\", "-LRB-", "G", "-LRB-", "E^l", "-LRB-", "S", "-RRB-", ",", "E^g", "-LRB-", "S", "-RRB-", "-RRB-", "=S\\", "-RRB-", ",", "which", "encompasses", "the", "reconstruction", "task", "."], ["Our", "generator", "is", "fully", "convolutional", ",", "so", "that", "it", "can", "generate", "output", "textures", "of", "arbitrary", "size", ":", "the", "output", "texture", "size", "is", "directly", "proportional", "to", "the", "size", "of", "the", "local", "tensor", "\\", "-LRB-", "z^l\\", "-RRB-", "."], ["A", "discriminator", "\\", "-LRB-", "D^", "-LCB-", "\\text", "-LCB-", "rec", "-RCB-", "-RCB-", "\\", "-RRB-", "is", "part", "of", "the", "reconstruction", "loss", "."], ["An", "identical", "but", "separately", "trained", "discriminator", "\\", "-LRB-", "D^", "-LCB-", "\\text", "-LCB-", "itp", "-RCB-", "-RCB-", "\\", "-RRB-", "evaluates", "the", "realism", "of", "interpolation", "."]], "ner": [[[11, 11, "a"], [17, 17, "a"], [22, 22, "a"]], [[32, 32, "a"]], [[45, 46, "a"]], [[88, 89, "a"], [122, 122, "p"], [137, 137, "p"], [139, 139, "v"]], [[143, 143, "a"]], [[204, 204, "a"]], [[240, 240, "a"]], [[264, 264, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [], [], [[137, 139, "v"]], [], [], [], []], "predicted_relations": [[], [], [], [[122, 122, 88, 89, "USED-FOR"], [137, 137, 88, 89, "USED-FOR"], [139, 139, 137, 137, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1901.03447-22c94a50-3e3e-4d78-89b1-01cdb82618ad", "sentences": [["We", "show", "the", "full", "training", "setup", "in", "Figure", "REF", "."], ["We", "will", "also", "explain", "ningcolorour", "setup", "in", "terms", "of", "formulas", "here", "."], ["As", "is", "shown", "in", "the", "upper-left", "of", "Figure", "REF", ",", "the", "network", "is", "given", "two", "real", "source", "texture", "images", "\\", "-LRB-", "S_1\\", "-RRB-", "and", "\\", "-LRB-", "S_2\\", "-RRB-", "from", "the", "real", "texture", "dataset", "\\", "-LRB-", "\\mathcal", "-LCB-", "S", "-RCB-", "\\", "-RRB-", "."], ["Each", "local", "encoder", "\\", "-LRB-", "E^l\\", "-RRB-", "encodes", "\\", "-LRB-", "S_i\\", "-RRB-", "-LRB-", "\\", "-LRB-", "i", "\\in", "\\lbrace", "1", ",", "2\\rbrace", "\\", "-RRB-", "-RRB-", "to", "a", "local", "latent", "tensor", "\\", "-LRB-", "z^l_i", "=", "E^l", "-LRB-", "S_i", "-RRB-", "\\", "-RRB-", "."], ["Meanwhile", ",", "each", "global", "encoder", "\\", "-LRB-", "E^g\\", "-RRB-", "encodes", "\\", "-LRB-", "S_i\\", "-RRB-", "to", "a", "global", "latent", "vector", "\\", "-LRB-", "z^g_i\\", "-RRB-", ",", "denoted", "as", "\\", "-LRB-", "z^g_i", "=", "E^g", "-LRB-", "S_i", "-RRB-", "\\", "-RRB-", "."], ["These", "latent", "variables", "are", "shown", "in", "green", "and", "blue", "boxes", "in", "the", "upper-left", "of", "Figure", "REF", "."]], "ner": [[], [], [[52, 54, "a"]], [[65, 66, "a"]], [[107, 108, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[36, 36, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1901.03447-a099de82-4820-41a0-b8f0-793be3495f3a", "sentences": [["We", "implement", "the", "random", "shuffling", "by", "row", "and", "column", "swapping", "over", "several", "scales", "from", "coarse", "to", "fine", "."], ["For", "this", "coarse", "to", "fine", "process", ",", "we", "use", "scales", "that", "are", "powers", "of", "two", ":", "\\", "-LRB-", "s_i", "=", "2^i\\", "-RRB-", "for", "\\", "-LRB-", "i=0", ",", "2", ",", "\\ldots", ",", "n\\", "-RRB-", "."], ["We", "set", "the", "coarsest", "scale", "\\", "-LRB-", "n\\", "-RRB-", "to", "give", "a", "scale", "\\", "-LRB-", "s_n\\", "-RRB-", "that", "is", "half", "the", "size", "of", "the", "local", "tensor", "\\", "-LRB-", "z^l_i\\", "-RRB-", "."], ["For", "each", "scale", "\\", "-LRB-", "s_i\\", "-RRB-", ",", "we", "define", "a", "grid", "over", "the", "tiled", "latent", "tensor", "\\", "-LRB-", "T", "-LRB-", "z^l", "-RRB-", "\\", "-RRB-", ",", "where", "each", "grid", "cell", "has", "size", "\\", "-LRB-", "s_i", "\\times", "s_i\\", "-RRB-", "."], ["For", "each", "scale", "\\", "-LRB-", "s_i\\", "-RRB-", ",", "we", "then", "apply", "a", "random", "shuffling", "on", "cells", "of", "the", "grid", "for", "that", "scale", ":", "we", "denote", "this", "by", "\\", "-LRB-", "P_", "-LCB-", "i", "-RCB-", "\\", "-RRB-", "."], ["This", "shuffling", "proceeds", "through", "grid", "rows", "first", "in", "top-down", "and", "then", "bottom-up", "order", ":", "each", "row", "is", "randomly", "swapped", "with", "the", "succeeding", "row", "with", "probability", "0.5", "."], ["Similarly", ",", "this", "is", "repeated", "on", "grid", "columns", ",", "with", "column", "swapping", "from", "left", "to", "right", "and", "right", "to", "left", "."], ["Thus", ",", "the", "entire", "shuffling", "operation", "is", ":", "\\", "-LRB-", "P\\big", "-LRB-", "T", "-LRB-", "z^l_i", "-RRB-", "\\big", "-RRB-", "=", "P_", "-LCB-", "0", "-RCB-", "\\circ", "P_", "-LCB-", "1", "-RCB-", "\\circ", "\\cdots", "\\circ", "P_", "-LCB-", "n", "-RCB-", "\\big", "-LRB-", "T", "-LRB-", "z^l_i", "-RRB-", "\\big", "-RRB-", "\\", "-RRB-"]], "ner": [[], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[32, 32, "v"]], [], [], [], [[183, 183, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1907.11565-fb4982ac-05c6-484e-9702-7d2afb33dd28", "sentences": [["For", "ST", "Multinomial", "and", "ST", "Gumbel-Softmax", "we", "tested", "learning-rate", "in", "-LRB-", "-LCB-", "1e-4", ",", "5e-4", ",", "1e-3", ",", "5e-3", "-RCB-", "-RRB-", "and", "decay", "in", "-LRB-", "-LCB-", "0.7", ",", "0.75", ",", "0.8", "-RCB-", "-RRB-", "."], ["For", "reinforce", ",", "we", "tested", "learning-rate", "in", "-LRB-", "-LCB-", "5e-4", ",", "5e-3", ",", "1e-2", ",", "5e-2", "-RCB-", "-RRB-", "and", "decay", "in", "-LRB-", "-LCB-", "0.7", ",", "0.8", ",", "0.9", "-RCB-", "-RRB-", "."], ["For", "PSST", "Gumbel", "softmax", "and", "for", "PSST", "Multinomial", "we", "used", "the", "same", "hyperparameters", "that", "were", "found", "to", "be", "best", "for", "ST", "Multinomial", "and", "ST", "Gumbel-Softmax", ",", "and", "we", "did", "not", "tuned", "them", "further", "-LRB-", "learning", "rate", "of", "\\", "-LRB-", "5e-3\\", "-RRB-", "and", "decay", "\\", "-LRB-", "0.75\\", "-RRB-", "-RRB-", "."]], "ner": [[[1, 2, "a"], [8, 8, "p"], [12, 12, "v"], [14, 14, "v"], [16, 16, "v"], [18, 18, "v"], [22, 22, "p"], [26, 26, "v"], [28, 28, "v"], [30, 30, "v"], [4, 5, "a"], [8, 8, "p"], [12, 12, "v"], [14, 14, "v"], [16, 16, "v"], [18, 18, "v"], [22, 22, "p"], [26, 26, "v"], [28, 28, "v"], [30, 30, "v"], [8, 8, "p"], [14, 14, "v"], [18, 18, "v"], [22, 22, "p"], [26, 26, "v"], [30, 30, "v"], [8, 8, "p"], [18, 18, "v"], [22, 22, "p"], [28, 28, "v"], [8, 8, "p"], [18, 18, "v"], [22, 22, "p"], [28, 28, "v"]], [[39, 39, "p"], [43, 43, "v"], [45, 45, "v"], [53, 53, "p"], [57, 57, "v"], [59, 59, "v"], [39, 39, "p"], [43, 43, "v"], [45, 45, "v"], [53, 53, "p"], [57, 57, "v"], [59, 59, "v"], [39, 39, "p"], [43, 43, "v"], [45, 45, "v"], [47, 47, "v"], [49, 49, "v"], [53, 53, "p"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [39, 39, "p"], [45, 45, "v"], [53, 53, "p"], [39, 39, "p"], [45, 45, "v"], [53, 53, "p"]], [[85, 86, "a"], [104, 104, "v"], [107, 107, "p"], [110, 110, "v"], [88, 89, "a"], [104, 104, "v"], [107, 107, "p"], [110, 110, "v"], [104, 104, "v"], [107, 107, "p"], [66, 68, "a"], [104, 104, "v"], [107, 107, "p"], [110, 110, "v"], [71, 72, "a"], [104, 104, "v"], [107, 107, "p"], [110, 110, "v"]]], "relations": [[], [], []], "predicted_ner": [[[5, 5, "a"], [8, 8, "p"], [22, 22, "p"], [30, 30, "v"]], [[35, 35, "a"], [39, 39, "p"], [53, 53, "p"], [61, 61, "v"]], [[66, 68, "a"], [71, 72, "a"], [89, 89, "a"], [99, 100, "p"], [104, 104, "v"], [107, 107, "p"], [110, 110, "v"]]], "predicted_relations": [[[8, 8, 4, 5, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [22, 22, 1, 2, "USED-FOR"], [22, 22, 4, 5, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [8, 8, 4, 5, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [12, 12, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [16, 16, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [22, 22, 1, 2, "USED-FOR"], [22, 22, 4, 5, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [8, 8, 4, 5, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [14, 14, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [22, 22, 1, 2, "USED-FOR"], [22, 22, 4, 5, "USED-FOR"], [8, 8, 4, 5, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [22, 22, 1, 2, "USED-FOR"], [22, 22, 4, 5, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [8, 8, 4, 5, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [18, 18, 8, 8, "USED-FOR"], [22, 22, 1, 2, "USED-FOR"], [22, 22, 4, 5, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"]], [[43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [43, 43, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [47, 47, 39, 39, "USED-FOR"], [47, 47, 39, 39, "USED-FOR"], [47, 47, 39, 39, "USED-FOR"], [47, 47, 39, 39, "USED-FOR"], [47, 47, 39, 39, "USED-FOR"], [49, 49, 39, 39, "USED-FOR"], [49, 49, 39, 39, "USED-FOR"], [49, 49, 39, 39, "USED-FOR"], [49, 49, 39, 39, "USED-FOR"], [49, 49, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"], [45, 45, 39, 39, "USED-FOR"]], [[107, 107, 85, 86, "USED-FOR"], [107, 107, 88, 89, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [107, 107, 85, 86, "USED-FOR"], [107, 107, 88, 89, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [107, 107, 85, 86, "USED-FOR"], [107, 107, 88, 89, "USED-FOR"], [107, 107, 85, 86, "USED-FOR"], [107, 107, 88, 89, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [107, 107, 85, 86, "USED-FOR"], [107, 107, 88, 89, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"]]]}
{"doc_key": "1907.11565-194bcbf5-fd12-4254-9b03-d8524135ae7b", "sentences": [["To", "select", "the", "best", "learning", "rate", "within", "the", "above", "sets", ",", "we", "trained", "a", "full", "curve", "of", "recall-vs-cider", "for", "each", "value", "and", "selected", "the", "rate", "that", "maximized", "the", "recall", "@", "10", "for", "CIDEr=1.125", "."], ["We", "repeated", "the", "same", "procedure", "for", "the", "decay", "-LRB-", "-LCB-", "0.7", ",", "0.75", ",", "0.8", "-RCB-", "-RRB-", ",", "together", "yielding", "the", "best", "rate", "=", "\\", "-LRB-", "5e-3\\", "-RRB-", ",", "and", "the", "best", "decay", "=", "\\", "-LRB-", "0.75\\", "-RRB-", "."], ["For", "Straight-through", "Gumbel", "Softmax", "we", "tested", "temperatures", "of", "\\", "-LRB-", "\\tau", "\\in", "\\lbrace", "0.5", ",", "1", ",", "3", ",", "5", ",", "7", ",10\\rbrace", "\\", "-RRB-", ",", "and", "found", "\\", "-LRB-", "\\tau", "=", "1\\", "-RRB-", "was", "best", "."]], "ner": [[[4, 5, "a"], [5, 5, "p"], [24, 24, "p"], [32, 32, "v"], [30, 30, "v"]], [[56, 56, "p"], [60, 60, "v"], [41, 41, "p"], [66, 66, "p"], [44, 44, "v"], [46, 46, "v"], [70, 70, "v"], [48, 48, "v"], [60, 60, "v"], [44, 44, "v"]], [[74, 76, "a"], [79, 79, "p"], [86, 86, "v"], [88, 88, "v"], [105, 105, "v"], [90, 90, "v"], [86, 86, "v"], [92, 92, "v"], [94, 94, "v"], [95, 95, "v"]]], "relations": [[], [], []], "predicted_ner": [[[4, 5, "p"], [17, 17, "a"]], [[44, 44, "v"], [46, 46, "v"], [48, 48, "v"], [60, 60, "v"], [66, 66, "p"], [70, 70, "v"]], [[75, 76, "a"]]], "predicted_relations": [[[5, 5, 4, 5, "USED-FOR"], [32, 32, 24, 24, "USED-FOR"]], [[46, 46, 41, 41, "USED-FOR"]], [[79, 79, 74, 76, "USED-FOR"]]]}
{"doc_key": "1907.11565-a3e96b2c-a469-4da2-b92e-39edfe247126", "sentences": [["For", "PSST", "Gumbel", "softmax", "and", "PSST", "Multinomial", "we", "tested", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "in", "-LCB-", "0", ",", "0.25", ",", "0.5", ",", "0.75", ",", "1", "-RCB-", ",", "and", "show", "performance", "as", "a", "function", "of", "\\", "-LRB-", "\\rho", "\\", "-RRB-", "in", "Fig", "."], ["REF", "."], ["When", "training", "with", "reinforce", ",", "we", "tested", "several", "baselines", "for", "reducing", "variance", "of", "the", "estimator", "-LRB-", "greedy", ",", "ground", "truth", ",", "no", "baseline", "-RRB-", "and", "report", "results", "obtained", "with", "the", "ground", "truth", "baseline", "which", "worked", "best", "."], ["At", "test", "time", ",", "we", "used", "a", "beam", "search", "of", "size", "2", "for", "generating", "captions", ",", "as", "in", "-LSB-", "27", "-RSB-", "."]], "ner": [[[1, 3, "a"], [16, 16, "v"], [18, 18, "v"], [20, 20, "v"], [22, 22, "v"], [18, 18, "v"], [20, 20, "v"], [22, 22, "v"], [24, 24, "v"], [5, 6, "a"], [16, 16, "v"], [18, 18, "v"], [20, 20, "v"], [22, 22, "v"], [18, 18, "v"], [20, 20, "v"], [22, 22, "v"], [24, 24, "v"]], [], [[47, 47, "a"], [60, 60, "a"], [62, 63, "a"], [74, 75, "a"], [65, 66, "a"]], [[88, 89, "a"], [91, 91, "p"], [92, 92, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"], [3, 3, "a"], [5, 6, "a"], [16, 16, "v"], [22, 22, "v"], [24, 24, "v"]], [], [[47, 47, "a"], [60, 60, "a"]], [[81, 83, "c"], [88, 89, "a"], [92, 92, "v"]]], "predicted_relations": [[], [], [], [[91, 91, 88, 89, "USED-FOR"], [92, 92, 91, 91, "USED-FOR"]]]}
{"doc_key": "1905.13358-7a547480-b4ae-41b1-a519-6ad790aca96c", "sentences": [["The", "training", "setup", "of", "the", "navigation", "agent", "is", "identical", "to", "Fried:2018", ":", "Speaker", "."], ["The", "agent", "learns", "to", "map", "the", "natural", "language", "instruction", "\\", "-LRB-", "\\mathcal", "-LCB-", "X", "-RCB-", "\\", "-RRB-", "and", "the", "initial", "visual", "scene", "\\", "-LRB-", "v_1\\", "-RRB-", "to", "a", "sequence", "of", "actions", "\\", "-LRB-", "a_", "-LCB-", "1", "..", "T", "-RCB-", "\\", "-RRB-", "."], ["Language", "instructions", "\\", "-LRB-", "\\mathcal", "-LCB-", "X", "-RCB-", "=x_", "-LCB-", "1", "..", "n", "-RCB-", "\\", "-RRB-", "are", "initialized", "with", "pre-trained", "GloVe", "word", "embeddings", "Pennington:2014", ":", "GloVe", "and", "encoded", "using", "a", "bidirectional", "RNN", "Schuster1997BidirectionalRN", "."], ["At", "each", "time", "step", "\\", "-LRB-", "t\\", "-RRB-", ",", "the", "agent", "perceives", "a", "360-degree", "panoramic", "view", "of", "its", "surroundings", "from", "the", "current", "location", "."], ["The", "view", "is", "discretized", "into", "\\", "-LRB-", "m\\", "-RRB-", "view", "angles", "-LRB-", "\\", "-LRB-", "m=36\\", "-RRB-", "in", "our", "implementation", ",", "3", "elevations", "x", "12", "headings", "at", "30-degree", "intervals", "-RRB-", "."], ["The", "image", "at", "view", "angle", "\\", "-LRB-", "i\\", "-RRB-", ",", "heading", "angle", "\\", "-LRB-", "\\phi", "\\", "-RRB-", "and", "elevation", "angle", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "is", "represented", "by", "a", "concatenation", "of", "the", "pre-trained", "CNN", "image", "features", "with", "the", "4-dimensional", "orientation", "feature", "-LSB-", "sin", "\\", "-LRB-", "\\phi", "\\", "-RRB-", ";", "cos", "\\", "-LRB-", "\\phi", "\\", "-RRB-", ";", "sin", "\\", "-LRB-", "\\theta", "\\", "-RRB-", ";", "cos", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "-RSB-", "to", "form", "\\", "-LRB-", "v_", "-LCB-", "t", ",", "i", "-RCB-", "\\", "-RRB-", "."], ["As", "in", "Fried:2018", ":", "Speaker", ",", "the", "agent", "is", "trained", "using", "student", "forcing", "where", "actions", "are", "sampled", "from", "the", "model", "during", "training", ",", "and", "supervised", "using", "a", "shortest-path", "action", "to", "reach", "the", "goal", "state", "."]], "ner": [[], [], [[76, 78, "a"], [86, 87, "a"]], [], [], [[177, 179, "a"]], [[238, 239, "a"], [254, 255, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [], [[76, 76, "a"], [87, 87, "a"]], [[103, 103, "v"]], [[121, 121, "p"], [128, 128, "v"], [134, 134, "v"], [137, 137, "v"], [140, 140, "v"]], [[177, 177, "a"], [182, 182, "v"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1905.13164-23be2f6a-bebd-4dce-ab7f-e898f403399f", "sentences": [["In", "all", "abstractive", "models", ",", "we", "apply", "dropout", "-LRB-", "with", "probability", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "-RRB-", "before", "all", "linear", "layers", ";", "label", "smoothing", "-LSB-", "34", "-RSB-", "with", "smoothing", "factor", "\\", "-LRB-", "0.1\\", "-RRB-", "is", "also", "used", "."], ["Training", "is", "in", "traditional", "sequence-to-sequence", "manner", "with", "maximum", "likelihood", "estimation", "."], ["The", "optimizer", "was", "Adam", "-LSB-", "17", "-RSB-", "with", "learning", "rate", "of", "\\", "-LRB-", "2", ",", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\beta", "_2", "=", "0.998\\", "-RRB-", ";", "we", "also", "applied", "learning", "rate", "warmup", "over", "the", "first", "\\", "-LRB-", "8,000\\", "-RRB-", "steps", ",", "and", "decay", "as", "in", "-LSB-", "35", "-RSB-", "."], ["All", "transformer-based", "models", "had", "256", "hidden", "units", ";", "the", "feed-forward", "hidden", "size", "was", "\\", "-LRB-", "1,024\\", "-RRB-", "for", "all", "layers", "."], ["All", "models", "were", "trained", "on", "4", "GPUs", "-LRB-", "NVIDIA", "TITAN", "Xp", "-RRB-", "for", "\\", "-LRB-", "500,000\\", "-RRB-", "steps", "."], ["We", "used", "gradient", "accumulation", "to", "keep", "training", "time", "for", "all", "models", "approximately", "consistent", "."], ["We", "selected", "the", "5", "best", "checkpoints", "based", "on", "performance", "on", "the", "validation", "set", "and", "report", "averaged", "results", "on", "the", "test", "set", "."], ["During", "decoding", "we", "use", "beam", "search", "with", "beam", "size", "5", "and", "length", "penalty", "with", "\\", "-LRB-", "\\alpha", "=", "0.4\\", "-RRB-", "-LSB-", "38", "-RSB-", ";", "we", "decode", "until", "an", "end-of-sequence", "token", "is", "reached", "."]], "ner": [[[7, 7, "a"], [10, 10, "p"], [14, 14, "v"], [32, 32, "v"], [14, 14, "v"], [32, 32, "v"]], [], [[52, 52, "a"], [57, 58, "p"], [82, 83, "p"], [62, 62, "v"], [67, 67, "v"], [76, 76, "v"]], [], [], [], [[159, 159, "v"]], [[182, 183, "a"], [185, 186, "p"], [187, 187, "v"], [196, 196, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [14, 14, "v"], [22, 23, "a"], [28, 29, "p"], [32, 32, "v"]], [], [[52, 52, "a"], [57, 58, "p"], [62, 62, "v"], [67, 67, "v"], [76, 76, "v"], [90, 90, "v"], [95, 95, "a"]], [[103, 103, "a"], [106, 106, "v"], [107, 108, "p"], [111, 111, "a"], [111, 113, "p"], [117, 117, "v"]], [[128, 128, "v"], [138, 138, "v"]], [[144, 145, "a"]], [[159, 159, "v"]], [[182, 183, "a"], [185, 186, "p"], [187, 187, "v"], [194, 194, "p"], [196, 196, "v"]]], "predicted_relations": [[], [], [[57, 58, 52, 52, "USED-FOR"], [82, 83, 52, 52, "USED-FOR"]], [], [], [], [], [[185, 186, 182, 183, "USED-FOR"], [187, 187, 185, 186, "USED-FOR"]]]}
{"doc_key": "1905.13205-92b665e0-9d95-4381-9714-eeb50563b729", "sentences": [["We", "train", "all", "of", "our", "networks", "using", "the", "Adam", "method", "for", "stochastic", "optimization", "-LSB-", "74", "-RSB-", ",", "with", "\\", "-LRB-", "\\beta", "_1=0.5\\", "-RRB-", "for", "all", "trained", "variables", ",", "\\", "-LRB-", "\\beta", "_2=0.9\\", "-RRB-", "for", "our", "Boltzmann", "machines", ",", "and", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "for", "our", "generator", "and", "discriminator", "."], ["As", "in", "previous", "works", "involving", "QBMs", "-LSB-", "27", "-RSB-", ",", "-LSB-", "26", "-RSB-", ",", "we", "take", "all", "\\", "-LRB-", "_a=2\\", "-RRB-", "."], ["During", "training", "on", "synthetic", "data", ",", "we", "set", "the", "learning", "rate", "for", "both", "of", "our", "Boltzmann", "machines", "to", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "and", "use", "\\", "-LRB-", "k=5\\", "-RRB-", "Gibbs", "steps", "."], ["Each", "Boltzmann", "machine", "has", "8", "visible", "units", "and", "2", "hidden", "units", ",", "which", "are", "sufficient", "for", "approximating", "the", "studied", "Bernoulli", "distribution", "."]], "ner": [[[8, 9, "a"], [21, 21, "v"], [31, 31, "v"], [35, 36, "c"], [42, 42, "v"], [46, 48, "c"], [21, 21, "v"], [35, 36, "a"]], [[69, 69, "v"], [69, 69, "v"]], [[87, 88, "c"], [81, 82, "p"], [102, 102, "p"], [102, 102, "v"], [87, 88, "a"]], [[115, 115, "v"], [112, 113, "p"], [111, 111, "v"], [116, 117, "p"], [115, 115, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"], [8, 9, "a"], [21, 21, "v"], [31, 31, "v"], [35, 36, "a"], [42, 42, "v"]], [[55, 55, "a"], [69, 69, "v"]], [[81, 82, "p"], [87, 88, "a"], [92, 95, "v"], [102, 102, "v"]], [[108, 109, "a"], [111, 111, "v"], [115, 115, "v"]]], "predicted_relations": [[[35, 36, 21, 21, "USED-FOR"], [35, 36, 31, 31, "USED-FOR"], [35, 36, 42, 42, "USED-FOR"], [35, 36, 21, 21, "USED-FOR"], [46, 48, 21, 21, "USED-FOR"], [46, 48, 31, 31, "USED-FOR"], [46, 48, 42, 42, "USED-FOR"], [46, 48, 21, 21, "USED-FOR"]], [], [[87, 88, 102, 102, "USED-FOR"], [102, 102, 102, 102, "USED-FOR"], [102, 102, 87, 88, "USED-FOR"], [102, 102, 81, 82, "USED-FOR"], [102, 102, 102, 102, "USED-FOR"]], []]}
{"doc_key": "1905.13205-63ce5e1c-713c-4db9-aa76-c7fead8d5062", "sentences": [["When", "training", "on", "the", "MNIST", "and", "CIFAR-10", "data", "sets", ",", "we", "consider", "Boltzmann", "machines", "with", "32", "visible", "units", "and", "8", "hidden", "units", "."], ["For", "consistency", ",", "we", "also", "set", "the", "dimension", "of", "the", "noise", "distribution", "for", "DCGAN", "to", "be", "32", "."], ["We", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "both", "our", "generator", "and", "discriminator", ",", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "our", "Boltzmann", "machines", "with", "\\", "-LRB-", "k=5\\", "-RRB-", "Gibbs", "steps", "."], ["Furthermore", ",", "we", "initialize", "our", "weights", "using", "Xavier", "initialization", "-LSB-", "75", "-RSB-", "and", "initialize", "our", "biases", "to", "zero", "."], ["In", "order", "to", "help", "the", "discriminator", "learn", "in", "the", "early", "stages", "of", "trainig", ",", "we", "use", "soft", "and", "noisy", "labels", "where", "a", "random", "number", "between", "0", "and", "\\", "-LRB-", "0.1\\", "-RRB-", "is", "used", "instead", "of", "0", "labels", "-LRB-", "fake", "images", "-RRB-", "and", "a", "random", "number", "between", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "1", "is", "used", "instead", "of", "1", "labels", "-LRB-", "real", "images", "-RRB-", "."], ["Each", "model", "is", "trained", "for", "30", "epochs", ",", "where", "an", "epoch", "represents", "one", "full", "pass", "through", "the", "training", "data", "."]], "ner": [[[4, 4, "a"], [6, 6, "a"], [12, 13, "a"], [16, 17, "p"], [15, 15, "v"], [20, 21, "p"], [19, 19, "v"], [15, 15, "v"], [12, 13, "p"]], [[39, 39, "v"], [36, 36, "a"], [30, 34, "p"], [39, 39, "v"]], [[78, 79, "a"], [83, 83, "p"], [83, 83, "v"], [44, 45, "a"], [65, 66, "a"], [59, 61, "p"], [78, 79, "p"]], [[95, 96, "a"]], [[123, 126, "a"], [145, 146, "p"], [166, 167, "p"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [6, 6, "a"], [12, 13, "a"], [15, 15, "v"], [19, 19, "v"], [20, 21, "p"]], [[36, 36, "a"], [39, 39, "v"]], [[44, 45, "p"], [50, 53, "v"], [65, 66, "p"], [70, 74, "v"], [78, 79, "a"], [83, 83, "v"], [85, 86, "p"]], [[95, 95, "a"], [105, 105, "v"]], [[132, 132, "v"], [136, 136, "v"], [142, 142, "v"], [155, 155, "v"], [158, 158, "v"], [163, 163, "v"]], [[175, 175, "v"], [176, 176, "p"], [179, 179, "v"], [182, 182, "v"]]], "predicted_relations": [[[16, 17, 4, 4, "USED-FOR"], [16, 17, 6, 6, "USED-FOR"], [16, 17, 12, 13, "USED-FOR"], [20, 21, 4, 4, "USED-FOR"], [20, 21, 6, 6, "USED-FOR"], [20, 21, 12, 13, "USED-FOR"], [12, 13, 4, 4, "USED-FOR"], [12, 13, 6, 6, "USED-FOR"], [12, 13, 12, 13, "USED-FOR"]], [], [[83, 83, 78, 79, "USED-FOR"], [83, 83, 83, 83, "USED-FOR"], [83, 83, 44, 45, "USED-FOR"], [83, 83, 65, 66, "USED-FOR"], [83, 83, 83, 83, "USED-FOR"], [83, 83, 59, 61, "USED-FOR"], [83, 83, 78, 79, "USED-FOR"], [78, 79, 78, 79, "USED-FOR"], [78, 79, 65, 66, "USED-FOR"]], [], [[145, 146, 123, 126, "USED-FOR"]], []]}
{"doc_key": "1906.07093-21b7b78f-4f07-4288-aefc-3cd981a0dfc4", "sentences": [["For", "multilingual", "adversarial", "training", ",", "we", "use", "2", "bidirectional", "LSTM", "layers", "each", "with", "200", "memory", "units", "in", "each", "direction", "as", "the", "shared", "layers", ",", "2", "bidirectional", "LSTM", "layers", "of", "200", "cells", "each", "direction", "as", "AM", "layers", "for", "each", "language", ",", "and", "1", "bidirectional", "LSTM", "layer", "with", "128", "cells", "each", "direction", "for", "LID", "."], ["The", "AM", "layers", "of", "a", "particular", "language", "will", "be", "updated", "only", "when", "the", "corresponding", "training", "data", "is", "presented", "."], ["In", "training", "of", "the", "adversarial", "layers", ",", "we", "removed", "silence", "frames", "which", "does", "not", "contain", "any", "language", "information", "."], ["An", "adversarial", "weight", "-LRB-", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "-RRB-", "of", "1", "is", "multiplied", "with", "the", "reversed", "gradients", "."], ["We", "have", "also", "tried", "other", "weights", "and", "that", "does", "not", "significantly", "change", "the", "performance", "."], ["Our", "training", "is", "done", "in", "parallel", "on", "CPUs", "using", "asynchronous", "stochastic", "gradient", "descent", "-LRB-", "ASGD", "-RRB-", "training", "described", "in", "-LSB-", "2", "-RSB-", ",", "-LSB-", "4", "-RSB-", ",", "-LSB-", "3", "-RSB-", ",", "-LSB-", "6", "-RSB-", "."], ["We", "choose", "the", "best", "model", "to", "be", "the", "one", "with", "highest", "frame", "accuracy", "on", "the", "development", "set", "."], ["The", "frame", "accuracy", "is", "calculated", "by", "uniformly", "sampling", "utterances", "from", "different", "languages", "."], ["For", "decoding", ",", "a", "standard", "5-gram", "language", "model", "is", "trained", "."]], "ner": [[[8, 9, "a"], [25, 26, "a"], [42, 43, "a"], [14, 15, "p"], [13, 13, "v"], [29, 29, "v"], [46, 46, "v"], [30, 30, "p"], [47, 47, "p"], [13, 13, "v"], [29, 29, "v"], [46, 46, "v"], [41, 41, "v"]], [], [], [[92, 93, "a"], [97, 97, "p"], [102, 102, "v"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"], [9, 9, "a"], [13, 13, "v"], [24, 24, "v"], [26, 26, "a"], [29, 29, "v"], [41, 41, "v"], [43, 43, "a"], [46, 46, "v"]], [], [], [[102, 102, "v"]], [], [[134, 140, "a"]], [[168, 168, "v"]], [], [[196, 196, "v"]]], "predicted_relations": [[[29, 29, 30, 30, "USED-FOR"], [30, 30, 8, 9, "USED-FOR"], [30, 30, 25, 26, "USED-FOR"], [30, 30, 42, 43, "USED-FOR"], [47, 47, 8, 9, "USED-FOR"], [47, 47, 25, 26, "USED-FOR"], [47, 47, 42, 43, "USED-FOR"], [29, 29, 30, 30, "USED-FOR"], [41, 41, 47, 47, "USED-FOR"]], [], [], [[97, 97, 92, 93, "USED-FOR"], [102, 102, 97, 97, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1906.06874-5a8d7098-0867-46c2-8a10-697040ee128d", "sentences": [["Different", "from", "DBPN", "-LSB-", "9", "-RSB-", "which", "has", "different", "structures", "and", "configurations", "for", "different", "up-sampling", "enlargement", ",", "the", "proposed", "HBPN", "network", "uses", "the", "same", "structure", "as", "shown", "in", "Figure", "REF", "."], ["In", "UBP", "and", "DBP", "blocks", ",", "we", "use", "\\", "-LRB-", "6\\times", "6\\", "-RRB-", "convolution", "filters", "with", "two", "striding", "and", "two", "padding", "for", "down-", "and", "up-sampling", "."], ["For", "shortcut", "connections", ",", "we", "use", "\\", "-LRB-", "3\\times", "3\\", "-RRB-", "convolution", "filters", "with", "one", "striding", "and", "1", "padding", "."], ["We", "initialize", "the", "weights", "based", "on", "-LSB-", "11", "-RSB-", "."], ["The", "testing", "data", "include", "Set5", "-LSB-", "2", "-RSB-", ",", "Set14", "-LSB-", "33", "-RSB-", ",", "BSD100", "-LSB-", "1", "-RSB-", ",", "Urban100", "-LSB-", "12", "-RSB-", "and", "Manga109", "-LSB-", "22", "-RSB-", "on", "\\", "-LRB-", "2\\times", "\\", "-RRB-", ",", "\\", "-LRB-", "4\\times", "\\", "-RRB-", "and", "\\", "-LRB-", "8\\times", "\\", "-RRB-", "SR", "enlargement", "."]], "ner": [[[2, 2, "a"], [19, 20, "a"]], [[44, 45, "p"]], [[68, 69, "p"]], [], [[91, 91, "a"], [96, 96, "a"], [101, 101, "a"], [106, 106, "a"], [111, 111, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [19, 20, "a"]], [[42, 42, "v"], [47, 47, "v"], [50, 50, "v"]], [[66, 66, "v"], [71, 71, "v"], [74, 74, "v"]], [], [[91, 91, "a"], [96, 96, "a"], [101, 101, "a"], [106, 106, "a"], [111, 111, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1905.09418-f7fe912a-26ca-4497-a2c4-7e2298ec1da3", "sentences": [["We", "follow", "the", "setup", "of", "Transformer", "base", "model", "-LSB-", "31", "-RSB-", "."], ["More", "precisely", ",", "the", "number", "of", "layers", "in", "the", "encoder", "and", "in", "the", "decoder", "is", "\\", "-LRB-", "N=6\\", "-RRB-", "."], ["We", "employ", "\\", "-LRB-", "h", "=", "8\\", "-RRB-", "parallel", "attention", "layers", ",", "or", "heads", "."], ["The", "dimensionality", "of", "input", "and", "output", "is", "\\", "-LRB-", "d_", "-LCB-", "model", "-RCB-", "=", "512\\", "-RRB-", ",", "and", "the", "inner-layer", "of", "a", "feed-forward", "networks", "has", "dimensionality", "\\", "-LRB-", "d_", "-LCB-", "ff", "-RCB-", "=2048\\", "-RRB-", "."]], "ner": [[[5, 7, "a"]], [[16, 25, "p"], [29, 29, "v"]], [[38, 38, "v"]], [[48, 52, "p"], [61, 61, "v"], [79, 79, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 7, "a"]], [[29, 29, "v"]], [[36, 38, "v"]], [[61, 61, "v"], [69, 70, "a"], [75, 78, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1911.06172-86af3020-42a6-45d3-8365-05d8050c7f66", "sentences": [["The", "Bi-GRU", "and", "feed-forward", "models", "were", "trained", "with", "a", "batch", "size", "of", "80", "and", "a", "learning", "rate", "of", "0.1", "."], ["The", "models", "were", "optimised", "using", "momentum-based", "SGD", "-LRB-", "\\", "-LRB-", "\\beta", "=", "0.9\\", "-RRB-", "-RRB-", "."], ["The", "Bi-GRU", "models", "were", "trained", "with", "2", "GRU", "layers", "of", "512", "neurons", "each", ",", "with", "50", "%", "dropout", "."], ["The", "character-level", "Bi-GRU", "models", "had", "a", "character", "embedding", "dimension", "of", "100", "."]], "ner": [[[1, 1, "a"], [9, 10, "p"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"], [1, 1, "a"]], [[26, 26, "a"], [30, 30, "p"], [32, 32, "v"]], [[37, 37, "a"], [37, 37, "a"], [43, 43, "a"], [47, 47, "p"], [46, 46, "v"], [53, 53, "p"]], [[57, 57, "a"], [57, 57, "a"], [61, 62, "a"], [63, 63, "p"], [65, 65, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"], [9, 10, "p"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"]], [[26, 26, "a"], [32, 32, "v"]], [[37, 37, "a"], [42, 42, "v"], [43, 43, "a"], [43, 44, "p"], [46, 46, "v"], [47, 47, "p"], [51, 52, "v"], [53, 53, "p"]], [[57, 57, "a"], [65, 65, "v"]]], "predicted_relations": [[[9, 10, 1, 1, "USED-FOR"], [9, 10, 1, 1, "USED-FOR"]], [[30, 30, 26, 26, "USED-FOR"]], [[47, 47, 37, 37, "USED-FOR"], [47, 47, 37, 37, "USED-FOR"], [47, 47, 43, 43, "USED-FOR"]], [[63, 63, 57, 57, "USED-FOR"], [63, 63, 57, 57, "USED-FOR"], [63, 63, 61, 62, "USED-FOR"], [65, 65, 63, 63, "USED-FOR"]]]}
{"doc_key": "1902.00842-a1d1cbd4-e490-4c61-8846-45c4eccf3846", "sentences": [["We", "train", "our", "neural", "network", "using", "Stochastic", "Gradient", "Descent", "using", "the", "Adam", "optimizer", "with", "binary", "crossentropy", "as", "a", "loss", "function", "."], ["We", "use", "a", "variation", "of", "the", "``", "poly", "''", "learning", "rate", "decay", "policy", "proposed", "in", "-LSB-", "11", "-RSB-", ":", "\\", "-LRB-", "LR", "-LRB-", "\\text", "-LCB-", "epoch", "-RCB-", "-RRB-", "=", "0.0006", "\\cdot", "\\left", "-LRB-", "\\frac", "-LCB-", "1000", "-", "\\text", "-LCB-", "epoch", "-RCB-", "-RCB-", "-LCB-", "1000", "-RCB-", "\\right", "-RRB-", "^", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-"]], "ner": [[[6, 8, "a"], [11, 12, "a"], [14, 15, "a"]], []], "relations": [[], []], "predicted_ner": [[[3, 4, "a"], [6, 8, "a"], [11, 11, "a"], [14, 15, "a"]], [[42, 42, "a"], [50, 50, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1910.01738-a5edeba1-2ea2-4b03-9727-51a1aca519a3", "sentences": [["A", "set", "of", "instances", "of", "tasks", "\\", "-LRB-", "T^i\\", "-RRB-", ",", "\\", "-LRB-", "i\\in", "\\lbrace", "1", ",", "\\dots", ",", "K\\rbrace", "\\", "-RRB-", ",", "and", "for", "each", "of", "them", "a", "set", "of", "demonstrations", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "^i", "=", "\\lbrace", "-LRB-", "I_", "-LCB-", "t-1", "-RCB-", "^i", ",", "I_t^i", ",", "\\mathbf", "-LCB-", "a", "-RCB-", "^i_t", "-RRB-", "\\rbrace", "_", "-LCB-", "t", "-RCB-", "\\", "-RRB-", "."], ["A", "randomly", "initialized", "neural", "network", "following", "the", "architecture", "described", "in", "Figure", "REF", "with", "weights", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "."]], "ner": [[], [[67, 68, "a"], [77, 77, "p"]]], "relations": [[], []], "predicted_ner": [[], []], "predicted_relations": [[], [[77, 77, 67, 68, "USED-FOR"]]]}
{"doc_key": "1910.01738-2ccbcaae-0396-404c-8366-c64a99d245dc", "sentences": [["\\", "-LRB-", "epoch=1\\", "-RRB-", "to", "\\", "-LRB-", "M\\", "-RRB-", "\\", "-LRB-", "step=1\\", "-RRB-", "to", "\\", "-LRB-", "N\\", "-RRB-", "Pick", "randomly", "\\", "-LRB-", "i", "\\in", "\\lbrace", "1", ",", "\\dots", ",", "K\\rbrace", "\\", "-RRB-", "."], ["Pick", "a", "random", "subset", "of", "samples", "to", "form", "a", "batch", "\\", "-LRB-", "\\mathcal", "-LCB-", "B", "-RCB-", "^i\\subset", "\\mathcal", "-LCB-", "D", "-RCB-", "^i\\", "-RRB-", "."], ["Adjust", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "with", "a", "gradient", "descent", "step", "on", "the", "following", "expression", "to", "minimize", ":", "\\", "-LRB-", "\\mathbb", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\mathcal", "-LCB-", "B", "-RCB-", "^i", "-RCB-", "\\left", "-LSB-", "\\Vert", "\\psi", "^i", "-LRB-", "\\varphi", "_t^i", ",", "\\Delta", "\\varphi", "^i_t", "-RRB-", "-", "\\mathbf", "-LCB-", "a", "-RCB-", "^i_t", "\\Vert", "^2_2\\right", "-RSB-", ".\\", "-RRB-"]], "ner": [[[2, 2, "p"], [2, 2, "v"], [11, 11, "v"], [25, 25, "v"], [7, 7, "v"], [11, 11, "p"], [2, 2, "v"], [11, 11, "v"], [25, 25, "v"], [16, 16, "v"]], [], [[67, 67, "p"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[65, 66, "a"]]], "predicted_relations": [[[2, 2, 2, 2, "USED-FOR"], [11, 11, 2, 2, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [7, 7, 2, 2, "USED-FOR"], [2, 2, 2, 2, "USED-FOR"], [11, 11, 2, 2, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [16, 16, 2, 2, "USED-FOR"]], [], []]}
{"doc_key": "1910.01738-fa14ffc4-44ab-43e0-b5a7-f936a3a4966d", "sentences": [["An", "instance", "of", "this", "task", "is", "parameterized", "by", "the", "position", "of", "a", "goal", "that", "the", "end-effector", "of", "the", "robot", "must", "reach", "within", "some", "margin", "of", "error", "-LRB-", "and", "in", "limited", "time", "-RRB-", "."], ["We", "use", "as", "raw", "inputs", "grayscale", "images", "of", "\\", "-LRB-", "64", "\\times", "64\\", "-RRB-", "pixels", "."], ["To", "increase", "the", "difficulty", "of", "the", "learning", ",", "in", "some", "cases", "we", "add", "a", "randomly", "moving", "distractor", "and", "Gaussian", "noise", ",", "as", "shown", "on", "Figure", "REF", "."]], "ner": [[[9, 12, "a"]], [], [[63, 65, "a"], [67, 68, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [[43, 43, "v"], [45, 45, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1910.01738-bd3472f4-d5d0-4008-8cbb-14c98b4f094e", "sentences": [["Generating", "demonstrations", ":", "For", "simplicity", ",", "we", "allow", "the", "target", "policies", "to", "have", "access", "to", "the", "ground", "truth", "state", "of", "the", "robot", "\\", "-LRB-", "-LRB-", "\\mathbf", "-LCB-", "q", "-RCB-", ",", "\\mathbf", "-LCB-", "\\dot", "-LCB-", "q", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "\\mathbf", "-LCB-", "q", "-RCB-", "\\", "-RRB-", "is", "the", "configuration", "of", "the", "robot", "arm", ",", "represented", "as", "a", "vector", "of", "size", "4", ":", "\\", "-LRB-", "-LRB-", "\\cos", "\\alpha", "_1", ",", "\\sin", "\\alpha", "_1", ",", "\\cos", "\\alpha", "_2", ",", "\\sin", "\\alpha", "_2", "-RRB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\alpha", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "_2\\", "-RRB-", "being", "respectively", "the", "first", "and", "second", "joint", "angles", "in", "radians", "."], ["To", "construct", "the", "target", "policies", ",", "we", "run", "the", "Hindsight", "Experience", "Replay", "-LRB-", "HER", "-RRB-", "RL", "algorithm", "-LSB-", "35", "-RSB-", "that", "also", "exploits", "the", "\\", "-LRB-", "-LRB-", "x", ",", "y", "-RRB-", "\\", "-RRB-", "parameters", "of", "the", "goal", "position", "."], ["It", "returns", "a", "parameterized", "policy", "capable", "of", "producing", "reaching", "motions", "to", "any", "reachable", "goal", "position", "."], ["Note", "that", "the", "purpose", "of", "our", "method", "is", "to", "generate", "state", "representation", "from", "-LRB-", "possibly", "noisy", "-RRB-", "inputs", "that", "are", "hard", "to", "exploit", "-LRB-", "such", "as", "raw", "images", "-RRB-", ",", "so", "access", "to", "the", "robot", "state", "is", "only", "given", "to", "the", "target", "policies", "that", "generate", "demonstrations", "."], ["The", "demonstration", "data", "used", "to", "train", "SRLfD", "consists", "of", "16", "different", "instances", "of", "the", "reaching", "task", ",", "with", "for", "each", "of", "them", "262", "trajectories", "computed", "from", "various", "initial", "positions", "using", "the", "target", "policy", "obtained", "with", "HER", "."]], "ner": [[], [[119, 126, "a"]], [], [], [[226, 227, "a"], [218, 218, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[64, 64, "v"]], [[119, 126, "a"]], [], [[171, 171, "a"]], [[218, 218, "a"], [221, 221, "v"], [234, 234, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1910.06044-f0df0644-f409-400b-a8ff-0fbcc81551f1", "sentences": [["For", "the", "impact", "of", "different", "batch", "sizes", "shown", "in", "Figure", "REF", ",", "we", "can", "observe", "that", "success", "rate", "hits", "the", "bottom", "-LRB-", "\\", "-LRB-", "82\\", "%", "\\", "-RRB-", "-RRB-", "when", "the", "batch", "size", "is", "set", "to", "relatively", "small", ",", "and", "reaches", "a", "relatively", "high", "level", "-LRB-", "\\", "-LRB-", "94\\", "%", "\\", "-RRB-", "-RRB-", "with", "batch", "size", "at", "20", "."], ["As", "we", "know", ",", "the", "batch", "size", "in", "training", "should", "not", "be", "set", "too", "small", "as", "it", "may", "lead", "to", "more", "calculation", "iterations", "and", "cause", "the", "model", "perform", "bad", "."], ["Hence", ",", "we", "think", "Class", "Sniffing", "should", "be", "effective", "under", "common", "batch", "size", "settings", "."]], "ner": [[[31, 32, "a"], [54, 55, "a"]], [[64, 65, "a"]], [[100, 101, "a"], [93, 94, "a"]]], "relations": [[], [], []], "predicted_ner": [[[24, 25, "v"], [48, 49, "v"], [57, 57, "v"]], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1910.06262-7403f08d-4bd7-485b-bbad-3d1555089b53", "sentences": [["The", "language", "modelling", "LSTM", "network", "consists", "of", "2-layers", "with", "1024", "hidden", "units", "and", "an", "equally", "sized", "character", "embedding", "space", "."], ["The", "parameters", "were", "trained", "using", "Adam", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "2\\cdot", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "a", "decay", "of", "\\", "-LRB-", "0.95\\", "-RRB-", ",", "gradient", "norm", "clipping", "of", "5", ",", "and", "dropout", "probability", "\\", "-LRB-", "0.2\\", "-RRB-", "for", "the", "inputs", "and", "the", "hidden", "layers", "."]], "ner": [[[3, 4, "a"]], [[28, 29, "p"], [42, 42, "p"], [46, 46, "v"], [49, 51, "p"], [53, 53, "v"], [56, 57, "p"], [60, 60, "v"], [25, 25, "a"]]], "relations": [[], []], "predicted_ner": [[[3, 4, "a"], [9, 9, "v"], [10, 11, "p"]], [[25, 25, "a"], [28, 29, "p"], [42, 42, "p"], [46, 46, "v"], [49, 51, "p"], [53, 53, "v"], [56, 57, "p"], [60, 60, "v"]]], "predicted_relations": [[], [[28, 29, 25, 25, "USED-FOR"], [42, 42, 25, 25, "USED-FOR"], [46, 46, 49, 51, "USED-FOR"], [49, 51, 25, 25, "USED-FOR"], [53, 53, 49, 51, "USED-FOR"], [60, 60, 49, 51, "USED-FOR"], [60, 60, 56, 57, "USED-FOR"]]]}
{"doc_key": "1910.06251-b26d148f-85e9-47fb-8a2d-96933c9fc265", "sentences": [["ReLU", "was", "used", "for", "activation", "throughout", "the", "experiments", "."], ["For", "tasks", "with", "output", "at", "every", "timestep", "such", "as", "the", "language", "modeling", "problem", "in", "Subsection", "REF", ",", "the", "recurrent", "weights", "of", "all", "layers", "were", "initialized", "uniformly", "in", "the", "range", "\\", "-LRB-", "-LSB-", "0", ",", "\\", "@", "root", "-LRB-", "T-t", "-RRB-", "\\of", "-LCB-", "\\gamma", "-RCB-", "-RSB-", "\\", "-RRB-", ",", "while", "for", "tasks", "such", "as", "classification", "where", "only", "the", "output", "at", "the", "last", "time", "step", "in", "the", "last", "layer", "is", "used", ",", "the", "recurrent", "weights", "of", "the", "last", "layer", "were", "initialized", "uniformly", "in", "the", "range", "\\", "-LRB-", "-LSB-", "\\", "@", "root", "-LRB-", "T-t", "-RRB-", "\\of", "-LCB-", "\\epsilon", "-RCB-", ",", "\\", "@", "root", "-LRB-", "T-t", "-RRB-", "\\of", "-LCB-", "\\gamma", "-RCB-", "-RSB-", "\\", "-RRB-", "as", "described", "in", "Subsection", "REF", "."], ["The", "recurrent", "weights", "are", "constrained", "to", "be", "in", "the", "range", "of", "\\", "-LRB-", "|u_n|\\le", "\\", "@", "root", "-LRB-", "T-t", "-RRB-", "\\of", "-LCB-", "\\gamma", "-RCB-", "\\", "-RRB-", "for", "IndRNN", "with", "ReLU", "as", "analysed", "in", "Subsection", "REF", "."], ["This", "is", "especially", "important", "in", "processing", "long", "sequences", "where", "a", "small", "change", "of", "recurrent", "weights", "may", "significantly", "change", "the", "gradients", "."], ["In", "our", "experiments", ",", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "is", "simply", "set", "to", "\\", "-LRB-", "1.0\\", "-RRB-", "for", "long", "sequences", "since", "\\", "-LRB-", "\\", "@", "root", "-LRB-", "T-t", "-RRB-", "\\of", "-LCB-", "\\gamma", "-RCB-", "\\", "-RRB-", "is", "already", "close", "to", "1", "when", "\\", "-LRB-", "T\\", "-RRB-", "is", "very", "large", "."], ["For", "short", "sequences", "such", "as", "20", "steps", ",", "the", "constraint", "can", "also", "be", "removed", "as", "the", "gradient", "exploding", "problem", "is", "not", "very", "severe", "in", "such", "cases", "."], ["We", "have", "also", "conducted", "an", "ablation", "study", "on", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", ",", "which", "also", "verifies", "that", "the", "performance", "is", "not", "very", "sensitive", "to", "the", "setting", "of", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "as", "long", "as", "it", "is", "in", "a", "reasonable", "range", "-LRB-", "values", "in", "\\", "-LRB-", "-LSB-", "1,10", "-RSB-", "\\", "-RRB-", "for", "example", "-RRB-", "."]], "ner": [[[0, 0, "a"]], [[37, 37, "p"], [91, 91, "p"], [51, 51, "p"], [114, 114, "p"]], [[154, 154, "a"], [134, 134, "p"], [147, 147, "p"]], [[167, 168, "c"]], [[197, 197, "v"], [188, 188, "p"], [213, 213, "p"], [200, 201, "c"]], [[240, 240, "p"]], [[299, 299, "p"], [268, 268, "p"], [288, 288, "p"], [263, 264, "c"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[41, 41, "v"]], [[152, 152, "a"], [154, 154, "a"]], [], [[188, 188, "p"], [197, 197, "v"], [221, 221, "v"], [225, 225, "p"]], [[236, 236, "v"]], [[268, 268, "p"], [288, 288, "p"]]], "predicted_relations": [[], [], [[134, 134, 154, 154, "USED-FOR"]], [], [[200, 201, 197, 197, "USED-FOR"]], [], []]}
{"doc_key": "1910.06251-489946f1-744f-4d26-9a1f-de3d0f284b82", "sentences": [["To", "accelerate", "training", ",", "batch", "normalization", "was", "used", "except", "in", "the", "simple", "adding", "problem", "."], ["Moreover", ",", "for", "classification", "tasks", "where", "the", "whole", "sequence", "is", "processed", "for", "output", "at", "the", "final", "time", "step", ",", "the", "statistics", "used", "in", "the", "batch", "normalization", "layer", "were", "obtained", "based", "on", "the", "samples", "at", "all", "time", "steps", ",", "while", "for", "other", "tasks", "such", "as", "language", "modeling", "which", "can", "not", "access", "information", "from", "future", "time", "steps", ",", "the", "statistics", "are", "obtained", "based", "on", "all", "the", "samples", "in", "each", "time", "step", "."], ["When", "dropout", "is", "applied", ",", "the", "dropout", "mask", "is", "shared", "over", "time", "to", "avoid", "the", "clipping", "of", "long", "memory", "."], ["Weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "is", "used", "for", "the", "weight", "parameters", "-LRB-", "without", "applying", "to", "the", "recurrent", "weight", "and", "bias", "-RRB-", "."], ["All", "the", "networks", "were", "trained", "using", "the", "Adam", "optimization", "method", "-LSB-", "50", "-RSB-", "with", "initial", "learning", "rate", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "learning", "rate", "is", "reduced", "by", "a", "factor", "of", "5", "when", "the", "accuracy", "-LRB-", "or", "loss", "-RRB-", "on", "the", "validation", "data", "no", "longer", "improves", "-LRB-", "drops", "-RRB-", "-LRB-", "with", "patience", "set", "to", "100", "-RRB-", "."]], "ner": [[[4, 5, "a"]], [[39, 40, "a"], [35, 35, "p"], [72, 72, "p"]], [[91, 92, "p"]], [[120, 121, "p"]], [[140, 142, "a"], [147, 149, "p"]], [[169, 169, "v"], [189, 189, "p"], [192, 192, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"]], [[39, 40, "a"]], [[86, 86, "a"]], [[105, 106, "p"], [110, 112, "v"]], [[140, 140, "a"], [148, 149, "p"], [153, 155, "v"]], [[161, 162, "p"], [169, 169, "v"], [192, 192, "v"]]], "predicted_relations": [[], [], [], [], [[147, 149, 140, 142, "USED-FOR"]], [[169, 169, 189, 189, "USED-FOR"], [192, 192, 189, 189, "USED-FOR"]]]}
{"doc_key": "1910.06251-a3dadc62-38a0-45ad-b069-1700cfc1f90a", "sentences": [["For", "the", "densely", "connected", "IndRNN", ",", "the", "network", "shape", "was", "simply", "following", "the", "conventional", "denseCNN", "-LSB-", "36", "-RSB-", "."], ["Each", "dense", "layer", "-LRB-", "the", "non-linear", "transformation", "function", "-RRB-", "consists", "of", "two", "composite", "functions", "as", "shown", "in", "Fig", "."], ["REF", "and", "produces", "k", "feature", "maps", ",", "termed", "as", "the", "growth", "rate", "."], ["The", "first", "composite", "function", "is", "called", "the", "bottleneck", "layer", "and", "the", "number", "of", "neurons", "is", "set", "to", "four", "times", "-LRB-", "4", "*", "k", "-RRB-", "the", "growth", "rate", "."], ["For", "each", "transition", "layer", ",", "the", "number", "of", "the", "neurons", "is", "set", "to", "be", "the", "half", "-LRB-", "50", "%", "-RRB-", "of", "the", "input", "feature", "maps", "."], ["The", "dense", "block", "configuration", "is", "set", "to", "-LRB-", "8,6,4", "-RRB-", ",", "where", "in", "the", "first", ",", "second", "and", "third", "dense", "block", ",", "8", ",", "6", "and", "4", "dense", "layers", "are", "used", ",", "respectively", "."], ["This", "keeps", "a", "relatively", "similar", "number", "of", "neurons", "in", "each", "dense", "block", "."], ["Note", "that", "it", "is", "different", "from", "the", "denseCNN", "-LSB-", "36", "-RSB-", "because", "the", "tasks", "in", "the", "following", "experiments", "do", "not", "concern", "pooling", "-LRB-", "which", "reduces", "the", "size", "of", "the", "features", "-RRB-", "."], ["For", "the", "whole", "network", ",", "one", "IndRNN", "layer", "with", "six", "times", "-LRB-", "6", "*", "k", "-RRB-", "the", "growth", "rate", "are", "used", "to", "process", "the", "input", "first", "before", "going", "through", "the", "following", "dense", "layers", "."], ["In", "the", "following", ",", "the", "residual", "IndRNN", "and", "the", "densely", "connected", "IndRNN", "are", "noted", "as", "res-IndRNN", "and", "dense-IndRNN", ",", "respectively", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[2, 4, "a"], [2, 4, "a"]], [], [[48, 49, "p"], [41, 41, "v"]], [[76, 77, "p"], [73, 73, "v"], [58, 59, "p"], [71, 73, "v"]], [[81, 82, "p"]], [[106, 108, "p"]], [], [], [[201, 202, "p"], [198, 198, "v"], [190, 191, "p"], [196, 198, "v"]], [[227, 229, "a"], [223, 224, "a"], [227, 229, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [14, 14, "a"]], [[30, 30, "v"]], [[41, 41, "v"]], [[68, 68, "v"], [71, 71, "v"], [73, 73, "p"]], [[96, 97, "v"]], [[127, 127, "v"], [129, 129, "v"], [131, 131, "v"]], [], [[159, 159, "a"]], [[189, 189, "v"], [190, 190, "a"], [193, 193, "v"], [196, 196, "v"], [198, 198, "p"]], [[224, 224, "a"], [229, 229, "a"], [233, 233, "a"], [235, 235, "a"]], []], "predicted_relations": [[], [], [], [[73, 73, 76, 77, "USED-FOR"], [71, 73, 76, 77, "USED-FOR"]], [], [], [], [], [[198, 198, 201, 202, "USED-FOR"], [196, 198, 201, 202, "USED-FOR"]], [], []]}
{"doc_key": "1909.05357-a3ea484f-65c3-4a54-80be-e356c6d683f2", "sentences": [["We", "follow", "the", "same", "architecture", "as", "proposed", "in", "-LSB-", "12", "-RSB-", "for", "the", "LSTM-Autoencoder", "."], ["In", "LSTM", ",", "we", "set", "the", "input", "embedding", "dimension", "as", "100", "and", "hidden", "as", "200", "."], ["We", "use", "RMSprop", "as", "the", "optimizer", "with", "a", "learning", "rate", "of", "0.001", "."], ["We", "train", "the", "LSTM", "with", "a", "batch", "size", "of", "32", "and", "100", "epochs", "."], ["For", "Autoencoder", ",", "we", "set", "the", "hidden", "size", "as", "20", "."], ["We", "use", "Adam", "as", "the", "optimizer", "with", "a", "learning", "rate", "of", "0.001", "."], ["We", "train", "the", "model", "with", "a", "batch", "size", "of", "32", "for", "10", "epochs", "."]], "ner": [[[13, 13, "a"]], [[16, 16, "a"], [21, 23, "p"], [25, 25, "v"], [27, 27, "p"], [29, 29, "v"]], [[33, 33, "a"], [39, 40, "p"], [42, 42, "v"], [39, 40, "p"], [42, 42, "v"]], [[47, 47, "a"], [55, 55, "v"]], [[64, 64, "p"]], [[77, 78, "p"], [80, 80, "v"], [71, 71, "a"], [77, 78, "p"], [80, 80, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "a"]], [[16, 16, "a"], [25, 25, "v"], [29, 29, "v"]], [[33, 33, "a"], [39, 40, "p"], [42, 42, "v"]], [[47, 47, "a"], [50, 51, "p"], [53, 53, "v"], [55, 55, "v"], [56, 56, "p"]], [[59, 59, "a"], [64, 65, "p"], [67, 67, "v"]], [[71, 71, "a"], [77, 78, "p"], [80, 80, "v"]], [[88, 89, "p"], [91, 91, "v"], [93, 93, "v"], [94, 94, "p"]]], "predicted_relations": [[], [[21, 23, 16, 16, "USED-FOR"], [25, 25, 27, 27, "USED-FOR"], [29, 29, 27, 27, "USED-FOR"]], [[39, 40, 33, 33, "USED-FOR"], [39, 40, 33, 33, "USED-FOR"]], [], [], [[77, 78, 71, 71, "USED-FOR"], [77, 78, 71, 71, "USED-FOR"]], []]}
{"doc_key": "1909.05357-27d0faa2-7130-42c8-b16a-797702c15bd4", "sentences": [["For", "vanilla", "CNN", ",", "we", "use", "the", "most", "common", "CNN", "architecture", "used", "in", "NLP", "tasks", ",", "where", "the", "convolutional", "layer", "on", "top", "of", "word", "embedding", "has", "128", "filters", "followed", "by", "a", "ReLU", "and", "max", "pooling", "layer", "before", "the", "final", "softmax", "."], ["We", "use", "Adam", "as", "the", "optimizer", "with", "a", "learning", "rate", "of", "0.001", "."], ["We", "train", "the", "model", "with", "a", "batch", "size", "64", "for", "100", "epochs", "."]], "ner": [[[1, 2, "a"]], [[43, 43, "a"]], [[65, 65, "p"], [64, 64, "v"], [60, 61, "a"], [65, 65, "a"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [9, 9, "a"], [26, 26, "v"], [31, 31, "a"], [33, 34, "a"], [39, 39, "a"]], [[43, 43, "a"], [49, 50, "p"], [52, 52, "v"]], [[57, 57, "a"], [60, 61, "p"], [62, 62, "v"], [64, 64, "v"], [65, 65, "p"]]], "predicted_relations": [[], [], [[65, 65, 60, 61, "USED-FOR"], [65, 65, 65, 65, "USED-FOR"], [64, 64, 65, 65, "USED-FOR"]]]}
{"doc_key": "1909.05357-530d6844-c1cf-4487-8e0a-52350a2dc860", "sentences": [["Our", "proposed", "model", "O-Proto", "uses", "the", "similar", "CNN", "architecture", ",", "the", "optimizer", "and", "the", "learning", "rate", "in", "the", "previous", "Vanilla", "CNN", "."], ["The", "input", "word", "embeddings", "are", "pre-trained", "by", "1-billion-token", "Wikipedia", "corpus", "."], ["We", "set", "the", "batch", "size", "as", "10", "."], ["In", "Eq", "."], ["REF", ",", "REF", ",", "REF", "and", "REF", ",", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", ",", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_2\\", "-RRB-", "are", "hyper-parameters", ",", "which", "we", "fix", "\\", "-LRB-", "\\beta", "\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "as", "1.0", "by", "default", ",", "and", "set", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_2\\", "-RRB-", "as", "10.0", ",", "0.4", "and", "0.8", "according", "to", "the", "meta-valid", "performance", "of", "Amazon", "dataset", "."], ["The", "sentence", "encoder", ",", "CNN", ",", "has", "200", "filters", ",", "followed", "by", "a", "tanh", "and", "mean", "pooling", "layer", "before", "the", "final", "regression", "layer", "."], ["The", "maximum", "length", "of", "tokens", "per", "example", "is", "40", ",", "and", "any", "words", "out", "of", "this", "range", "will", "be", "discarded", "."], ["During", "training", ",", "we", "set", "the", "size", "of", "sampled", "negative", "labels", "Step", "3", "-LRB-", "section", "3.1", "-RRB-", "to", "at", "most", "four", ",", "so", "there", "will", "be", "maximum", "five", "labels", "involved", "in", "a", "training", "step", "-LRB-", "1", "positive", ",", "4", "negative", "-RRB-", "."], ["The", "supporting", "set", "size", "for", "each", "label", "are", "20", "."]], "ner": [[[19, 20, "a"], [7, 7, "a"], [20, 20, "a"]], [[29, 31, "a"]], [], [], [[88, 88, "a"], [54, 54, "p"], [113, 113, "p"], [135, 135, "v"], [137, 137, "v"], [139, 139, "v"]], [[153, 153, "a"], [162, 162, "a"], [164, 165, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [3, 3, "a"], [7, 7, "a"], [14, 15, "p"], [19, 20, "a"]], [[29, 29, "v"]], [[36, 37, "p"], [39, 39, "v"]], [], [[54, 54, "p"], [60, 60, "p"], [66, 66, "p"], [95, 95, "p"], [101, 101, "p"], [105, 105, "v"], [113, 113, "p"], [135, 135, "v"], [137, 137, "v"], [139, 139, "v"], [146, 147, "a"]], [[153, 153, "a"], [156, 156, "v"], [162, 162, "a"], [164, 165, "a"]], [[181, 181, "v"]], [[206, 206, "v"], [214, 214, "v"], [221, 221, "v"], [229, 229, "v"], [232, 232, "v"]], [[244, 244, "v"]]], "predicted_relations": [[], [], [], [], [[54, 54, 88, 88, "USED-FOR"], [113, 113, 88, 88, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1910.01335-64b07519-9490-473f-bfc9-94e8ad610fe0", "sentences": [["In", "our", "setup", ",", "for", "both", "the", "encoder", "and", "decoder", ",", "the", "dimension", "of", "word", "embeddings", "and", "hidden", "states", "was", "set", "to", "200", "."], ["We", "adopted", "pre-trained", "word", "embedding", "Glove", "-LSB-", "18", "-RSB-", ",", "and", "out-of-vocabulary", "words", "and", "segment", "labels", "were", "initiated", "with", "random", "vectors", "."], ["Embedding", "weight", "sharing", "strategy", "was", "applied", "by", "sharing", "the", "same", "embedding", "matrix", "\\", "-LRB-", "W_", "-LCB-", "emb", "-RCB-", "\\", "-RRB-", "for", "both", "encoder", "and", "decoder", "."], ["This", "sharing", "significantly", "reduced", "parameter", "size", "and", "boosted", "the", "performance", "by", "reusing", "the", "semantic", "and", "syntactic", "information", "in", "one", "embedding", "space", "-LSB-", "21", "-RSB-", "."], ["The", "learning", "rate", "was", "fixed", "to", "\\", "-LRB-", "0.0001\\", "-RRB-", "and", "the", "batch", "size", "was", "set", "to", "32", "."], ["We", "adopted", "gradient", "clipping", "with", "a", "maximum", "gradient", "norm", "of", "\\", "-LRB-", "2.0\\", "-RRB-", "."], ["Adam", "algorithm", "-LSB-", "32", "-RSB-", "was", "used", "for", "stochastic", "optimization", ",", "with", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2=0.99\\", "-RRB-", "."], ["The", "vocabulary", "size", "was", "\\", "-LRB-", "10K\\", "-RRB-", "."], ["We", "limited", "source", "contents", "to", "300", "tokens", "and", "the", "decoding", "length", "to", "100", "tokens", "."], ["We", "adopted", "early-stop", "strategy", "with", "validation", "in", "each", "training", "epoch", "."], ["During", "testing", ",", "we", "set", "the", "beam", "search", "size", "to", "5", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [[27, 29, "a"]], [], [], [[98, 99, "p"], [105, 105, "v"], [109, 110, "p"], [114, 114, "v"]], [[122, 124, "p"], [128, 128, "v"]], [[131, 132, "a"], [146, 146, "v"], [149, 149, "v"], [134, 134, "v"]], [], [], [], [[193, 194, "a"], [193, 195, "p"], [197, 197, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[22, 22, "v"]], [[27, 29, "a"]], [], [[90, 90, "v"]], [[98, 99, "p"], [105, 105, "v"], [109, 110, "p"], [114, 114, "v"]], [[118, 119, "a"], [122, 124, "p"], [128, 128, "v"]], [[131, 132, "a"]], [[158, 158, "v"]], [[166, 166, "v"], [173, 173, "v"]], [], [[193, 195, "p"], [197, 197, "v"]], []], "predicted_relations": [[], [], [], [], [], [[128, 128, 122, 124, "USED-FOR"]], [], [], [], [], [[193, 195, 193, 194, "USED-FOR"], [197, 197, 193, 195, "USED-FOR"]], []]}
{"doc_key": "1910.01221-b7e57462-9d02-4773-8db9-4fbe0c12d0fa", "sentences": [["-LSB-", "!", "b", "-RSB-", "Adversarial", "training", "of", "ROMark", "Combined", "-LSB-", "l", "-RSB-", "Batch", "size", ":", "\\", "-LRB-", "b\\", "-RRB-", ",", "Learning", "Rate", ":", "\\", "-LRB-", "\\gamma", "_", "-LCB-", "\\beta", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "_", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "_", "-LCB-", "\\phi", "-RCB-", "\\", "-RRB-", ",", "Attack", "functions", ":", "\\", "-LRB-", "N_1", ",", "...", ",", "N_K\\", "-RRB-", "Randomly", "initialize", "the", "networks", ":", "\\", "-LRB-", "D_", "-LCB-", "\\phi", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "E_", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "C_", "-LCB-", "\\beta", "-RCB-", "\\", "-RRB-", "."], ["Randomly", "sample", "message", "batch", "\\", "-LRB-", "M\\", "-RRB-", "of", "batch", "size", "\\", "-LRB-", "b\\", "-RRB-", "."], ["Select", "K", "integers", ":", "\\", "-LRB-", "k_", "-LCB-", "1", "-RCB-", ",", "...", ",", "k_", "-LCB-", "i", "-RCB-", ",", "...", ",", "k_", "-LCB-", "K", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "K\\", "-RRB-", "is", "the", "number", "of", "types", "of", "attacks", "and", "\\", "-LRB-", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "K", "-RCB-", "k_", "-LCB-", "i", "-RCB-", "=b\\", "-RRB-", "Read", "minibatch", "\\", "-LRB-", "B=\\lbrace", "x_1", ",", "...", ",", "x_b\\rbrace", "\\", "-RRB-", "from", "training", "set", "."], ["Generate", "the", "watermarked", "minibatch", "\\", "-LRB-", "B_", "-LCB-", "wm", "-RCB-", "=\\lbrace", "E_", "-LCB-", "\\theta", "-RCB-", "-LRB-", "x_i", ",", "m_i", "-RRB-", ":", "x_i", "\\in", "B", ",", "m_i", "\\in", "M\\rbrace", "\\", "-RRB-", "Separate", "the", "minibatch", "\\", "-LRB-", "B_", "-LCB-", "wm", "-RCB-", "\\", "-RRB-", "into", "\\", "-LRB-", "K\\", "-RRB-", "subsets", "\\", "-LRB-", "\\lbrace", "B^", "-LCB-", "1", "-RCB-", "_", "-LCB-", "wm", "-RCB-", ",", "...", ",", "B^", "-LCB-", "K", "-RCB-", "_", "-LCB-", "wm", "-RCB-", "\\rbrace", "\\", "-RRB-", "where", "each", "contains", "\\", "-LRB-", "k_", "-LCB-", "i", "-RCB-", "\\", "-RRB-", "images", "Load", "severity", "ranges", "of", "attacks", ":", "\\", "-LRB-", "S_1", ",", "...", ",", "S_K\\", "-RRB-", "i", "=", "1", ",", "2", ",", "...", ",", "K", "Search", "the", "worst-case", "\\", "-LRB-", "s^", "-LCB-", "*", "-RCB-", "_", "-LCB-", "i", "-RCB-", "\\", "-RRB-", "by", ":", "\\", "-LRB-", "s^", "-LCB-", "*", "-RCB-", "_", "-LCB-", "i", "-RCB-", "=", "\\operatornamewithlimits", "-LCB-", "arg\\", ",", "max", "-RCB-", "_", "-LCB-", "s", "\\in", "S_i", "-RCB-", "\\sum", "_", "-LCB-", "x^", "-LCB-", "wm", "-RCB-", "\\in", "B^", "-LCB-", "i", "-RCB-", "-RCB-", "L", "-LRB-", "m", ",", "D_", "-LCB-", "\\phi", "-RCB-", "-LRB-", "N_i", "-LRB-", "x^", "-LCB-", "wm", "-RCB-", ",", "s", "-RRB-", "-RRB-", "-RRB-", "\\", "-RRB-", "Calculate", "the", "worst-case", "attacked", "image", "batch", "\\", "-LRB-", "B^", "-LCB-", "i", "-RCB-", "_", "-LCB-", "att", "-RCB-", "=", "\\lbrace", "N_"]], "ner": [[[4, 5, "a"], [12, 13, "p"], [2, 2, "v"], [17, 17, "v"], [20, 21, "p"], [53, 54, "p"]], [[109, 109, "v"]], [[167, 167, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[7, 8, "a"], [20, 21, "p"]], [], [[113, 113, "v"], [170, 170, "a"]], [[217, 217, "a"], [291, 291, "p"]]], "predicted_relations": [[[12, 13, 4, 5, "USED-FOR"], [2, 2, 20, 21, "USED-FOR"], [2, 2, 53, 54, "USED-FOR"], [17, 17, 53, 54, "USED-FOR"], [20, 21, 4, 5, "USED-FOR"], [53, 54, 4, 5, "USED-FOR"]], [], [], []]}
{"doc_key": "1906.04726-83636de1-b2ce-4d5d-9079-aa4b8e47d1d1", "sentences": [["We", "fit", "each", "regression", "model", "'s", "parameters", "by", "L-BFGS", "."], ["We", "then", "evaluate", "the", "model", "'s", "fitness", "by", "measuring", "its", "held-out", "data", "likelihood\u2014that", "is", ",", "the", "probability", "it", "assigns", "to", "the", "\\", "-LRB-", "y_", "-LCB-", "ij", "-RCB-", "\\", "-RRB-", "values", "for", "held-out", "intents", "\\", "-LRB-", "i\\", "-RRB-", "."], ["Here", "we", "use", "the", "previously", "fitted", "\\", "-LRB-", "d_j\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "\\", "-RRB-", "parameters", ",", "but", "we", "must", "newly", "fit", "\\", "-LRB-", "n_i\\", "-RRB-", "values", "for", "the", "new", "\\", "-LRB-", "i\\", "-RRB-", "using", "MAP", "estimates", "or", "posterior", "means", "."], ["A", "full", "comparison", "of", "our", "models", "under", "various", "conditions", "can", "be", "found", "in", "app", ":", "goodness-of-fit-plot", "."], ["The", "primary", "findings", "are", "as", "follows", "."], ["On", "Europarl", "data", "-LRB-", "which", "has", "fewer", "languages", "-RRB-", ",", "Model", "2", "performs", "best", "."], ["On", "the", "Bible", "corpora", ",", "all", "models", "are", "relatively", "close", "to", "one", "another", ",", "though", "the", "robust", "Model", "2L", "gets", "more", "consistent", "results", "than", "Model", "2", "across", "data", "subsets", "."], ["We", "use", "MAP", "estimates", "under", "Model", "2", "for", "all", "remaining", "experiments", "for", "speed", "and", "simplicity.Further", "enhancements", "are", "possible", ":", "we", "discuss", "our", "\u201c", "Model", "3", "\u201d", "in", "app", ":", "model-3", ",", "but", "it", "did", "not", "seem", "to", "fit", "better", "."]], "ner": [[[8, 8, "a"]], [], [[56, 56, "p"], [61, 61, "p"], [73, 73, "p"], [84, 85, "v"], [87, 88, "v"]], [], [], [[124, 125, "a"]], [[153, 154, "a"], [146, 147, "a"]], [[164, 165, "a"], [161, 162, "v"], [182, 183, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [], [], [], [], [[125, 125, "v"]], [[140, 140, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1911.11899-3f1375e1-00c4-4430-9ec5-08de277f9cd9", "sentences": [["For", "a", "fair", "and", "rational", "comparison", "with", "baselines", "and", "competitive", "approaches", ",", "we", "set", "most", "of", "the", "hyper-parameters", "by", "following", "prior", "works", "-LSB-", "9", "-RSB-", ",", "-LSB-", "3", "-RSB-", ",", "and", "also", "use", "50D", "word", "embedding", "and", "5D", "position", "embedding", "released", "by", "-LSB-", "8", "-RSB-", ",", "-LSB-", "3", "-RSB-", "for", "initialization", ",", "where", "the", "dimension", "of", "\\", "-LRB-", "d_h\\", "-RRB-", "equals", "to", "150", "."], ["The", "filters", "number", "of", "CNN", "\\", "-LRB-", "d_c\\", "-RRB-", "equals", "to", "230", "and", "the", "kernel", "size", "\\", "-LRB-", "m\\", "-RRB-", "in", "CNN", "equals", "to", "3", "."], ["In", "output", "layer", ",", "we", "employ", "dropout", "-LSB-", "18", "-RSB-", "for", "regularization", ",", "where", "the", "drop", "probability", "is", "set", "to", "\\", "-LRB-", "0.5\\", "-RRB-", "."], ["To", "minimize", "the", "loss", "function", "defined", "in", "Eq.REF", ",", "we", "use", "stochastic", "gradient", "descent", "with", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "and", "decay", "the", "learning", "rate", "to", "one", "tenth", "every", "100K", "steps", "."]], "ner": [[], [], [[112, 112, "v"]], [[136, 136, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[33, 33, "v"], [37, 37, "v"], [62, 62, "v"]], [[68, 68, "a"], [75, 75, "v"], [82, 82, "p"], [85, 85, "a"], [88, 88, "v"]], [[96, 96, "a"], [112, 112, "v"]], [[126, 128, "a"], [131, 132, "p"], [136, 136, "v"], [142, 143, "p"], [145, 145, "v"], [148, 148, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1911.11952-fbba6027-fd75-4399-ab3a-91b8a17bb37a", "sentences": [["AllenNLP", "-LSB-", "9", "-RSB-", "and", "PyTorch", "-LSB-", "17", "-RSB-", "are", "used", "as", "the", "development", "and", "experimentation", "environments", "."], ["ADAM", "optimizer", "-LSB-", "14", "-RSB-", "with", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "is", "used", "for", "training", "."], ["Transformer", "encoder", "consists", "of", "1", "layer", "and", "8", "attention", "heads", "."], ["Projection", ",", "feedforward", "and", ",", "hidden", "dimensions", "of", "the", "encoder", "are", "256", ",", "128", "and", ",", "128", ",", "respectively", "."], ["Target", "vocabulary", "size", "is", "pruned", "to", "include", "only", "the", "top", "5000", "frequent", "tokens", ",", "tokenized", "by", "WordPiece", "."], ["Number", "of", "decoding", "steps", "is", "limited", "to", "maximum", "input", "sequence", "length", "of", "13", "tokens", "."], ["Target", "embedding", "dimension", "is", "set", "to", "768", "."], ["During", "evaluation", "decoding", ",", "Beam", "search", "of", "size", "16", "is", "used", "."], ["Each", "of", "the", "models", "have", "approximately", "7", "million", "parameters", "."], ["We", "chose", "this", "set", "of", "parameters", "such", "that", "the", "baseline", "model", "would", "perform", "well", "on", "the", "dataset", "."], ["Models", "are", "trained", "for", "20", "epochs", ",", "and", "the", "best", "model", "is", "chosen", "based", "on", "Max-BLEU", "score", "on", "the", "development", "set", "."]], "ner": [[[0, 0, "a"], [5, 5, "a"]], [[18, 19, "a"], [24, 25, "p"]], [[40, 41, "a"], [44, 44, "v"], [47, 47, "v"]], [[62, 62, "v"], [64, 64, "v"], [67, 67, "v"], [64, 64, "v"], [67, 67, "v"]], [[80, 83, "p"], [80, 83, "v"], [85, 87, "c"], [73, 73, "p"]], [[96, 99, "p"], [101, 102, "v"]], [[106, 106, "p"], [110, 110, "v"]], [[116, 117, "a"], [119, 119, "p"], [120, 120, "v"]], [], [], [[167, 168, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [5, 5, "a"]], [[18, 18, "a"], [24, 25, "p"], [29, 31, "v"]], [[44, 44, "v"], [45, 45, "p"], [47, 47, "v"]], [[62, 62, "v"], [64, 64, "v"], [67, 67, "v"]], [[81, 81, "v"]], [[101, 101, "v"]], [[110, 110, "v"]], [[116, 117, "a"], [120, 120, "v"]], [[130, 130, "v"]], [], [[156, 156, "v"]]], "predicted_relations": [[], [[24, 25, 18, 19, "USED-FOR"]], [], [], [[80, 83, 80, 83, "USED-FOR"]], [], [[110, 110, 106, 106, "USED-FOR"]], [[119, 119, 116, 117, "USED-FOR"], [120, 120, 119, 119, "USED-FOR"]], [], [], []]}
{"doc_key": "1912.05687-3e915607-34b2-40c2-968f-4de023cd871c", "sentences": [["To", "tune", "the", "competitive", "models", ",", "we", "did", "a", "grid", "search", "on", "the", "following", "hyper", "parameters", "for", "each", "model", "using", "hold-out", "for", "partitioning", "the", "data", "."], ["We", "randomly", "partition", "both", "NCI60", "and", "GDSC", "data", "to", "80", "%", "training", ",", "10", "%", "validation", "and", "10", "%", "test", "."], ["The", "same", "training", ",", "validation", "and", "test", "datasets", "were", "used", "for", "all", "models", "."], ["The", "hyper", "parameters", "were", "tuned", "using", "the", "training", "and", "validation", "sets", "."], ["The", "test", "sets", "were", "hold", "out", "for", "evaluating", "the", "final", "performance", "of", "each", "tuned", "model", "."]], "ner": [[[9, 10, "a"], [14, 15, "p"], [22, 24, "p"], [20, 20, "a"]], [[35, 45, "v"]], [], [[62, 63, "p"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[30, 30, "a"], [32, 32, "a"], [35, 36, "v"], [39, 40, "v"], [43, 44, "v"]], [], [], []], "predicted_relations": [[[14, 15, 9, 10, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1912.05687-f98721d9-7c47-42af-9bbd-e30a68dd27e8", "sentences": [["For", "unbiased", "evaluation", "of", "machine", "learning", "models", ",", "nested", "cross-validation", "-LSB-", "50", "-RSB-", "-LRB-", "CV", "-RRB-", "is", "often", "considered", "where", "an", "inner", "CV", "is", "used", "for", "model", "selection", "-LRB-", "hyper", "parameter", "selection", "-RRB-", "and", "an", "outer", "CV", "is", "used", "for", "evaluating", "the", "model", "tuned", "by", "the", "inner", "CV", "."], ["However", ",", "nested", "CV", "is", "often", "extremely", "computationally", "intensive", "and", "thus", "we", "considered", "a", "training-validation-test", "-LRB-", "hold-out", "-RRB-", "approach", "where", "the", "hyper-parameters", "are", "tested", "on", "the", "validation", "set", "and", "the", "selected", "model", "is", "evaluated", "based", "on", "the", "separate", "test", "set", "."], ["We", "used", "training-validation-test", "approach", "as", "the", "sample", "size", "is", "relatively", "large", "and", "thus", ",", "both", "training-validation-test", "and", "nested", "CV", "approaches", "are", "expected", "to", "provide", "similar", "results", "for", "comparing", "different", "modeling", "approaches", "."], ["To", "illustrate", "the", "similar", "behavior", ",", "we", "compared", "the", "results", "of", "nested", "CV", "and", "training-validation-test", "-LRB-", "hold-out", "-RRB-", "approach", "using", "three", "cell", "lines", "randomly", "selected", "from", "the", "NCI60", "dataset", "."], ["As", "the", "results", "provided", "in", "figure", "REF", "indicates", ",", "the", "difference", "in", "the", "results", "are", "minimal", "."], ["On", "the", "other", "hand", ",", "to", "compare", "the", "time", "complexity", "of", "the", "two", "approaches", ",", "we", "selected", "one", "cell", "line", "with", "a", "fixed", "CNN", "architecture", "."], ["Within", "the", "CNN", "architecture", ",", "a", "grid", "of", "hyper", "parameters", "was", "defined", "."], ["In", "a", "single", "run", "-LRB-", "architecture", "-RRB-", "that", "takes", "48", "hours", "on", "Texas", "Tech", "University", "high", "performance", "computer", "center", ",", "50", "different", "models", "can", "be", "tried", "using", "training-validation-test", ",", "whereas", "only", "4", "models", "can", "be", "tried", "using", "nested", "cross-validation", "."], ["Given", "the", "time", "complexity", "and", "similar", "performance", "of", "the", "two", "approaches", ",", "we", "used", "training-validation-test", "approach", "for", "hyper", "parameter", "selection", "and", "model", "evaluation", "as", "we", "could", "search", "considerably", "larger", "space", "of", "hyper", "parameters", "."]], "ner": [[[8, 9, "a"]], [[63, 67, "a"]], [], [[136, 140, "a"], [149, 150, "a"]], [], [[192, 193, "a"]], [[197, 198, "a"], [203, 204, "p"]], [[245, 246, "a"]], [[279, 280, "p"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"]], [[63, 67, "a"]], [[92, 93, "a"], [105, 105, "a"]], [[136, 140, "a"], [142, 142, "v"]], [], [[181, 181, "v"], [186, 186, "v"], [192, 192, "a"]], [[197, 197, "a"]], [[217, 217, "v"], [228, 228, "v"], [239, 239, "v"]], [[257, 257, "v"], [262, 263, "a"]]], "predicted_relations": [[], [], [], [], [], [], [[203, 204, 197, 198, "USED-FOR"]], [], []]}
{"doc_key": "1909.11835-6252659c-5ade-4987-b4c0-a3287a429d26", "sentences": [["Training", "setup", "."], ["The", "surrogate", "has", "been", "trained", "with", "an", "Adam", "optimizer", "-LSB-", "17", "-RSB-", "regarding", "to", "this", "adaptive", "loss", "with", "the", "following", "parameters", "for", "the", "optimizer", ":", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.99\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.99\\", "-RRB-", ",", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "and", "for", "the", "adaptive", "loss", ":", "\\", "-LRB-", "\\lambda", "_k", "=", "0.01\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "_k\\", "-RRB-", "=", "\\", "-LRB-", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "k_0", "=", "0.001\\", "-RRB-", "."], ["The", "generator", "has", "also", "been", "trained", "with", "an", "Adam", "optimizer", "configured", "similarly", "to", "the", "surrogate", "'s", "with", "the", "following", "parameters", "for", "the", "optimizer", ":", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.99\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.99\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "."], ["These", "parameters", "are", "fairly", "standard", "and", "yield", "good", "results", "for", "the", "problems", "the", "GAMIN", "was", "confronted", "to", "."], ["Remark", "that", "an", "extensive", "hyperparameter", "search", "is", "a", "non-trivial", "process", "in", "the", "black-box", "setting", "."]], "ner": [[], [[10, 11, "a"], [28, 29, "p"], [45, 45, "v"], [53, 53, "v"], [45, 45, "v"], [53, 53, "v"], [58, 58, "p"], [18, 19, "a"], [68, 69, "a"], [76, 76, "v"], [87, 87, "v"], [92, 92, "p"], [94, 94, "v"]], [[105, 106, "a"], [121, 122, "p"], [138, 138, "v"], [146, 146, "v"], [138, 138, "v"], [146, 146, "v"], [151, 151, "p"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[10, 10, "a"], [18, 19, "a"], [28, 29, "p"], [33, 36, "v"], [45, 45, "v"], [53, 53, "v"], [68, 69, "a"], [73, 74, "p"], [75, 76, "v"], [87, 87, "v"], [92, 94, "v"]], [[105, 105, "a"], [121, 122, "p"], [126, 129, "v"], [146, 146, "v"]], [], []], "predicted_relations": [[], [[28, 29, 10, 11, "USED-FOR"], [28, 29, 18, 19, "USED-FOR"], [53, 53, 58, 58, "USED-FOR"], [53, 53, 58, 58, "USED-FOR"], [58, 58, 10, 11, "USED-FOR"], [58, 58, 18, 19, "USED-FOR"], [58, 58, 68, 69, "USED-FOR"], [87, 87, 92, 92, "USED-FOR"], [92, 92, 68, 69, "USED-FOR"], [94, 94, 92, 92, "USED-FOR"]], [[121, 122, 105, 106, "USED-FOR"], [146, 146, 151, 151, "USED-FOR"], [146, 146, 151, 151, "USED-FOR"], [151, 151, 105, 106, "USED-FOR"]], [], []]}
{"doc_key": "1903.10930-8b79ebda-0dda-4f91-b59a-871051922c6a", "sentences": [["For", "all", "our", "experiments", ",", "we", "train", "the", "TPP-PHOCNet", "for", "\\", "-LRB-", "100\\,000\\", "-RRB-", "iterations", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "which", "is", "divided", "by", "10", "after", "\\", "-LRB-", "70\\,000\\", "-RRB-", "iterations", "."], ["We", "use", "Adam", "optimization", "with", "a", "mini-batch", "size", "of", "10", ",", "hyperparameters", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "5\\cdot", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["Analogue", "to", "subsec", ":", "sigtdo", ",", "we", "apply", "two", "dropout", "layers", "during", "training", "."], ["Furthermore", ",", "a", "simple", "data", "augmentation", "strategy", "is", "used", "as", "we", "apply", "a", "random", "affine", "transformation", "to", "all", "input", "images", "at", "training", "time", "."]], "ner": [[[8, 8, "a"], [14, 14, "p"], [40, 40, "p"], [17, 19, "p"], [23, 23, "v"], [34, 34, "v"]], [[48, 49, "p"], [51, 51, "v"], [73, 73, "v"], [57, 57, "v"], [63, 63, "v"], [67, 68, "p"], [44, 45, "a"]], [[89, 90, "a"]], [[107, 109, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "a"], [12, 12, "v"], [18, 19, "p"], [23, 26, "v"], [34, 34, "v"], [38, 38, "v"]], [[44, 45, "a"], [48, 49, "p"], [51, 51, "v"], [67, 68, "p"], [73, 76, "v"]], [[84, 84, "a"], [88, 88, "v"], [89, 89, "a"], [89, 90, "p"]], []], "predicted_relations": [[[14, 14, 8, 8, "USED-FOR"], [17, 19, 8, 8, "USED-FOR"], [23, 23, 17, 19, "USED-FOR"], [34, 34, 40, 40, "USED-FOR"]], [[73, 73, 67, 68, "USED-FOR"], [67, 68, 44, 45, "USED-FOR"]], [], []]}
{"doc_key": "1903.10930-23831269-ca4c-459a-9e31-dc72181d5b67", "sentences": [["The", "metaclassifiers", "are", "trained", "for", "\\", "-LRB-", "25\\,000\\", "-RRB-", "iterations", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", ",", "which", "is", "divided", "by", "10", "after", "\\", "-LRB-", "10\\,000\\", "-RRB-", ",", "\\", "-LRB-", "15\\,000\\", "-RRB-", "and", "\\", "-LRB-", "20\\,000\\", "-RRB-", "iterations", "."], ["For", "optimization", ",", "we", "use", "the", "same", "Adam", "optimizer", "as", "for", "the", "TPP-PHOCNet", "with", "a", "weight", "decay", "of", "\\", "-LRB-", "5\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[13, 14, "p"]], [[54, 55, "a"], [62, 63, "p"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "v"], [13, 14, "p"], [18, 21, "v"], [29, 29, "v"], [33, 33, "v"], [38, 38, "v"], [43, 43, "v"]], [[54, 54, "a"], [59, 59, "a"], [62, 63, "p"]]], "predicted_relations": [[], []]}
{"doc_key": "1907.10471-ab82042a-c51a-4e76-800a-4126193c57e7", "sentences": [["Our", "model", "is", "trained", "stage-by-stage", "to", "save", "GPU", "memory", "."], ["The", "first", "stage", "consists", "of", "3D", "semantic", "segmentation", "and", "proposal", "generation", ",", "while", "the", "second", "is", "for", "box", "prediction", "."], ["For", "the", "first", "stage", ",", "we", "use", "ADAM", "-LSB-", "12", "-RSB-", "optimizer", "with", "an", "initial", "learning", "rate", "0.001", "for", "the", "first", "80", "epochs", "and", "then", "decay", "it", "to", "0.0001", "for", "the", "last", "20", "epochs", "."], ["Each", "batch", "consists", "of", "16", "point", "clouds", "evenly", "distributed", "on", "4", "GPU", "cards", "."], ["For", "the", "second", "stage", ",", "we", "train", "50", "epochs", "with", "batch", "size", "1", "."], ["The", "learning", "rate", "is", "initialized", "as", "0.001", "for", "first", "40", "epochs", "and", "is", "then", "decayed", "by", "0.1", "in", "every", "5", "epochs", "."], ["For", "each", "input", "point", "cloud", ",", "we", "sample", "256", "proposals", ",", "with", "ratio", "1:1", "for", "positives", "and", "negatives", "."], ["Our", "implementation", "is", "based", "on", "Tensorflow", "-LSB-", "1", "-RSB-", "."], ["For", "the", "box", "prediction", "network", ",", "a", "proposal", "is", "considered", "positive", "if", "its", "maximum", "3D", "IoU", "with", "all", "ground-truth", "boxes", "is", "higher", "than", "0.55", "and", "negative", "if", "its", "maximum", "3D", "IoU", "is", "below", "0.45", "during", "training", "the", "car", "model", "."], ["The", "positive", "and", "negative", "3D", "IoU", "thresholds", "are", "0.5", "and", "0.4", "for", "the", "pedestrian", "and", "cyclist", "models", "."], ["Besides", ",", "for", "the", "IoU", "branch", ",", "we", "only", "train", "on", "positive", "proposals", "."]], "ner": [[], [], [[37, 37, "a"], [44, 46, "p"], [47, 47, "v"], [58, 58, "v"], [61, 63, "c"], [45, 46, "a"]], [[69, 69, "v"]], [[89, 90, "p"]], [[99, 99, "v"], [94, 95, "a"]], [], [], [[158, 159, "a"], [173, 174, "a"], [167, 167, "v"], [181, 182, "c"], [177, 177, "v"], [181, 182, "c"]], [[188, 189, "a"], [192, 192, "v"], [197, 200, "c"], [194, 194, "v"], [197, 200, "c"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [], [[37, 37, "a"], [45, 46, "p"], [47, 47, "v"], [51, 51, "v"], [52, 52, "p"], [58, 58, "v"], [62, 62, "v"], [63, 63, "p"]], [[69, 69, "v"], [75, 75, "v"]], [[86, 86, "v"], [87, 87, "p"], [89, 90, "p"], [91, 91, "v"]], [[94, 95, "p"], [99, 99, "v"], [102, 102, "v"], [103, 103, "p"], [109, 109, "v"], [112, 112, "v"], [113, 113, "p"]], [[123, 123, "v"], [128, 128, "v"]], [[139, 139, "a"]], [[146, 148, "a"], [167, 167, "v"], [177, 177, "v"]], [[192, 192, "v"], [194, 194, "v"]], []], "predicted_relations": [[], [], [[44, 46, 37, 37, "USED-FOR"], [44, 46, 45, 46, "USED-FOR"], [47, 47, 44, 46, "USED-FOR"], [61, 63, 58, 58, "USED-FOR"]], [], [], [], [], [], [], [], []]}
{"doc_key": "1909.10801-24cf48f1-a174-4d20-a146-e5cb8b8621dd", "sentences": [["The", "models", "are", "implemented", "in", "PyTorch", "and", "trained", "using", "Adam", "-LSB-", "8", "-RSB-", "and", "a", "learning", "rate", "cosine", "decay", "schedule", "from", "\\", "-LRB-", "6e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "down", "to", "\\", "-LRB-", "3e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["To", "avoid", "overfitting", "uninformative", "noisy", "patterns", "in", "stale", "data", "input", "sequence", "length", "is", "set", "to", "30", "days", "."], ["In", "addition", ",", "to", "enable", "a", "fair", "comparison", "and", "avoid", "additional", "overfitting", "we", "employ", "an", "early", "stopping", "scheme", "based", "on", "training", "loss", "that", "is", "motivated", "by", "different", "convergence", "times", "of", "different", "models", "."], ["We", "use", "a", "static", "testing", "approach", "with", "a", "long", "period", "of", "446", "out-of-sample", "trading", "days", "to", "test", "stability", "of", "the", "learned", "trading", "strategy", "under", "turbulent", "market", "conditions", "and", "a", "wider", "distributional", "shift", "between", "in-sample", "and", "out-of-sample", "data", "."], ["PyTorch", "code", "for", "models", "and", "training", "procedure", "is", "included", "in", "the", "supplementary", "material", "."]], "ner": [[[9, 9, "a"], [15, 16, "p"]], [], [[73, 74, "a"]], [[94, 95, "a"], [100, 100, "p"], [102, 102, "v"], [103, 105, "c"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [9, 9, "a"], [23, 26, "v"], [33, 36, "v"]], [[47, 48, "a"], [55, 55, "v"]], [[78, 79, "a"]], [[102, 102, "v"]], []], "predicted_relations": [[[15, 16, 9, 9, "USED-FOR"]], [], [], [[100, 100, 94, 95, "USED-FOR"], [102, 102, 100, 100, "USED-FOR"], [103, 105, 102, 102, "USED-FOR"]], []]}
{"doc_key": "1912.12814-98a81933-b98a-4675-8556-577b4e861132", "sentences": [["Following", "DARTS", "-LSB-", "19", "-RSB-", ",", "half", "of", "the", "CIFAR-10", "training", "data", "are", "held", "out", "as", "the", "validation", "set", "for", "architecture", "search", "."], ["A", "small", "network", "consisting", "of", "8", "cells", "is", "trained", "using", "RC-DARTS", "for", "50", "epochs", ",", "with", "batch", "size", "64", "-LRB-", "for", "both", "the", "training", "and", "validation", "iterations", "-RRB-", "and", "the", "initial", "number", "of", "channels", "16", "."], ["Momentum", "SGD", "and", "Adam", "optimizer", "are", "used", "to", "optimize", "the", "weights", "\\", "-LRB-", "w\\", "-RRB-", "and", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "iteratively", "in", "unconstrained", "training", "step", "."], ["In", "architectural", "projection", "step", "-LRB-", "ref", "."], ["Eq", "."], ["-LRB-", "REF", "-RRB-", "-RRB-", ",", "we", "use", "Adam", "optimizer", "with", "initial", "learning", "rate", "of", "3e-4", ",", "momentum", "of", "\\", "-LRB-", "-LRB-", "0.5", ",", "0.999", "-RRB-", "\\", "-RRB-", ",", "and", "no", "weight", "decay", "."], ["The", "number", "of", "iterations", "in", "phase", "I", "\\", "-LRB-", "e_u\\", "-RRB-", "is", "set", "to", "150", "-LRB-", "i.e", "."], ["0.5", "epoch", "-RRB-", ";", "The", "number", "of", "iteration", "in", "phase", "II", "\\", "-LRB-", "e_p\\", "-RRB-", "is", "set", "to", "500", "."], ["The", "lower/upper", "bounds", "for", "constraints", "of", "#", "params", "and", "FLOPs", "are", "1.8e5/2.0e5", "and", "2.8e7/3.3e7", "respectively", "."], ["These", "numbers", "are", "decided", "by", "experiments", "."], ["All", "experiments", "run", "with", "PyTorch", "using", "NVIDIA", "V100", "GPUs", "."]], "ner": [[[1, 1, "a"], [9, 9, "a"]], [[33, 33, "a"], [33, 33, "a"]], [[59, 60, "a"], [62, 63, "a"]], [], [], [[102, 103, "a"], [105, 107, "p"], [109, 109, "v"], [111, 111, "p"], [125, 126, "p"], [124, 124, "v"]], [[133, 134, "a"], [129, 131, "p"], [142, 142, "v"], [129, 131, "p"]], [[155, 156, "a"], [164, 164, "v"]], [[170, 175, "a"], [177, 177, "v"], [177, 177, "v"], [179, 179, "v"], [179, 179, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [6, 6, "v"], [9, 9, "a"]], [[28, 28, "v"], [33, 33, "a"], [35, 35, "v"], [36, 36, "p"], [39, 40, "p"], [41, 41, "v"], [57, 57, "v"]], [[59, 59, "a"], [62, 62, "a"], [77, 77, "p"]], [], [], [[102, 102, "a"], [106, 107, "p"], [109, 109, "v"], [111, 111, "p"], [116, 116, "v"], [118, 118, "v"], [125, 126, "p"]], [[142, 142, "v"]], [[146, 146, "v"], [147, 147, "p"], [164, 164, "v"]], [], [], [[193, 193, "a"]]], "predicted_relations": [[], [], [], [], [], [[105, 107, 102, 103, "USED-FOR"], [109, 109, 105, 107, "USED-FOR"], [111, 111, 102, 103, "USED-FOR"], [125, 126, 102, 103, "USED-FOR"]], [[129, 131, 133, 134, "USED-FOR"], [129, 131, 133, 134, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1912.10667-82d327da-ff50-454e-9958-bde81cb3e984", "sentences": [["Since", "the", "image", "tiles", "are", "too", "large", "to", "be", "fed", "through", "a", "deep", "CNN", "due", "to", "limited", "GPU", "memory", ",", "we", "randomly", "extract", "image", "patches", "of", "size", "of", "256\\", "-LRB-", "\\times", "\\", "-RRB-", "256", "pixels", "as", "the", "training", "set", "."], ["Following", "standard", "practice", ",", "we", "only", "use", "horizontal", "and", "vertical", "flipping", "as", "data", "augmentation", "during", "training", "."], ["For", "testing", ",", "the", "whole", "image", "is", "split", "into", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "patches", "with", "a", "stride", "of", "256", "."], ["Then", ",", "the", "predictions", "of", "all", "patches", "are", "concatenated", "for", "evaluation", "."]], "ner": [[[28, 28, "v"], [33, 33, "v"]], [[52, 53, "a"], [47, 50, "v"]], [[74, 74, "p"], [68, 68, "v"], [69, 69, "v"], [76, 76, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[33, 33, "v"]], [], [[69, 69, "v"], [76, 76, "v"]], []], "predicted_relations": [[], [], [[76, 76, 74, 74, "USED-FOR"]], []]}
{"doc_key": "1905.03197-02f58667-b829-4d63-8952-8fb1186a0799", "sentences": [["Adam", "-LSB-", "21", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "is", "used", "for", "optimization", "."], ["The", "learning", "rate", "is", "3e-5", ",", "with", "linear", "warmup", "over", "the", "first", "\\", "-LRB-", "40,000\\", "-RRB-", "steps", "and", "linear", "decay", "."], ["The", "dropout", "rate", "is", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "weight", "decay", "is", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["The", "batch", "size", "is", "330", "."], ["The", "pre-training", "procedure", "runs", "for", "about", "\\", "-LRB-", "770,000\\", "-RRB-", "steps", "."], ["It", "takes", "about", "7", "hours", "for", "\\", "-LRB-", "10,000\\", "-RRB-", "steps", "using", "8", "Nvidia", "Telsa", "V100", "32GB", "GPU", "cards", "with", "mixed", "precision", "training", "."]], "ner": [[[0, 0, "a"], [8, 8, "v"], [14, 14, "v"]], [], [[48, 48, "v"]], [[57, 57, "v"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [8, 8, "v"]], [[22, 23, "p"], [25, 25, "v"], [28, 29, "a"], [35, 35, "v"], [39, 40, "a"]], [[43, 44, "p"], [48, 48, "v"]], [[52, 53, "p"], [57, 57, "v"]], [[61, 62, "p"], [64, 64, "v"]], [[74, 74, "v"]], [[81, 81, "v"], [86, 86, "v"], [90, 90, "v"], [94, 94, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1905.03282-370f59b8-93f0-41b8-bf12-c3ba96a38411", "sentences": [["Problem", "1", "-LRB-", "the", "non-differentiability", "of", "\\", "-LRB-", "\\varphi", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "-RRB-", ":", "The", "STCA", "ternarization", "operator", "\\", "-LRB-", "\\varphi", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "is", "not", "differentiable", "with", "respect", "to", "\\", "-LRB-", "\\bf", "x\\", "-RRB-", "."], ["Therefore", ",", "one", "can", "envision", "several", "approaches", "to", "approximate", "\\", "-LRB-", "\\varphi", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "by", "some", "differentiable", "surrogate", "function", ",", "as", "for", "example", "by", "a", "hard-thresholding", "operator", "that", "preserves", "the", "same", "mutual", "information", "as", "for", "the", "ternarization", "operator", "for", "a", "range", "of", "sparsity", "levels", "\\", "-LRB-", "S_x\\", "-RRB-", "-LSB-", "17", "-RSB-", ",", "or", "by", "considering", "a", "linear", "approximation", ",", "i.e.", ",", "\\", "-LRB-", "\\varphi", "-LRB-", "AW", "-LCB-", "\\bf", "x", "-RCB-", "-RRB-", "=AW", "-LCB-", "\\bf", "x", "-RCB-", "\\", "-RRB-", ",", "that", "yields", "to", ":"]], "ner": [[[17, 19, "a"]], [[68, 69, "a"], [85, 86, "p"], [89, 89, "v"], [99, 100, "a"]]], "relations": [[], []], "predicted_ner": [[[17, 17, "a"]], []], "predicted_relations": [[], [[85, 86, 68, 69, "USED-FOR"], [89, 89, 85, 86, "USED-FOR"]]]}
{"doc_key": "1905.03282-13450262-4fd4-48b8-976e-1862b3e40817", "sentences": [["Problem", "2", "-LRB-", "model", "prior", "for", "real", "data", "-RRB-", ":", "The", "above", "assumed", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "-norm", "regularizer", "works", "only", "for", "the", "synthetic", "i.i.d", "Gaussian", "data", "."], ["In", "the", "case", "of", "real", "images", ",", "it", "is", "too", "restrictive", "."], ["The", "class", "of", "sparsification", "priors", "is", "also", "relatively", "restrictive", "in", "view", "of", "a", "single", "overcomplete", "shallow", "representation", "."], ["Instead", ",", "recent", "works", "-LSB-", "18", "-RSB-", ",", "-LSB-", "19", "-RSB-", "suggested", "using", "a", "generative", "model", "\\", "-LRB-", "-LCB-", "\\bf", "x", "-RCB-", "=", "g_", "-LCB-", "\\theta", "_G", "-RCB-", "-LRB-", "-LCB-", "\\bf", "z", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "g_", "-LCB-", "\\theta", "_G", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "is", "a", "generator", "of", "GAN", "or", "decoder", "of", "VAE", "trained", "on", "corresponding", "data", "\\", "-LRB-", "\\lbrace", "-LCB-", "\\bf", "x", "-RCB-", "_i\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^N\\", "-RRB-", ",", "where", "\\", "-LRB-", "N\\", "-RRB-", "denotes", "the", "number", "of", "training", "samples", "."], ["In", "this", "case", ",", "the", "reconstruction", "problem", "reduces", "to", ":"]], "ner": [[], [], [], [[113, 113, "a"], [117, 117, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[113, 113, "a"], [117, 117, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2109.08364-f94a29d8-6cd4-40ee-8bb1-b37f514f9d50", "sentences": [["In", "our", "experiment", ",", "we", "set", "the", "number", "of", "N", "in", "Fig", "."], ["REF", "to", "5", "and", "adopt", "4", "heads", "for", "self-attention", "."], ["Different", "from", "the", "feature", "dimension", "value", "of", "64", "or", "128", "in", "prior", "works", "-LSB-", "40", "-RSB-", ",", "-LSB-", "37", "-RSB-", ",", "we", "set", "the", "middle", "feature", "dimension", "of", "the", "model", "to", "96", "for", "GraFormer", "with", "a", "dropout", "rate", "of", "0.25", "."], ["We", "adopt", "Adam", "-LSB-", "14", "-RSB-", "optimizer", "for", "optimization", "with", "an", "initial", "learning", "rate", "of", "0.001", "and", "mini-batches", "of", "64", "."], ["For", "Human3.6M", ",", "we", "multiply", "the", "learning", "rate", "by", "0.9", "every", "75000", "steps", "."], ["For", "hand", "datasets", ",", "the", "learning", "rate", "decays", "by", "0.9", "every", "30", "epochs", "."], ["We", "train", "GraFormer", "for", "50", "epochs", "on", "Human3.6M", ",", "900", "epochs", "on", "Obman", "and", "GHD", "and", "3000", "epochs", "on", "FHAD", "."]], "ner": [[], [], [[30, 30, "v"], [56, 56, "a"], [47, 49, "p"], [54, 54, "v"], [59, 60, "p"], [62, 62, "v"]], [[66, 66, "a"], [75, 77, "p"], [79, 79, "v"], [81, 81, "p"], [83, 83, "v"]], [], [], [[115, 115, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "p"]], [[15, 15, "v"], [18, 18, "v"]], [[30, 30, "v"], [32, 32, "v"], [54, 54, "v"], [56, 56, "a"], [59, 60, "p"], [62, 62, "v"]], [[66, 66, "a"], [76, 77, "p"], [79, 79, "v"], [81, 81, "p"], [83, 83, "v"]], [[86, 86, "a"], [91, 92, "p"], [94, 94, "v"], [96, 96, "v"]], [[104, 105, "p"], [108, 108, "v"], [110, 110, "v"], [111, 111, "p"]], [[115, 115, "a"], [117, 117, "v"], [118, 118, "p"], [120, 120, "c"], [122, 122, "v"], [123, 123, "p"], [125, 125, "a"], [127, 127, "a"], [129, 129, "v"], [130, 130, "p"], [132, 132, "a"]]], "predicted_relations": [[], [], [[59, 60, 56, 56, "USED-FOR"], [62, 62, 59, 60, "USED-FOR"]], [[75, 77, 66, 66, "USED-FOR"], [79, 79, 75, 77, "USED-FOR"], [81, 81, 66, 66, "USED-FOR"], [83, 83, 81, 81, "USED-FOR"]], [], [], []]}
{"doc_key": "2101.01165-ec217a86-d4c9-400d-98c5-dffbb14f4fa7", "sentences": [["For", "training", "our", "networks", ",", "we", "gather", "equal", "number", "of", "real", "and", "fake", "videos", "from", "the", "mentioned", "datasets", ",", "and", "create", "train", "and", "test", "subsets", "with", "a", "70", "%", "-vs-30", "%", "split", "-LRB-", "unless", "otherwise", "is", "noted", "in", "the", "results", "section", "-RRB-", "."], ["We", "use", "the", "following", "hyper-parameters", "determined", "empirically", ":", "adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "1e-04\\", "-RRB-", ",", "0.3", "dropout", "probability", ",", "batch", "size", "of", "32", ",", "and", "0.2", "threshold", "for", "leaky", "ReLU", "layers", "."], ["We", "train", "the", "models", "for", "100", "epochs", "and", "validate", "every", "10", "epochs", "."]], "ner": [[[21, 24, "a"], [31, 31, "p"]], [[55, 56, "p"], [60, 60, "v"], [64, 65, "p"], [63, 63, "v"], [67, 68, "p"], [70, 70, "v"], [74, 78, "p"], [73, 73, "v"]], [[81, 83, "a"], [86, 86, "p"], [91, 91, "p"], [85, 85, "v"], [88, 88, "p"], [89, 91, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [27, 28, "v"]], [[51, 51, "a"], [55, 56, "p"], [60, 60, "v"], [63, 63, "v"], [64, 65, "p"], [67, 68, "p"], [70, 70, "v"], [73, 73, "v"], [74, 74, "p"], [76, 77, "a"]], [[85, 85, "v"], [86, 86, "p"], [90, 90, "v"], [91, 91, "p"]]], "predicted_relations": [[[31, 31, 21, 24, "USED-FOR"]], [[60, 60, 55, 56, "USED-FOR"], [63, 63, 64, 65, "USED-FOR"], [70, 70, 64, 65, "USED-FOR"]], [[86, 86, 81, 83, "USED-FOR"], [91, 91, 81, 83, "USED-FOR"], [85, 85, 86, 86, "USED-FOR"], [85, 85, 91, 91, "USED-FOR"], [85, 85, 88, 88, "USED-FOR"], [88, 88, 81, 83, "USED-FOR"], [89, 91, 86, 86, "USED-FOR"], [89, 91, 91, 91, "USED-FOR"], [89, 91, 88, 88, "USED-FOR"]]]}
{"doc_key": "2108.01375-cedbaa9d-4e4b-4281-a8ab-2de6d131eaea", "sentences": [["In", "-LSB-", "5", "-RSB-", ",", "the", "authors", "are", "using", "as", "input", "to", "the", "TCN", "the", "raw", "3D", "skeleton", "points", "."], ["We", "have", "used", "a", "similar", "setup", ",", "but", "have", "also", "tested", "the", "system", "performance", "when", "it", "receives", "as", "input", "the", "angles", "between", "different", "joints", "."], ["For", "3D", "skeleton", "points", "setup", ",", "we", "take", "the", "computed", "-LRB-", "X", ",", "Y", ",", "Z", "-RRB-", "values", "of", "each", "skeleton", "joint", "and", "concatenate", "all", "values", "to", "form", "a", "skeleton", "feature", "."], ["A", "skeleton", "feature", "per", "frame", "is", "a", "66", "dimensional", "vector", "obtained", "by", "multiplying", "the", "number", "of", "joints", "-LRB-", "which", "is", "22", "-RRB-", "with", "the", "data", "per", "point", "-LRB-", "which", "is", "3", "-RRB-", "as", "it", "can", "be", "seen", "in", "Figure", "REF", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[13, 13, "a"], [16, 18, "a"]], [[40, 43, "a"]], [[46, 48, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[13, 13, "a"]], [], [], [[84, 85, "v"], [97, 97, "v"], [107, 107, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.01375-8f76aa1f-c1f8-4426-8e3e-4bfc09ff2e68", "sentences": [["For", "the", "Res-TCN", "parameters", ",", "we", "used", "the", "same", "configuration", "as", "proposed", "by", "-LSB-", "5", "-RSB-", ":", "stochastic", "gradient", "descent", "with", "nesterov", "acceleration", "with", "a", "momentum", "of", "0.9", ",", "all", "convolution", "layers", "have", "applied", "a", "\\", "-LRB-", "L1\\", "-RRB-", "regularizer", "with", "a", "weight", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "to", "prevent", "overfitting", "a", "dropout", "of", "0.5", "is", "applied", "after", "every", "ReLU", "."]], "ner": [[[27, 27, "v"], [60, 60, "v"]]], "relations": [[]], "predicted_ner": [[[2, 2, "a"], [17, 19, "a"], [21, 22, "a"], [27, 27, "v"], [37, 37, "a"], [42, 42, "p"], [46, 48, "v"], [58, 58, "p"], [60, 60, "v"], [65, 65, "a"]]], "predicted_relations": [[]]}
{"doc_key": "2103.00737-f54297ed-12f1-424c-bf10-ab455e6e01bf", "sentences": [["For", "each", "training", "program", ",", "our", "meta-algorithm", "used", "\\", "-LRB-", "2^", "-LCB-", "15", "-RCB-", "\\", "-RRB-", "samples", "from", "the", "analytic", "-LRB-", "for", "\\", "-LRB-", "\\mathsf", "-LCB-", "gauss", "-RCB-", "\\", "-RRB-", "-RRB-", "or", "approximate", "-LRB-", "for", "the", "rest", ",", "by", "HMC", "-RRB-", "posterior", "distribution", "for", "the", "program.Except", "for", "\\", "-LRB-", "\\mathsf", "-LCB-", "rb", "-RCB-", "\\", "-RRB-", ";", "see", "the", "discussion", "on", "Rosenbrock", "models", "in", "Appendix", "."], ["Similarly", ",", "our", "meta-algorithm", "computed", "the", "marginal", "likelihood", "analytically", "-LRB-", "for", "\\", "-LRB-", "\\mathsf", "-LCB-", "gauss", "-RCB-", "\\", "-RRB-", "-RRB-", "or", "approximately", "-LRB-", "for", "the", "rest", "-RRB-", "using", "layered", "adaptive", "importance", "sampling", "-LSB-", "26", "-RSB-", "where", "the", "proposals", "were", "defined", "by", "an", "HMC", "chain", "."], ["We", "performed", "mini-batch", "training", ";", "a", "single", "gradient", "update", "was", "done", "with", "a", "training", "program", "and", "a", "mini", "batch", "of", "size", "\\", "-LRB-", "2^", "-LCB-", "12", "-RCB-", "\\", "-RRB-", "-LRB-", "out", "of", "\\", "-LRB-", "2^", "-LCB-", "15", "-RCB-", "\\", "-RRB-", "samples", "for", "the", "program", "-RRB-", "."], ["We", "used", "Adam", "-LSB-", "20", "-RSB-", "with", "its", "hyperparameters", "\\", "-LRB-", "\\lbrace", "\\beta", "_1=0.9", ",", "\\", ",", "\\beta", "_2=0.999", ",", "\\", ",", "\\textrm", "-LCB-", "weight\\_decay", "-RCB-", "=0\\rbrace", "\\", "-RRB-", ",", "and", "the", "initial", "learning", "rate", "was", "set", "to", "\\", "-LRB-", "0.001\\", "-RRB-", "."], ["When", "the", "average", "training", "loss", "converged", "enough", ",", "the", "training", "stopped", "."], ["We", "repeated", "the", "same", "experiments", "three", "times", "using", "different", "random", "seeds", "."]], "ner": [[[39, 39, "a"]], [[107, 107, "a"]], [], [[158, 158, "a"], [169, 169, "v"], [174, 174, "v"], [169, 169, "v"], [174, 174, "v"], [182, 182, "v"], [196, 196, "v"], [188, 190, "p"], [196, 196, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [60, 61, "a"]], [[68, 68, "a"], [93, 96, "a"]], [[112, 113, "a"]], [[158, 158, "a"], [189, 190, "p"], [196, 196, "v"]], [], [[216, 216, "v"]]], "predicted_relations": [[], [], [], [[182, 182, 188, 190, "USED-FOR"], [188, 190, 158, 158, "USED-FOR"]], [], []]}
{"doc_key": "2103.00737-b8b8f1f2-3d06-49c1-b0ae-1f40760479dc", "sentences": [["Results", "Fig", "."], ["REF", "shows", "the", "training", "and", "test", "losses", "for", "\\", "-LRB-", "\\mathsf", "-LCB-", "gauss", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\mathsf", "-LCB-", "hierl", "-RCB-", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\mathsf", "-LCB-", "milky", "-RCB-", "\\", "-RRB-", "under", "three", "random", "seeds", "."], ["The", "losses", "for", "the", "other", "model", "classes", "are", "in", "Appendix", "."], ["The", "training", "loss", "was", "averaged", "over", "the", "training", "set", "and", "8", "batch", "updates", ",", "and", "the", "test", "loss", "over", "the", "test", "set", "."], ["The", "training", "losses", "in", "all", "three", "experiments", "decreased", "rapidly", ",", "and", "more", "importantly", ",", "these", "decreases", "were", "accompanied", "by", "the", "downturns", "of", "the", "test", "losses", ",", "which", "shows", "that", "the", "learnt", "parameters", "generalised", "to", "the", "test", "programs", "well", "."], ["The", "later", "part", "of", "Fig", "."], ["REF", "shows", "cases", "where", "the", "test", "loss", "increases", "."], ["This", "was", "because", "the", "loss", "of", "only", "a", "few", "programs", "in", "the", "test", "set", "-LRB-", "of", "50", "programs", "-RRB-", "became", "large", "."], ["Even", "in", "this", "situation", ",", "the", "losses", "of", "the", "rest", "remained", "small", "."]], "ner": [[], [[15, 15, "a"], [24, 24, "a"], [34, 34, "a"]], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[39, 39, "v"]], [], [[64, 64, "v"]], [[82, 82, "v"]], [], [], [[147, 147, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2106.09171-7df39f48-1d5b-4402-a79f-67a3ec812145", "sentences": [["LiRA-Supervised", "In", "LiRA-Supervised", ",", "we", "train", "word-level", "-LRB-", "Fig", "."], ["-LSB-", "fig", ":", "variationsd", "-RSB-", "2a", "-RRB-", "and", "sentence-level", "lip-reading", "models", "-LRB-", "Fig", "."], ["-LSB-", "fig", ":", "variationsd", "-RSB-", "2d", "-RRB-", "from", "scratch", "."], ["In", "particular", ",", "for", "the", "task", "of", "word-level", "lip-reading", ",", "we", "add", "a", "MS-TCN", "followed", "by", "a", "linear", "classifier", "with", "an", "output", "dimension", "of", "500", "on", "top", "of", "the", "encoder", "like", "."], ["A", "cross-entropy", "loss", "is", "employed", "to", "optimise", "the", "whole", "model", "using", "Adam", "with", "decoupled", "Weight", "decay", "-LRB-", "AdamW", "-RRB-", "with", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_", "-LCB-", "2", "-RCB-", "=0.999\\", "-RRB-", ",", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "and", "a", "weight", "decay", "of", "0.01", "for", "80", "epochs", "with", "a", "batch", "size", "of", "32", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.0003", "."], ["For", "the", "task", "of", "sentence-level", "lip-reading", ",", "we", "use", "12", "multi-head", "attention", "blocks", "-LRB-", "\\", "-LRB-", "d^", "-LCB-", "-LCB-", "\\rm", "ff", "-RCB-", "-RCB-", "=2048\\", "-RRB-", ",", "\\", "-LRB-", "n^", "-LCB-", "-LCB-", "\\rm", "head", "-RCB-", "-RCB-", "=4\\", "-RRB-", ",", "\\", "-LRB-", "d^", "-LCB-", "-LCB-", "\\rm", "q", "-RCB-", "-RCB-", "=256\\", "-RRB-", ",", "\\", "-LRB-", "d^", "-LCB-", "-LCB-", "\\rm", "k", "-RCB-", "-RCB-", "=256\\", "-RRB-", ",", "\\", "-LRB-", "d^", "-LCB-", "-LCB-", "\\rm", "v", "-RCB-", "-RCB-", "=256\\", "-RRB-", "-RRB-", "together", "with", "a", "linear", "layer", "on", "the", "top", "of", "conformer", "blocks", "like", "."], ["Following", ",", "we", "use", "a", "combination", "of", "CTC", "and", "cross-entropy", "loss", "to", "train", "a", "hybrid", "CTC/Attention", "architecture", "for", "50", "epochs", "with", "a", "batch", "size", "of", "8", "."], ["In", "this", "case", ",", "we", "use", "Adam", "with", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_", "-LCB-", "2", "-RCB-", "=0.98\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-9", "-RCB-", "\\", "-RRB-", "with", "the", "first", "25", "000", "steps", "for", "warm-up", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.0004", "."], ["At", "the", "decoding", "phase", ",", "we", "use", "a", "beam", "size", "of", "20", "for", "beam", "search", "."], ["During", "decoding", ",", "we", "also", "apply", "a", "transformer-based", "language", "model", "trained", "on", "LRS2", ",", "LRS3", ",", "and", "Librispeech", "960h", "-LRB-", "16.2", "million", "words", "in", "total", "-RRB-", "."], ["Due", "to", "graphic", "memory", "limitations", ",", "we", "exclude", "utterances", "with", "more", "than", "600", "frames", "during", "training", "."]], "ner": [[], [], [], [[47, 47, "a"]], [[77, 77, "a"], [93, 93, "v"], [103, 103, "v"], [108, 108, "p"], [83, 83, "a"], [93, 93, "v"], [108, 108, "p"]], [], [[163, 163, "v"], [175, 175, "v"], [187, 187, "v"], [199, 199, "v"], [211, 211, "v"], [187, 187, "v"], [199, 199, "v"], [211, 211, "v"], [187, 187, "v"], [199, 199, "v"], [211, 211, "v"]], [[234, 234, "a"], [242, 242, "a"]], [[260, 260, "a"], [269, 269, "v"], [284, 284, "p"], [269, 269, "v"], [279, 279, "v"], [284, 284, "p"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [[47, 47, "a"], [55, 56, "p"], [58, 58, "v"]], [[67, 68, "a"], [77, 77, "a"], [93, 93, "v"], [103, 103, "v"], [117, 118, "p"], [120, 120, "v"], [122, 122, "v"], [123, 123, "p"], [126, 127, "p"], [129, 129, "v"]], [[133, 134, "p"], [138, 138, "v"]], [[149, 149, "v"], [163, 163, "v"], [187, 187, "v"], [199, 199, "v"], [211, 211, "v"]], [[234, 234, "a"], [236, 237, "a"], [242, 243, "a"], [245, 245, "v"], [246, 246, "p"], [249, 250, "p"], [252, 252, "v"]], [[260, 260, "a"], [269, 269, "v"], [294, 295, "v"]], [[302, 303, "p"], [307, 307, "v"]], [[317, 318, "p"], [320, 320, "v"]], [[332, 332, "a"], [337, 337, "a"], [339, 339, "a"], [342, 343, "a"], [345, 345, "v"]], [[364, 364, "v"]]], "predicted_relations": [[], [], [], [], [[103, 103, 108, 108, "USED-FOR"], [103, 103, 108, 108, "USED-FOR"], [108, 108, 77, 77, "USED-FOR"], [108, 108, 83, 83, "USED-FOR"], [108, 108, 77, 77, "USED-FOR"], [108, 108, 83, 83, "USED-FOR"]], [], [], [], [[284, 284, 260, 260, "USED-FOR"], [279, 279, 284, 284, "USED-FOR"], [279, 279, 284, 284, "USED-FOR"], [284, 284, 260, 260, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2106.09171-a2c929c6-8203-4275-8324-1d6ae5dd375c", "sentences": [["LiRA-Frozen", "At", "the", "end", "of", "self-supervised", "training", ",", "the", "features", "extracted", "from", "the", "pre-trained", "frozen", "encoder", "are", "fed", "to", "a", "classifier", "for", "evaluation", "."], ["For", "word-level", "lip-reading", ",", "we", "use", "a", "MS-TCN", ",", "followed", "by", "a", "linear", "layer", "with", "an", "output", "size", "of", "500", "for", "classification", "-LRB-", "Fig", ".", "-LSB-", "fig", ":", "variationsd", "-RSB-", "2b", "-RRB-", "."], ["For", "the", "sentence-level", "lip-reading", ",", "the", "LiRA", "features", "are", "first", "fed", "to", "12", "conformer", "blocks", ",", "and", "then", "the", "encoded", "representations", "are", "used", "for", "CTC/attention", "joint", "training", "-LRB-", "Fig", "."], ["-LSB-", "fig", ":", "variationsd", "-RSB-", "2e", "-RRB-", "."]], "ner": [[], [[31, 31, "a"], [43, 43, "v"]], [[81, 83, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[31, 31, "a"], [43, 43, "v"]], [[63, 63, "a"], [69, 69, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2111.14819-ce953b81-c956-44af-bf36-9e8bf3cd78a0", "sentences": [["dVAE", "Setups", "."], ["We", "use", "a", "four-layer", "DGCNN", "-LSB-", "57", "-RSB-", "to", "learn", "the", "inter-patch", "relationships", ",", "modeling", "the", "internal", "structures", "of", "input", "point", "clouds", "."], ["During", "dVAE", "training", ",", "we", "set", "the", "vocabulary", "size", "\\", "-LRB-", "N\\", "-RRB-", "to", "8192", "."], ["Our", "decoder", "is", "also", "a", "DGCNN", "architecture", "followed", "by", "a", "FoldingNet", "-LSB-", "62", "-RSB-", "."], ["It", "is", "worth", "noting", "that", "the", "performance", "of", "dVAE", "is", "susceptible", "to", "hyper-parameters", ",", "which", "makes", "that", "the", "configurations", "of", "image-based", "dVAE", "-LSB-", "41", "-RSB-", "can", "not", "be", "directly", "used", "in", "our", "scenarios", "."], ["The", "commonly", "used", "\\", "-LRB-", "\\ell", "_1\\", "-RRB-", "-style", "Chamfer", "Distance", "loss", "is", "employed", "during", "the", "reconstruction", "procedure", "."], ["Since", "the", "value", "of", "this", "\\", "-LRB-", "\\ell", "_1\\", "-RRB-", "loss", "is", "numerically", "small", ",", "the", "weight", "of", "KLD", "loss", "in", "Eq.REF", "must", "be", "smaller", "than", "that", "in", "the", "image", "tasks", "."], ["We", "set", "the", "weight", "of", "KLD", "loss", "to", "0", "in", "the", "first", "10,000", "steps", "and", "gradually", "increased", "to", "0.1", "in", "the", "following", "100,000", "steps", "."], ["The", "learning", "rate", "is", "set", "to", "0.0005", "with", "a", "cosine", "learning", "schedule", "with", "60,000", "steps", "warming", "up", "."], ["We", "decay", "the", "temperature", "in", "Gumble-softmax", "function", "from", "1", "to", "0.0625", "in", "100,000", "steps", "following", "-LSB-", "41", "-RSB-", "."], ["We", "train", "dVAE", "for", "a", "total", "of", "150,000", "steps", "with", "a", "batch", "size", "of", "64", "."]], "ner": [[], [[7, 7, "a"]], [], [[47, 47, "a"], [52, 52, "a"]], [], [[100, 102, "a"]], [[128, 129, "a"], [126, 126, "p"]], [[147, 148, "a"], [145, 145, "p"], [150, 150, "v"], [160, 160, "v"], [160, 160, "v"], [160, 160, "v"]], [[173, 173, "v"], [168, 169, "a"], [176, 178, "a"]], [[195, 195, "v"], [190, 191, "a"], [188, 188, "p"], [193, 193, "v"], [195, 195, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[6, 6, "v"], [7, 7, "a"]], [[33, 34, "p"], [37, 37, "p"], [40, 40, "v"]], [[47, 47, "a"], [52, 52, "a"]], [[65, 65, "a"], [78, 78, "a"]], [[100, 102, "a"]], [[128, 129, "a"]], [[147, 148, "a"], [150, 150, "v"], [154, 154, "v"], [160, 160, "v"], [164, 164, "v"]], [[168, 169, "p"], [173, 173, "v"], [180, 180, "v"]], [[190, 191, "a"], [193, 193, "v"], [195, 195, "v"], [197, 197, "v"]], [[206, 206, "a"], [211, 211, "v"], [215, 216, "p"], [218, 218, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[126, 126, 128, 129, "USED-FOR"]], [[145, 145, 147, 148, "USED-FOR"], [150, 150, 145, 145, "USED-FOR"]], [], [], []]}
{"doc_key": "2111.14819-b3b0bfce-f7d8-4f8a-a013-1e2cba1fe59c", "sentences": [["MPM", "Setups", "."], ["In", "our", "experiments", ",", "we", "set", "the", "depth", "for", "the", "Transformer", "to", "12", ",", "the", "feature", "dimension", "to", "384", ",", "and", "the", "number", "of", "heads", "to", "6", "."], ["The", "stochastic", "depth", "-LSB-", "15", "-RSB-", "with", "a", "0.1", "rate", "is", "applied", "in", "our", "transformer", "encoder", "."], ["During", "MPM", "pre-training", ",", "we", "fix", "the", "weights", "of", "Tokenizer", "learned", "by", "dVAE", "."], ["25", "%", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "45", "%", "input", "point", "embeddings", "are", "randomly", "masked", "out", "."], ["The", "model", "is", "then", "trained", "to", "infer", "the", "expected", "point", "tokens", "at", "those", "masked", "locations", "."], ["In", "terms", "of", "MoCo", ",", "we", "set", "the", "memory", "bank", "size", "to", "16,384", ",", "temperature", "to", "0.07", ",", "and", "weight", "momentum", "to", "0.999", "."], ["We", "employ", "an", "AdamW", "-LSB-", "29", "-RSB-", "optimizer", ",", "using", "an", "initial", "learning", "rate", "of", "0.0005", "and", "a", "weight", "decay", "of", "0.05", "."], ["The", "model", "is", "trained", "for", "300", "epochs", "with", "a", "batch", "size", "of", "128", "."]], "ner": [[], [[13, 13, "a"], [10, 10, "p"], [15, 15, "v"], [18, 19, "p"], [21, 21, "v"], [25, 27, "p"], [29, 29, "v"]], [[33, 33, "p"], [32, 33, "a"], [40, 40, "p"], [39, 39, "v"]], [[49, 50, "a"], [50, 50, "a"]], [], [], [[107, 107, "v"], [98, 98, "a"], [103, 105, "p"], [107, 107, "v"], [109, 109, "p"], [111, 111, "v"], [114, 115, "p"], [117, 117, "v"]], [[132, 132, "p"], [122, 122, "a"], [130, 132, "p"], [134, 134, "v"], [137, 138, "p"], [140, 140, "v"]], [[148, 148, "p"], [147, 147, "v"], [151, 152, "p"], [154, 154, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[15, 15, "v"], [18, 19, "p"], [21, 21, "v"], [29, 29, "v"]], [[32, 33, "p"], [39, 39, "v"]], [[60, 60, "a"]], [[62, 63, "v"], [69, 70, "v"]], [], [[98, 98, "a"], [107, 107, "v"], [109, 109, "p"], [111, 111, "v"], [114, 115, "p"], [117, 117, "v"]], [[122, 122, "a"], [131, 132, "p"], [134, 134, "v"], [137, 138, "p"], [140, 140, "v"]], [[147, 147, "v"], [148, 148, "p"], [151, 152, "p"], [154, 154, "v"]]], "predicted_relations": [[], [[10, 10, 13, 13, "USED-FOR"], [15, 15, 10, 10, "USED-FOR"], [18, 19, 13, 13, "USED-FOR"], [21, 21, 18, 19, "USED-FOR"], [29, 29, 25, 27, "USED-FOR"]], [], [], [], [], [[103, 105, 98, 98, "USED-FOR"], [109, 109, 98, 98, "USED-FOR"], [114, 115, 98, 98, "USED-FOR"]], [[132, 132, 122, 122, "USED-FOR"], [130, 132, 122, 122, "USED-FOR"], [134, 134, 130, 132, "USED-FOR"], [134, 134, 137, 138, "USED-FOR"], [137, 138, 122, 122, "USED-FOR"], [140, 140, 137, 138, "USED-FOR"]], [[147, 147, 148, 148, "USED-FOR"], [154, 154, 148, 148, "USED-FOR"]]]}
{"doc_key": "2108.12472-93ad6f07-2296-46ea-afba-d5bc8d0d1718", "sentences": [["All", "our", "experiments", "were", "run", "using", "NVIDIA", "V100", "GPUs", "for", "training", "and", "validation", ",", "some", "trainings", "were", "done", "on", "A100", "."], ["We", "distributed", "our", "training", "to", "2-4", "GPUs", "depending", "on", "availability", "."], ["Each", "training", "epoch", "for", "CE", "ranged", "from", "30", "minutes", "to", "1", "hour", "depending", "on", "number", "of", "GPUs", "utilized", "."]], "ner": [[[6, 8, "a"], [19, 19, "a"]], [[26, 26, "v"]], [[33, 36, "a"], [46, 49, "p"]]], "relations": [[], [], []], "predicted_ner": [[[19, 19, "a"]], [[26, 26, "v"]], [[36, 36, "a"], [39, 39, "v"], [42, 42, "v"]]], "predicted_relations": [[], [], [[46, 49, 33, 36, "USED-FOR"]]]}
{"doc_key": "2108.12472-dc1e8c3e-e458-4558-8888-d597a2ca13ed", "sentences": [["Validation", "and", "testing", "-LRB-", "1,779", "and", "2,155", "samples", "for", "testA", "and", "testB", "of", "WebNLG+", "2020", "-RRB-", "lasted", "from", "40", "minutes", "to", "1", "hour", "depending", "on", "machines", "."], ["Computation", "was", "dominated", "by", "beam", "search", "generation", "as", "we", "used", "beam", "search", "with", "beam", "size", "of", "5", "and", "a", "max", "sequence", "length", "of", "192", "-LRB-", "since", "linearized", "graph", "sequence", "can", "be", "quite", "long", "-RRB-", "."], ["We", "used", "the", "official", "scoring", "scripts", "released", "by", "WebNLG+", "2020", "Challenge", "to", "score", "all", "our", "experiments", "."], ["The", "evaluation", "of", "graph", "being", "the", "most", "computationally", "expensive", "as", "all", "possible", "matching", "combinations", "are", "tested", "in", "what", "looks", "like", "a", "factorial", "complexity", ",", "taking", "scoring", "of", "set", "of", "triples", "larger", "than", "8", "from", "impractical", "to", "not", "feasible", "."]], "ner": [[[0, 2, "a"]], [[31, 33, "a"], [40, 41, "p"], [50, 50, "v"], [46, 48, "p"]], [[65, 67, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "v"], [6, 6, "v"], [13, 14, "a"], [18, 18, "v"], [21, 21, "v"]], [[31, 32, "a"], [37, 38, "a"], [40, 41, "p"], [43, 43, "v"], [50, 50, "v"]], [], [[111, 111, "v"]]], "predicted_relations": [[], [[40, 41, 31, 33, "USED-FOR"], [50, 50, 46, 48, "USED-FOR"], [46, 48, 31, 33, "USED-FOR"]], [], []]}
{"doc_key": "2108.12472-a62303c6-8ed5-4d62-b95b-c0913a8dc953", "sentences": [["All", "our", "models", "were", "built", "using", "PyTorch", "."], ["Total", "effective", "batch", "sizes", "were", "set", "to", "either", "20", "or", "24", "samples", "for", "our", "distributed", "training", "."], ["We", "adjusted", "the", "batch", "size", "on", "each", "worker", "to", "ensure", "consistent", "global", "batch", "size", "of", "20", "or", "24", "."]], "ner": [[[6, 6, "a"]], [[22, 23, "a"], [16, 16, "v"], [18, 18, "v"]], [[28, 29, "p"], [37, 38, "p"], [40, 40, "v"], [36, 38, "c"], [42, 42, "v"], [36, 38, "c"]]], "relations": [[], [], []], "predicted_ner": [[], [[16, 16, "v"], [18, 18, "v"]], [[40, 40, "v"], [42, 42, "v"]]], "predicted_relations": [[], [], [[40, 40, 37, 38, "USED-FOR"], [42, 42, 37, 38, "USED-FOR"]]]}
{"doc_key": "2107.02137-27d6071e-7438-4d3e-969d-88a888698d92", "sentences": [["Both", "the", "universal", "representation", "module", "and", "the", "task-specific", "representation", "modules", "of", "ERNIE", "3.0", "uses", "the", "Transformer-XL", "-LSB-", "33", "-RSB-", "structure", "as", "the", "backbone", "."], ["For", "the", "universal", "representation", "module", ",", "we", "adopt", "a", "structure", "with", "48", "layers", ",", "4096", "hidden", "units", "and", "64", "heads", "."], ["For", "the", "task-specific", "representation", "modules", ",", "we", "adopt", "a", "structure", "with", "12", "layers", ",", "768", "hidden", "units", "and", "12", "heads", "."], ["The", "total", "parameter", "of", "universal", "representation", "module", "and", "task-specific", "representation", "modules", "is", "10", "billion", "."], ["The", "activation", "function", "used", "is", "GeLU", "-LSB-", "45", "-RSB-", "."], ["The", "maximum", "sequence", "length", "of", "context", "and", "the", "memory", "length", "of", "language", "generation", "is", "set", "to", "512", "and", "128", ",", "respectively", "."], ["The", "total", "batch", "size", "of", "all", "pre-training", "tasks", "is", "set", "to", "6144", "."], ["We", "use", "Adam", "-LSB-", "46", "-RSB-", "with", "learning", "rate", "of", "1e-4", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", ",", "L2", "weight", "decay", "of", "0.01", ",", "learning", "rate", "warmup", "over", "the", "first", "10,000", "steps", "and", "linear", "decay", "of", "the", "learning", "rate", "."], ["In", "the", "first", "10,000", "steps", ",", "we", "also", "use", "the", "progressive", "learning", "to", "speedup", "convergence", "in", "the", "initial", "stage", "of", "pre-training", "."], ["The", "model", "is", "trained", "for", "a", "total", "of", "375", "billion", "tokens", "with", "384", "NVDIA", "v100", "GPU", "cards", "and", "is", "implemented", "on", "PaddlePaddle", "framework", "."], ["By", "virtue", "of", "parameter", "sharding", "used", "in", "-LSB-", "47", "-RSB-", ",", "-LSB-", "48", "-RSB-", ",", "we", "manage", "to", "reduce", "the", "memory", "usage", "of", "our", "model", "and", "address", "the", "problem", "of", "the", "total", "parameter", "of", "model", "exceeding", "the", "memory", "of", "a", "single", "GPU", "card", "."]], "ner": [[[15, 15, "a"]], [[39, 40, "p"], [38, 38, "v"], [43, 43, "p"], [42, 42, "v"]], [[60, 61, "p"], [59, 59, "v"], [64, 64, "p"], [56, 56, "v"], [63, 63, "v"]], [], [[86, 86, "a"]], [], [], [[128, 128, "a"], [133, 134, "p"], [156, 157, "p"], [169, 170, "p"], [136, 136, "v"], [141, 141, "v"], [147, 147, "v"], [150, 152, "p"], [154, 154, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[11, 12, "a"], [15, 15, "a"]], [[35, 35, "v"], [36, 36, "p"], [38, 38, "v"], [39, 40, "p"], [42, 42, "v"]], [[56, 56, "v"], [57, 57, "p"], [59, 59, "v"], [60, 61, "p"], [63, 63, "v"]], [[78, 78, "v"]], [[86, 86, "a"]], [[107, 107, "v"], [109, 109, "v"]], [[124, 124, "v"]], [[128, 128, "a"], [133, 134, "p"], [136, 136, "v"], [150, 150, "a"], [150, 152, "p"], [154, 154, "v"], [156, 157, "p"], [162, 162, "v"], [165, 166, "v"], [169, 170, "p"]], [[175, 175, "v"], [182, 183, "a"]], [[202, 202, "v"], [206, 206, "v"], [215, 216, "a"]], [[242, 242, "a"]]], "predicted_relations": [[], [[38, 38, 43, 43, "USED-FOR"], [42, 42, 43, 43, "USED-FOR"]], [[59, 59, 64, 64, "USED-FOR"], [56, 56, 64, 64, "USED-FOR"], [63, 63, 64, 64, "USED-FOR"]], [], [], [], [], [[133, 134, 128, 128, "USED-FOR"], [156, 157, 128, 128, "USED-FOR"], [136, 136, 133, 134, "USED-FOR"], [147, 147, 150, 152, "USED-FOR"], [150, 152, 128, 128, "USED-FOR"], [154, 154, 156, 157, "USED-FOR"], [154, 154, 150, 152, "USED-FOR"]], [], [], []]}
{"doc_key": "2107.02195-23f30b26-3157-4969-ae5f-411d6eef04a0", "sentences": [["We", "test", "all", "audio", "encoders", "in", "the", "Music", "Recognition", "scenario", ",", "where", "training", "converges", "within", "\\", "-LRB-", "5\\times", "10^8\\", "-RRB-", "environment", "steps", "."], ["We", "then", "choose", "the", "best-performing", "encoder", "for", "other", "experiments", ",", "where", "we", "train", "for", "\\", "-LRB-", "10^9\\", "-RRB-", "steps", "in", "Sound", "Instruction", "scenarios", "and", "for", "\\", "-LRB-", "2\\times", "10^9\\", "-RRB-", "steps", "in", "Duel", "scenario", "."], ["We", "fixed", "the", "image", "resolution", "to", "128x72", "and", "set", "the", "frameskip", "to", "4", "for", "all", "environments", "except", "Duel", "which", "was", "run", "with", "2-frameskip", "."]], "ner": [[[7, 9, "a"], [20, 21, "a"], [20, 21, "p"]], [[43, 45, "a"], [55, 56, "a"], [50, 50, "v"], [55, 55, "c"]], [[70, 70, "v"], [80, 80, "v"], [61, 62, "p"], [68, 68, "p"], [80, 80, "p"], [75, 75, "c"]]], "relations": [[], [], []], "predicted_ner": [[[18, 18, "v"]], [[39, 39, "v"], [51, 51, "v"]], [[64, 64, "v"], [70, 70, "v"], [75, 75, "a"]]], "predicted_relations": [[[20, 21, 7, 9, "USED-FOR"], [20, 21, 20, 21, "USED-FOR"]], [], [[80, 80, 80, 80, "USED-FOR"], [75, 75, 80, 80, "USED-FOR"]]]}
{"doc_key": "2107.05599-48fa53be-62b2-4573-bbeb-db923e01b23e", "sentences": [["-LSB-", "20", "-RSB-", "presents", "an", "evolutionary", "approach", "for", "exploring", "and", "finding", "effective", "and", "customisable", "neural", "style", "transfer", "blends", "."], ["Upwards", "of", "1000", "neural", "style", "transfer", "models", "trained", "on", "1-10", "style", "images", "each", ",", "can", "be", "blended", "through", "model", "interpolation", ",", "using", "an", "interface", "that", "is", "controlled", "by", "the", "user", "."], ["MAP-Elites", "-LSB-", "55", "-RSB-", "in", "combination", "with", "a", "fitness", "function", "calculated", "using", "the", "output", "from", "a", "ResNet", "model", "-LSB-", "37", "-RSB-", "were", "used", "in", "evolutionary", "searches", "for", "optimal", "neural", "style", "transfer", "blends", "."]], "ner": [[[5, 6, "a"], [14, 16, "a"]], [[22, 24, "a"], [29, 30, "p"], [28, 28, "v"]], [[50, 50, "a"], [66, 67, "a"], [78, 80, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [[21, 21, "v"], [28, 28, "v"]], [[50, 50, "a"], [66, 67, "a"]]], "predicted_relations": [[], [[29, 30, 22, 24, "USED-FOR"], [28, 28, 29, 30, "USED-FOR"]], []]}
{"doc_key": "2107.08591-cf6f3723-6d47-4caf-a8c7-346efb76e7ad", "sentences": [["Our", "network", "is", "trained", "end-to-end", "with", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "batch", "size", "16", "-LRB-", "at", "most", "case", "-RRB-", ",", "momentum", "0.9", ",", "and", "weight", "decay", "0.0001", "."], ["The", "pre-trained", "models", "are", "trained", "on", "the", "ImageNet", "and", "the", "output", "stride", "is", "set", "to", "1/8", "."], ["Following", "previous", "works", ",", ",", ",", "we", "use", "the", "poly", "strategy", "in", "which", "the", "current", "learning", "rate", "is", "multiplied", "by", "\\", "-LRB-", "-LRB-", "1", "-", "\\frac", "-LCB-", "iter", "-RCB-", "-LCB-", "max\\_iter", "-RCB-", "-RRB-", "^", "-LCB-", "power", "-RCB-", "\\", "-RRB-", "each", "iteration", "with", "power", "0.9", "."], ["The", "base", "learning", "rate", "is", "set", "to", "0.01", "."], ["Following", "the", "previous", "works", ",", ",", ",", "the", "weight", "balance", "parameters", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "are", "set", "to", "\\", "-LRB-", "10^3\\", "-RRB-", "and", "10", "to", "maintain", "a", "balance", "with", "the", "cross-entropy", "loss", "function", "."], ["The", "iteration", "number", "is", "set", "to", "40K", "for", "Cityscapes", ",", "10K", "for", "CamVid", ",", "60K", "for", "Pascal", "VOC", "2012", ",", "and", "125K", "for", "ADE20K", "."], ["The", "input", "size", "is", "set", "to", "\\", "-LRB-", "513", "\\times", "513\\", "-RRB-", "for", "Cityscapes", ",", "\\", "-LRB-", "480", "\\times", "360\\", "-RRB-", "for", "CamVid", ",", "and", "\\", "-LRB-", "473", "\\times", "473\\", "-RRB-", "for", "both", "Pascal", "VOC", "2012", "and", "ADE20K", "during", "training", "and", "inference", "."], ["For", "data", "augmentation", ",", "the", "random", "horizontal", "flip", "and", "random", "resize", "between", "0.5", "and", "2", "are", "adopted", "."], ["Then", ",", "all", "images", "are", "resized", "to", "have", "the", "maximum", "extent", "of", "the", "long", "side", "of", "the", "input", "size", "and", "padded", "with", "mean", "to", "the", "input", "size", "."], ["For", "inference", ",", "we", "verify", "the", "performance", "on", "a", "single", "scale", "and", "original", "inputs", "."], ["Besides", ",", "only", "the", "conventional", "cross-entropy", "loss", "is", "applied", "in", "the", "experiments", ",", "the", "class", "probability", "weighting", ",", "hard", "sample", "mining", "strategy", ",", "and", "deep", "supervision", "are", "excluded", "unless", "otherwise", "specified", "."], ["Our", "method", "is", "implemented", "by", "Pytorch", "framework", "."], ["All", "networks", "are", "trained", "on", "a", "single", "NVIDIA", "Tesla", "V100", "GPU", "with", "32GB", "memory", "."]], "ner": [[[13, 14, "p"], [15, 15, "v"], [22, 22, "p"], [23, 23, "v"], [26, 27, "p"], [28, 28, "v"], [23, 23, "v"]], [[37, 37, "a"]], [[90, 90, "v"], [56, 57, "a"], [82, 82, "p"], [89, 89, "p"], [90, 90, "v"]], [[93, 95, "p"], [99, 99, "v"]], [[109, 111, "a"], [128, 128, "v"], [128, 128, "v"], [131, 131, "v"], [138, 140, "a"]], [], [], [], [], [], [], [[308, 308, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [6, 11, "a"], [13, 14, "p"], [15, 15, "v"], [23, 23, "v"], [26, 27, "p"], [28, 28, "v"]], [[37, 37, "a"], [45, 45, "v"]], [[62, 63, "p"], [90, 90, "v"]], [[94, 95, "p"], [99, 99, "v"]], [[109, 111, "p"], [114, 114, "p"], [120, 120, "p"], [128, 128, "v"], [131, 131, "v"], [138, 138, "a"]], [[143, 144, "p"], [148, 148, "v"], [149, 150, "c"], [152, 152, "v"], [154, 154, "a"], [156, 156, "v"], [158, 160, "a"], [163, 163, "v"], [165, 165, "a"]], [[175, 175, "v"], [177, 177, "v"], [184, 184, "v"], [186, 186, "v"], [189, 189, "a"], [194, 194, "v"], [196, 196, "v"], [200, 202, "a"], [204, 204, "a"]], [[222, 222, "v"], [224, 224, "v"]], [], [], [[276, 277, "a"]], [[304, 304, "a"]], [[323, 323, "v"]]], "predicted_relations": [[[15, 15, 22, 22, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 26, 27, "USED-FOR"]], [], [], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2107.10963-19221707-280e-4b48-bad8-86e03272b8cd", "sentences": [["In", "all", "our", "experiments", ",", "we", "used", "RMSProp", "optimizer", "."], ["In", "smaller", "scale", "experiments", ",", "the", "learning", "rate", "was", "chosen", "to", "be", "either", "\\", "-LRB-", "0.02\\", "-RRB-", ",", "or", "\\", "-LRB-", "0.04\\", "-RRB-", "."], ["The", "dropout", "keep", "probability", "and", "the", "weight", "decay", "were", "\\", "-LRB-", "80\\", "%", "\\", "-RRB-", "and", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "correspondingly", "."], ["In", "all", "of", "our", "experiments", ",", "we", "used", "exponential", "moving", "averages", "of", "all", "trained", "variable", "for", "inference", "."]], "ner": [[[7, 8, "a"]], [[16, 17, "p"], [25, 25, "v"], [31, 31, "v"]], [[35, 37, "p"], [40, 41, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"]], [[16, 17, "p"], [25, 25, "v"], [31, 31, "v"]], [[35, 37, "p"], [40, 41, "p"], [45, 46, "v"], [52, 55, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2108.06421-6807f003-9240-4613-b0cf-559c286b5f5b", "sentences": [["Other", "than", "the", "method", "for", "generating", "similar", "image", "pairs", ",", "identical", "parameters", "were", "used", "for", "GeoCLR", "and", "SimCLR", "to", "allow", "for", "comparison", "."], ["Both", "method", "are", "trained", "on", "the", "all", "86,772", "images", "in", "the", "dataset", "."], ["We", "also", "benchmark", "the", "performance", "of", "the", "proposed", "method", "against", "conventional", "supervised", "transfer", "learning", "using", "ResNet18", "that", "was", "pre-trained", "on", "ImageNet", "."]], "ner": [[[15, 15, "a"], [17, 17, "a"]], [], [[51, 51, "a"], [56, 56, "a"]]], "relations": [[], [], []], "predicted_ner": [[[15, 15, "a"], [17, 17, "a"]], [[30, 30, "v"]], [[44, 44, "a"], [51, 51, "a"], [56, 56, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2108.06421-c4d47d6a-d15b-4eee-b2af-4dd8604355d1", "sentences": [["Though", "deeper", "CNN", "architectures", ",", "larger", "minibatch", "sizes", "and", "epoch", "are", "known", "to", "provide", "accuracy", "gains", "for", "SimCLR", ",", "these", "above", "parameters", "are", "set", "considering", "the", "computational", "power", "that", "can", "be", "reasonably", "deployed", "in", "the", "field", ",", "where", "access", "to", "high-performance", "computers", "networks", "is", "limited", "."], ["The", "workstation", "used", "for", "experiments", "in", "this", "paper", "used", "a", "single", "NVIDIA", "TITAN", "RTX", "with", "24", "GB", "VRAM", "."], ["The", "GeoCLR", "training", "and", "fine", "tuning", "with", "pseudo-labelling", "carried", "out", "in", "this", "work", "each", "took", "approximately", "a", "day", "-LRB-", "26", "hours", "for", "GeoCLR", "training", "and", "a", "few", "minutes", "for", "fine-tuning", "-RRB-", "for", "the", "dataset", "of", "~86k", "images", "gathered", "in", "24", "hours", "of", "bottom", "time", "over", "multiple", "AUV", "dives", "."], ["This", "indicates", "that", "the", "results", "could", "be", "made", "available", "in", "timeframes", "relevant", "to", "assist", "planning", "and", "interpretation", "between", "dives", "during", "multi-day", "field", "expeditions", "."]], "ner": [[[17, 17, "a"], [1, 3, "p"], [5, 7, "p"], [9, 9, "p"]], [], [[66, 66, "a"], [87, 87, "a"], [67, 67, "p"], [88, 88, "p"], [94, 94, "p"], [90, 92, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"], [17, 17, "a"]], [[61, 62, "v"]], [[84, 84, "v"], [87, 87, "a"], [104, 104, "v"]], []], "predicted_relations": [[[1, 3, 17, 17, "USED-FOR"]], [], [[67, 67, 66, 66, "USED-FOR"], [88, 88, 66, 66, "USED-FOR"], [88, 88, 87, 87, "USED-FOR"], [94, 94, 66, 66, "USED-FOR"], [94, 94, 87, 87, "USED-FOR"]], []]}
{"doc_key": "2105.04019-217db207-2695-4111-85bc-aa79a0f25df7", "sentences": [["We", "use", "the", "Adam", "optimizer", "-LSB-", "11", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3.5", "-RCB-", "\\", "-RRB-", ",", "and", "up", "to", "\\", "-LRB-", "10^6\\", "-RRB-", "iterations", "of", "training", "."], ["Furthermore", ",", "we", "set", "\\", "-LRB-", "\\alpha", "=0.25\\", "-RRB-", "and", "a", "use", "a", "steepness", "of", "two", "times", "the", "number", "of", "layers", "-LRB-", "\\", "-LRB-", "s=2n\\", "-RRB-", "for", "odd-even", "and", "\\", "-LRB-", "s=", "-LRB-", "\\log", "_2n", "-RRB-", "-LRB-", "1+\\log", "_2n", "-RRB-", "\\", "-RRB-", "for", "bitonic", ".", "-RRB-"], ["We", "use", "a", "constant", "batch", "size", "of", "100", "as", "in", "previous", "works", "unless", "denoted", "otherwise", "."], ["Note", "that", ",", "although", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "is", "chosen", "as", "a", "constant", "value", "for", "all", "\\", "-LRB-", "n\\", "-RRB-", ",", "a", "higher", "accuracy", "is", "possible", "when", "optimizing", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "for", "each", "\\", "-LRB-", "n\\", "-RRB-", "separately", "."]], "ner": [[[3, 4, "a"], [10, 11, "p"], [29, 29, "p"], [27, 27, "v"]], [[39, 39, "p"], [40, 40, "v"], [46, 46, "p"], [57, 57, "v"], [60, 60, "c"], [76, 76, "c"]], [[83, 84, "p"], [86, 86, "v"]], [[101, 101, "p"], [126, 126, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [10, 11, "p"], [27, 27, "v"]], [[39, 39, "p"], [40, 40, "v"], [48, 48, "v"]], [[82, 84, "p"], [86, 86, "v"]], [[101, 101, "p"], [126, 126, "p"]]], "predicted_relations": [[[10, 11, 3, 4, "USED-FOR"], [29, 29, 3, 4, "USED-FOR"], [27, 27, 29, 29, "USED-FOR"]], [[40, 40, 39, 39, "USED-FOR"], [40, 40, 46, 46, "USED-FOR"], [57, 57, 39, 39, "USED-FOR"], [57, 57, 46, 46, "USED-FOR"], [60, 60, 40, 40, "USED-FOR"], [60, 60, 57, 57, "USED-FOR"], [76, 76, 57, 57, "USED-FOR"]], [], []]}
{"doc_key": "2103.12235-264f6124-2c66-4c3a-8eee-2390c2e96c0e", "sentences": [["Since", "documents", "can", "contain", "up", "to", "hundreds", "of", "sentences", ",", "for", "efficient", "training", "of", "our", "evidence", "retrieval", "model", ",", "we", "downsample", "the", "negative", "examples", "to", "7", "for", "IIRC", "and", "3", "for", "HotpotQA", "."], ["But", "no", "downsampling", "is", "done", "during", "inference", "."], ["For", "IIRC", ",", "we", "take", "\\", "-LRB-", "m=4\\", "-RRB-", "for", "the", "top-\\", "-LRB-", "m\\", "-RRB-", "context", "marginalization", "and", "take", "\\", "-LRB-", "m=5\\", "-RRB-", "for", "HotpotQA", "."], ["For", "the", "weight", "for", "invalid", "context", "loss", ",", "we", "use", "\\", "-LRB-", "0.5\\", "-RRB-", "for", "IIRCWe", "performed", "a", "simple", "binary", "search", "and", "found", "0.5", "to", "work", "better", "than", "0", "or", "1.", "and", "0", "for", "HotpotQA", "since", "it", "does", "not", "have", "unanswerable", "questions", "."], ["For", "memory", "and", "storage", "efficiency", ",", "we", "tie", "the", "pretrained", "language", "model", "weights", "among", "all", "the", "components", "in", "our", "joint", "model", "."], ["The", "models", "are", "trained", "for", "30", "epochs", "for", "IIRC", "and", "5", "epochs", "for", "HotpotQA", "fullwiki", "."], ["Our", "most", "expensive", "experiment", "takes", "about", "1.5", "days", "to", "run", "on", "two", "RTX", "8000", "-LRB-", "48GB", "-RRB-", "GPUs", "or", "one", "A100", "-LRB-", "40GB", "-RRB-", "GPU", ",", "while", "a", "typical", "experiment", "takes", "about", "half", "of", "that", "computing", "power.Note", "that", "our", "models", "are", "jointly", "trained", ",", "thus", "this", "is", "the", "total", "training", "cost", "for", "both", "retrieval", "and", "reasoning", "."]], "ner": [[[15, 17, "a"], [27, 27, "c"], [31, 31, "c"]], [], [[42, 42, "c"], [65, 65, "c"]], [[69, 69, "p"], [79, 79, "v"], [90, 90, "v"], [79, 79, "v"], [90, 90, "v"], [95, 95, "v"], [99, 99, "v"], [101, 101, "c"], [71, 73, "a"]], [[119, 122, "a"]], [[140, 140, "c"], [145, 145, "c"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[15, 17, "a"], [25, 25, "v"], [27, 27, "a"], [29, 29, "v"], [31, 31, "a"]], [], [[42, 42, "a"], [48, 48, "v"], [54, 54, "p"], [62, 62, "v"], [65, 65, "a"]], [[79, 79, "v"], [90, 90, "v"], [95, 95, "v"], [99, 99, "v"], [101, 101, "a"]], [[129, 130, "a"]], [[137, 137, "v"], [138, 138, "p"], [140, 140, "a"], [142, 142, "v"], [143, 143, "p"], [145, 145, "a"]], [[154, 154, "v"], [159, 159, "v"], [160, 161, "v"], [163, 163, "v"], [167, 167, "v"], [168, 168, "v"], [170, 170, "v"], [180, 180, "v"]]], "predicted_relations": [[], [], [], [[69, 69, 71, 73, "USED-FOR"], [101, 101, 79, 79, "USED-FOR"], [101, 101, 79, 79, "USED-FOR"]], [], [], []]}
{"doc_key": "2111.12525-ea1dda8e-e30b-4b0e-91df-72503d0059bb", "sentences": [["We", "configured", "the", "segmentation", "network", "\\", "-LRB-", "f_", "-LCB-", "\\phi", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "as", "a", "U-Net", "-LSB-", "0", "-RSB-", ",", "the", "most", "commonly", "used", "network", "architecture", "for", "medical", "image", "segmentation", ",", "with", "an", "EfficientNet-b2", "backbone", "-LSB-", "67", "-RSB-", "."], ["For", "our", "proposed", "method", ",", "we", "trained", "the", "segmentation", "network", "using", "an", "Adam", "optimizer", "-LSB-", "68", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "with", "learning", "rate", "decay", "."], ["We", "evaluated", "our", "method", "at", "the", "2k-th", "epoch", "where", "the", "learning", "rate", "decays", "to", "zero", "."]], "ner": [[[18, 18, "a"], [36, 36, "a"]], [[54, 55, "a"], [61, 63, "p"], [75, 77, "a"]], [[86, 86, "p"], [85, 85, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 4, "a"], [18, 18, "a"], [36, 36, "a"]], [[45, 45, "a"], [50, 51, "a"], [54, 54, "a"], [62, 63, "p"], [68, 70, "v"], [75, 76, "p"]], [[82, 82, "a"], [85, 85, "v"], [89, 90, "p"], [93, 93, "v"]]], "predicted_relations": [[], [[61, 63, 54, 55, "USED-FOR"]], [[85, 85, 86, 86, "USED-FOR"]]]}
{"doc_key": "2103.14572-7e86bd1d-58d9-439d-b160-484eb6b37ec4", "sentences": [["Unless", "otherwise", "specified", ",", "Adam", "optimizer", "-LSB-", "30", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.0002\\", "-RRB-", ",", "weight", "decay", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "was", "used", "for", "training", "."], ["Learning", "rate", "was", "reduced", "by", "a", "factor", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "when", "the", "validation", "loss", "stopped", "improving", "after", "a", "dataset-dependent", "number", "of", "iterations", "."], ["Training", "was", "stopped", "when", "the", "learning", "rate", "dropped", "below", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "or", "maximum", "number", "of", "iterations", "was", "reached", "."], ["In", "all", "our", "experiments", "we", "use", "16-dimensional", "embedding", "space", ",", "i.e", "."], ["the", "output", "from", "the", "U-Net", "after", "the", "last", "1\\", "-LRB-", "\\times", "\\", "-RRB-", "1", "convolution", "has", "16", "channels", "."], ["Input", "images", "were", "globally", "normalized", "to", "zero", "mean", "and", "a", "standard", "deviation", "of", "one", "unless", "stated", "otherwise", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[4, 5, "a"], [11, 13, "p"], [17, 17, "v"], [20, 21, "p"], [34, 34, "v"], [40, 40, "v"], [17, 17, "v"], [34, 34, "v"], [40, 40, "v"]], [[57, 57, "v"], [57, 57, "v"]], [], [[103, 105, "a"]], [[117, 117, "v"], [122, 122, "v"]], [[135, 135, "p"], [138, 139, "p"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [12, 13, "p"], [17, 17, "v"], [20, 21, "p"], [24, 27, "v"]], [[47, 48, "p"], [57, 57, "v"], [61, 62, "a"]], [[77, 78, "p"], [83, 86, "v"]], [[103, 103, "v"]], [[113, 113, "a"], [122, 122, "v"], [125, 125, "v"]], [[134, 134, "v"], [141, 141, "v"]], []], "predicted_relations": [[[11, 13, 4, 5, "USED-FOR"], [17, 17, 11, 13, "USED-FOR"], [17, 17, 20, 21, "USED-FOR"], [20, 21, 4, 5, "USED-FOR"], [17, 17, 11, 13, "USED-FOR"], [17, 17, 20, 21, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2104.07398-32f925bc-b943-42bf-b455-538503617ef8", "sentences": [["For", "target", "terminology", "extraction", "phase", ",", "we", "adopt", "the", "commonly", "used", "Transformer", "encoder", "with", "1024", "embedding/hidden", "units", ",", "4096", "feed-forward", "filter", "size", ",", "6", "layers", "and", "8", "heads", "per", "layer", "as", "the", "basic", "."], ["During", "training", ",", "the", "batch", "size", "is", "set", "to", "128", "and", "the", "sentence", "length", "is", "limited", "to", "100", "BPE", "tokens", "."], ["We", "employ", "the", "Adam", "-LSB-", "10", "-RSB-", "optimizer", "with", "\\", "-LRB-", "lr\\", "-RRB-", "=", "0.0001", ",", "\\", "-LRB-", "t_", "-LCB-", "warm\\_up", "-RCB-", "\\", "-RRB-", "=", "4000", "and", "\\", "-LRB-", "dropout\\", "-RRB-", "=", "0.1", "."]], "ner": [[[11, 12, "a"], [15, 16, "p"], [14, 14, "v"], [19, 21, "p"], [18, 18, "v"], [24, 24, "p"], [23, 23, "v"], [27, 29, "p"], [26, 26, "v"]], [[38, 39, "a"], [46, 47, "a"]], [[58, 58, "a"], [66, 66, "p"], [69, 69, "v"], [80, 80, "v"], [84, 84, "p"], [87, 87, "v"]]], "relations": [[], [], []], "predicted_ner": [[[11, 12, "a"], [14, 14, "v"], [18, 18, "v"], [19, 21, "a"], [23, 23, "v"], [24, 24, "p"], [26, 26, "v"]], [[38, 39, "p"], [43, 43, "v"], [51, 51, "v"]], [[58, 58, "a"], [69, 69, "v"], [73, 76, "a"], [80, 80, "v"], [87, 87, "v"]]], "predicted_relations": [[[15, 16, 11, 12, "USED-FOR"], [19, 21, 11, 12, "USED-FOR"], [18, 18, 24, 24, "USED-FOR"], [24, 24, 11, 12, "USED-FOR"], [23, 23, 24, 24, "USED-FOR"], [27, 29, 11, 12, "USED-FOR"]], [], [[69, 69, 66, 66, "USED-FOR"], [87, 87, 84, 84, "USED-FOR"]]]}
{"doc_key": "2109.05168-6e3400fc-b417-4e20-a3d8-e177f8443a62", "sentences": [["The", "hyperparameters", "are", "selected", "based", "on", "the", "best", "performing", "model", "on", "the", "dev", "set", "."], ["We", "use", "grid", "search", "to", "fine-tune", "the", "model", ",", "and", "select", "select", "the", "learning", "rate", "from", "\\", "-LRB-", "\\lbrace", "1e-5", ",", "2e-5\\rbrace", "\\", "-RRB-", ",", "batch", "size", "from", "\\", "-LRB-", "\\lbrace", "4,8\\rbrace", "\\", "-RRB-", "and", "gradient", "accumulation", "from", "\\", "-LRB-", "\\lbrace", "4,8,16\\rbrace", "\\", "-RRB-", "."], ["The", "model", "is", "trained", "up", "to", "4", "epochs", "."], ["Details", "about", "the", "experiment", "setting", "is", "in", "Appendix", "."]], "ner": [[[9, 9, "a"]], [[22, 22, "a"], [28, 29, "p"], [34, 34, "v"], [36, 36, "v"], [40, 41, "p"], [46, 46, "v"], [56, 56, "v"], [46, 46, "v"], [56, 56, "v"], [50, 51, "p"], [46, 46, "v"], [56, 56, "v"], [46, 46, "v"], [56, 56, "v"], [56, 56, "v"]], [[61, 61, "a"], [66, 66, "v"], [66, 66, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[17, 18, "a"], [28, 29, "p"], [33, 36, "v"], [40, 41, "p"], [45, 46, "v"], [50, 51, "p"], [55, 56, "v"]], [[66, 66, "v"], [67, 67, "p"]], []], "predicted_relations": [[], [[34, 34, 28, 29, "USED-FOR"], [36, 36, 28, 29, "USED-FOR"], [56, 56, 50, 51, "USED-FOR"], [56, 56, 50, 51, "USED-FOR"], [56, 56, 50, 51, "USED-FOR"], [56, 56, 50, 51, "USED-FOR"], [56, 56, 50, 51, "USED-FOR"]], [], []]}
{"doc_key": "2109.05281-ec98346f-9505-4a9c-9b12-70701f19dbe1", "sentences": [["We", "implement", "COSMic\u2014as", "described", "in", "Section", "\u2014with", "PyTorch", "-LSB-", "35", "-RSB-", "and", "train", "on", "a", "GTX1080", "GPU", "."], ["We", "pre-compute", "BERThttps", ":", "//github.com/google-research/bert", "and", "ResNethttps", ":", "//www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2", "features", "using", "their", "TensorFlow", "-LSB-", "0", "-RSB-", "implementations", "."], ["We", "use", "the", "public", "ViLBERThttps", ":", "//github.com/facebookresearch/vilbert-multi-task", "implementation", "."], ["We", "use", "a", "batch", "size", "of", "4", ",", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "for", "fine-tuning", "ViLBERT", "and", "use", "RAdam", "optimizer", "and", "stop", "the", "training", "when", "the", "validation", "score", "does", "not", "change", "for", "3", "epochs", "."], ["For", "COSMic", "Vanilla", ",", "we", "train", "with", "a", "batch-size", "of", "10", ",", "Adam", "optimizer", "-LSB-", "20", "-RSB-", "with", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "that", "decays", "by", "a", "factor", "of", "\\", "-LRB-", "10^", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "every", "10", "epochs", "."], ["We", "observe", "that", "the", "Vanilla", "converges", "in", "approximately", "100", "epochs", "and", "ViLBERT", "converges", "in", "9", "epochs", "."], ["ViLBERT", "has", "250", "million", "parameters", "."], ["COSMic", "Vanilla", "includes", "3,062,913", "trainable", "parameters", "."], ["Pre-trained", "BERT-Large", "and", "ResNet50V2", "have", "an", "additional", "350", "million", "parameters", "."], ["The", "setup", "for", "coherence-aware", "captioning", "models", "to", "obtain", "machine-generated", "captions", "for", "our", "study", "is", "the", "same", "as", "-LSB-", "2", "-RSB-", "."]], "ner": [[[7, 7, "a"]], [], [], [[69, 69, "a"], [55, 56, "p"], [72, 73, "a"]], [[101, 102, "a"], [109, 110, "p"], [90, 91, "a"]], [[149, 149, "a"]], [[155, 155, "a"]], [[161, 162, "a"]], [[169, 169, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [15, 15, "v"]], [[30, 30, "a"]], [], [[48, 49, "p"], [51, 51, "v"], [55, 56, "p"], [61, 63, "v"], [69, 69, "a"], [72, 72, "a"], [86, 86, "v"], [87, 87, "p"]], [[90, 91, "a"], [97, 97, "p"], [99, 99, "v"], [108, 110, "p"], [114, 116, "v"], [128, 130, "v"], [135, 135, "v"], [136, 136, "p"]], [[142, 142, "a"], [146, 146, "v"], [149, 149, "a"], [152, 152, "v"], [153, 153, "p"]], [[155, 155, "a"], [157, 157, "v"]], [[161, 162, "a"], [164, 164, "v"]], [[169, 169, "a"], [171, 171, "a"], [175, 175, "v"]], []], "predicted_relations": [[], [], [], [], [[109, 110, 101, 102, "USED-FOR"], [109, 110, 90, 91, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2110.14577-e5c81293-2182-43f8-adca-a1d8ffa9d51e", "sentences": [["We", "train", "all", "our", "models", "using", "stochastic", "gradient", "descent", "for", "200", "epochs", "and", "a", "batch", "size", "of", "128", "on", "RTX", "2080", "GPUs", "."], ["We", "use", "a", "starting", "learning", "rate", "of", "0.1", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "5.0e-4\\", "-RRB-", "."], ["For", "ResNet18", "experiments", ",", "we", "use", "a", "cosine", "scheduler", "for", "learning", "rate", "."], ["For", "Wide", "ResNet-20-10", "experiments", ",", "we", "use", "a", "step", "scheduler", "which", "multiplies", "the", "learning", "rate", "at", "epoch", "60", ",", "120", "and", "160", "by", "0.2", "."]], "ner": [[[10, 10, "v"], [17, 17, "v"]], [[30, 30, "v"], [38, 38, "v"]], [[42, 42, "a"]], [[55, 56, "a"], [77, 77, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 8, "a"], [10, 10, "v"], [11, 11, "p"], [14, 15, "p"], [17, 17, "v"]], [[27, 28, "p"], [30, 30, "v"], [33, 34, "p"], [38, 38, "v"]], [[42, 42, "a"], [51, 52, "p"]], [[56, 56, "a"], [67, 68, "p"], [73, 73, "v"], [75, 75, "v"], [77, 77, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2112.04228-fd61b3ef-c390-49e8-86af-6d63c82acb0b", "sentences": [["We", "train", "our", "model", "on", "a", "single", "Nvidia", "2080ti", "GPU", "with", "a", "total", "batch", "size", "of", "32", "."], ["We", "use", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "5", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "-LRB-", "\\", "-LRB-", "\\beta", "_1", "\\", "-RRB-", "=0.9", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=0.998", "-RRB-", ",", "and", "the", "weight", "decays", "to", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["We", "utilize", "the", "plateau", "learning", "rate", "schedule", "to", "update", "the", "learning", "rate", ",", "which", "tracks", "the", "BLEU", "-LSB-", "41", "-RSB-", "score", "on", "the", "validation", "set", ",", "the", "patience", "and", "factor", "are", "set", "to", "9", "and", "0.5", ",", "respectively", "."], ["The", "validation", "set", "is", "evaluated", "every", "100", "steps", "."], ["During", "validation", ",", "we", "use", "a", "beam", "search", "algorithm", "with", "a", "beam", "size", "of", "3", "and", "a", "length", "penalty", "value", "-1", "to", "decode", "the", "text", "sequence", "."], ["Training", "ends", "when", "the", "learning", "rate", "is", "less", "than", "\\", "-LRB-", "10^", "-LCB-", "-7", "-RCB-", "\\", "-RRB-", "."], ["During", "training", ",", "the", "weights", "of", "the", "loss", "function", "\\", "-LRB-", "\\lambda", "_1", "-", "\\lambda", "_4\\", "-RRB-", "are", "set", "to", "10", ",", "1", ",", "0.6", ",", "and", "0.4", "respectively", "."]], "ner": [[], [[21, 22, "a"], [25, 26, "p"], [45, 45, "v"], [52, 52, "v"], [45, 45, "v"], [64, 64, "v"], [32, 32, "v"], [62, 62, "v"]], [[73, 74, "p"], [79, 80, "p"], [72, 75, "a"], [96, 96, "p"], [102, 102, "v"], [98, 98, "p"], [104, 104, "v"]], [], [[123, 125, "a"], [128, 129, "p"], [131, 131, "v"], [134, 136, "p"], [137, 137, "v"]], [[148, 149, "p"], [155, 155, "v"]], [[169, 170, "a"], [182, 182, "v"], [184, 184, "v"], [186, 186, "v"], [189, 189, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [13, 14, "p"], [16, 16, "v"]], [[21, 21, "a"], [25, 26, "p"], [30, 30, "v"], [32, 35, "v"], [41, 42, "p"], [62, 65, "v"]], [[79, 80, "p"], [85, 85, "a"], [102, 102, "v"], [104, 104, "v"]], [[114, 114, "v"]], [[123, 125, "a"], [128, 129, "p"], [131, 131, "v"], [137, 137, "v"]], [[148, 149, "p"], [155, 158, "v"]], [[173, 174, "p"], [176, 177, "p"], [182, 182, "v"], [184, 184, "v"], [186, 186, "v"], [189, 189, "v"]]], "predicted_relations": [[], [[32, 32, 25, 26, "USED-FOR"]], [[73, 74, 72, 75, "USED-FOR"], [79, 80, 72, 75, "USED-FOR"], [102, 102, 96, 96, "USED-FOR"], [102, 102, 98, 98, "USED-FOR"], [98, 98, 72, 75, "USED-FOR"]], [], [[128, 129, 123, 125, "USED-FOR"], [131, 131, 134, 136, "USED-FOR"], [134, 136, 123, 125, "USED-FOR"], [137, 137, 128, 129, "USED-FOR"], [137, 137, 134, 136, "USED-FOR"]], [[155, 155, 148, 149, "USED-FOR"]], []]}
{"doc_key": "2108.04938-a0e10f7a-0b7e-4e6d-b718-06aed61916e9", "sentences": [["We", "first", "resize", "all", "images", "of", "OpenI", "to", "\\", "-LRB-", "206\\times", "206\\", "-RRB-", "and", "apply", "the", "unsupervised", "feature", "learner", ",", "PixelHop++", "."], ["We", "use", "a", "three-level", "PixelHop++", "with", "the", "following", "hyper-parameters", ":", "\\", "-LRB-", "w", "=", "3\\", "-RRB-", ",", "\\", "-LRB-", "d", "=", "1\\", "-RRB-", ",", "\\", "-LRB-", "s", "=", "1\\", "-RRB-", ",", "and", "\\", "-LRB-", "E", "=", "0.00005\\", "-RRB-", "."], ["Then", ",", "we", "apply", "PCA", "to", "its", "output", "channels", "and", "concatenate", "the", "generated", "vectors", "to", "form", "a", "set", "of", "\\", "-LRB-", "Q\\", "-RRB-", "visual", "features", "of", "dimension", "D", ",", "i.e.", ",", "\\", "-LRB-", "V", "=", "-LSB-", "v_1", ",", "v_2", ",", "...", ",", "v_Q", "-RSB-", ",", "v_i\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^D\\", "-RRB-", "."], ["In", "BERTHop", ",", "\\", "-LRB-", "D\\", "-RRB-", "is", "set", "to", "be", "2048", "."], ["In", "our", "experiments", "setup", ",", "\\", "-LRB-", "Q\\", "-RRB-", "is", "equal", "to", "15", "but", "may", "vary", "depending", "on", "the", "size", "of", "the", "output", "channels", "of", "the", "PixelHop++", "model", "and", "also", "the", "number", "of", "PCA", "components", "."]], "ner": [[], [[34, 34, "p"], [36, 36, "v"], [41, 41, "p"], [43, 43, "v"], [50, 50, "v"], [48, 48, "p"], [43, 43, "v"], [50, 50, "v"], [56, 56, "p"], [58, 58, "v"]], [[65, 65, "a"], [88, 88, "p"], [111, 111, "p"]], [[115, 115, "a"], [119, 119, "p"], [125, 125, "v"]], [[160, 160, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [11, 11, "v"], [20, 20, "a"]], [[26, 26, "a"], [36, 36, "v"], [41, 43, "v"], [58, 58, "v"]], [[65, 65, "a"], [88, 88, "v"]], [[115, 115, "a"], [125, 125, "v"]], [[139, 139, "v"], [153, 153, "a"]]], "predicted_relations": [[], [[43, 43, 34, 34, "USED-FOR"], [43, 43, 48, 48, "USED-FOR"], [50, 50, 48, 48, "USED-FOR"], [43, 43, 34, 34, "USED-FOR"], [43, 43, 48, 48, "USED-FOR"], [50, 50, 48, 48, "USED-FOR"]], [], [[125, 125, 119, 119, "USED-FOR"]], []]}
{"doc_key": "2108.04938-0104130e-9443-4941-a999-f9c4c73aa95a", "sentences": [["As", "for", "the", "transformer", "backbone", ",", "we", "use", "BlueBERT-Base", "-LRB-", "Uncased", ",", "PubMed+MIMIC-III", "-RRB-", "from", "Huggingface", "-LSB-", "40", "-RSB-", ",", "a", "transformer", "library", "."], ["Having", "the", "visual", "features", "from", "the", "visual", "encoder", "and", "text", "embedding", ",", "we", "train", "the", "transformer", "on", "the", "training", "set", "of", "OpenI", "with", "2,912", "image-text", "pairs", "."], ["We", "use", "batch", "size", "=", "18", ",", "learning", "rate", "=", "\\", "-LRB-", "1e-5\\", "-RRB-", ",", "max-seq-length", "=", "128", ",", "and", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "as", "the", "optimizer", "with", "momentum", "=", "0.9", "and", "train", "it", "for", "240", "epochs", "."]], "ner": [[[8, 8, "a"]], [[45, 45, "a"]], [[71, 73, "a"], [53, 54, "p"], [56, 56, "v"], [58, 59, "p"], [63, 63, "v"], [66, 66, "p"], [68, 68, "v"], [81, 81, "p"], [83, 83, "v"], [89, 89, "p"], [88, 88, "v"]]], "relations": [[], [], []], "predicted_ner": [[[8, 8, "a"]], [[45, 45, "a"], [47, 47, "v"]], [[53, 54, "p"], [56, 56, "v"], [58, 59, "p"], [63, 63, "v"], [66, 66, "a"], [68, 68, "v"], [71, 76, "a"], [81, 81, "p"], [83, 83, "v"], [88, 88, "v"], [89, 89, "p"]]], "predicted_relations": [[], [], [[56, 56, 53, 54, "USED-FOR"], [56, 56, 66, 66, "USED-FOR"], [63, 63, 58, 59, "USED-FOR"], [63, 63, 66, 66, "USED-FOR"], [68, 68, 66, 66, "USED-FOR"], [83, 83, 89, 89, "USED-FOR"], [88, 88, 89, 89, "USED-FOR"]]]}
{"doc_key": "2110.05999-6d530c8d-c4e9-4789-ae55-a9169e3f7750", "sentences": [["We", "collect", "322K", "contiguous", "texts", "from", "BookCorpus", "-LSB-", "44", "-RSB-", "and", "keep", "the", "first", "512", "bpe", "subwords", "of", "each", "example", "for", "training", "."], ["Since", "the", "warm-start", "training", "aims", "at", "initializing", "the", "latent", "embeddings", "for", "reconstructing", "the", "target", "text", ",", "we", "do", "not", "feed", "any", "input", "to", "the", "encoder", "."], ["We", "use", "a", "fixed", "Gumbel", "temperature", "of", "0.9", "and", "a", "fixed", "learning", "rate", "of", "1e-4", "."], ["We", "use", "a", "batch", "size", "of", "4", "and", "a", "gradient", "accumulation", "step", "of", "4", "and", "train", "on", "the", "collected", "data", "for", "one", "epoch", "which", "takes", "about", "7", "hours", "on", "1", "GeForce", "RTX", "2080", "-LRB-", "11G", "-RRB-", "."]], "ner": [[[6, 6, "a"]], [], [[53, 54, "a"], [63, 63, "v"], [60, 61, "a"]], [[74, 76, "p"], [71, 71, "v"], [78, 78, "v"], [68, 69, "a"], [74, 76, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "v"], [6, 6, "a"], [14, 14, "v"], [15, 15, "v"]], [], [[53, 54, "p"], [56, 56, "v"], [60, 61, "p"], [63, 63, "v"]], [[68, 69, "p"], [71, 71, "v"], [74, 76, "p"], [78, 78, "v"], [86, 86, "v"], [91, 91, "v"], [94, 94, "v"], [99, 99, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2110.05999-98262cdc-3d47-41f6-a97f-f562bd74e265", "sentences": [["For", "fine-tuning", "the", "generator", "and", "the", "posterior", "network", "for", "text", "reconstruction", ",", "we", "anneal", "the", "Gumbel", "temperature", "from", "\\", "-LRB-", "\\tau", "_", "-LCB-", "max", "-RCB-", "=0.9\\", "-RRB-", "to", "\\", "-LRB-", "\\tau", "_", "-LCB-", "min", "-RCB-", "=0.1\\", "-RRB-", "using", "exponential", "decay", "schedule", "where", "the", "Gumbel", "temperature", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "at", "step", "\\", "-LRB-", "T\\", "-RRB-", "is", ":", "\\", "-LRB-", "\\max", "-LSB-", "\\tau", "_", "-LCB-", "min", "-RCB-", ",", "\\tau", "_", "-LCB-", "max", "-RCB-", "\\times", "\\exp", "-LRB-", "-10^", "-LCB-", "-4", "-RCB-", "\\times", "T", "-RRB-", "-RSB-", "\\", "-RRB-", "."], ["We", "linearly", "decrease", "the", "learning", "rate", "from", "1e-4", "to", "0", "throughout", "the", "fine-tuning", "."], ["We", "use", "a", "batch", "size", "of", "4", "and", "a", "gradient", "accumulation", "step", "of", "4", "."], ["We", "fine-tune", "for", "five", "epochs", "on", "Wikiplots", "and", "one", "epoch", "on", "WritingPrompts", ",", "which", "takes", "about", "12", "hours", "and", "6", "hours", "on", "1", "GeForce", "RTX", "2080", "-LRB-", "11G", "-RRB-", ",", "respectively", "."]], "ner": [[[15, 16, "a"], [43, 44, "a"], [15, 16, "p"], [43, 44, "p"], [25, 25, "v"], [35, 35, "v"], [25, 25, "v"], [35, 35, "v"], [78, 78, "v"], [78, 78, "v"], [35, 35, "v"]], [[94, 94, "v"], [96, 96, "v"], [94, 94, "v"], [94, 94, "v"]], [[107, 107, "v"], [114, 114, "v"], [107, 107, "v"], [114, 114, "v"]], [[122, 122, "c"], [138, 138, "v"], [127, 127, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[15, 16, "p"], [25, 25, "v"], [35, 35, "v"], [43, 44, "p"], [54, 54, "p"], [81, 81, "p"]], [[91, 92, "p"], [94, 94, "v"], [96, 96, "v"]], [[104, 105, "p"], [107, 107, "v"], [110, 112, "p"], [114, 114, "v"]], [[119, 119, "v"], [120, 120, "p"], [122, 122, "a"], [124, 124, "v"], [125, 125, "p"], [132, 132, "v"], [135, 135, "v"], [138, 138, "v"], [143, 143, "v"]]], "predicted_relations": [[[15, 16, 15, 16, "USED-FOR"], [43, 44, 15, 16, "USED-FOR"], [43, 44, 43, 44, "USED-FOR"], [35, 35, 43, 44, "USED-FOR"], [35, 35, 43, 44, "USED-FOR"], [35, 35, 43, 44, "USED-FOR"]], [], [], [[122, 122, 138, 138, "USED-FOR"]]]}
{"doc_key": "2110.05999-e52e0cf8-83dc-46e9-9b11-ad5c04851ac7", "sentences": [["For", "fine-tuning", "the", "prior", "network", ",", "we", "initialize", "the", "encoder", "with", "the", "pre-trained", "parameters", "of", "the", "encoder", "of", "\\", "-LRB-", "\\text", "-LCB-", "BART", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "base", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["We", "linearly", "decrease", "the", "learning", "rate", "from", "1e-4", "to", "0", "during", "training", "."], ["The", "maximum", "target", "sequence", "length", "is", "set", "to", "\\", "-LRB-", "\\text", "-LCB-", "MaxLength", "-RCB-", "=64\\", "-RRB-", "."], ["We", "use", "a", "batch", "size", "of", "128", "and", "a", "gradient", "accumulation", "step", "of", "8", "."], ["We", "fine-tune", "the", "model", "for", "100", "epochs", "which", "takes", "about", "13", "hours", "on", "1", "GeForce", "RTX", "2080", "-LRB-", "11G", "-RRB-", "."], ["During", "inference", ",", "we", "randomly", "sample", "a", "sequence", "of", "latent", "codes", "from", "the", "prior", "network", "autoregressively", "and", "set", "the", "minimum", "sequence", "length", "to", "38", "and", "44", "for", "Wikiplots", "and", "WritingPrompts", ",", "respectively", "."]], "ner": [[], [[38, 39, "a"], [41, 41, "v"], [43, 43, "v"]], [[59, 59, "a"], [61, 61, "v"]], [[67, 68, "a"], [70, 70, "v"], [73, 75, "a"], [77, 77, "v"]], [[85, 85, "a"], [84, 84, "v"]], [[119, 121, "a"], [127, 127, "p"], [123, 123, "v"], [129, 129, "p"], [125, 125, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"]], [[38, 39, "p"], [41, 41, "v"], [43, 43, "v"], [44, 45, "c"]], [[61, 61, "v"]], [[67, 68, "p"], [70, 70, "v"], [73, 75, "p"], [77, 77, "v"]], [[82, 82, "a"], [84, 84, "v"], [85, 85, "p"], [89, 89, "v"], [92, 92, "v"], [97, 97, "v"]], [[123, 123, "v"], [125, 125, "v"]]], "predicted_relations": [[], [], [], [], [], [[127, 127, 119, 121, "USED-FOR"], [129, 129, 119, 121, "USED-FOR"]]]}
{"doc_key": "2110.13953-f47ab21b-ddd2-4e7a-be19-49f26457a071", "sentences": [["To", "adversarially", "train", "the", "models", "as", "described", "in", "Section", "REF", ",", "we", "initialize", "with", "models", "trained", "in", "the", "standard", "fashion", "."], ["We", "then", "train", "these", "models", "in", "an", "adversarial", "manner", "for", "60", "epochs", "of", "1000", "episodes", "each", "."], ["We", "use", "the", "same", "hyperparameters", "and", "experimental", "setup", "as", "we", "did", "for", "the", "standard", "training", ",", "except", "that", "we", "reduce", "the", "learning", "rate", "by", "a", "factor", "of", "10", "."], ["Thus", ",", "the", "learning", "rate", "is", "initially", "set", "to", "0.1", "for", "the", "first", "20", "epochs", ",", "then", "modified", "to", "0.006", "for", "epochs", "20", "to", "40", ",", "0.0012", "for", "epochs", "40", "to", "50", ",", "and", "0.0024", "thereafter", "."], ["To", "find", "the", "adversarial", "examples", ",", "we", "find", "the", "worst-case", "examples", "using", "algorithm", "run", "for", "3", "iterations", "."], ["We", "then", "use", "these", "worst-case", "examples", "as", "the", "query", "data", "to", "update", "the", "model", "parameters", "."]], "ner": [[[4, 4, "a"], [14, 14, "a"]], [[25, 25, "a"]], [[59, 60, "p"]], [[70, 71, "p"], [76, 76, "v"], [77, 81, "c"], [86, 86, "v"], [87, 91, "c"], [93, 93, "v"], [94, 98, "c"], [101, 101, "v"], [102, 102, "c"]], [[116, 116, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[31, 31, "v"], [32, 32, "p"], [34, 34, "v"], [35, 35, "p"]], [[59, 60, "p"], [65, 65, "v"]], [[70, 71, "p"], [76, 76, "v"], [80, 80, "v"], [81, 81, "p"], [86, 86, "v"], [93, 93, "v"], [101, 101, "v"]], [[119, 119, "v"], [120, 120, "p"]], []], "predicted_relations": [[], [], [], [[77, 81, 76, 76, "USED-FOR"], [77, 81, 86, 86, "USED-FOR"], [77, 81, 93, 93, "USED-FOR"], [77, 81, 101, 101, "USED-FOR"], [87, 91, 76, 76, "USED-FOR"], [87, 91, 86, 86, "USED-FOR"], [87, 91, 93, 93, "USED-FOR"], [87, 91, 101, 101, "USED-FOR"], [94, 98, 86, 86, "USED-FOR"], [94, 98, 93, 93, "USED-FOR"], [94, 98, 101, 101, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 101, 101, "USED-FOR"]], [], []]}
{"doc_key": "2110.10261-0da8fab6-60e6-4368-b5e1-504815c42f27", "sentences": [["All", "our", "RNN", "LMs", "use", "a", "single", "layer", "of", "Gated", "Recurrent", "Units", "-LRB-", "GRUs", "-RRB-", "."], ["Input", "and", "output", "word", "embedding", "matrices", "are", "shared", "and", "tied", "during", "training", "."], ["We", "set", "the", "dimensional", "of", "word", "embeddings", "to", "be", "64", "."], ["Similarly", ",", "the", "hidden", "states", "of", "the", "GRU", "are", "set", "to", "64", "."], ["Training", "uses", "a", "batch", "size", "of", "32", "."], ["We", "employ", "the", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.001", "."], ["The", "learning", "rate", "is", "scheduled", "to", "reduce", "by", "a", "factor", "of", "0.1", "if", "the", "loss", "does", "not", "decrease", "for", "10", "epochs", "."], ["We", "leverage", "an", "early", "stopping", "strategy", ",", "on", "the", "dev", "set", "perplexity", ",", "with", "a", "patience", "set", "to", "15", "epochs", "."], ["The", "maximum", "number", "of", "arcs", "in", "a", "confusion", "bin", "is", "restricted", "to", "5", "and", "the", "confusion", "bin", "scores", "are", "re-normalized", "to", "sum", "to", "1.0", "."]], "ner": [[], [[16, 21, "p"]], [[32, 35, "p"], [38, 38, "v"], [38, 38, "v"]], [[51, 51, "v"], [43, 47, "p"], [51, 51, "v"]], [], [[64, 65, "a"], [68, 70, "p"], [72, 72, "v"]], [], [[99, 101, "a"], [111, 111, "p"], [114, 115, "v"]], [[118, 125, "p"], [129, 129, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 3, "a"], [9, 14, "a"]], [], [[38, 38, "v"]], [[47, 47, "a"], [51, 51, "v"]], [[56, 57, "p"], [59, 59, "v"]], [[64, 64, "a"], [69, 70, "p"], [72, 72, "v"]], [[75, 76, "p"], [85, 85, "v"], [93, 93, "v"], [94, 94, "p"]], [[114, 114, "v"], [115, 115, "p"]], [[129, 129, "v"], [140, 140, "v"]]], "predicted_relations": [[], [], [], [], [], [[68, 70, 64, 65, "USED-FOR"]], [], [[111, 111, 99, 101, "USED-FOR"], [114, 115, 111, 111, "USED-FOR"]], []]}
{"doc_key": "2110.10318-a4135a5e-feba-49dd-8b10-bf1f5afe1d31", "sentences": [["Our", "default", "parameters", "are", "as", "follows", ":", "We", "use", "Adam", "optimizer", "with", "500", "warmup", "steps=500", "and", "weight", "decay", "of", "0.01", "."], ["Our", "batch", "size", "is", "16", "."], ["Models", "were", "trained", "using", "2", "NVIDIA", "v100", "GPUs", "."], ["Training", "time", "for", "TPP", "ranged", "from", "30", "mins", "to", "32hrs", "for", "different", "settings", "."], ["NER", "training", "time", "was", "around", "1.5", "hrs", "."], ["Sentiment", "training", "time", "was", "1", "minute", ",", "and", "UD", "POS", "training", "time", "was", "also", "1", "minute", "."]], "ner": [[[9, 10, "a"], [13, 14, "p"], [12, 12, "v"], [14, 14, "v"], [16, 17, "p"], [19, 19, "v"]], [[22, 23, "p"], [25, 25, "v"]], [[32, 34, "a"]], [[39, 39, "a"]], [[50, 50, "a"]], [[58, 58, "a"], [66, 67, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"], [12, 12, "v"], [16, 17, "p"], [19, 19, "v"]], [[22, 23, "p"], [25, 25, "v"]], [[31, 31, "v"]], [[42, 42, "v"], [45, 45, "v"]], [[55, 55, "v"]], [[62, 62, "v"], [72, 72, "v"]]], "predicted_relations": [[[13, 14, 9, 10, "USED-FOR"], [12, 12, 13, 14, "USED-FOR"], [14, 14, 13, 14, "USED-FOR"], [16, 17, 9, 10, "USED-FOR"], [19, 19, 16, 17, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2109.10257-cb192178-a89c-4430-b99a-e21a1bbe8f48", "sentences": [["For", "all", "of", "our", "experiments", ",", "we", "use", "SGD", "optimizer", "."], ["The", "initial", "learning", "rate", "for", "GTA-IM", "is", "0.01", "and", "0.03", "for", "the", "PROX", "dataset", "."], ["The", "number", "of", "training", "epochs", "is", "450", "and", "we", "decrease", "the", "learning", "rate", "by", "a", "factor", "of", "0.2", "every", "200", "epochs", "."], ["We", "use", "a", "batch", "size", "of", "128", "and", "1", "second", "of", "observation", "and", "2", "seconds", "for", "predictions", "following", "the", "settings", "of", "-LSB-", "5", "-RSB-", "."], ["We", "used", "GTX-1080Ti", "for", "training", "on", "a", "128", "GB", "RAM", "machine", "."], ["The", "need", "for", "a", "large", "RAM", "comes", "when", "the", "models", "are", "trained", "using", "the", "visual", "signal", "."], ["Training", "each", "model", "took", "between", "8", "hours", "and", "24", "hours", "depending", "on", "the", "used", "dataset", "."]], "ner": [[[8, 9, "a"]], [[12, 14, "p"], [18, 18, "v"], [16, 16, "c"], [20, 20, "v"], [23, 24, "c"]], [[27, 30, "p"], [32, 32, "v"], [43, 43, "v"]], [[51, 52, "p"], [54, 54, "v"], [56, 57, "v"], [61, 62, "v"]], [[80, 80, "v"], [75, 75, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[13, 14, "p"], [16, 16, "a"], [18, 18, "v"], [20, 20, "v"], [23, 24, "a"]], [[29, 30, "p"], [32, 32, "v"], [37, 38, "p"], [43, 43, "v"], [45, 45, "v"], [46, 46, "p"]], [[51, 52, "p"], [54, 54, "v"], [56, 56, "v"], [61, 61, "v"]], [[75, 75, "a"], [80, 81, "v"]], [], [[107, 107, "v"], [110, 110, "v"]]], "predicted_relations": [[], [[23, 24, 20, 20, "USED-FOR"]], [[32, 32, 27, 30, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2102.05526-b237e356-16d1-4df6-a060-6362f8d85f5b", "sentences": [["The", "dynamic", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "-VAE", "has", "several", "tunable", "model", "parameters", ",", "as", "seen", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "to", "Eq", ".", "-LRB-", "-RRB-", "."], ["These", "model", "parameters", "were", "tuned", "on", "an", "independent", "dataset", ",", "collected", "with", "the", "identical", "instrumentation", "but", "at", "a", "different", "location", "."], ["The", "data", "had", "a", "similar", "distribution", "as", "the", "data", "used", "in", "this", "work", "and", "we", "obtained", ":", "\\", "-LRB-", "a=0.2\\", "-RRB-", "and", "\\", "-LRB-", "b=0.05\\", "-RRB-", ",", "\\", "-LRB-", "w_1=w_2=1.2\\", "-RRB-", ",", "\\", "-LRB-", "w_3=0.9\\", "-RRB-", "and", "\\", "-LRB-", "w_4=1.1\\", "-RRB-", "."], ["These", "parameters", "were", "found", "to", "be", "sufficiently", "robust", "on", "the", "dataset", "used", "in", "this", "work", "without", "any", "fine-tuning", "."]], "ner": [[], [], [[45, 45, "p"]], [[52, 52, "p"], [68, 68, "p"], [68, 68, "v"], [73, 73, "p"], [73, 73, "v"], [78, 78, "v"], [78, 78, "v"], [83, 83, "v"], [88, 88, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [], []], "predicted_relations": [[], [], [], [[68, 68, 68, 68, "USED-FOR"], [68, 68, 68, 68, "USED-FOR"], [68, 68, 73, 73, "USED-FOR"], [73, 73, 73, 73, "USED-FOR"], [73, 73, 68, 68, "USED-FOR"], [73, 73, 73, 73, "USED-FOR"], [78, 78, 68, 68, "USED-FOR"], [78, 78, 73, 73, "USED-FOR"], [78, 78, 68, 68, "USED-FOR"], [78, 78, 73, 73, "USED-FOR"]], []]}
{"doc_key": "2105.08665-867bccbb-3bf2-4b38-b8fb-e1559f67d297", "sentences": [["We", "train", "the", "2D", "CNN", "+", "LSTM", "model", "and", "the", "3D", "CNN", "model", "on", "the", "same", "dataset", "to", "benchmark", "the", "performance", "against", "each", "other", "."], ["For", "training", ",", "we", "take", "a", "subset", "of", "UCF50", "with", "38", "classes", "which", "have", "almost", "equal", "distribution", "of", "videos", "i.e", "."], ["more", "than", "120", "videos", "per", "class", "."], ["The", "dataset", "consists", "of", "4557", "videos", "and", "we", "use", "90", "%", "of", "it", "for", "training", "and", "10", "%", "of", "it", "for", "validation", "."], ["For", "ensuring", "the", "best", "performance", ",", "we", "augment", "the", "data", "using", "random", "sampling", "and", "central", "cropping", "of", "videos", "."]], "ner": [[[3, 7, "a"], [10, 12, "a"]], [[33, 33, "a"], [31, 31, "p"], [35, 36, "v"], [41, 41, "p"]], [[46, 51, "v"]], [[57, 58, "v"]], [[87, 88, "a"], [90, 91, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 4, "a"]], [[33, 33, "a"], [35, 35, "v"]], [[48, 48, "v"]], [[57, 57, "v"], [62, 63, "v"], [69, 70, "v"]], []], "predicted_relations": [[], [[41, 41, 33, 33, "USED-FOR"]], [], [], []]}
{"doc_key": "2105.08649-e57eb83e-1781-401a-b775-c07179b15da9", "sentences": [["We", "implement", "our", "approaches", "using", "PyTorchhttps", ":", "//pytorch.org/", "."], ["We", "apply", "Adam", "-LSB-", "31", "-RSB-", "with", "a", "learning", "rate", "of", "0.001", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "1e^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "to", "prevent", "overfitting", ",", "and", "a", "mini-batch", "size", "of", "4096", "across", "all", "tasks", "."], ["For", "the", "fair", "competition", ",", "we", "set", "the", "default", "architecture", "of", "the", "dense", "neural", "network", "with", "two", "hidden", "layers", "and", "100", "neurons", "per", "layer", "for", "all", "models", "that", "involve", "DNN", "."], ["To", "avoid", "overfitting", ",", "we", "perform", "the", "early-stopping", "strategy", "based", "on", "AUC", "on", "the", "validation", "set", "."], ["A", "dropout", "method", "is", "also", "applied", "across", "all", "models", "with", "a", "rate", "of", "0.5", "for", "the", "MovieLens-1M", "dataset", "and", "0.2", "for", "the", "other", "two", "datasets", "to", "prevent", "overfitting", "."], ["The", "dimension", "of", "feature", "embeddings", "is", "set", "to", "16", "for", "all", "the", "models", "across", "all", "tasks", "consistently", "."], ["More", "specifically", ",", "the", "number", "of", "layers", "in", "DCN", "set", "to", "2", "."], ["The", "maximum", "order", "in", "HOFM", "is", "set", "to", "3", "."], ["The", "attention", "embedding", "size", "of", "model", "AFM", "and", "AutoInt", "is", "64", "."], ["Additionally", ",", "the", "number", "of", "heads", "in", "AutoInt", "is", "set", "to", "4", "."], ["The", "default", "number", "of", "logarithmic", "neurons", "in", "AFN", "is", "set", "to", "1500", ",", "1200", ",", "800", "for", "Criteo", ",", "Avazu", ",", "and", "Movielens", "datasets", "."], ["For", "our", "model", "DCAP", ",", "we", "set", "the", "maximum", "depth", "of", "network", "to", "2", "as", "a", "bounded", "order", "of", "feature", "interactions", "."]], "ner": [[], [[11, 11, "a"], [17, 18, "p"], [20, 20, "v"], [23, 24, "p"], [40, 41, "a"], [18, 18, "p"]], [[56, 62, "a"], [68, 68, "v"]], [[86, 87, "a"], [90, 90, "v"]], [[115, 115, "v"], [97, 98, "a"], [107, 107, "p"], [109, 109, "v"], [112, 113, "c"], [115, 115, "v"], [118, 120, "c"]], [[126, 129, "a"]], [[154, 154, "v"], [147, 151, "a"]], [[157, 160, "a"]], [[167, 174, "a"]], [[181, 185, "a"]], [[193, 198, "a"], [202, 202, "v"], [204, 204, "v"], [206, 206, "v"]], [[229, 229, "v"], [224, 227, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[11, 11, "a"], [17, 18, "p"], [20, 20, "v"], [23, 24, "p"], [28, 30, "v"], [40, 41, "p"], [43, 43, "v"]], [[60, 62, "a"], [64, 64, "v"], [65, 66, "p"], [68, 68, "v"], [77, 77, "a"]], [], [[97, 98, "a"], [109, 109, "v"], [115, 115, "v"], [119, 119, "v"]], [[133, 133, "v"]], [[151, 151, "a"], [154, 154, "v"]], [[160, 160, "a"], [164, 164, "v"]], [[172, 172, "a"], [174, 174, "a"], [176, 176, "v"]], [[185, 185, "a"], [189, 189, "v"]], [[198, 198, "a"], [202, 202, "v"], [204, 204, "v"], [206, 206, "v"], [207, 208, "c"], [208, 208, "a"], [210, 210, "a"]], [[219, 219, "a"], [229, 229, "v"]]], "predicted_relations": [[], [[17, 18, 11, 11, "USED-FOR"], [20, 20, 23, 24, "USED-FOR"], [23, 24, 11, 11, "USED-FOR"], [18, 18, 11, 11, "USED-FOR"]], [], [], [[118, 120, 115, 115, "USED-FOR"], [118, 120, 115, 115, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2111.11703-7a08a214-1129-47fd-98bf-6c07cbb3030d", "sentences": [["For", "all", "models", ",", "teacher", "forcing", "was", "used", ",", "the", "batch", "size", "was", "set", "to", "64", ",", "and", "training", "was", "conducted", "for", "2", "epochs", ",", "when", "the", "losses", "converged", "."], ["The", "Adam", "optimizer", "-LSB-", "22", "-RSB-", "was", "used", "for", "all", "models", ",", "with", "the", "parameters", "\\", "-LRB-", "-LRB-", "\\alpha", ",", "\\beta", "_", "-LCB-", "1", "-RCB-", ",", "\\beta", "_", "-LCB-", "2", "-RCB-", "-RRB-", "=", "-LRB-", "0.0005,0.9,0.999", "-RRB-", "\\", "-RRB-", "."], ["For", "CLSM", "or", "VAE", ",", "we", "conducted", "KL-annealing", "linearly", "from", "\\", "-LRB-", "\\beta", "=0\\", "-RRB-", "or", "\\", "-LRB-", "\\gamma", "=0\\", "-RRB-", "for", "2", "epochs", "-LSB-", "0", "-RSB-", "."]], "ner": [[], [[31, 32, "a"], [48, 48, "p"], [64, 64, "v"], [64, 64, "v"], [64, 64, "v"], [50, 50, "p"], [56, 56, "p"], [64, 64, "v"], [64, 64, "v"], [64, 64, "v"], [64, 64, "v"], [64, 64, "v"], [64, 64, "v"]], [[76, 76, "a"], [81, 81, "p"], [82, 82, "v"], [88, 88, "v"], [94, 94, "v"], [70, 72, "c"], [87, 87, "p"], [82, 82, "v"], [88, 88, "v"], [94, 94, "v"], [70, 72, "c"]]], "relations": [[], [], []], "predicted_ner": [[[10, 11, "p"], [15, 15, "v"], [22, 22, "v"], [23, 23, "p"]], [[31, 31, "a"], [38, 40, "c"], [48, 48, "p"]], [[70, 70, "a"], [72, 72, "a"], [76, 76, "a"], [81, 81, "p"], [81, 82, "v"], [87, 87, "p"], [91, 91, "v"], [92, 92, "p"]]], "predicted_relations": [[], [[48, 48, 31, 32, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [50, 50, 31, 32, "USED-FOR"], [56, 56, 31, 32, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"], [64, 64, 50, 50, "USED-FOR"], [64, 64, 56, 56, "USED-FOR"]], [[81, 81, 76, 76, "USED-FOR"], [82, 82, 81, 81, "USED-FOR"], [88, 88, 81, 81, "USED-FOR"], [88, 88, 87, 87, "USED-FOR"], [70, 72, 82, 82, "USED-FOR"], [70, 72, 88, 88, "USED-FOR"], [70, 72, 82, 82, "USED-FOR"], [70, 72, 88, 88, "USED-FOR"], [87, 87, 76, 76, "USED-FOR"], [82, 82, 81, 81, "USED-FOR"], [88, 88, 81, 81, "USED-FOR"], [88, 88, 87, 87, "USED-FOR"], [70, 72, 82, 82, "USED-FOR"], [70, 72, 88, 88, "USED-FOR"], [70, 72, 82, 82, "USED-FOR"], [70, 72, 88, 88, "USED-FOR"]]]}
{"doc_key": "2111.00400-da48609d-e62d-4d1f-b9e7-0ccee9c6e8e7", "sentences": [["The", "three", "versions", "of", "FAN", "are", "as", "follows", ":", "1-", "FAN-a", ":", "an", "LSTM", "based", "encoder", ",", "two", "LSTM", "based", "decoders", ",", "and", "an", "additive", "attention", "attender", ";", "2-", "FAN-b", ":", "an", "LSTM", "based", "encoder", ",", "two", "self-attention", "based", "decoders", ",", "a", "cross-attention", "attender", ";", "3-", "FAN-c", ":", "a", "self-attention", "based", "encoder", "and", "two", "self-attention", "based", "decoders", ",", "and", "a", "cross-attention", "attender", "."], ["In", "FAN-a", ",", "we", "used", "a", "\\", "-LRB-", "3\\times", "612\\", "-RRB-", "LSTM", "in", "the", "encoder", "and", "two", "decoders", "."], ["In", "FAN-b", ",", "we", "used", "a", "\\", "-LRB-", "4\\times", "768\\", "-RRB-", "LSTM", "in", "the", "encoder", "and", "3", "layers", "of", "self-attention", "layers", "in", "each", "decoder", "."], ["In", "FAN-c", ",", "we", "used", "12", "self-attention", "layers", "in", "the", "encoder", ",", "5", "self-attention", "layers", "in", "the", "slot", "value", "decoder", ",", "and", "3", "self-attention", "layers", "in", "the", "slot", "tag", "decoder", "."], ["The", "input", "dimension", "-LRB-", "d-model", "-RRB-", "was", "set", "to", "256", "."], ["For", "all", "self-attention", "layers", ",", "we", "used", "4", "heads", "and", "a", "2,048-hidden", "unit", "feedforward", "net", "is", "used", "."], ["For", "the", "multi-task", "and", "direct", "A2I", "in", "-LSB-", "11", "-RSB-", ",", "the", "size", "of", "the", "encoder", "and", "decoder", "were", "set", "to", "\\", "-LRB-", "3\\times", "612\\", "-RRB-", "and", "\\", "-LRB-", "4\\times", "612\\", "-RRB-", ",", "respectively", "."], ["We", "trained", "these", "models", "using", "500", "hours", "of", "data", "in-house", "data", "."]], "ner": [[[13, 13, "a"], [18, 18, "a"], [32, 32, "a"], [37, 37, "a"], [49, 49, "a"], [54, 54, "a"], [24, 25, "a"], [42, 42, "a"], [60, 60, "a"]], [[74, 74, "a"]], [[93, 93, "a"], [101, 101, "a"], [90, 90, "v"]], [[113, 113, "a"], [120, 120, "a"], [130, 130, "a"]], [[139, 140, "p"], [147, 147, "v"]], [[151, 151, "a"], [157, 157, "p"], [156, 156, "v"], [160, 163, "p"], [160, 160, "v"]], [[196, 196, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "v"], [4, 4, "a"], [13, 13, "a"], [17, 17, "v"], [18, 18, "a"], [32, 32, "a"], [36, 36, "v"], [53, 53, "v"]], [[71, 72, "v"], [74, 74, "a"], [79, 79, "v"]], [[90, 91, "v"], [93, 93, "a"], [98, 98, "v"]], [[112, 112, "v"], [119, 119, "v"], [129, 129, "v"]], [[147, 147, "v"]], [[156, 156, "v"], [160, 161, "v"], [162, 163, "a"]], [[190, 191, "v"], [196, 197, "v"]], [[207, 207, "v"]]], "predicted_relations": [[], [], [], [], [], [[157, 157, 151, 151, "USED-FOR"], [156, 156, 157, 157, "USED-FOR"], [160, 163, 151, 151, "USED-FOR"], [160, 160, 160, 163, "USED-FOR"]], [], []]}
{"doc_key": "2111.00400-e1059f3f-b271-41d4-9c53-0df722feeed0", "sentences": [["For", "the", "FSC", "dataset", ",", "we", "built", "smaller", "models", "to", "prevent", "overfitting", "as", "the", "FSC", "dataset", "is", "very", "small", "and", "not", "complex", "."], ["We", "observed", "models", "of", "size", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "3", "millions", "deliver", "good", "results", "and", "do", "n't", "suffer", "from", "overfitting", "."], ["For", "FSC", ",", "the", "FANS", "models", "were", "built", "as", "follows", ":", "In", "FAN-a", ",", "we", "used", "a", "\\", "-LRB-", "1\\times", "256\\", "-RRB-", "LSTM", "in", "the", "encoder", "and", "two", "decoders", "."], ["In", "FAN-b", ",", "we", "used", "a", "\\", "-LRB-", "2\\times", "232\\", "-RRB-", "LSTM", "in", "the", "encode", "and", "2", "layers", "of", "self-attention", "layers", "in", "each", "decoder", "with", "1", "head", "and", "a", "800-hidden", "unit", "feedforward", "net", "."], ["In", "FAN-c", ",", "we", "used", "2", "self-attention", "layers", "in", "the", "encoder", ",", "1", "self-attention", "layer", "in", "the", "slot", "value", "decoder", ",", "and", "1", "self-attention", "layer", "in", "the", "slot", "tag", "decoder", "with", "4", "heads", "and", "a", "1024-hidden", "unit", "feedforward", "net", "."], ["The", "input", "dimension", "-LRB-", "d-model", "-RRB-", "for", "all", "these", "models", "was", "set", "to", "128", "."], ["For", "the", "multi-task", "and", "direct", "A2I", "in", "-LSB-", "11", "-RSB-", ",", "the", "size", "of", "the", "encoder", "and", "decoder", "were", "set", "to", "\\", "-LRB-", "1\\times", "256\\", "-RRB-", "and", "\\", "-LRB-", "1\\times", "350\\", "-RRB-", "LSTM", ",", "respectively", "."]], "ner": [[[2, 3, "a"], [14, 15, "a"]], [[27, 27, "p"]], [[49, 50, "a"], [67, 67, "p"], [57, 57, "c"], [49, 50, "a"]], [[86, 86, "p"], [76, 76, "c"], [83, 83, "v"], [91, 91, "v"], [94, 95, "p"], [104, 107, "p"]], [[144, 144, "v"], [114, 114, "v"], [115, 116, "p"], [141, 141, "p"], [144, 147, "p"]], [[162, 162, "v"]], [[176, 176, "p"], [196, 196, "p"], [166, 169, "c"], [166, 169, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 3, "a"], [14, 15, "a"]], [[33, 33, "v"]], [[46, 46, "a"], [64, 65, "v"], [67, 67, "a"], [72, 72, "v"]], [[83, 84, "v"], [86, 86, "a"], [91, 91, "v"], [100, 100, "v"], [106, 107, "a"]], [[114, 114, "v"], [121, 121, "v"], [131, 131, "v"], [140, 140, "v"], [144, 145, "v"], [146, 147, "a"]], [[162, 162, "v"]], [[187, 188, "v"], [193, 194, "v"], [196, 196, "a"]]], "predicted_relations": [[], [], [[67, 67, 49, 50, "USED-FOR"], [67, 67, 49, 50, "USED-FOR"]], [[76, 76, 83, 83, "USED-FOR"], [83, 83, 86, 86, "USED-FOR"], [91, 91, 94, 95, "USED-FOR"]], [[144, 144, 144, 147, "USED-FOR"], [114, 114, 115, 116, "USED-FOR"]], [], [[176, 176, 166, 169, "USED-FOR"]]]}
{"doc_key": "2103.16806-0355725f-cb80-4d4f-8182-0f7969e8c15b", "sentences": [["Following", "previous", "works", ",", "we", "use", "isotropic", "Gaussian", "blur", "kernels", "to", "simulate", "the", "PSF", "."], ["The", "range", "of", "kernel", "width", "is", "fixed", "to", "1", ",", "and", "the", "kernel", "size", "is", "fixed", "to", "\\", "-LRB-", "8\\times", "8\\", "-RRB-", "."], ["For", "CAVE", "and", "Pavia", ",", "we", "directly", "take", "the", "whole", "image", "for", "training", "."], ["As", "for", "the", "WV2", ",", "the", "LR-HSI", "are", "cropped", "to", "\\", "-LRB-", "128\\times", "128\\", "-RRB-", "image", "patches", "for", "training", ",", "and", "no", "data", "augmentations", "were", "used", "."], ["The", "parameter", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "are", "empirically", "set", "to", "0.01", "and", "30", ",", "respectively", "."], ["Adam", "optimizer", "is", "used", "with", "default", "setting", "."], ["We", "train", "SRFN", "for", "55000", "iterations", "on", "CAVE", ",", "and", "the", "learning", "rate", "is", "initialized", "to", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "SRFN", "is", "trained", "for", "20000", "iteration", "on", "WV2", "and", "10000", "iteration", "on", "Pavias", ",", "while", "the", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "4\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["Through", "all", "the", "experiments", ",", "the", "training", "batchsize", "is", "set", "to", "1", "."], ["All", "the", "models", "are", "trained", "on", "a", "server", "equipped", "with", "NVIDIA", "RTX", "2080", "Ti", "GPU", "."]], "ner": [[], [[23, 23, "v"]], [], [], [[96, 96, "v"], [98, 98, "v"]], [[102, 103, "a"]], [[112, 112, "a"]], [[137, 137, "a"]], [[180, 180, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[23, 23, "v"], [35, 35, "v"]], [[39, 39, "a"], [41, 41, "a"]], [[55, 55, "a"], [58, 58, "a"], [65, 65, "v"]], [[83, 83, "p"], [89, 89, "p"], [96, 96, "v"], [98, 98, "v"]], [[102, 102, "a"]], [[112, 112, "a"], [114, 114, "v"], [117, 117, "a"], [121, 122, "p"], [128, 131, "v"]], [[137, 137, "a"], [141, 141, "v"], [144, 144, "a"], [146, 146, "v"], [149, 149, "a"], [154, 155, "p"], [162, 164, "v"]], [[175, 176, "p"], [180, 180, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2103.11263-5165850f-6a0f-4cfe-a963-1019acb592f3", "sentences": [["For", "all", "test-time", "learning", "variants", ",", "we", "limit", "the", "maximum", "number", "of", "questions", "generated", "per", "context", "to", "4000", "and", "the", "maximum", "number", "of", "training", "steps", "to", "1500", "."], ["The", "number", "of", "training", "steps", "is", "linearly", "dependent", "on", "the", "selected", "batch", "size", "\\", "-LRB-", "\\in", "-LSB-", "16", ",", "64", "-RSB-", "\\", "-RRB-", "."], ["For", "our", "\\", "-LRB-", "K\\", "-RRB-", "-neighbor", "TTL", "setup", "that", "uses", "Context", "Expansion", ",", "we", "limit", "the", "number", "of", "retrieved", "contexts", "to", "500", "."], ["In", "Curriculum", "Test-Time", "RC", ",", "we", "ensure", "that", "all", "variants", "have", "an", "equal", "number", "-LRB-", "1000", "-RRB-", "of", "generated", "QA-pairs", "per-context", "."], ["We", "evaluate", "multiple", "learning", "rates", "within", "the", "range", "1e-5", "to", "5e-5", "."], ["We", "use", "the", "Adam", "-LSB-", "24", "-RSB-", "optimizer", "and", "truncate", "the", "paragraphs", "to", "a", "maximum", "sequence", "length", "of", "384", "."], ["The", "number", "384", "was", "chosen", "by", "evaluating", "the", "99th", "percentile", "of", "the", "combined", "length", "of", "question", "and", "the", "contexts", ",", "to", "reduce", "training", "overhead", "and", "GPU", "memory", "size", "."], ["Long", "documents", "are", "split", "into", "multiple", "windows", "with", "a", "stride", "of", "128", "."], ["All", "experiments", "were", "conducted", "on", "two", "Nvidia", "RTX-8000", "GPUs", "."], ["We", "use", "ten", "percent", "of", "the", "training", "data", "to", "perform", "three", "hyper-parameter", "trials", "for", "each", "variant", "."], ["We", "train", "models", "with", "three", "random", "seeds", ",", "and", "report", "the", "mean", "F1", "and", "EM", "scores", "."]], "ner": [[], [], [[63, 64, "a"]], [[77, 79, "a"]], [], [[113, 113, "a"], [128, 128, "v"], [113, 113, "a"]], [[132, 132, "v"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[17, 17, "v"], [26, 26, "v"]], [[39, 40, "p"]], [[56, 56, "p"], [74, 74, "v"]], [[91, 91, "v"]], [[106, 106, "v"], [108, 108, "v"]], [[113, 113, "a"], [128, 128, "v"]], [[132, 132, "v"]], [[170, 170, "v"]], [[177, 177, "v"]], [[184, 185, "v"], [192, 192, "v"]], [[203, 203, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2104.07182-50b227ca-a730-4c9a-a1b6-4c56b36b54f7", "sentences": [["Each", "training", "sequential", "example", "comprises", "10", "past", "and", "current", "sweeps", "-LRB-", "\\", "-LRB-", "-0.9\\", "-RRB-", "s", ",", "\\", "-LRB-", "-0.8\\", "-RRB-", "s", ",", "...", ",", "0s", "-RRB-", ",", "and", "41", "current", "and", "future", "timestamps", "for", "ground-truth", "supervision", "-LRB-", "0s", ",", "\\", "-LRB-", "0.1\\", "-RRB-", "s", ",", "...", ",", "\\", "-LRB-", "4.0\\", "-RRB-", "s", "-RRB-", "."], ["The", "frame", "at", "current", "timestamp", "is", "referred", "to", "as", "the", "key", "frame", "."], ["Each", "scene", "on", "the", "in-house", "data", "set", "is", "25s", "long", ",", "producing", "at", "most", "200", "complete", "sequential", "examples", "."], ["We", "trained", "all", "of", "the", "models", "with", "decimated", "key", "frames", "in", "the", "training", "split", "once", "-LRB-", "i.e.", ",", "every", "sequential", "example", "whose", "key", "frame", "is", "at", "\\", "-LRB-", "t\\", "-RRB-", ",", "\\", "-LRB-", "t+0.2\\", "-RRB-", "s", ",", "\\", "-LRB-", "t+0.4\\", "-RRB-", "s", ",", "\\", "-LRB-", "\\ldots", "\\", "-RRB-", ",", "is", "used", "once", "during", "model", "training", "-RRB-", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "v"], [13, 13, "v"], [19, 19, "v"], [25, 25, "v"], [29, 29, "v"], [38, 38, "v"], [42, 42, "v"], [50, 50, "v"]], [], [[76, 76, "v"], [82, 82, "v"]], [[120, 120, "v"], [126, 126, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.03027-7ef88851-635c-4811-9aa9-12a5121b6755", "sentences": [["Optimization", "."], ["All", "models", "are", "trained", "in", "mixed-precision", "-LRB-", "32-bit", "weights", ",", "16-bit", "gradients", "-RRB-", "using", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "with", "Nesterov", "'s", "acceleration", "with", "momentum", "coefficient", "set", "to", "0.9", "and", "cosine", "annealing", "of", "the", "learning", "rate", "schedule", "for", "200", "epochs", "."], ["Training", "of", "the", "Multi-Head", "model", "involves", "mini-batches", "that", "contain", "samples", "from", "all", "tasks", "."]], "ner": [[], [[27, 28, "p"], [31, 31, "v"], [37, 39, "p"], [33, 34, "v"], [7, 7, "a"], [9, 10, "p"], [12, 13, "p"]], []], "relations": [[], [], []], "predicted_ner": [[], [[9, 9, "v"], [12, 12, "v"], [16, 21, "a"], [23, 25, "a"], [27, 28, "p"], [31, 31, "v"], [37, 39, "p"], [41, 41, "v"], [42, 42, "p"]], [[47, 48, "a"]]], "predicted_relations": [[], [[27, 28, 7, 7, "USED-FOR"], [31, 31, 37, 39, "USED-FOR"], [9, 10, 7, 7, "USED-FOR"], [12, 13, 7, 7, "USED-FOR"]], []]}
{"doc_key": "2106.03027-ed05e260-cd78-48ab-acc2-1e3d4c240155", "sentences": [["Hyper-parameter", "optimization", "."], ["We", "used", "Ray", "Tune", "-LSB-", "30", "-RSB-", "for", "hyper-parameter", "optimization", "."], ["The", "Async", "Successive", "Halving", "Algorithm", "-LRB-", "ASHA", "-RRB-", "scheduler", "-LSB-", "87", "-RSB-", "was", "used", "to", "prune", "hyper-parameter", "choices", "with", "the", "search", "space", "determined", "by", "Nevergrad", "-LSB-", "88", "-RSB-", "."], ["The", "mini-batch", "size", "was", "varied", "over", "-LSB-", "8", ",", "16", ",", "32", ",", "64", "-RSB-", ";", "logarithm", "-LRB-", "base", "10", "-RRB-", "of", "the", "learning", "rate", "was", "sampled", "from", "a", "uniform", "distribution", "on", "\\", "-LRB-", "-LSB-", "-4", ",", "-2", "-RSB-", "\\", "-RRB-", ";", "dropout", "probability", "was", "sampled", "from", "a", "uniform", "distribution", "on", "\\", "-LRB-", "-LSB-", "0.1,0.5", "-RSB-", "\\", "-RRB-", ";", "logarithm", "of", "the", "weight", "decay", "coefficient", "was", "sampled", "from", "\\", "-LRB-", "-LSB-", "-6", ",", "-2", "-RSB-", "\\", "-RRB-", "."], ["We", "used", "a", "set", "of", "experiments", "for", "multi-task", "learning", "on", "the", "Coarse-CIFAR100", "dataset", "with", "different", "samples/class", "-LRB-", "100", "and", "500", "-RRB-", "to", "perform", "hyper-parameter", "tuning", "."], ["The", "final", "values", "that", "were", "chosen", "are", ",", "learning-rate", "of", "0.01", ",", "mini-batch", "size", "of", "16", ",", "dropout", "probability", "of", "0.2", "and", "weight-decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[0, 1, "a"]], [[5, 6, "a"]], [[38, 38, "a"]], [[50, 50, "v"], [52, 52, "v"], [54, 54, "v"], [56, 56, "v"], [97, 97, "v"], [97, 97, "v"]], [[132, 133, "a"]], [[162, 162, "v"], [157, 157, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[5, 6, "a"]], [[15, 15, "a"], [38, 38, "a"]], [[44, 45, "p"], [62, 62, "v"], [66, 67, "p"], [85, 86, "p"], [97, 97, "v"], [105, 107, "p"]], [[132, 133, "a"], [138, 138, "v"], [140, 140, "v"]], [[155, 155, "p"], [157, 157, "v"], [159, 160, "p"], [162, 162, "v"], [164, 165, "p"], [167, 167, "v"], [169, 169, "p"], [173, 175, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2106.03027-b5c00d49-0cb3-4601-b50c-f8ebeafcf120", "sentences": [["Data", "augmentation", "."], ["MNIST", "and", "CIFAR10/100", "datasets", "use", "padding", "-LRB-", "4", "pixels", "-RRB-", "with", "random", "cropping", "to", "an", "image", "of", "size", "28x28", "or", "32x32", "respectively", "for", "data", "augmentation", "."], ["CIFAR10/100", "images", "additionally", "have", "random", "left/right", "flips", "for", "data", "augmentation", "."], ["Images", "are", "finally", "normalized", "to", "have", "mean", "0.5", "and", "standard", "deviation", "0.25", "."]], "ner": [[[0, 1, "a"]], [[10, 11, "v"], [21, 21, "v"], [3, 3, "c"], [23, 23, "v"], [5, 5, "c"], [3, 3, "a"], [5, 5, "a"]], [[29, 29, "c"], [29, 29, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[3, 3, "a"], [10, 10, "v"], [21, 21, "v"], [23, 23, "v"]], [], [[47, 47, "v"], [51, 51, "v"]]], "predicted_relations": [[], [[3, 3, 10, 11, "USED-FOR"], [5, 5, 10, 11, "USED-FOR"]], [], []]}
{"doc_key": "2101.01444-310811ef-3f7e-4d79-9a46-a90a28080194", "sentences": [["Our", "discriminator", "models", "have", "three", "layers", "each", ",", "with", "16", "nodes", "per", "layer", "."], ["All", "layers", "use", "LeakyReLU", "activations", "with", "a", "leak", "of", "\\", "-LRB-", "0.2\\", "-RRB-", ",", "except", "for", "the", "last", "layer", ",", "which", "is", "Sigmoid-activated", "."], ["The", "discriminators", "are", "trained", "with", "soft", "labels", "-LRB-", "uniform", "distribution", "of", "\\", "-LRB-", "0.0", "..", "0.2\\", "-RRB-", "and", "\\", "-LRB-", "0.8", "..", "1.0\\", "-RRB-", "respectively", "-RRB-", "-LSB-", "14", "-RSB-", "."]], "ner": [[[9, 9, "v"]], [[17, 17, "v"], [36, 36, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [4, 4, "v"], [9, 9, "v"]], [[17, 17, "a"], [21, 21, "p"], [25, 25, "v"]], [[51, 51, "v"], [53, 53, "v"], [58, 58, "v"], [60, 60, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2101.01444-340baccf-ecf6-4f7a-9a38-c601baf4f2cf", "sentences": [["The", "generators", "also", "have", "four", "layers", "each", ",", "with", "16", "nodes", "per", "layer", "."], ["Similar", "to", "the", "discriminators", ",", "the", "generator", "'s", "layers", "use", "LeakyReLU", "activations", ",", "but", "with", "a", "leak", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["The", "last", "layer", "uses", "linear", "activation", "."]], "ner": [[], [[24, 25, "a"], [30, 30, "p"], [34, 34, "v"]], [[41, 42, "a"]]], "relations": [[], [], []], "predicted_ner": [[[4, 4, "v"], [9, 9, "v"]], [[24, 25, "a"], [34, 34, "v"]], [[41, 42, "a"]]], "predicted_relations": [[], [[30, 30, 24, 25, "USED-FOR"]], []]}
{"doc_key": "2101.01444-91a27280-3998-408c-bd0b-61c5f1d403d0", "sentences": [["Generators", "and", "discriminators", "are", "optimized", "under", "the", "use", "of", "Adam", "optimizer", "-LSB-", "7", "-RSB-", "both", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.0005\\", "-RRB-", ",", "which", "linearly", "decays", "to", "0", "after", "100", "epochs", "."], ["Whereas", "the", "generators", "share", "a", "common", "optimizer", ",", "the", "discriminators", "are", "both", "trained", "by", "individual", "optimizers", "."], ["During", "training", ",", "we", "use", "mini", "batches", "with", "a", "batch", "size", "of", "16", "."], ["The", "whole", "training", "for", "each", "model", "in", "the", "ensemble", "lasts", "200", "epochs", "."], ["This", "training", "protocol", "is", "similar", "to", "that", "of", "the", "original", "CycleGAN", "implementation", "-LSB-", "16", "-RSB-", "."]], "ner": [[[9, 10, "a"], [17, 18, "p"], [22, 22, "v"]], [], [[56, 57, "a"], [60, 61, "p"], [63, 63, "v"]], [], [[91, 91, "v"], [88, 89, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 9, "a"], [17, 18, "p"], [22, 22, "v"], [29, 29, "v"], [31, 31, "v"], [32, 32, "p"]], [], [[60, 61, "p"], [63, 63, "v"]], [[75, 75, "v"], [76, 76, "p"]], [[88, 88, "a"]]], "predicted_relations": [[[17, 18, 9, 10, "USED-FOR"], [22, 22, 17, 18, "USED-FOR"]], [], [[60, 61, 56, 57, "USED-FOR"]], [], []]}
{"doc_key": "2109.12564-3b27836f-972b-4684-ac79-983d135afc8d", "sentences": [["In", "the", "experiments", ",", "all", "the", "images", "are", "resized", "with", "\\", "-LRB-", "m", "=", "224\\", "-RRB-", "."], ["Two", "variants", "of", "the", "proposed", "Vision", "Transformer", "Hashing", "-LRB-", "VTS", "-RRB-", "are", "used", "for", "experiments", ",", "i.e.", ",", "VTS32", "and", "VTS16", "having", "patch", "size", "\\", "-LRB-", "k", "=", "32\\", "-RRB-", "and", "16", ",", "respectively", "."], ["Thus", ",", "the", "number", "of", "patches", "\\", "-LRB-", "N", "=", "49\\", "-RRB-", "and", "196", "for", "VTS32", "and", "VTS16", ",", "respectively", "."], ["The", "hidden", "size", "-LRB-", "\\", "-LRB-", "de\\", "-RRB-", "-RRB-", "is", "set", "as", "768", "in", "the", "experiments", "."], ["The", "number", "of", "transformer", "blocks", "-LRB-", "\\", "-LRB-", "L\\", "-RRB-", "-RRB-", "as", "well", "as", "the", "number", "of", "attention", "heads", "-LRB-", "\\", "-LRB-", "A_h\\", "-RRB-", "-RRB-", "are", "12", "in", "the", "VTS", "models", "."], ["The", "hash", "code", "is", "generated", "with", "16", ",", "32", "and", "64", "bit", "length", "."], ["All", "the", "models", "are", "trained", "for", "150", "epochs", "with", "a", "batch", "size", "of", "32", "using", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["The", "testing", "is", "performed", "at", "every", "30", "epochs", "and", "the", "best", "results", "are", "reported", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[12, 12, "p"], [14, 14, "v"]], [[39, 40, "p"], [45, 45, "v"], [48, 48, "v"], [48, 48, "v"], [45, 45, "v"], [45, 45, "v"]], [], [[74, 75, "p"], [85, 85, "v"]], [[91, 94, "p"], [116, 116, "v"], [105, 108, "p"], [116, 116, "v"]], [[130, 130, "v"], [128, 128, "v"], [128, 128, "v"], [130, 130, "v"], [132, 132, "v"], [130, 130, "v"]], [[149, 149, "v"], [149, 149, "v"], [143, 143, "p"], [142, 142, "v"], [146, 147, "p"], [149, 149, "v"], [155, 156, "p"], [151, 152, "a"]], [[174, 174, "p"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[12, 12, "p"], [12, 14, "v"]], [[17, 17, "v"], [22, 27, "a"], [35, 35, "a"], [37, 37, "a"], [43, 43, "p"], [43, 45, "v"], [48, 48, "v"]], [[60, 62, "v"], [65, 65, "v"], [67, 67, "a"], [69, 69, "a"]], [[74, 75, "p"], [85, 85, "v"]], [[116, 116, "v"]], [[128, 128, "v"], [130, 130, "v"], [132, 132, "v"]], [[142, 142, "v"], [143, 143, "p"], [146, 147, "p"], [149, 149, "v"], [151, 151, "a"], [155, 156, "p"], [160, 162, "v"]], [[173, 173, "v"], [174, 174, "p"]], []], "predicted_relations": [[[14, 14, 12, 12, "USED-FOR"]], [], [], [], [], [], [[149, 149, 143, 143, "USED-FOR"], [149, 149, 143, 143, "USED-FOR"], [142, 142, 143, 143, "USED-FOR"], [149, 149, 143, 143, "USED-FOR"], [155, 156, 151, 152, "USED-FOR"]], [], []]}
{"doc_key": "2103.01716-fcf221bd-d7e1-4e9e-8d06-33af0336a2fa", "sentences": [["We", "trained", "four", "instances", "of", "the", "eum", "model", "."], ["The", "first", "and", "second", "instances", ",", "model1", "and", "model2", ",", "are", "trained", "with", "srt", "loss", "using", "feature", "embeddings", "obtained", "from", "ResNet-50", "and", "MobileFaceNet", ",", "respectively", "."], ["The", "third", "and", "fourth", "instances", ",", "model3", "and", "model4", ",", "are", "trained", "with", "triplet", "loss", "using", "feature", "embeddings", "obtained", "from", "ResNet-50", "and", "MobileFaceNet", ",", "respectively", "as", "an", "ablation", "study", "to", "our", "proposed", "srt", "."], ["The", "proposed", "EUM", "models", "in", "this", "paper", "are", "implemented", "by", "Pytorch", "and", "trained", "on", "Nvidia", "GeForce", "RTX", "2080", "GPU", "."], ["All", "models", "are", "trained", "using", "SGD", "optimizer", "with", "initial", "learning", "rate", "of", "1e-1", "and", "batch", "size", "of", "512", "."], ["The", "learning", "rate", "is", "divided", "by", "10", "at", "\\", "-LRB-", "30k", ",", "60k", ",", ",90k\\", "-RRB-", "training", "iterations", "."], ["The", "early-stopping", "patience", "parameter", "is", "set", "to", "3", "-LRB-", "around", "30k", "training", "iteration", "-RRB-", "causing", "model1", ",", "model2", ",", "model3", ",", "and", "model4", "to", "stop", "after", "80k", ",", "70k", ",", "60k", ",", "10k", "training", "iterations", ",", "respectively", "."]], "ner": [[], [[22, 23, "p"], [29, 29, "a"], [31, 31, "a"]], [[48, 49, "p"], [55, 55, "a"], [57, 57, "a"]], [], [[94, 95, "p"], [101, 101, "v"], [97, 99, "c"], [106, 106, "v"], [103, 104, "c"]], [], [[128, 130, "p"], [134, 134, "v"], [136, 139, "c"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [6, 7, "a"]], [[22, 23, "a"], [29, 29, "a"], [31, 31, "a"]], [[48, 49, "a"], [55, 55, "a"], [57, 57, "a"], [67, 67, "a"]], [[71, 72, "a"]], [[94, 94, "a"], [98, 99, "p"], [101, 101, "v"], [103, 104, "p"], [106, 106, "v"]], [[109, 110, "p"], [114, 114, "v"], [118, 118, "v"], [120, 120, "v"]], [[129, 130, "p"], [134, 134, "v"], [137, 137, "v"], [149, 149, "a"], [153, 153, "v"], [155, 155, "v"], [157, 157, "v"], [159, 159, "v"]]], "predicted_relations": [[], [[22, 23, 29, 29, "USED-FOR"]], [], [], [[97, 99, 101, 101, "USED-FOR"], [97, 99, 106, 106, "USED-FOR"]], [], [[136, 139, 134, 134, "USED-FOR"]]]}
{"doc_key": "2112.01723-49bd1c96-2403-4152-aa9f-2f6862b71db4", "sentences": [["The", "training", "parameters", "used", "in", "-LSB-", "22", "-RSB-", "are", "provided", "here", "."], ["We", "used", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "\\eta", "_", "-LCB-", "0", "-RCB-", "=", "0.01\\", "-RRB-", "and", "exponentially", "decayed", "that", "rate", "by", "computing", ":", "\\", "-LRB-", "\\eta", "_", "-LCB-", "k+1", "-RCB-", "=", "\\eta", "_", "-LCB-", "k", "-RCB-", "\\cdot", "\\exp", "-LRB-", "-0.6", "\\cdot", "k", "-RRB-", ",", "\\", "-RRB-"]], "ner": [[], [[15, 17, "a"], [16, 17, "p"], [27, 27, "v"]]], "relations": [[], []], "predicted_ner": [[], [[16, 17, "p"], [27, 27, "v"]]], "predicted_relations": [[], [[16, 17, 15, 17, "USED-FOR"]]]}
{"doc_key": "2112.01723-46546801-d12b-4c56-a171-ef1efc35e8b5", "sentences": [["at", "every", "\\", "-LRB-", "k\\", "-RRB-", "epoch", "."], ["The", "Binary-Cross", "Entropy", "loss", "function", "was", "modified", "by", "doubling", "the", "weight", "term", "for", "false", "positive", "error", "cases", "to", "trade-off", "false", "positives", "for", "false", "negatives", ":", "\\", "-LRB-", "L", "-LRB-", "y", ",", "\\hat", "-LCB-", "y", "-RCB-", "-RRB-", "=", "-", "y", "\\cdot", "\\log", "-LRB-", "\\hat", "-LCB-", "y", "-RCB-", "-RRB-", "-", "2", "\\cdot", "-LRB-", "1", "-", "y", "-RRB-", "\\cdot", "\\log", "-LRB-", "1", "-", "\\hat", "-LCB-", "y", "-RCB-", "-RRB-", ",", "\\", "-RRB-"]], "ner": [[], [[9, 12, "a"], [18, 19, "p"], [56, 56, "v"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "p"]], [[9, 10, "a"], [35, 35, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2105.00930-1ce440fb-2f71-4a65-b2db-803b3f7f1635", "sentences": [["The", "FusionNet", "model", "contains", "a", "large", "number", "of", "trainable", "parameters", "."], ["In", "order", "to", "prohibit", "overfitting", ",", "we", "have", "used", "dropout\\", "-LRB-", "=0.6\\", "-RRB-", "along", "with", "Weight", "Regularization", ",", "Batch", "Normalization", "and", "Early", "Stopping", "."], ["Both", "the", "pt-GAN", "model", "as", "well", "as", "the", "pose", "clustering", "module", "is", "trained", "independently", "."], ["After", "training", ",", "the", "FusionNet", "model", "is", "trained", "for", "classification", "accuracy", "keeping", "the", "other", "two", "models", "frozen", "."]], "ner": [[[1, 2, "a"], [1, 2, "a"]], [[20, 20, "p"], [22, 22, "v"], [26, 27, "a"], [29, 30, "a"], [32, 33, "a"]], [[37, 38, "a"], [43, 45, "a"]], [[54, 55, "a"], [54, 55, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"]], [[22, 22, "v"], [29, 30, "a"], [32, 33, "a"]], [[37, 38, "a"]], [[54, 55, "a"], [64, 64, "v"]]], "predicted_relations": [[], [[22, 22, 20, 20, "USED-FOR"]], [], []]}
{"doc_key": "2112.13756-6c7341aa-ec89-4cb1-97ee-a96dde08d6d4", "sentences": [["The", "skip-gram", "embeddings", "were", "trained", "using", "default", "parameters", "-LRB-", "vector", "dimensionality", ":", "100", ";", "subword", ":", "between", "3", "and", "6", "characters", ";", "learning", "rate", ":", "0.05", ";", "epochs", ":", "5", "-RRB-", "."], ["The", "NN", "was", "trained", "for", "25", "epochs", "for", "all", "100", "classes", "using", "the", "corpus", "specific", "pre-trained", "skip-gram", "embeddings", "from", "the", "step", "before", ",", "applying", "default", "parameters", "-LRB-", "learning", "rate", ":", "0.05", "-RRB-", "."]], "ner": [[[1, 2, "a"], [9, 10, "p"], [12, 12, "v"], [14, 14, "p"], [16, 20, "v"], [22, 23, "p"], [25, 25, "v"], [27, 27, "p"], [29, 29, "v"], [22, 23, "p"], [25, 25, "v"], [27, 27, "p"]], [[48, 49, "a"], [41, 41, "v"], [59, 60, "p"], [62, 62, "v"], [38, 38, "p"], [33, 33, "a"], [59, 60, "p"], [62, 62, "v"], [38, 38, "p"], [37, 37, "v"]]], "relations": [[], []], "predicted_ner": [[[12, 12, "v"], [17, 17, "v"], [19, 19, "v"], [22, 23, "p"], [25, 25, "v"], [27, 27, "p"], [29, 29, "v"]], [[33, 33, "a"], [37, 37, "v"], [38, 38, "p"], [41, 41, "v"], [59, 60, "p"], [62, 62, "v"]]], "predicted_relations": [[[9, 10, 1, 2, "USED-FOR"], [12, 12, 9, 10, "USED-FOR"], [12, 12, 14, 14, "USED-FOR"], [14, 14, 1, 2, "USED-FOR"], [16, 20, 9, 10, "USED-FOR"], [16, 20, 22, 23, "USED-FOR"], [16, 20, 22, 23, "USED-FOR"], [25, 25, 27, 27, "USED-FOR"], [25, 25, 27, 27, "USED-FOR"], [29, 29, 27, 27, "USED-FOR"], [29, 29, 27, 27, "USED-FOR"], [25, 25, 27, 27, "USED-FOR"], [25, 25, 27, 27, "USED-FOR"]], [[41, 41, 38, 38, "USED-FOR"], [41, 41, 38, 38, "USED-FOR"], [59, 60, 48, 49, "USED-FOR"], [38, 38, 33, 33, "USED-FOR"], [59, 60, 48, 49, "USED-FOR"], [38, 38, 33, 33, "USED-FOR"], [37, 37, 38, 38, "USED-FOR"], [37, 37, 38, 38, "USED-FOR"]]]}
{"doc_key": "2104.13913-4f595021-fe2a-4544-a2ce-daa3aabfe6aa", "sentences": [["For", "the", "fine-tuning", "of", "the", "BioBERT", "models", ",", "we", "use", "the", "learning", "rate", "of", "2e-5", ",", "batch", "size", "of", "16", ",", "training", "epoch", "of", "10", ",", "and", "max", "sequence", "length", "of", "128", "."], ["During", "the", "fine-tuning", "of", "PubMedBERT", "models", ",", "the", "learning", "rate", "of", "2e-5", ",", "batch", "size", "of", "8", ",", "training", "epoch", "of", "10", "and", "max", "sequence", "length", "of", "256", "are", "utilized", "."]], "ner": [[[5, 6, "a"], [11, 12, "p"], [14, 14, "v"], [16, 17, "p"], [19, 19, "v"], [21, 22, "p"], [24, 24, "v"], [27, 29, "p"], [31, 31, "v"], [11, 12, "p"], [14, 14, "v"], [16, 17, "p"], [21, 22, "p"], [24, 24, "v"], [27, 29, "p"]], [[41, 42, "p"], [44, 44, "v"], [46, 47, "p"], [51, 52, "p"], [54, 54, "v"], [56, 58, "p"], [37, 38, "a"], [41, 42, "p"], [44, 44, "v"], [46, 47, "p"], [49, 49, "v"], [51, 52, "p"], [54, 54, "v"], [56, 58, "p"], [60, 60, "v"]]], "relations": [[], []], "predicted_ner": [[[5, 6, "a"], [11, 12, "p"], [14, 14, "v"], [16, 17, "p"], [19, 19, "v"], [21, 22, "p"], [24, 24, "v"], [31, 31, "v"]], [[37, 38, "a"], [41, 42, "p"], [44, 44, "v"], [46, 47, "p"], [49, 49, "v"], [51, 52, "p"], [54, 54, "v"], [60, 60, "v"]]], "predicted_relations": [[[11, 12, 5, 6, "USED-FOR"], [14, 14, 11, 12, "USED-FOR"], [14, 14, 21, 22, "USED-FOR"], [14, 14, 11, 12, "USED-FOR"], [14, 14, 21, 22, "USED-FOR"], [16, 17, 5, 6, "USED-FOR"], [19, 19, 21, 22, "USED-FOR"], [19, 19, 21, 22, "USED-FOR"], [21, 22, 5, 6, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 29, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 29, "USED-FOR"], [27, 29, 5, 6, "USED-FOR"], [31, 31, 27, 29, "USED-FOR"], [31, 31, 27, 29, "USED-FOR"], [11, 12, 5, 6, "USED-FOR"], [14, 14, 11, 12, "USED-FOR"], [14, 14, 21, 22, "USED-FOR"], [14, 14, 11, 12, "USED-FOR"], [14, 14, 21, 22, "USED-FOR"], [16, 17, 5, 6, "USED-FOR"], [21, 22, 5, 6, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 29, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 29, "USED-FOR"], [27, 29, 5, 6, "USED-FOR"]], [[41, 42, 37, 38, "USED-FOR"], [44, 44, 41, 42, "USED-FOR"], [44, 44, 51, 52, "USED-FOR"], [44, 44, 41, 42, "USED-FOR"], [44, 44, 51, 52, "USED-FOR"], [46, 47, 37, 38, "USED-FOR"], [51, 52, 37, 38, "USED-FOR"], [54, 54, 51, 52, "USED-FOR"], [54, 54, 56, 58, "USED-FOR"], [54, 54, 51, 52, "USED-FOR"], [54, 54, 56, 58, "USED-FOR"], [56, 58, 37, 38, "USED-FOR"], [41, 42, 37, 38, "USED-FOR"], [44, 44, 41, 42, "USED-FOR"], [44, 44, 51, 52, "USED-FOR"], [44, 44, 41, 42, "USED-FOR"], [44, 44, 51, 52, "USED-FOR"], [46, 47, 37, 38, "USED-FOR"], [49, 49, 51, 52, "USED-FOR"], [49, 49, 56, 58, "USED-FOR"], [49, 49, 51, 52, "USED-FOR"], [49, 49, 56, 58, "USED-FOR"], [51, 52, 37, 38, "USED-FOR"], [54, 54, 51, 52, "USED-FOR"], [54, 54, 56, 58, "USED-FOR"], [54, 54, 51, 52, "USED-FOR"], [54, 54, 56, 58, "USED-FOR"], [56, 58, 37, 38, "USED-FOR"], [60, 60, 56, 58, "USED-FOR"], [60, 60, 56, 58, "USED-FOR"]]]}
{"doc_key": "2104.13913-421d8da6-2171-41d3-be64-db1827347fff", "sentences": [["In", "the", "contrastive", "pre-training", "step", "of", "the", "BERT", "models", ",", "we", "use", "the", "same", "learning", "rate", "with", "the", "fine-tuning", ",", "and", "the", "training", "epoch", "is", "selected", "from", "-LSB-", "2", ",", "4", ",", "6", ",", "8", ",", "10", "-RSB-", "based", "on", "the", "performance", "on", "the", "development", "set", "."], ["If", "there", "is", "no", "development", "set", "-LRB-", "e.g.", ",", "PPI", "task", "-RRB-", ",", "we", "will", "use", "6", "as", "the", "default", "training", "epoch", "."], ["Since", "contrastive", "learning", "benefits", "more", "from", "larger", "batch", "-LSB-", "4", "-RSB-", ",", "we", "utilize", "the", "batch", "size", "of", "256", "and", "128", "for", "BioBERT", "and", "PubMedBERT", "respectively", "."], ["In", "addition", ",", "the", "temperature", "parameter", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "is", "set", "to", "0.1", "during", "the", "training", "."]], "ner": [[[7, 8, "a"], [14, 15, "p"], [13, 13, "v"], [22, 23, "p"], [28, 28, "v"], [30, 30, "v"], [32, 32, "v"], [34, 34, "v"], [36, 36, "v"]], [[67, 68, "p"], [63, 63, "v"]], [[79, 79, "v"], [85, 86, "p"], [88, 88, "v"], [92, 92, "c"], [90, 90, "v"], [94, 94, "c"]], [[101, 102, "p"], [111, 111, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"], [14, 15, "p"], [22, 23, "p"]], [[63, 63, "v"], [67, 68, "p"]], [[85, 86, "p"], [88, 88, "v"], [90, 90, "v"], [92, 92, "a"], [94, 94, "a"]], [[101, 102, "p"], [111, 111, "v"], [112, 114, "c"]]], "predicted_relations": [[[14, 15, 7, 8, "USED-FOR"], [13, 13, 22, 23, "USED-FOR"], [22, 23, 7, 8, "USED-FOR"], [28, 28, 22, 23, "USED-FOR"], [30, 30, 22, 23, "USED-FOR"], [32, 32, 22, 23, "USED-FOR"], [34, 34, 22, 23, "USED-FOR"], [36, 36, 22, 23, "USED-FOR"]], [[63, 63, 67, 68, "USED-FOR"]], [], []]}
{"doc_key": "2106.04335-6b162ca3-4751-4753-b139-bcecfed904a3", "sentences": [["Training", "tasks", "of", "FSAF", "."], ["To", "construct", "a", "diverse", "collection", "of", "tasks", "for", "the", "training", "of", "FSAF", ",", "we", "leverage", "GP", "functions", "with", "RBF", ",", "Mat\u00e8rn-3/2", ",", "and", "spectral", "mixture", "kernels", "to", "capture", "smooth", "functions", ",", "functions", "with", "abrupt", "local", "variations", ",", "and", "functions", "of", "periodic", "nature", ",", "respectively", "."], ["For", "both", "the", "RBF", "and", "the", "Mat\u00e8rn-3/2", "kernels", ",", "we", "consider", "three", "possible", "ranges", "of", "lengthscales", ",", "including", "\\", "-LRB-", "-LSB-", "0.07,0.13", "-RSB-", ",", "-LSB-", "0.17,0.23", "-RSB-", ",", "-LSB-", "0.27,0.33", "-RSB-", "\\", "-RRB-", "."], ["For", "the", "spectral", "mixture", "kernels", ",", "we", "consider", "mixtures", "of", "two", "Gaussian", "components", "of", "periods", "\\", "-LRB-", "0.3\\", "-RRB-", "and", "\\", "-LRB-", "0.6\\", "-RRB-", "and", "three", "possible", "ranges", "of", "the", "lengthscales", ",", "including", "\\", "-LRB-", "-LSB-", "0.27,0.33", "-RSB-", ",", "-LSB-", "0.47,0.53", "-RSB-", ",", "-LSB-", "0.57,0.63", "-RSB-", "\\", "-RRB-", "."], ["As", "a", "result", ",", "there", "are", "nine", "candidate", "tasks", "in", "the", "task", "collection", "\\", "-LRB-", "\\operatorname", "-LCB-", "\\mathcal", "-LCB-", "T", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["In", "each", "training", "iteration", "\\", "-LRB-", "i\\", "-RRB-", ",", "three", "out", "of", "the", "nine", "tasks", "are", "selected", "uniformly", "at", "random", "from", "the", "above", "task", "collection", "-LRB-", "and", "hence", "\\", "-LRB-", "\\vert", "\\operatorname", "-LCB-", "\\mathcal", "-LCB-", "T", "-RCB-", "-RCB-", "_i\\vert", "=3\\", "-RRB-", "in", "Algorithm", "-RRB-", "."], ["The", "input", "domain", "of", "these", "GP", "functions", "is", "configured", "to", "be", "\\", "-LRB-", "-LSB-", "0,1", "-RSB-", "^", "-LCB-", "3", "-RCB-", "\\", "-RRB-", "."], ["To", "facilitate", "the", "training", "procedure", ",", "we", "discretize", "the", "continuous", "input", "domain", "by", "using", "the", "Sobol", "sequence", "to", "generate", "a", "grid", "on", "which", "the", "GP", "functions", "and", "the", "AFs", "are", "evaluated", ",", "as", "typically", "done", "in", "BO", "."]], "ner": [[], [[20, 21, "a"], [23, 23, "v"], [25, 25, "v"]], [[53, 53, "v"], [56, 56, "v"]], [[101, 101, "v"], [106, 106, "v"]], [], [], [[208, 209, "a"]], [[250, 251, "a"], [241, 242, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[16, 16, "a"], [23, 23, "a"], [25, 25, "a"]], [[53, 53, "a"], [56, 56, "v"], [61, 61, "v"]], [[94, 94, "v"], [101, 101, "v"], [106, 106, "v"], [109, 109, "v"]], [[139, 139, "v"]], [[167, 167, "v"], [171, 171, "v"]], [], [[241, 242, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2106.04335-eb40e2ea-6b73-4c15-aacf-f2a05475d486", "sentences": [["Network", "architecture", "of", "each", "DQN", "particle", "."], ["For", "all", "the", "DQN", "particles", "used", "in", "the", "experiments", ",", "we", "adopt", "the", "standard", "dueling", "network", "architecture", "-LSB-", "53", "-RSB-", ",", "where", "one", "value", "network", "and", "an", "advantage", "network", "are", "maintained", "to", "produce", "the", "estimated", "Q-values", "."], ["For", "a", "fair", "comparison", "between", "FSAF", "and", "MetaBO", ",", "both", "the", "value", "network", "and", "the", "advantage", "network", "of", "our", "FSAF", "are", "configured", "to", "have", "4", "fully-connected", "hidden", "layers", "with", "ReLU", "activation", "functions", "and", "200", "hidden", "units", "per", "layer", "."], ["As", "described", "in", "Section", "REF", ",", "the", "input", "of", "an", "advantage", "network", "consists", "of", "a", "four-tuple", ",", "namely", "the", "posterior", "mean", "\\", "-LRB-", "\\mu", "_t", "-LRB-", "x", "-RRB-", "\\", "-RRB-", ",", "the", "posterior", "standard", "deviation", "\\", "-LRB-", "\\sigma", "_t", "-LRB-", "x", "-RRB-", "\\", "-RRB-", ",", "the", "best", "observation", "so", "far", "\\", "-LRB-", "y_t^", "*", "\\", "-RRB-", ",", "and", "the", "ratio", "between", "the", "current", "timestamp", "and", "total", "sampling", "budget", "\\", "-LRB-", "\\frac", "-LCB-", "t", "-RCB-", "-LCB-", "T", "-RCB-", "\\", "-RRB-", "."], ["Accordingly", ",", "the", "input", "of", "a", "value", "network", "consists", "of", "\\", "-LRB-", "y_t^", "*", "\\", "-RRB-", "and", "\\", "-LRB-", "\\frac", "-LCB-", "t", "-RCB-", "-LCB-", "T", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[4, 5, "a"], [0, 1, "p"]], [[21, 23, "v"], [34, 35, "a"], [30, 31, "a"]], [[68, 81, "v"], [59, 60, "a"], [55, 56, "a"]], [[93, 94, "a"]], [[169, 170, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[21, 22, "a"], [29, 29, "v"]], [[49, 49, "a"], [51, 51, "a"], [63, 63, "a"], [68, 68, "v"], [73, 73, "a"], [77, 77, "v"]], [[93, 94, "a"]], [[169, 170, "a"]]], "predicted_relations": [[[0, 1, 4, 5, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2110.13414-c9476a3b-eee3-4e76-92b0-85b7acf692ec", "sentences": [["Unless", "otherwise", "specified", ",", "we", "use", "ResNet-34", "-LSB-", "15", "-RSB-", "as", "the", "classifier", "."], ["We", "train", "it", "using", "Stochastic", "Gradient", "Descent", "Optimizer", "-LSB-", "0", "-RSB-", "with", "the", "constant", "learning", "rate", "of", "0.1", ",", "weight", "decay", "of", "5e-4", ",", "and", "the", "momentum", "of", "0.9", "."], ["For", "CIFAR-10", ",", "we", "use", "the", "batch", "size", "of", "128", "and", "train", "for", "100", "epochs", "."], ["For", "GTSRB", ",", "the", "number", "of", "epochs", "is", "the", "same", "but", "the", "batch", "size", "is", "increased", "to", "256", "."]], "ner": [[[6, 6, "a"]], [[18, 21, "a"], [28, 29, "p"], [31, 31, "v"], [33, 34, "p"], [36, 36, "v"], [40, 40, "p"], [42, 42, "v"]], [[45, 45, "a"], [50, 51, "p"], [53, 53, "v"], [57, 57, "v"], [50, 51, "p"], [57, 57, "v"]], [[72, 73, "p"], [61, 61, "a"], [72, 73, "p"], [77, 77, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[28, 29, "p"], [31, 31, "v"], [33, 34, "p"], [36, 36, "v"], [40, 40, "p"], [42, 42, "v"]], [[45, 45, "a"], [50, 51, "p"], [53, 53, "v"], [57, 57, "v"], [58, 58, "p"]], [[61, 61, "a"], [72, 73, "p"], [77, 77, "v"]]], "predicted_relations": [[], [[31, 31, 33, 34, "USED-FOR"], [36, 36, 28, 29, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"]], [[50, 51, 45, 45, "USED-FOR"], [50, 51, 45, 45, "USED-FOR"]], [[72, 73, 61, 61, "USED-FOR"], [72, 73, 61, 61, "USED-FOR"]]]}
{"doc_key": "2110.13414-9882623c-d2b6-4558-8e46-f55f3cef5bc5", "sentences": [["We", "compare", "our", "attack", "against", "the", "input-instance-key", "attack", "of", "Chen", "et", "al", "."], ["-LSB-", "1", "-RSB-", "since", "this", "attack", "is", "the", "closest", "to", "ours", "."], ["We", "follow", "the", "same", "settings", "-LRB-", "a", "key", "instance", "was", "chosen", "from", "one", "of", "the", "classes", "and", "added", "with", "a", "noise", "generated", "from", "a", "uniform", "distribution", "in", "the", "range", "-5.0", "to", "5.0", "-RRB-", "they", "discussed", "in", "the", "paper", "for", "the", "poison", "instance", "generation", "."], ["We", "have", "generated", "poison", "instances", "for", "both", "CIFAR-10", "and", "GTSRB", "datasets", "."], ["This", "is", "to", "compare", "the", "stealthiness", "of", "an", "attack", "based", "on", "full-sized", "usual", "triggers", "vs", "full-size", "host-free", "triggers", "of", "our", "setting", "."], ["For", "training", "the", "input-instance-key", "attack", ",", "in", "case", "of", "GTSRB", "we", "use", "keep", "right", "-LRB-", "class", "38", "-RRB-", "as", "the", "Trojan", "class", "-LRB-", "key", "-RRB-", "and", "stop", "sign", "-LRB-", "class", "14", "-RRB-", "as", "the", "target", "class", "and", "for", "CIFAR-10", "we", "use", "cat", "-LRB-", "class", "3", "-RRB-", "as", "the", "Trojan", "class", "-LRB-", "key", "-RRB-", "and", "dog", "-LRB-", "class", "5", "-RRB-", "as", "the", "target", "class", "."]], "ner": [[[6, 7, "a"]], [], [[45, 45, "p"], [49, 50, "c"]], [[76, 76, "a"], [78, 78, "a"]], [], [[106, 107, "a"], [141, 141, "a"], [112, 112, "a"], [115, 116, "a"], [129, 130, "a"], [144, 144, "a"], [157, 157, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 7, "a"]], [], [[37, 37, "v"], [56, 56, "v"]], [[76, 76, "a"], [78, 78, "a"]], [], [[112, 112, "a"], [115, 116, "a"], [119, 119, "v"], [141, 141, "a"], [144, 144, "a"], [147, 147, "v"], [157, 157, "a"], [160, 160, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2108.09208-eb774151-8a80-4eed-91ab-7aae18ceba13", "sentences": [["We", "finetuned", "our", "models", "on", "\\", "-LRB-", "S=3\\", "-RRB-", "source", "domains", "and", "tested", "on", "the", "remaining", "target", "."], ["We", "splitted", "our", "training", "sets", "in", "90", "%", "train", "and", "10", "%", "validation", ",", "and", "used", "the", "best", "performing", "model", "on", "the", "validation", "set", "for", "the", "final", "test", ",", "following", "the", "validation", "strategy", "described", "in", "Section", "dsam", ":", "sec", ":", "methodology", "."], ["For", "preprocessing", ",", "we", "used", "random", "zooming", "with", "rescaling", ",", "horizontal", "flipping", ",", "brightness/contrast/saturation/hue", "perturbations", "and", "normalization", "using", "ImageNet", "'s", "statistics", "."], ["We", "used", "a", "batch", "size", "of", "96", "-LRB-", "32", "images", "per", "source", "domain", "-RRB-", "and", "trained", "using", "SGD", "with", "momentum", "set", "at", "0.9", "and", "initial", "learning", "rate", "at", "0.01", "and", "0.007", "for", "ResNet", "'s", "and", "AlexNet", "'s", "experiments", "respectively", "."], ["We", "considered", "an", "epoch", "as", "the", "minimum", "number", "of", "steps", "necessary", "to", "iterate", "over", "the", "largest", "source", "domain", "and", "we", "trained", "our", "models", "for", "30", "epochs", ",", "scaling", "the", "learning", "rate", "by", "a", "factor", "of", "0.2", "every", "10", "epochs", "."], ["We", "used", "the", "same", "setup", "to", "train", "our", "ResNet-18", "Deep", "All", "baselines", "."], ["We", "repeated", "each", "experiment", "5", "times", ",", "averaging", "the", "results", "."]], "ner": [[], [], [[61, 61, "a"]], [[99, 99, "a"], [101, 101, "p"], [104, 104, "v"], [106, 108, "p"], [110, 110, "v"], [112, 112, "v"], [117, 119, "c"], [85, 86, "a"], [85, 86, "p"], [88, 88, "v"]], [[157, 157, "v"], [125, 125, "a"], [125, 125, "p"], [146, 146, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"]], [[24, 25, "v"], [28, 29, "v"], [54, 54, "a"]], [[78, 78, "a"]], [[85, 86, "p"], [88, 88, "v"], [90, 90, "v"], [99, 99, "a"], [104, 104, "v"], [107, 108, "p"], [110, 110, "v"], [112, 112, "v"], [114, 114, "a"], [117, 117, "a"]], [[146, 146, "v"], [147, 147, "p"], [151, 152, "p"], [157, 157, "v"], [159, 159, "v"], [160, 160, "p"]], [[170, 171, "a"]], [[179, 179, "v"]]], "predicted_relations": [[], [], [], [[101, 101, 99, 99, "USED-FOR"], [101, 101, 85, 86, "USED-FOR"], [104, 104, 106, 108, "USED-FOR"], [106, 108, 99, 99, "USED-FOR"], [112, 112, 106, 108, "USED-FOR"], [117, 119, 110, 110, "USED-FOR"], [117, 119, 112, 112, "USED-FOR"]], [[125, 125, 125, 125, "USED-FOR"]], [], []]}
{"doc_key": "2108.09208-af7a3fe7-41be-4d09-ac18-b342f7f982ab", "sentences": [["For", "the", "classification", "model", "\\", "-LRB-", "C\\", "-RRB-", "we", "use", "AlexNet", "and", "ResNet18", "backbones", "."], ["Specifically", ",", "Baseline", ",", "Rotation", "and", "Mixup", "are", "trained", "using", "SGD", "with", "\\", "-LRB-", "0.9\\", "-RRB-", "momentum", "for", "\\", "-LRB-", "30k\\", "-RRB-", "iterations", "."], ["We", "set", "the", "batch", "size", "to", "32", "images", "per", "source", "domain", ":", "since", "in", "all", "the", "testbed", "there", "are", "three", "source", "domains", "each", "data", "batch", "contains", "96", "images", "."], ["The", "learning", "rate", "and", "the", "weigh", "decay", "are", "respectively", "fixed", "to", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["Regarding", "the", "hyperparameters", "of", "the", "individual", "algorithms", ",", "we", "empirically", "set", "the", "Rotation", "auxiliary", "weight", "to", "\\", "-LRB-", "\\sigma", "=", "0.5\\", "-RRB-", "and", "for", "Mixup", "\\", "-LRB-", "\\gamma", "=", "0.4\\", "-RRB-", "."]], "ner": [[[10, 10, "a"], [12, 12, "a"]], [[17, 17, "a"], [19, 19, "a"], [21, 21, "a"], [25, 25, "a"], [31, 31, "p"], [29, 29, "v"], [37, 37, "p"], [35, 35, "v"]], [[42, 43, "p"], [45, 49, "v"]], [[69, 70, "p"], [81, 81, "v"], [86, 86, "v"]], [[101, 101, "a"], [102, 103, "p"], [109, 109, "v"], [113, 113, "a"], [116, 116, "p"], [118, 118, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "p"], [10, 10, "a"], [12, 12, "a"]], [[19, 19, "a"], [21, 21, "a"], [25, 25, "a"], [29, 29, "v"], [31, 31, "p"], [35, 35, "v"]], [[42, 43, "p"], [45, 45, "v"], [58, 58, "v"], [65, 65, "v"]], [[69, 70, "p"], [73, 74, "p"], [81, 81, "v"], [86, 86, "v"]], [[109, 109, "v"], [113, 113, "a"], [116, 116, "p"], [118, 118, "v"]]], "predicted_relations": [[], [[31, 31, 17, 17, "USED-FOR"], [31, 31, 19, 19, "USED-FOR"], [31, 31, 21, 21, "USED-FOR"], [31, 31, 25, 25, "USED-FOR"], [37, 37, 25, 25, "USED-FOR"], [35, 35, 31, 31, "USED-FOR"], [35, 35, 37, 37, "USED-FOR"]], [], [], [[102, 103, 101, 101, "USED-FOR"], [116, 116, 101, 101, "USED-FOR"], [116, 116, 113, 113, "USED-FOR"]]]}
{"doc_key": "2110.01269-ff96a08e-ced4-4a66-97f4-a53696c0bb92", "sentences": [["We", "evaluate", "our", "method", "on", "real", "-LRB-", "indoor", ",", "outdoor", "-RRB-", "and", "synthetic", "datasets", "."], ["The", "indoor", "dataset", "is", "3DMatch", "-LSB-", "44", "-RSB-", "."], ["We", "use", "the", "standard", "train/test", "splits", "and", "the", "procedure", "of", "-LSB-", "6", "-RSB-", ",", "-LSB-", "9", "-RSB-", ",", "-LSB-", "10", "-RSB-", ",", "-LSB-", "7", "-RSB-", "to", "generate", "pairs", "of", "scans", "with", "at", "least", "30", "%", "of", "overlap", "for", "training", "and", "testing", "."], ["During", "training", ",", "as", "in", "-LSB-", "6", "-RSB-", ",", "we", "apply", "data", "augmentation", "using", "random", "rotations", "in", "\\", "-LRB-", "-LSB-", "0^", "-LCB-", "\\circ", "-RCB-", ",", "360^", "-LCB-", "\\circ", "-RCB-", "-RRB-", "\\", "-RRB-", "around", "a", "random", "axis", ",", "and", "random", "scalings", "in", "\\", "-LRB-", "-LSB-", "0.8", ",", "1.2", "-RSB-", "\\", "-RRB-", "."], ["For", "the", "experiments", "on", "outdoor", "data", ",", "we", "use", "the", "KITTI", "odometry", "dataset", "-LSB-", "13", "-RSB-", "and", "follow", "the", "same", "protocol", "as", "-LSB-", "6", "-RSB-", ":", "GPS-IMU", "is", "used", "to", "create", "pairs", "of", "scans", "that", "are", "at", "least", "10m", "apart", ";", "the", "ground-truth", "transformation", "is", "computed", "using", "GPS", "followed", "by", "ICP", "."], ["Unlike", "in", "-LSB-", "6", "-RSB-", ",", "we", "do", "not", "use", "data", "augmentation", "during", "training", "on", "KITTI", "."], ["For", "synthetic", "data", ",", "we", "use", "ModelNet40", "-LSB-", "40", "-RSB-", "and", "follow", "the", "setup", "of", "-LSB-", "38", "-RSB-", "to", "simulate", "partial", "registration", "problems", "."]], "ner": [[], [[19, 19, "a"]], [], [[80, 81, "a"]], [[127, 129, "a"], [143, 143, "a"], [167, 167, "a"]], [], [[192, 192, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[19, 19, "a"]], [[57, 58, "v"]], [[110, 110, "v"], [112, 112, "v"]], [[127, 129, "a"], [143, 143, "a"], [155, 155, "v"]], [[184, 184, "a"]], [[192, 192, "a"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2110.01269-a0af81d4-c162-4843-95ba-c401807b2310", "sentences": [["All", "models", "are", "trained", "using", "AdamW", "-LSB-", "23", "-RSB-", ",", "with", "a", "weight", "decay", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "a", "batch", "size", "of", "1", ",", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "."], ["On", "3Dmatch", "and", "KITTI", ",", "the", "models", "are", "trained", "for", "100", "epochs", "with", "a", "learning", "rate", "divided", "by", "10", "after", "60", "and", "80", "epochs", "."], ["On", "ModelNet40", ",", "it", "is", "sufficient", "to", "train", "the", "models", "for", "10", "epochs", "-LRB-", "with", "a", "learning", "rate", "divided", "by", "10", "after", "6", "and", "8", "epochs", "-RRB-", "to", "observe", "convergence", "."], ["All", "results", "are", "reported", "using", "the", "models", "obtained", "at", "the", "last", "epoch", "."], ["The", "temperature", "\\", "-LRB-", "s\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "is", "set", "to", "\\", "-LRB-", "s=0.03\\", "-RRB-", "."]], "ner": [[[5, 5, "a"], [12, 13, "p"], [17, 17, "v"], [33, 33, "v"], [21, 22, "p"], [24, 24, "v"], [28, 29, "p"], [17, 17, "v"], [33, 33, "v"]], [[50, 51, "p"], [47, 47, "p"], [59, 59, "p"], [46, 46, "v"], [37, 39, "c"], [54, 54, "v"]], [[77, 78, "p"], [73, 73, "p"], [86, 86, "p"], [72, 72, "v"], [81, 81, "v"], [62, 62, "c"]], [], [[106, 106, "p"], [120, 120, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [12, 13, "p"], [17, 17, "v"], [21, 22, "p"], [24, 24, "v"], [28, 29, "p"], [33, 33, "v"]], [[37, 37, "a"], [39, 39, "a"], [46, 46, "v"], [47, 47, "p"], [50, 51, "p"], [54, 54, "v"], [56, 56, "v"], [58, 58, "v"]], [[62, 62, "a"], [72, 72, "v"], [73, 73, "p"], [77, 78, "p"], [81, 81, "v"], [83, 83, "v"], [85, 85, "v"], [86, 86, "p"]], [], [[106, 106, "p"], [109, 109, "p"], [120, 120, "v"]]], "predicted_relations": [[[12, 13, 5, 5, "USED-FOR"], [17, 17, 12, 13, "USED-FOR"], [21, 22, 5, 5, "USED-FOR"], [28, 29, 5, 5, "USED-FOR"], [17, 17, 12, 13, "USED-FOR"]], [[46, 46, 47, 47, "USED-FOR"], [46, 46, 59, 59, "USED-FOR"], [37, 39, 46, 46, "USED-FOR"], [37, 39, 54, 54, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"]], [[72, 72, 73, 73, "USED-FOR"], [72, 72, 86, 86, "USED-FOR"], [81, 81, 86, 86, "USED-FOR"], [62, 62, 72, 72, "USED-FOR"]], [], []]}
{"doc_key": "2106.06770-3f6aa108-ff34-423c-b8ea-72706264e638", "sentences": [["In", "terms", "of", "models", ",", "all", "our", "experiments", "use", "the", "same", "three", "models", ":", "A", "multilayer", "perceptron", "-LRB-", "MLP", "-RRB-", "with", "two", "hidden", "layers", "of", "100", "neurons", "each", ",", "the", "standard", "LeNet5", "from", "-LSB-", "27", "-RSB-", ",", "and", "the", "standard", "ResNet18", "-LSB-", "28", "-RSB-", "."], ["We", "used", "a", "single", "V100", "GPU", "to", "train", "all", "models", ",", "resulting", "in", "training", "times", "which", "oscillated", "between", "5", "minutes", "for", "the", "MLP", ",", "to", "around", "40", "minutes", "for", "the", "ResNet18", "."]], "ner": [[[22, 23, "p"], [25, 26, "v"], [31, 31, "a"], [40, 40, "a"]], [[75, 75, "a"]]], "relations": [[], []], "predicted_ner": [[[11, 11, "v"], [15, 19, "a"], [21, 21, "v"], [22, 23, "p"], [25, 25, "v"], [31, 31, "a"], [40, 40, "a"]], [[49, 49, "v"], [63, 63, "v"], [71, 71, "v"], [75, 75, "a"]]], "predicted_relations": [[[22, 23, 31, 31, "USED-FOR"], [22, 23, 40, 40, "USED-FOR"]], []]}
{"doc_key": "2109.01316-9b61176d-1416-4c50-9432-b7d8518abb4f", "sentences": [["Multi", "scale", ":", "3", "random", "variables", "-LRB-", "marked", "as", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "-RRB-", "are", "used", "to", "determine", "the", "resize", "scale", "."], ["\\", "-LRB-", "\\alpha", "\\", "-RRB-", "is", "first", "uniformly", "sampled", "from", "range", "-LRB-", "1.0,2.0", "-RRB-", ",", "and", "with", "a", "50", "%", "probability", "to", "take", "its", "reciprocal.\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "are", "both", "uniformly", "sampled", "from", "range", "-LRB-", "-0.2,0.2", "-RRB-", "."], ["An", "image", "of", "size", "-LRB-", "h", ",", "w", "-RRB-", "is", "then", "resized", "to", "-LRB-", "h", "*", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "*", "-LRB-", "1+\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "-RRB-", ",", "w", "*", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "*", "-LRB-", "1+\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "-RRB-", "-RRB-", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[3, 3, "v"], [11, 11, "p"]], [[37, 37, "p"], [53, 54, "v"]], [[98, 98, "p"], [114, 114, "p"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2109.01316-5de89c34-ffe4-4da3-a365-23039335c72e", "sentences": [["Dataset", "used", ",", "training", "schedule", "and", "loss", "function", "are", "different", "among", "2", "parts", "."], ["In", "the", "first", "part", ",", "we", "only", "use", "VSPW", "training", "set", "."], ["An", "AdamW", "optimizer", "is", "used", ",", "with", "betas=", "-LRB-", "0.9,0.999", "-RRB-", ".Weight", "decay", "of", "AdamW", "is", "set", "to", "0.02", "."], ["The", "model", "is", "trained", "for", "160k", "iterations", "in", "this", "part", "."], ["The", "learning", "rate", "follows", "a", "linear", "schedule", "and", "warm-up", "is", "applied", "."], ["To", "be", "specific", ",", "the", "learning", "rate", "of", "backbone", "grow", "from", "0", "to", "6e-6", "in", "the", "first", "1500", "iterations", ",", "and", "gradually", "reduce", "to", "0", "in", "the", "rest", "iterations", ",", "learning", "rate", "is", "always", "changing", "in", "a", "linear", "way.The", "learning", "rate", "of", "decoder", "-LRB-", "OCRNet", "-RRB-", "is", "always", "10", "times", "of", "the", "backbone", "'s", "learning", "rate", "."], ["A", "pixel-distribution-based", "loss", "function", "-LRB-", "described", "in", "Sec", "REF", "-RRB-", "is", "used", "."]], "ner": [[], [[22, 24, "a"]], [[27, 28, "a"], [35, 35, "v"], [35, 35, "v"], [44, 44, "v"]], [], [[58, 59, "p"], [62, 63, "a"]], [[74, 75, "p"], [99, 100, "p"], [108, 109, "p"], [123, 124, "p"], [82, 82, "v"], [77, 77, "c"], [121, 121, "c"], [80, 80, "v"], [93, 93, "v"], [77, 77, "c"], [121, 121, "c"], [117, 124, "v"]], [[127, 129, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "v"]], [[22, 22, "a"]], [[27, 27, "a"], [40, 40, "a"], [44, 44, "v"]], [[51, 51, "v"]], [[58, 59, "p"]], [[74, 75, "p"], [80, 80, "v"], [82, 82, "v"], [86, 86, "v"], [93, 93, "v"], [99, 100, "p"], [108, 109, "p"], [117, 117, "v"]], []], "predicted_relations": [[], [], [], [], [], [[82, 82, 74, 75, "USED-FOR"], [82, 82, 99, 100, "USED-FOR"], [121, 121, 117, 124, "USED-FOR"], [121, 121, 117, 124, "USED-FOR"], [117, 124, 123, 124, "USED-FOR"]], []]}
{"doc_key": "2109.01316-ab459543-98b7-47ed-a787-23b068889625", "sentences": [["In", "the", "second", "part", ",", "we", "aim", "to", "boost", "the", "model", "'s", "performance", "on", "some", "classes", "with", "low", "IoU", ",", "so", "we", "add", "COCO", "dataset", "for", "training", "."], ["Still", "with", "AdamW", "optimizer", ",", "The", "model", "is", "trained", "for", "40k", "iterations", "in", "this", "part", "."], ["Without", "warm-up", ",", "both", "backbone", "and", "decoder", "take", "the", "learning", "rate", "that", "reduce", "from", "1e-5", "to", "0", "in", "a", "linear", "way", "."], ["Further", "more", ",", "we", "deepen", "the", "model", ",", "with", "the", "depth", "of", "4", "stages", "added", "to", "-LRB-", "4,6,20,4", "-RRB-", "."], ["A", "confusion-matrix-based", "loss", "function", "-LRB-", "described", "in", "Sec", "REF", "-RRB-", "is", "used", "."]], "ner": [[[23, 24, "a"]], [[30, 31, "a"]], [[53, 54, "p"], [58, 60, "v"], [56, 57, "c"]], [], [[87, 89, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[23, 24, "a"]], [[30, 30, "a"], [38, 38, "v"]], [[53, 54, "p"], [58, 58, "v"], [60, 60, "v"]], [[78, 78, "v"]], []], "predicted_relations": [[], [], [[58, 60, 53, 54, "USED-FOR"], [56, 57, 58, 60, "USED-FOR"]], [], []]}
{"doc_key": "2109.01316-f7fea408-6155-4d59-8872-b1ce0017781c", "sentences": [["We", "get", "our", "baseline", "model", "VOLO-D5", "architecture", "and", "pretrained", "models", "from", "https", ":", "//github.com/sail-sg/volo", "."], ["VOLO-D5", "Model", "is", "trained", "with", "AdamW", "optimizer", "with", "default", "betas", "-LRB-", "0.95", ",", "0.999", "-RRB-", "and", "uses", "imagenet", "pretrained", "model.The", "initial", "learning", "rate", "is", "set", "to", "6e-5", "and", "decreased", "by", "polynomial", "decay", "."]], "ner": [[[5, 6, "a"]], [[20, 21, "a"], [24, 24, "p"], [45, 45, "v"], [28, 28, "v"], [35, 37, "p"], [46, 46, "p"], [32, 34, "a"]]], "relations": [[], []], "predicted_ner": [[[5, 5, "a"]], [[15, 16, "a"], [20, 20, "a"], [26, 26, "v"], [28, 28, "v"], [32, 32, "a"], [36, 37, "p"], [41, 41, "v"], [45, 46, "a"]]], "predicted_relations": [[], [[24, 24, 20, 21, "USED-FOR"], [28, 28, 24, 24, "USED-FOR"], [35, 37, 20, 21, "USED-FOR"], [35, 37, 32, 34, "USED-FOR"], [46, 46, 20, 21, "USED-FOR"], [46, 46, 32, 34, "USED-FOR"]]]}
{"doc_key": "2107.09840-4f180b79-ad2a-4c95-9d2a-d32c18a854a5", "sentences": [["Our", "model", "is", "based", "on", "the", "multilingual", "BERT", "-LRB-", "mBERT", "-RRB-", "-LSB-", "5", "-RSB-", "implemented", "in", "GluonNLP", "-LSB-", "9", "-RSB-", "."], ["As", "in", "previous", "work", "-LSB-", "5", "-RSB-", ",", "-LSB-", "39", "-RSB-", ",", "we", "tokenize", "the", "input", "sentences", "using", "WordPiece", ",", "concatenate", "them", ",", "feed", "the", "sequence", "to", "BERT", ",", "and", "use", "the", "hidden", "representation", "of", "the", "first", "token", "-LRB-", "\\", "-LRB-", "-LSB-", "CLS", "-RSB-", "\\", "-RRB-", "-RRB-", "for", "classification", "."], ["The", "final", "output", "is", "computed", "by", "applying", "a", "linear", "projection", "and", "a", "softmax", "layer", "to", "the", "hidden", "representation", "."], ["We", "use", "a", "dropout", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "on", "the", "final", "encoder", "layer", "and", "fix", "the", "embedding", "layer", "during", "fine-tuning", "."], ["Following", "-LSB-", "21", "-RSB-", ",", "we", "fine-tune", "mBERT", "by", "-LSB-", "1", "-RRB-", "-RSB-"]], "ner": [[], [[39, 39, "a"]], [[79, 80, "a"], [83, 84, "a"]], [[93, 94, "p"], [98, 98, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [6, 10, "a"], [16, 16, "a"]], [[48, 48, "a"]], [[83, 83, "a"]], [[93, 94, "p"], [98, 98, "v"]], [[120, 120, "a"]]], "predicted_relations": [[], [], [], [[98, 98, 93, 94, "USED-FOR"]], []]}
{"doc_key": "2110.10864-ffe8f100-4a5a-44d9-8a90-1d4801781806", "sentences": [["We", "use", "the", "SGD", "optimizer", "with", "Nesterov", "momentum", "-LSB-", "44", "-RSB-", "to", "fine-tune", "VGG-16", "and", "ResNet-38/56/164", ",", "where", "the", "momentum", "is", "set", "as", "0.9", "."], ["The", "fine-tuning", "process", "takes", "200", "epochs", "with", "a", "batch", "size", "of", "128", ",", "and", "the", "weight", "decay", "is", "set", "to", "be", "1e-3", "."], ["We", "augment", "the", "training", "samples", "with", "a", "standard", "data", "augmentation", "scheme", "-LSB-", "14", "-RSB-", "."], ["The", "learning", "rates", "of", "VGG-16", "and", "ResNet-38/56/164", "are", "started", "as", "0.006", "and", "0.05", ",", "and", "multiplied", "by", "0.28", "and", "0.14", "at", "40", "%", "and", "80", "%", "of", "the", "total", "number", "of", "epochs", "."], ["Our", "training", "codes", "are", "implemented", "in", "PyTorch", "."]], "ner": [[[3, 4, "a"], [7, 7, "p"], [19, 19, "p"], [23, 23, "v"], [13, 13, "a"], [15, 15, "a"]], [[40, 41, "a"], [46, 46, "v"]], [[56, 57, "a"]], [[67, 67, "a"], [73, 73, "v"], [69, 69, "a"], [75, 75, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [6, 7, "a"], [13, 13, "a"], [19, 19, "p"], [23, 23, "v"]], [[29, 29, "v"], [30, 30, "p"], [33, 34, "p"], [36, 36, "v"], [40, 41, "p"], [46, 46, "v"]], [], [[64, 65, "p"], [67, 67, "a"], [73, 73, "v"], [75, 75, "v"], [80, 80, "v"], [82, 82, "v"], [84, 85, "v"], [87, 88, "v"]], []], "predicted_relations": [[[7, 7, 3, 4, "USED-FOR"], [19, 19, 3, 4, "USED-FOR"], [19, 19, 13, 13, "USED-FOR"], [19, 19, 15, 15, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2112.03126-a3cd69b1-8494-486e-a79d-20694dd31570", "sentences": [["The", "ensemble", "of", "MLPs", "consists", "of", "10", "independent", "models", "."], ["Each", "MLP", "is", "trained", "for", "\\", "-LRB-", "-LCB-", "\\sim", "-RCB-", "4\\", "-RRB-", "epochs", "using", "the", "Adam", "optimizer", "-LSB-", "14", "-RSB-", "with", "\\", "-LRB-", "0.001\\", "-RRB-", "learning", "rate", "."], ["The", "batch", "size", "is", "64", "."], ["This", "setting", "is", "used", "for", "all", "methods", "and", "datasets", "."]], "ner": [[[1, 3, "a"], [6, 6, "v"]], [[11, 11, "a"], [22, 22, "p"], [20, 20, "v"], [25, 26, "p"], [35, 36, "p"], [33, 33, "v"]], [[39, 40, "p"], [42, 42, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [6, 6, "v"]], [[22, 22, "p"], [25, 25, "a"], [33, 33, "v"], [35, 36, "p"]], [[39, 40, "p"], [42, 42, "v"]], []], "predicted_relations": [[], [[22, 22, 11, 11, "USED-FOR"], [20, 20, 22, 22, "USED-FOR"], [25, 26, 11, 11, "USED-FOR"], [33, 33, 35, 36, "USED-FOR"]], [], []]}
{"doc_key": "2112.03126-e5948df2-f7f5-4357-83ec-ae931fba0c01", "sentences": [["MLP", "architecture", "."], ["We", "adopt", "the", "MLP", "architecture", "from", "-LSB-", "35", "-RSB-", "."], ["Specifically", ",", "we", "use", "MLPs", "with", "two", "hidden", "layers", "with", "ReLU", "nonlinearity", "and", "batch", "normalization", "."], ["The", "sizes", "of", "hidden", "layers", "are", "128", "and", "32", "for", "datasets", "with", "a", "number", "of", "classes", "less", "than", "30", ",", "and", "256", "and", "128", "for", "others", "."]], "ner": [[[0, 1, "a"]], [[6, 7, "a"]], [[20, 21, "p"], [23, 24, "p"], [26, 27, "p"]], [[32, 33, "p"], [35, 37, "v"], [39, 47, "c"], [50, 52, "v"], [54, 54, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [[17, 17, "a"], [19, 19, "v"], [20, 21, "p"], [23, 24, "a"], [26, 27, "a"]], [[35, 35, "v"], [37, 37, "v"], [47, 47, "v"], [50, 50, "v"], [52, 52, "v"]]], "predicted_relations": [[], [], [], [[39, 47, 50, 52, "USED-FOR"], [54, 54, 50, 52, "USED-FOR"]]]}
{"doc_key": "2112.02990-97e2fdd1-8018-45f5-b690-9ab1e5b21c88", "sentences": [["The", "3D", "and", "4D", "sparse", "U-Nets", "are", "implemented", "with", "MinkowskiEngine", "-LSB-", "4", "-RSB-", "using", "2cm", "voxel", "size", "for", "3D", "and", "5cm", "voxel", "size", "for", "4D", "."], ["For", "pre-training", "we", "consider", "only", "geometry", "information", "from", "the", "scene-object", "sequence", "augmentations", "."], ["We", "use", "an", "SGD", "optimizer", "with", "initial", "learning", "rate", "0.25", "and", "a", "batch-size", "of", "12", "."], ["The", "learning", "rate", "is", "decreased", "by", "a", "factor", "of", "0.99", "every", "1000", "steps", "."], ["We", "train", "for", "50K", "steps", "until", "convergence", "."]], "ner": [[[9, 9, "a"]], [], [[42, 43, "a"], [51, 51, "p"], [53, 53, "v"], [51, 51, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "v"], [3, 3, "v"], [5, 5, "a"], [9, 9, "a"], [14, 14, "v"], [20, 20, "v"]], [], [[42, 42, "a"], [46, 47, "p"], [48, 48, "v"], [51, 51, "p"], [53, 53, "v"]], [[56, 57, "p"], [64, 64, "v"], [66, 66, "v"]], [[72, 72, "v"]]], "predicted_relations": [[], [], [[51, 51, 42, 43, "USED-FOR"]], [], []]}
{"doc_key": "2104.11178-8d05ac6f-7160-4d8e-81ce-ee4d21357d59", "sentences": [["We", "pre-train", "VATT", "from", "scratch", "using", "Adam", "-LSB-", "45", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "1\\", "-LRB-", "e\\", "-RRB-", "-4", ",", "10k", "warmup", "steps", ",", "500k", "steps", "in", "total", ",", "a", "batch", "size", "of", "2048", ",", "and", "a", "quarter-period", "cosine", "schedule", "to", "anneal", "the", "learning", "rate", "from", "1\\", "-LRB-", "e\\", "-RRB-", "-4", "to", "5\\", "-LRB-", "e\\", "-RRB-", "-5", "."], ["In", "the", "exploration", "experiments", ",", "we", "use", "a", "batch", "size", "of", "512", "while", "keeping", "the", "rest", "of", "the", "training", "parameters", "the", "same", "."], ["Our", "pipeline", "is", "implemented", "in", "Tensorflow", "-LRB-", "v2.4", "-RRB-", ",", "and", "our", "models", "are", "trained", "for", "3", "days", "using", "256", "TPUs", "-LRB-", "v3", "-RRB-", "."]], "ner": [[[6, 6, "a"], [12, 14, "p"], [16, 20, "v"], [48, 52, "v"], [23, 24, "p"], [22, 22, "v"], [26, 26, "v"], [32, 33, "p"], [35, 35, "v"], [39, 41, "p"], [43, 58, "v"]], [[68, 69, "p"]], [[88, 88, "a"], [103, 103, "a"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "a"], [13, 14, "p"], [18, 18, "p"], [22, 22, "v"], [23, 24, "p"], [26, 26, "v"], [32, 33, "p"], [35, 35, "v"], [45, 46, "p"], [50, 50, "p"]], [[68, 69, "p"], [71, 71, "v"]], [[84, 84, "a"], [99, 99, "v"], [102, 102, "v"]]], "predicted_relations": [[[12, 14, 6, 6, "USED-FOR"], [16, 20, 12, 14, "USED-FOR"], [48, 52, 39, 41, "USED-FOR"], [23, 24, 6, 6, "USED-FOR"], [22, 22, 12, 14, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [26, 26, 23, 24, "USED-FOR"], [32, 33, 6, 6, "USED-FOR"], [35, 35, 23, 24, "USED-FOR"], [35, 35, 32, 33, "USED-FOR"], [39, 41, 6, 6, "USED-FOR"], [43, 58, 32, 33, "USED-FOR"], [43, 58, 39, 41, "USED-FOR"]], [], []]}
{"doc_key": "2104.01148-847c2631-0d8f-4329-abf9-dfe7db1f08c0", "sentences": [["We", "report", "the", "hyperparameters", "used", "for", "ObSuRF", "in", "tab", ":", "hyperparams", "."], ["In", "addition", "to", "the", "architectural", "parameters", "introduced", "above", ",", "we", "note", "the", "importance", "of", "the", "standard", "deviation", "of", "the", "color", "distribution", "\\", "-LRB-", "\\sigma", "_C\\", "-RRB-", "-LRB-", "eq", ":", "colordist", "-RRB-", "for", "tuning", "the", "relative", "importance", "of", "color", "compared", "to", "depth", "."], ["We", "also", "report", "how", "we", "ramp", "up", "the", "overlap", "loss", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_O\\", "-RRB-", ":", "From", "the", "beginning", "of", "training", "to", "the", "iteration", "at", "which", "we", "start", "the", "ramp", "up", ",", "we", "set", "\\", "-LRB-", "k_O", "=", "0\\", "-RRB-", "."], ["During", "the", "ramp", "up", "period", ",", "we", "linearly", "increase", "\\", "-LRB-", "k_O\\", "-RRB-", "until", "it", "reaches", "the", "maximum", "value", "\\", "-LRB-", "\\hat", "-LCB-", "k", "-RCB-", "_O\\", "-RRB-", "."], ["We", "train", "using", "the", "Adam", "optimizer", "with", "default", "parameters", ",", "and", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "4e-4\\", "-RRB-", "."], ["We", "reduce", "the", "learning", "rate", "by", "a", "factor", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "every", "100k", "iterations", "."], ["Finally", ",", "we", "note", "that", "for", "the", "3D", "models", ",", "we", "used", "gradient", "norm", "clipping", "during", "training", ",", "i.e.", ",", "at", "each", "iteration", ",", "we", "determine", "the", "L2", "norm", "of", "the", "gradients", "of", "our", "model", "as", "if", "they", "would", "form", "a", "single", "vector", "."], ["If", "this", "norm", "exceeds", "1", ",", "we", "divide", "all", "gradients", "by", "that", "norm", "."], ["When", "training", "on", "MultiShapeNet", ",", "we", "find", "that", "very", "rare", ",", "extremely", "strong", "gradients", "can", "derail", "training", "."], ["We", "therefore", "skip", "all", "training", "steps", "with", "norm", "greater", "than", "1000", "entirely", "."]], "ner": [[[6, 6, "a"]], [[39, 41, "c"]], [[62, 63, "p"], [93, 93, "p"], [95, 95, "v"], [73, 87, "c"]], [[109, 109, "p"], [115, 116, "c"]], [[130, 131, "a"], [138, 140, "p"], [144, 144, "v"]], [[158, 158, "v"], [158, 158, "v"]], [[176, 178, "p"]], [[212, 212, "v"], [208, 212, "c"]], [], [[250, 250, "v"], [247, 250, "c"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [10, 10, "a"]], [], [[62, 63, "a"], [93, 93, "p"], [93, 95, "v"]], [], [[130, 130, "a"], [139, 140, "p"], [144, 144, "v"]], [[150, 151, "p"], [158, 158, "v"], [161, 161, "v"]], [[176, 178, "a"]], [[212, 212, "v"]], [[225, 225, "a"]], [[250, 250, "v"]]], "predicted_relations": [[], [], [[95, 95, 93, 93, "USED-FOR"], [73, 87, 95, 95, "USED-FOR"]], [], [[138, 140, 130, 131, "USED-FOR"], [144, 144, 138, 140, "USED-FOR"]], [], [], [[208, 212, 212, 212, "USED-FOR"]], [], [[247, 250, 250, 250, "USED-FOR"]]]}
{"doc_key": "2104.01037-7e7b6448-7771-40cf-99a3-615405b7c6e7", "sentences": [["We", "initialize", "the", "Transformer", "with", "CamemBERT", "-LSB-", "18", "-RSB-", "weights", "for", "DEFT", "and", "BioBERT", "-LSB-", "14", "-RSB-", "for", "GENIA", "unless", "mentioned", "otherwise", ",", "and", "the", "remaining", "parameters", "using", "the", "method", "of", "-LSB-", "5", "-RSB-", "."], ["Dropout", "-LSB-", "27", "-RSB-", "is", "applied", "with", "a", "probability", "of", "0.25", "everywhere", "."], ["We", "optimize", "the", "parameters", "by", "backpropagation", "with", "Adam", "-LSB-", "11", "-RSB-", "without", "weight", "decay", ",", "over", "40", "epochs", "for", "DEFT", "and", "10", "epochs", "for", "GENIA", "."], ["We", "use", "two", "learning", "steps", ":", "one", "for", "the", "Transformer", "weights", ",", "initialized", "at", "\\", "-LRB-", "4\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "one", "for", "the", "rest", "of", "the", "model", ",", "initialized", "at", "\\", "-LRB-", "9\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["The", "learning", "rate", "follows", "a", "linear", "decay", "schedule", "with", "a", "warmup", "for", "10", "%", "of", "the", "steps", "."], ["We", "insert", "the", "tag", "embeddings", "in", "the", "Transformers", "at", "layer", "\\", "-LRB-", "L_", "-LCB-", "tag", "-RCB-", "=", "6\\", "-RRB-", "for", "BERT", "with", "12", "layers", "and", "19", "for", "BERT", "with", "24", "layers", "."], ["On", "an", "Nvidia", "K80", "GPU", "graphics", "card", ",", "learning", "on", "100", "documents", "takes", "about", "20", "minutes", "."]], "ner": [[[5, 5, "a"], [13, 13, "a"]], [[35, 35, "a"], [43, 43, "p"], [45, 45, "v"]], [[55, 55, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [11, 11, "a"], [13, 13, "a"], [18, 18, "a"]], [[35, 35, "a"], [45, 45, "v"]], [[53, 53, "a"], [55, 55, "a"], [60, 61, "p"], [64, 64, "v"], [65, 65, "p"], [67, 67, "a"], [69, 69, "v"], [70, 70, "p"], [72, 72, "a"]], [[76, 76, "v"], [77, 78, "p"], [80, 80, "v"], [91, 93, "v"], [99, 99, "v"], [112, 114, "v"]], [[120, 121, "p"], [131, 132, "v"]], [[149, 152, "p"], [154, 154, "v"], [157, 157, "a"], [159, 159, "v"], [160, 160, "p"], [162, 162, "v"], [163, 164, "c"], [164, 164, "a"], [166, 166, "v"], [167, 167, "p"]], [[179, 179, "v"], [183, 183, "v"]]], "predicted_relations": [[], [[43, 43, 35, 35, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2109.04014-4568e749-ef7a-4548-b787-77b86dc888d5", "sentences": [["Our", "neural", "retrievers", "were", "trained", "on", "eight", "Nvidia", "RTX8000", "GPUs", ",", "where", "we", "set", "the", "training", "epoch", "to", "be", "30", ",", "learning", "rate", "-LRB-", "lr", "-RRB-", "be", "1e-5", ",", "batch", "size", "-LRB-", "bs", "-RRB-", "be", "64", ",", "gradient", "accumulation", "step", "-LRB-", "gas", "-RRB-", "be", "4", "."], ["All", "the", "readers", "were", "performed", "at", "four", "GTX1080", "and", "V100", "NVIDIA", "GPUs", "."], ["For", "both", "Image-DPR", "and", "Caption-DPR", ",", "In", "CReader", ",", "we", "set", "the", "training", "epoch", "as", "3", ",", "lr", "as", "2e-5", ",", "and", "batch-size", "as", "16", "."], ["In", "EReader", ",", "we", "set", "the", "training", "epoch", "as", "3", ",", "lr", "as", "1e-5", ",", "batch-size", "as", "4", ",", "and", "gradient", "accumulation", "as", "4", "."]], "ner": [[[7, 9, "a"], [15, 16, "a"], [15, 16, "p"], [44, 44, "v"], [21, 22, "p"], [29, 30, "p"], [37, 39, "p"]], [], [[71, 72, "a"], [71, 72, "p"], [83, 83, "v"]], [[91, 92, "a"], [91, 92, "p"], [102, 102, "v"], [108, 108, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"], [6, 6, "v"], [15, 16, "p"], [19, 19, "v"], [21, 22, "p"], [27, 27, "v"], [29, 30, "p"], [35, 35, "v"], [44, 44, "v"]], [[52, 52, "v"], [53, 53, "a"], [55, 55, "v"]], [[61, 61, "a"], [63, 63, "a"], [66, 66, "a"], [71, 72, "p"], [74, 74, "v"], [76, 76, "p"], [78, 78, "v"], [81, 81, "p"], [83, 83, "v"]], [[86, 86, "a"], [91, 92, "p"], [94, 94, "v"], [96, 96, "p"], [98, 98, "v"], [100, 100, "p"], [102, 102, "v"], [105, 106, "c"], [108, 108, "v"]]], "predicted_relations": [[[15, 16, 15, 16, "USED-FOR"], [21, 22, 7, 9, "USED-FOR"], [21, 22, 15, 16, "USED-FOR"], [29, 30, 7, 9, "USED-FOR"], [29, 30, 15, 16, "USED-FOR"]], [], [[71, 72, 71, 72, "USED-FOR"], [83, 83, 71, 72, "USED-FOR"]], [[91, 92, 91, 92, "USED-FOR"], [102, 102, 91, 92, "USED-FOR"], [108, 108, 91, 92, "USED-FOR"]]]}
{"doc_key": "2109.04002-833b1226-9e77-4061-86e7-ec64015e01be", "sentences": [["We", "use", "the", "Adam", "optimizer", "-LSB-", "13", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1", "=", "\\text", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "\\text", "-LCB-", "0.98", "-RCB-", "\\", "-RRB-", "to", "optimize", "the", "model", "."], ["Further", ",", "the", "same", "learning", "rate", "schedule", "as", "-LSB-", "31", "-RSB-", "is", "used", ",", "i.e.", ",", "linearly", "increase", "the", "learning", "rate", "for", "4000", "steps", "to", "2e-4", "and", "decay", "proportionally", "to", "the", "inverse", "square", "root", "of", "the", "step", "number", "."], ["We", "accumulate", "the", "batch", "size", "to", "9,600", "and", "adopt", "half-precision", "training", "implemented", "by", "apexhttps", ":", "//github.com/NVIDIA/apex", "for", "faster", "convergence", "-LSB-", "23", "-RSB-", "."], ["For", "regularization", ",", "we", "also", "use", "a", "dropout", "-LSB-", "28", "-RSB-", "\\", "-LRB-", "p", "=", "\\text", "-LCB-", "0.3", "-RCB-", "\\", "-RRB-", "and", "a", "label", "smoothing", "-LSB-", "30", "-RSB-", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "ls", "-RCB-", "=", "\\text", "-LCB-", "0.1", "-RCB-", "\\", "-RRB-", "."], ["As", "for", "our", "approach", ",", "we", "sample", "256", "candidates", "from", "each", "languages", "'", "development", "corpora", "every", "100", "steps", "to", "calculate", "the", "Self-evaluated", "Competence", "\\", "-LRB-", "c\\", "-RRB-", "for", "each", "language", "and", "HRLs-evaluated", "Competence", "\\", "-LRB-", "\\hat", "-LCB-", "c", "-RCB-", "\\", "-RRB-", "for", "each", "LRL", "."]], "ner": [[[3, 4, "a"], [16, 16, "v"], [28, 28, "v"]], [[41, 43, "a"], [60, 60, "p"], [59, 59, "v"], [41, 42, "p"], [56, 57, "p"], [62, 62, "v"]], [[85, 86, "a"]], [[106, 106, "a"], [112, 112, "p"], [116, 116, "v"], [122, 123, "a"], [137, 137, "v"]], [[159, 159, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [16, 16, "v"], [28, 28, "v"]], [[41, 42, "p"], [56, 57, "p"], [59, 59, "v"], [62, 62, "v"]], [[79, 80, "p"], [82, 82, "v"], [85, 86, "c"]], [[100, 100, "a"], [106, 106, "a"], [122, 123, "a"], [129, 133, "a"]], [[145, 145, "a"], [149, 149, "v"], [158, 158, "v"]]], "predicted_relations": [[], [[59, 59, 60, 60, "USED-FOR"], [59, 59, 56, 57, "USED-FOR"], [62, 62, 60, 60, "USED-FOR"], [62, 62, 56, 57, "USED-FOR"]], [], [[112, 112, 106, 106, "USED-FOR"]], []]}
{"doc_key": "2102.11055-a6eb470f-0d57-4e9b-a3f6-c83f13d7b4ad", "sentences": [["Exploration", "."], ["The", "training", "process", "starts", "after", "some", "number", "of", "time", "steps", "-LRB-", "1000", "steps", "for", "Reacher-v2", "and", "10000", "steps", "for", "the", "other", "environments", "-RRB-", ",", "and", "we", "use", "a", "purely", "exploratory", "policy", "in", "this", "initial", "phase", "to", "collect", "samples", "for", "the", "replay", "buffer", "for", "all", "the", "algorithms", "."], ["During", "training", ",", "Gaussian", "noise", "is", "added", "to", "each", "action", "for", "exploration", "for", "the", "neural", "cases", "."], ["In", "the", "tabular", "case", ",", "we", "use", "the", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "-greedy", "policy", "as", "the", "behavior", "policy", "instead", "."]], "ner": [[], [], [[52, 53, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[13, 13, "v"], [16, 16, "a"], [18, 18, "v"]], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2107.06916-f888224b-1ae9-4a43-af56-993d9a05f536", "sentences": [["We", "train", "our", "compact", "CNN", "models", "from", "scratch", "using", "the", "SGD", "optimizer", "with", "a", "momentum", "of", "0.9", "and", "the", "batch", "size", "is", "set", "to", "256", "."], ["On", "CIFAR-10", ",", "we", "train", "the", "compact", "CNNs", "for", "a", "total", "of", "300", "epochs", "and", "the", "weight", "decay", "is", "set", "to", "5\\", "-LRB-", "\\times", "\\", "-RRB-", "10\\", "-LRB-", "^", "-LCB-", "\\text", "-LCB-", "-4", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["The", "learning", "rate", "is", "initially", "set", "to", "0.1", ",", "and", "then", "divided", "by", "10", "at", "the", "training", "points", "of", "150", "and", "225", "epochs", "."], ["On", "ILSVRC-2012", ",", "90", "epochs", "are", "given", "to", "train", "compact", "ResNet-50", "with", "the", "weight", "decay", "set", "to", "1\\", "-LRB-", "\\times", "\\", "-RRB-", "10\\", "-LRB-", "^\\text", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "the", "initial", "learning", "rate", "is", "set", "to", "0.1", ",", "which", "is", "then", "multiplied", "by", "0.1", "at", "the", "points", "of", "30", "and", "60", "training", "epochs", "."], ["Besides", ",", "following", "-LSB-", "38", "-RSB-", ",", "-LSB-", "36", "-RSB-", ",", "-LSB-", "29", "-RSB-", ",", "we", "also", "consider", "the", "cosine", "scheduler", "-LSB-", "60", "-RSB-", "to", "adjust", "the", "learning", "rate", "for", "ResNet-50", "with", "the", "weight", "decay", "set", "to", "1\\", "-LRB-", "\\times", "\\", "-RRB-", "10\\", "-LRB-", "^\\text", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "1\\", "-LRB-", "\\times", "\\", "-RRB-", "10\\", "-LRB-", "^\\text", "-LCB-", "-2", "-RCB-", "\\", "-RRB-", "for", "ResNet-50", "."]], "ner": [[[10, 11, "a"], [14, 14, "p"], [16, 16, "v"], [19, 20, "p"], [24, 24, "v"]], [[42, 43, "a"], [27, 27, "p"], [27, 27, "p"]], [[65, 66, "a"], [71, 71, "v"], [75, 86, "c"], [71, 71, "v"]], [[101, 102, "a"], [89, 89, "p"], [122, 123, "a"], [127, 127, "v"], [134, 134, "v"], [89, 89, "p"], [127, 127, "v"], [134, 134, "v"], [132, 143, "c"]], [[178, 179, "a"], [172, 173, "a"]], [[198, 199, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [10, 10, "a"], [16, 16, "v"], [19, 20, "p"], [24, 24, "v"]], [[27, 27, "a"], [33, 33, "a"], [38, 38, "v"], [42, 43, "p"]], [[65, 66, "p"], [71, 71, "v"], [77, 77, "v"], [83, 83, "v"], [85, 85, "v"], [86, 86, "p"]], [[89, 89, "a"], [91, 91, "v"], [98, 98, "a"], [101, 102, "p"], [122, 123, "p"], [127, 127, "v"], [134, 134, "v"], [139, 139, "v"], [141, 141, "v"], [142, 143, "p"]], [[164, 165, "a"], [172, 173, "p"], [175, 175, "a"], [178, 179, "p"]], [[198, 199, "p"], [217, 217, "a"]]], "predicted_relations": [[[19, 20, 10, 11, "USED-FOR"]], [], [[75, 86, 71, 71, "USED-FOR"], [75, 86, 71, 71, "USED-FOR"]], [[89, 89, 101, 102, "USED-FOR"], [89, 89, 101, 102, "USED-FOR"], [132, 143, 127, 127, "USED-FOR"], [132, 143, 134, 134, "USED-FOR"], [132, 143, 127, 127, "USED-FOR"], [132, 143, 134, 134, "USED-FOR"]], [], []]}
{"doc_key": "2110.04291-ab5cc68d-4c85-4c2e-868f-73c7bb3396f4", "sentences": [["All", "the", "models", "are", "implemented", "in", "Pytorch", "-LSB-", "33", "-RSB-", "."], ["We", "use", "the", "HuggingFace", "library", "-LSB-", "44", "-RSB-", "to", "train", "BERT", "and", "ALBERT", "models", "."], ["Both", "models", "are", "initialized", "with", "the", "weights", "of", "their", "``", "base", "''", "versions", "for", "fair", "comparison", "."], ["The", "transformer", "network", "in", "GlobalPair", "model", "is", "made", "up", "of", "2", "transformer", "blocks", ",", "with", "hidden", "size", "of", "768", ",", "feed-forward", "intermediate", "layer", "size", "3072", "and", "12", "attention", "heads", "."], ["We", "use", "Adam", "optimizer", "and", "a", "batch", "size", "of", "2", "for", "all", "three", "datasets", "."], ["For", "SIND", "and", "ROCStories", ",", "learning", "rate", "used", "is", "\\", "-LRB-", "5", "*", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "and", "decay", "factor", "is", "\\", "-LRB-", "0.2\\", "-RRB-", "per", "epoch", "."], ["For", "ACL", ",", "we", "found", "the", "training", "to", "be", "quite", "stochastic", "but", "the", "final", "results", "reported", "are", "for", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "1", "*", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "decayed", "to", "\\", "-LRB-", "1", "*", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "after", "1st", "epoch", "and", "constant", "afterwards", "."], ["We", "use", "a", "beam", "of", "size", "64", "."]], "ner": [[[6, 6, "a"]], [[14, 15, "a"], [21, 21, "a"], [23, 23, "a"]], [], [[47, 48, "a"], [58, 59, "p"], [61, 61, "v"], [67, 67, "v"], [70, 71, "p"], [69, 69, "v"], [53, 53, "v"]], [[75, 76, "a"], [79, 80, "p"], [82, 82, "v"]], [[113, 113, "v"], [93, 94, "a"], [89, 91, "p"], [108, 109, "a"], [89, 91, "p"], [113, 113, "v"], [113, 113, "v"]], [[138, 139, "a"], [119, 119, "p"], [119, 119, "p"]], [[177, 177, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[21, 21, "a"], [23, 23, "a"]], [], [[44, 45, "a"], [47, 48, "a"], [53, 53, "v"], [61, 61, "v"], [63, 63, "a"], [67, 67, "v"], [69, 69, "v"]], [[75, 75, "a"], [82, 82, "v"], [83, 86, "c"], [85, 85, "v"]], [[89, 89, "a"], [91, 91, "a"], [93, 94, "p"], [99, 104, "v"], [108, 109, "p"], [113, 113, "v"]], [[119, 119, "a"], [138, 139, "p"], [143, 148, "v"], [156, 161, "v"]], [[177, 177, "v"]]], "predicted_relations": [[], [], [], [[58, 59, 47, 48, "USED-FOR"], [61, 61, 58, 59, "USED-FOR"], [70, 71, 47, 48, "USED-FOR"], [69, 69, 70, 71, "USED-FOR"], [53, 53, 58, 59, "USED-FOR"]], [], [[89, 91, 93, 94, "USED-FOR"], [89, 91, 93, 94, "USED-FOR"]], [[119, 119, 138, 139, "USED-FOR"], [119, 119, 138, 139, "USED-FOR"]], []]}
{"doc_key": "2109.04843-54479da8-2f17-4dad-b048-8c4e2b540ee7", "sentences": [["We", "implemented", "the", "model", "using", "PyTorch", "1.2", "and", "trained", "it", "on", "four", "NVIDIA", "Tesla", "P100", "GPUs", "."], ["Our", "batches", "contained", "eight", "clips", ",", "each", "comprising", "six", "frames", "at", "520\u00d7520", "resolution", "."], ["We", "used", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "0.001", ",", "decreasing", "the", "rate", "by", "a", "factor", "of", "0.7", "after", "each", "epoch", "."], ["Our", "test", "models", "generally", "converged", "after", "seven", "epochs", ",", "or", "about", "9.5", "hours", "of", "training", "."]], "ner": [[[5, 5, "a"], [12, 15, "a"]], [], [[34, 35, "a"], [38, 39, "p"], [41, 41, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [11, 11, "v"]], [[20, 20, "v"], [25, 25, "v"], [28, 28, "v"]], [[34, 34, "a"], [38, 39, "p"], [41, 41, "v"], [50, 50, "v"]], [[61, 61, "v"], [62, 62, "p"], [66, 66, "v"]]], "predicted_relations": [[], [], [[38, 39, 34, 35, "USED-FOR"]], []]}
{"doc_key": "2109.05872-7f68ed23-5209-4ebf-a26e-0b6261114fee", "sentences": [["By", "default", ",", "we", "assume", "there", "are", "\\", "-LRB-", "n", "=", "50\\", "-RRB-", "clients", "in", "total", "for", "each", "task", ",", "20", "%", "of", "which", "are", "Byzantine", "nodes", "with", "fixed", "attack", "method", ",", "and", "the", "training", "data", "are", "IID", "among", "clients", "."], ["To", "verify", "the", "resilience", "and", "robustness", ",", "we", "will", "also", "evaluate", "the", "impact", "of", "different", "fractions", "of", "malicious", "clients", "for", "different", "attacks", "and", "defenses", "."], ["Furthermore", ",", "our", "approach", "will", "also", "be", "evaluated", "in", "non-IID", "settings", "."], ["In", "all", "experiments", ",", "we", "set", "the", "lower", "and", "upper", "bounds", "of", "gradient", "norm", "as", "\\", "-LRB-", "L", "=", "0.1\\", "-RRB-", "and", "\\", "-LRB-", "R", "=", "3.0\\", "-RRB-", ",", "and", "randomly", "select", "10", "%", "of", "coordinates", "to", "compute", "sign", "statistics", "in", "our", "SignGuard-based", "algorithms", "."], ["Each", "training", "procedure", "is", "run", "for", "60", "epochs", "for", "MNIST/Fashion-MNIST/AG-News", "and", "160", "epochs", "for", "CIFAR-10", ",", "and", "local", "iteration", "is", "always", "set", "to", "1", "."], ["We", "employ", "momentum", "in", "PS", "side", "and", "the", "momentum", "parameter", "is", "set", "to", "0.9", ",", "and", "weight", "decay", "is", "set", "to", "0.0005", "."], ["More", "details", "on", "some", "key", "hyper-parameters", "are", "described", "in", "Appendix", "REF"]], "ner": [[], [], [], [[97, 97, "v"], [104, 104, "v"]], [], [[161, 161, "v"], [169, 169, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "v"], [20, 21, "v"], [25, 26, "a"]], [], [[69, 69, "a"]], [[90, 91, "p"], [95, 95, "p"], [97, 97, "v"], [104, 104, "v"], [110, 111, "v"], [120, 120, "a"]], [[129, 129, "v"], [130, 130, "p"], [134, 134, "v"], [135, 135, "p"], [137, 137, "a"], [146, 146, "v"]], [[156, 157, "p"], [161, 161, "v"], [164, 165, "p"], [169, 169, "v"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2106.02637-7af2d347-3a2f-44f5-b320-5f628db45f19", "sentences": [["Architecture", "."], ["Through", "the", "introduction", "of", "object", "proposals", ",", "the", "architectural", "discrepancy", "is", "reduced", "between", "pretraining", "and", "downstream", "detection", "finetuning", "."], ["Mask", "R-CNN", "-LSB-", "16", "-RSB-", "is", "a", "commonly", "adopted", "framework", "to", "evaluate", "transfer", "performance", "."], ["To", "demonstrate", "the", "extensibility", "and", "flexibility", "of", "SoCo", ",", "we", "provide", "details", "of", "SoCo", "alignment", "for", "the", "detection", "architectures", "R50-FPN", "and", "R50-C4", "."], ["SoCo-R50-FPN", ":", "ResNet-50", "-LSB-", "31", "-RSB-", "with", "FPN", "-LSB-", "14", "-RSB-", "is", "used", "as", "the", "image-level", "feature", "encoder", "."], ["RoIAlign", "-LSB-", "16", "-RSB-", "is", "then", "used", "to", "extract", "RoI", "features", "on", "feature", "maps", "\\", "-LRB-", "\\lbrace", "P_2", ",", "P_3", ",", "P_4", ",", "P_5\\rbrace", "\\", "-RRB-", "with", "a", "stride", "of", "\\", "-LRB-", "\\lbrace", "4", ",", "8", ",", "16", ",", "32\\rbrace", "\\", "-RRB-", "."], ["According", "to", "the", "image", "areas", "of", "object", "proposals", ",", "each", "RoI", "feature", "is", "then", "transformed", "to", "an", "object-level", "representation", "by", "the", "head", "network", "as", "in", "Mask", "R-CNN", "."], ["SoCo-R50-C4", ":", "on", "the", "standard", "ResNet-50", "architecture", ",", "we", "insert", "the", "RoI", "operation", "on", "the", "output", "of", "the", "4-th", "residual", "block", "."], ["The", "entire", "5-th", "residual", "block", "is", "treated", "as", "the", "head", "network", "to", "encode", "object-level", "features", "."], ["Both", "the", "projection", "network", "and", "prediction", "network", "are", "2-layer", "MLPs", "which", "consist", "of", "a", "linear", "layer", "with", "output", "size", "4096", "followed", "by", "batch", "normalization", "-LSB-", "32", "-RSB-", ",", "rectified", "linear", "units", "-LRB-", "ReLU", "-RRB-", "-LSB-", "33", "-RSB-", ",", "and", "a", "final", "linear", "layer", "with", "output", "dimension", "256", "."]], "ner": [[], [], [[21, 22, "a"]], [[55, 55, "a"]], [[61, 61, "a"], [59, 59, "a"], [66, 66, "a"]], [[78, 78, "a"]], [[146, 147, "a"]], [[154, 154, "a"]], [], [[209, 210, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[22, 22, "a"]], [[43, 43, "a"], [55, 55, "a"], [57, 57, "a"]], [[59, 59, "a"], [61, 61, "a"], [66, 66, "a"]], [], [[146, 147, "a"]], [[149, 149, "a"], [154, 154, "a"], [167, 167, "v"]], [[173, 173, "v"]], [[206, 206, "v"], [215, 220, "a"], [233, 233, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2106.02637-8b3e39d1-0f2d-4ac4-b8ef-6178d0691074", "sentences": [["Dataset", "."], ["We", "adopt", "the", "widely", "used", "ImageNet", "-LSB-", "0", "-RSB-", "which", "consists", "of", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "1.28", "million", "images", "for", "self-supervised", "pretraining", "."]], "ner": [[], [[7, 7, "a"]]], "relations": [[], []], "predicted_ner": [[], [[7, 7, "a"], [19, 19, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.02637-99a06347-7e2e-4a1f-b6f1-b138cbd3a6cc", "sentences": [["Optimization", "."], ["We", "use", "a", "100-epoch", "training", "schedule", "in", "all", "the", "ablation", "studies", "and", "report", "the", "results", "of", "100-epochs", "and", "400-epochs", "in", "the", "comparisons", "with", "state-of-the-art", "methods", "."], ["We", "use", "the", "LARS", "optimizer", "-LSB-", "34", "-RSB-", "with", "a", "cosine", "decay", "learning", "rate", "schedule", "-LSB-", "35", "-RSB-", "and", "a", "warm-up", "period", "of", "10", "epochs", "."], ["The", "base", "learning", "rate", "\\", "-LRB-", "lr_", "-LCB-", "\\text", "-LCB-", "base", "-RCB-", "-RCB-", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "1.0\\", "-RRB-", "and", "is", "scaled", "linearly", "-LSB-", "36", "-RSB-", "with", "the", "batch", "size", "-LRB-", "\\", "-LRB-", "lr\\", "-RRB-", "=", "\\", "-LRB-", "lr_", "-LCB-", "\\text", "-LCB-", "base", "-RCB-", "-RCB-", "\\times", "\\", "-RRB-", "BatchSize\\", "-LRB-", "/256\\", "-RRB-", "-RRB-", "."], ["The", "weight", "decay", "is", "set", "to", "\\", "-LRB-", "1.0", "\\times", "\\text", "-LCB-", "e", "-RCB-", "^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["The", "total", "batch", "size", "is", "set", "to", "2048", "over", "16", "Nvidia", "V100", "GPUs", "."], ["For", "the", "update", "of", "the", "target", "network", ",", "following", "-LSB-", "2", "-RSB-", ",", "the", "momentum", "coefficient", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "starts", "from", "\\", "-LRB-", "0.99\\", "-RRB-", "and", "is", "increased", "to", "1", "during", "training", "."], ["Synchronized", "batch", "normalization", "is", "enabled", "."]], "ner": [[], [[18, 18, "p"], [20, 20, "p"]], [[31, 32, "a"], [38, 42, "a"], [48, 49, "a"], [52, 52, "p"], [51, 51, "v"]], [[55, 57, "p"], [74, 74, "v"]], [[119, 119, "v"], [112, 113, "p"]], [], [[160, 161, "p"], [171, 171, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[5, 5, "v"], [6, 7, "p"]], [[31, 31, "a"], [38, 39, "a"], [51, 51, "v"], [52, 52, "p"]], [[60, 66, "p"], [74, 74, "v"], [85, 86, "p"], [107, 107, "v"]], [[112, 113, "p"], [119, 119, "v"]], [[134, 135, "p"], [139, 139, "v"], [141, 141, "v"]], [[160, 161, "p"], [164, 164, "p"], [171, 171, "v"], [177, 177, "v"], [178, 179, "c"]], [[182, 183, "a"]]], "predicted_relations": [[], [], [[52, 52, 31, 32, "USED-FOR"], [52, 52, 38, 42, "USED-FOR"], [52, 52, 48, 49, "USED-FOR"], [51, 51, 52, 52, "USED-FOR"]], [], [[119, 119, 112, 113, "USED-FOR"]], [], [[171, 171, 160, 161, "USED-FOR"]], []]}
{"doc_key": "2108.07887-7a857794-7541-4038-9b67-8b35045699b1", "sentences": [["We", "base", "our", "training", "setup", "on", "CHER", "-LSB-", "7", "-RSB-", "."], ["We", "train", "all", "agents", "on", "minibatches", "of", "size", "\\", "-LRB-", "k", "=", "64\\", "-RRB-", "for", "50", "epochs", "using", "MPI", "for", "parallelisation", "over", "16", "CPU", "cores", ";", "each", "epoch", "consists", "of", "1600", "-LRB-", "\\", "-LRB-", "16", "\\times", "100\\", "-RRB-", "-RRB-", "episodes", ",", "with", "evaluation", "over", "160", "-LRB-", "\\", "-LRB-", "16", "\\times", "10\\", "-RRB-", "-RRB-", "episodes", "at", "the", "end", "of", "each", "epoch", "."], ["Remaining", "hyperparameters", "for", "the", "baselines", "are", "taken", "from", "the", "original", "work", "-LSB-", "0", "-RSB-", ",", "-LSB-", "7", "-RSB-", ",", "-LSB-", "30", "-RSB-", "."], ["Our", "method", ",", "DTGSH", ",", "uses", "partial", "trajectories", "of", "length", "\\", "-LRB-", "b", "=", "2\\", "-RRB-", "and", "\\", "-LRB-", "m", "=", "100\\", "-RRB-", "as", "the", "number", "of", "candidate", "goals", "."]], "ner": [[[6, 6, "a"]], [[29, 29, "a"], [47, 47, "v"]], [], [[98, 98, "a"], [107, 107, "p"], [109, 109, "v"], [114, 114, "p"], [116, 116, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[21, 21, "p"], [21, 23, "v"], [26, 26, "v"], [27, 27, "p"], [33, 33, "v"], [41, 41, "v"], [45, 47, "v"], [55, 55, "v"], [59, 59, "v"], [61, 61, "v"]], [], [[96, 96, "a"], [98, 98, "a"], [107, 109, "v"], [114, 114, "p"], [114, 116, "v"]]], "predicted_relations": [[], [], [], [[107, 107, 98, 98, "USED-FOR"], [109, 109, 107, 107, "USED-FOR"], [109, 109, 114, 114, "USED-FOR"], [114, 114, 98, 98, "USED-FOR"], [116, 116, 107, 107, "USED-FOR"], [116, 116, 114, 114, "USED-FOR"]]]}
{"doc_key": "2108.07421-59e7908b-5659-479a-b1f1-55a50ce85182", "sentences": [["It", "is", "straightforward", "to", "the", "optimal", "solution", "for", "-LRB-", "REF", "-RRB-", ",", "which", "is", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "^b", "=", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", "."], ["To", "obtain", "the", "optimal", "solution", "for", "the", "scaling", "parameter", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "we", "take", "the", "derivative", "of", "-LRB-", "REF", "-RRB-", "with", "respective", "to", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "."], ["It", "is", "\\", "-LRB-", "-2", "\\mathbf", "-LCB-", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "^T\\mathbf", "-LCB-", "w", "-RCB-", "^b", "+", "2\\alpha", "p\\", "-RRB-", "."], ["By", "setting", "it", "to", "0", ",", "we", "will", "get", "\\", "-LRB-", "\\alpha", "=", "\\frac", "-LCB-", "\\mathbf", "-LCB-", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "^T\\mathbf", "-LCB-", "w", "-RCB-", "^b", "-RCB-", "-LCB-", "p", "-RCB-", "\\", "-RRB-", "."], ["Since", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "^b", "=", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "the", "scaling", "parameter", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "will", "be", "\\", "-LRB-", "\\alpha", "=", "\\frac", "-LCB-", "\\sum", "_j", "|\\widetilde", "-LCB-", "w", "-RCB-", "_j|", "-RCB-", "-LCB-", "p", "-RCB-", ".\\", "-RRB-"]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[51, 51, "p"], [68, 68, "p"]], [], [[100, 100, "v"], [107, 107, "p"]], [[164, 164, "p"], [171, 171, "p"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.07421-e00f78bd-2269-40ae-934e-7b6b74da39c9", "sentences": [["The", "optimal", "binary", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "^b\\", "-RRB-", "is", "obtained", "by", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "^b", "=", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "where", "sign", "-LRB-", "-RRB-", "is", "the", "element-wise", "sign", "function", "which", "return", "1", "if", "the", "element", "is", "larger", "or", "equal", "than", "zero", "and", "return", "\\", "-LRB-", "-1\\", "-RRB-", "otherwise", "."], ["Similarly", ",", "\\", "-LRB-", "\\mathbf", "-LCB-", "V", "-RCB-", "^b\\", "-RRB-", "can", "be", "obtained", "by", "\\", "-LRB-", "\\mathbf", "-LCB-", "V", "-RCB-", "^b", "=", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "V", "-RCB-", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", "."], ["Since", "the", "sign", "-LRB-", "-RRB-", "function", "are", "not", "differentiable", ",", "STE", "estimates", "the", "gradients", "with", "respect", "to", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "w", "-RCB-", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\widetilde", "-LCB-", "V", "-RCB-", "-RCB-", "\\", "-RRB-", "as", "if", "the", "non-differentiable", "function", "sign", "-LRB-", "-RRB-", "is", "not", "present", "."], ["In", "other", "word", ",", "STE", "will", "simply", "estimate", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RRB-", "-RCB-", "-LCB-", "\\partial", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RCB-", "\\", "-RRB-", "as", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RCB-", "-LCB-", "\\partial", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RCB-", "=", "1\\", "-RRB-", "."], ["In", "practice", ",", "we", "also", "employ", "the", "gradient", "clipping", "as", "in", "-LSB-", "9", "-RSB-", "."], ["Then", ",", "the", "gradient", "for", "the", "non-differentiable", "sign", "function", "is", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\text", "-LCB-", "sign", "-RCB-", "-LRB-", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RRB-", "-RCB-", "-LCB-", "\\partial", "\\tilde", "-LCB-", "w", "-RCB-", "_j", "-RCB-", "=", "1_", "-LCB-", "|\\tilde", "-LCB-", "w", "-RCB-", "_j|\\le", "1", "-RCB-", ".\\", "-RRB-"]], "ner": [[], [], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[51, 51, "v"], [60, 60, "v"]], [], [], [], [[227, 228, "a"]], [[278, 278, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2112.12252-2fe69aa7-56d9-4e39-85c5-66b8fc2bb876", "sentences": [["Yolov5", "-LSB-", "61", "-RSB-", "is", "a", "state", "of", "the", "art", "implementation", "of", "the", "Yolo", "object", "detection", "model", "implemented", "with", "multiple", "improvements", "to", "the", "Yolo", "framework", "that", "have", "been", "found", "in", "recent", "years", "."], ["In", "this", "work", ",", "we", "used", "the", "unmodified", "YOLOv5m6", "implementation", "of", "Yolov5", "in", "release", "v5.0", "-LSB-", "65", "-RSB-", "with", "an", "image", "size", "of", "1280x1280px", "and", "a", "batchsize", "of", "48", "."], ["Unless", "otherwise", "specified", ",", "we", "used", "the", "provided", "weights", "pre-trained", "on", "COCO", "-LSB-", "62", "-RSB-", "."]], "ner": [[[0, 0, "a"]], [[44, 44, "a"], [53, 54, "p"], [56, 56, "v"], [59, 59, "p"], [61, 61, "v"]], [[74, 74, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"], [13, 16, "a"], [23, 24, "a"]], [[41, 41, "a"], [44, 44, "a"], [56, 56, "v"], [61, 61, "v"]], [[74, 74, "a"]]], "predicted_relations": [[], [[53, 54, 44, 44, "USED-FOR"], [56, 56, 53, 54, "USED-FOR"], [59, 59, 44, 44, "USED-FOR"]], []]}
{"doc_key": "2112.12252-0fea9f1a-242c-47d6-a518-4b695f7821d2", "sentences": [["Furthermore", ",", "as", "a", "two-stage", "detector", "we", "take", "the", "best", "performing", "single-model", "-LRB-", "no", "ensemble", "-RRB-", "on", "VisDrone", "from", "the", "workshop", "report", "-LSB-", "4", "-RSB-", "-LRB-", "DE-FPN", "-RRB-", ",", "i.e", "."], ["a", "Faster", "R-CNN", "-LRB-", "F.R", ".", "-RRB-"], ["with", "a", "ResNeXt-101", "64-4d", "-LSB-", "66", "-RSB-", "backbone", "-LRB-", "removing", "P6", "-RRB-", ",", "which", "is", "trained", "using", "color", "jitter", "and", "random", "image", "cropping", "."], ["The", "anchor", "sizes", "and", "strides", "are", "decreased", "to", "-LRB-", "16", ",", "32", ",", "64", ",", "128", ",", "256", "-RRB-", "and", "-LRB-", "4", ",", "8", ",", "16", ",", "32", ",", "64", "-RRB-", "."]], "ner": [[[17, 17, "a"]], [[32, 33, "a"]], [[40, 41, "a"], [55, 56, "a"], [58, 60, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[17, 17, "a"]], [[33, 33, "a"]], [[40, 41, "a"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.14851-f444aaca-534d-4440-8ff1-e1e1144dadc5", "sentences": [["In", "each", "of", "our", "experiments", ",", "we", "randomly", "choose", "one", "user", "from", "the", "530", "FaceScrub", "identities", "to", "be", "the", "attacker", "."], ["We", "perturb", "100", "%", "of", "the", "training", "pictures", "of", "that", "user", "-LRB-", "70", "%", "of", "all", "pictures", "-RRB-", "with", "the", "chosen", "attack", "-LRB-", "Fawkes", "v0.3", ",", "Fawkes", "v1.0", ",", "or", "LowKey", "-RRB-", "."], ["The", "training", "set", "for", "the", "model", "trainer", "contains", "these", "perturbed", "pictures", ",", "as", "well", "as", "the", "training", "pictures", "of", "all", "other", "529", "FaceScrub", "users", "."]], "ner": [[], [[44, 45, "a"], [47, 48, "a"], [51, 51, "a"]], []], "relations": [[], [], []], "predicted_ner": [[[9, 9, "v"], [13, 13, "v"], [14, 14, "a"]], [[23, 24, "v"], [33, 34, "v"]], [[75, 75, "v"], [76, 76, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2106.14851-b023b448-cb87-4519-969d-b0a26ed9fe74", "sentences": [["For", "linear", "fine-tuning", "and", "end-to-end", "fine-tuning", ",", "we", "add", "a", "530-class", "linear", "layer", "on", "top", "of", "a", "pre-trained", "feature", "extractor", ",", "and", "train", "either", "only", "the", "linear", "layer", ",", "or", "the", "entire", "model", "."], ["For", "linear", "fine-tuning", ",", "we", "train", "a", "logistic", "regression", "model", "using", "sklearn", "."], ["To", "fine-tune", "the", "entire", "model", ",", "we", "minimize", "the", "cross-entropy", "loss", "for", "500", "steps", "with", "a", "batch", "size", "of", "32", "using", "AdaDelta", "with", "learning", "rate", "\\", "-LRB-", "\\eta", "=1\\", "-RRB-", "."], ["We", "perform", "no", "data", "augmentation", "during", "training", "."]], "ner": [[[1, 2, "a"], [4, 5, "a"]], [[35, 36, "a"], [41, 42, "a"]], [[56, 57, "a"], [68, 68, "a"], [70, 71, "p"], [75, 75, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "v"]], [[45, 45, "a"]], [[56, 57, "a"], [59, 59, "v"], [60, 60, "p"], [63, 64, "p"], [66, 66, "v"], [68, 68, "a"], [70, 71, "p"]], []], "predicted_relations": [[], [], [[70, 71, 68, 68, "USED-FOR"], [75, 75, 70, 71, "USED-FOR"]], []]}
{"doc_key": "2105.06977-f13ad411-395a-4052-be73-f8057f1d6f9d", "sentences": [["We", "follow", "the", "Transformer", "base", "-LSB-", "42", "-RSB-", "configuration", "in", "all", "our", "experiments", ",", "with", "\\", "-LRB-", "N", "=", "6\\", "-RRB-", "encoder", "and", "decoder", "layers", ",", "\\", "-LRB-", "h", "=", "8\\", "-RRB-", "attention", "heads", ",", "hidden", "size", "\\", "-LRB-", "d_\\text", "-LCB-", "model", "-RCB-", "=", "512\\", "-RRB-", "and", "feedforward", "size", "\\", "-LRB-", "d_\\text", "-LCB-", "ff", "-RCB-", "=", "2048\\", "-RRB-", "."], ["We", "use", "the", "learning", "rate", "schedule", "and", "regularization", "described", "in", "-LSB-", "42", "-RSB-", "."], ["We", "train", "using", "the", "Adam", "optimizer", "-LSB-", "15", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1", "=", "0.9", ",", "\\beta", "_2", "=", "0.98\\", "-RRB-", "."]], "ner": [[[3, 4, "a"]], [], [[77, 78, "a"], [88, 88, "v"], [93, 93, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 4, "a"], [17, 19, "v"], [28, 30, "v"], [35, 36, "p"], [44, 44, "v"], [47, 48, "p"], [56, 56, "v"]], [], [[77, 77, "a"], [88, 88, "v"], [93, 93, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2108.01208-5b47518a-1b2a-4372-9fd5-c044d07148ca", "sentences": [["The", "baseline", "pointer", "network", "has", "1", "encoder", "and", "decoder", "BLSTM", "layer", "with", "128", "hidden", "size", "."], ["We", "train", "it", "using", "learning", "rate", "0.0003", "with", "Adam", "and", "batch_size", "32", "."], ["For", "our", "proposed", "model", "we", "employ", "2", "encoders", "-LRB-", "one", "for", "each", "turn", "-RRB-", "and", "1", "decoder", "with", "the", "same", "dimension", ",", "but", "modified", "attention", "head", "."], ["We", "train", "it", "with", "batch", "size", "128", "and", "learning", "rate", "0.0001", "with", "Adam", "."], ["We", "use", "pretrained", "ANEs", "that", "are", "fixed", "during", "training", "."]], "ner": [[[2, 3, "a"], [6, 6, "p"], [5, 5, "v"], [9, 14, "c"], [8, 8, "p"], [5, 5, "v"], [9, 14, "c"], [8, 8, "p"], [5, 5, "v"]], [[24, 24, "a"]], [[44, 44, "v"], [45, 45, "p"], [44, 44, "v"], [31, 32, "a"], [36, 36, "p"], [35, 35, "v"], [38, 41, "c"], [45, 45, "p"], [44, 44, "v"], [48, 49, "c"], [53, 54, "p"]], [[68, 68, "a"]], [[72, 73, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 3, "a"], [5, 5, "v"], [9, 9, "a"], [12, 12, "v"], [13, 14, "p"]], [[20, 21, "p"], [22, 22, "v"], [24, 24, "a"], [26, 26, "p"], [27, 27, "v"]], [[35, 35, "v"], [38, 38, "v"], [44, 44, "v"]], [[60, 61, "p"], [62, 62, "v"], [64, 65, "p"], [66, 66, "v"], [68, 68, "a"]], [[73, 73, "a"]]], "predicted_relations": [[[6, 6, 2, 3, "USED-FOR"], [5, 5, 6, 6, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"], [8, 8, 2, 3, "USED-FOR"], [5, 5, 6, 6, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"], [8, 8, 2, 3, "USED-FOR"], [5, 5, 6, 6, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"], [5, 5, 8, 8, "USED-FOR"]], [], [[44, 44, 45, 45, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [45, 45, 31, 32, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [36, 36, 31, 32, "USED-FOR"], [35, 35, 36, 36, "USED-FOR"], [45, 45, 31, 32, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [48, 49, 44, 44, "USED-FOR"], [48, 49, 44, 44, "USED-FOR"], [48, 49, 44, 44, "USED-FOR"]], [], []]}
{"doc_key": "2109.09233-a9e946f0-47c0-48d8-ada7-b4e65773a4df", "sentences": [["We", "train", "the", "models", "by", "applying", "5-Fold", "Cross", "ValidationWe", "experiment", "also", "10-Fold", ",", "but", "the", "models", "show", "worse", "performance", "in", "the", "test", "set.", ",", "with", "the", "epochs", "of", "5", ",", "learning", "rate", "as", "1e-5", ",", "batch", "size", "as", "2", "."], ["We", "use", "the", "GPU", "of", "the", "Google", "Colabhttps", ":", "//colab.research.google.com/", "as", "an", "environment", "for", "training", "the", "models", "."], ["We", "use", "a", "fixed", "random", "seed", "of", "1234", "to", "ensure", "reproducible", "results", "."], ["The", "official", "results", "are", "obtained", "by", "a", "TIRA", "machine", "-LSB-", "25", "-RSB-", "."]], "ner": [[[26, 26, "a"], [26, 26, "p"], [6, 6, "v"], [28, 28, "v"], [33, 33, "v"], [30, 31, "a"], [30, 31, "p"], [33, 33, "v"], [35, 36, "a"], [35, 36, "p"], [38, 38, "v"]], [], [[62, 63, "a"], [62, 63, "p"], [65, 65, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "v"], [11, 11, "v"], [26, 26, "p"], [28, 28, "v"], [30, 31, "p"], [33, 33, "v"], [35, 36, "p"], [38, 38, "v"]], [], [[65, 65, "v"]], [[78, 79, "a"]]], "predicted_relations": [[[26, 26, 26, 26, "USED-FOR"], [26, 26, 30, 31, "USED-FOR"], [28, 28, 26, 26, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"], [30, 31, 26, 26, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"]], [], [[62, 63, 62, 63, "USED-FOR"]], []]}
{"doc_key": "2109.11375-a737267e-1fef-4be2-bd2d-4d2e07ab3338", "sentences": [["We", "will", "approximate", "the", "posterior", "distribution", "\\", "-LRB-", "P_", "-LCB-", "X|Y=y", "-RCB-", "\\", "-RRB-", "for", "arbitrary", "observations", "\\", "-LRB-", "y\\", "-RRB-", "using", "a", "conditional", "SNF", "\\", "-LRB-", "-LRB-", "X_0", ",", "...", ",", "X_T", "-RRB-", "\\", "-RRB-", "with", "\\", "-LRB-", "T=6\\", "-RRB-", "layers", ",", "where", "the", "layers", "themselves", "are", "defined", "as", "follows", ":"]], "ner": [[]], "relations": [[]], "predicted_ner": [[]], "predicted_relations": [[]]}
{"doc_key": "2109.11375-b3f768c2-0f6d-461e-a6bd-2ace5f8b6ce2", "sentences": [["For", "\\", "-LRB-", "t=1,4\\", "-RRB-", ",", "we", "use", "a", "deterministic", "layer", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t", "-LRB-", "y", ",", "x", ",", "A", "-RRB-", "=\\delta", "_", "-LCB-", "\\mathcal", "-LCB-", "T", "-RCB-", "_t", "-LRB-", "y", ",", "x", "-RRB-", "-RCB-", "-LRB-", "A", "-RRB-", "\\", "-RRB-", "."], ["Here", ",", "\\", "-LRB-", "\\mathcal", "-LCB-", "T", "-RCB-", "_t\\", "-RRB-", "is", "a", "conditional", "INN", "with", "\\", "-LRB-", "L=4\\", "-RRB-", "layers", ",", "where", "each", "subnetwork", "has", "two", "hidden", "layers", "with", "128", "neurons", "."]], "ner": [[[9, 10, "a"], [3, 3, "v"]], [[62, 62, "p"], [62, 62, "v"], [75, 75, "p"], [74, 74, "v"], [57, 58, "a"]]], "relations": [[], []], "predicted_ner": [[[3, 3, "v"]], [[57, 58, "a"], [62, 62, "v"], [70, 70, "v"], [74, 74, "v"]]], "predicted_relations": [[], [[62, 62, 62, 62, "USED-FOR"], [62, 62, 57, 58, "USED-FOR"], [62, 62, 62, 62, "USED-FOR"], [75, 75, 57, 58, "USED-FOR"], [74, 74, 62, 62, "USED-FOR"]]]}
{"doc_key": "2109.11375-b471fd6f-8e44-4208-add8-062a242b43bb", "sentences": [["For", "\\", "-LRB-", "t=2,5\\", "-RRB-", ",", "the", "layer", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t\\", "-RRB-", "consists", "of", "3", "Langevin", "steps", ",", "i.e.", ",", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t\\", "-RRB-", "is", "defined", "by", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t", "-LRB-", "y", ",", "\\cdot", ",", "\\cdot", "-RRB-", "=\\underbrace", "-LCB-", "\\tilde", "-LCB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t", "-RCB-", "-LRB-", "y", ",", "\\cdot", ",", "\\cdot", "-RRB-", "\\circ", "\\cdots", "\\circ", "\\tilde", "-LCB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t", "-RCB-", "-LRB-", "y", ",", "\\cdot", ",", "\\cdot", "-RRB-", "-RCB-", "_", "-LCB-", "3\\text", "-LCB-", "times", "-RCB-", "-RCB-", ",", "\\", "-RRB-"]], "ner": [[]], "relations": [[]], "predicted_ner": [[[3, 3, "v"], [18, 18, "v"]]], "predicted_relations": [[]]}
{"doc_key": "2109.11375-60a668cc-5a7c-4b51-9b8e-53182ae03798", "sentences": [["where", "\\", "-LRB-", "\\tilde", "-LCB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t", "-RCB-", "\\", "-RRB-", "is", "the", "kernel", "from", "-LRB-", "REF", "-RRB-", "."], ["In", "the", "Langevin", "steps", "we", "set", "\\", "-LRB-", "a_1", "=", "1e-6\\", "-RRB-", "and", "\\", "-LRB-", "a_2^2", "=", "2e-6\\", "-RRB-", "."]], "ner": [[[15, 15, "a"]], [[23, 24, "a"], [29, 29, "p"], [31, 31, "v"], [36, 36, "p"], [38, 38, "v"]]], "relations": [[], []], "predicted_ner": [[], []], "predicted_relations": [[], [[29, 29, 23, 24, "USED-FOR"], [31, 31, 29, 29, "USED-FOR"], [36, 36, 23, 24, "USED-FOR"], [38, 38, 36, 36, "USED-FOR"]]]}
{"doc_key": "2109.11375-19f6d139-7552-4bfe-ad36-ca37515a8603", "sentences": [["For", "layer", "\\", "-LRB-", "t", "=", "3,6\\", "-RRB-", "we", "take", "layers", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t\\", "-RRB-", "with", "3", "MCMC", "steps", "where", "the", "Markov", "kernel", "\\", "-LRB-", "Q_t\\", "-RRB-", "is", "given", "by", "-LRB-", "REF", "-RRB-", "."]], "ner": [[]], "relations": [[]], "predicted_ner": [[[4, 6, "v"], [20, 20, "v"], [21, 21, "a"]]], "predicted_relations": [[]]}
{"doc_key": "2109.11375-29b8485c-bb4b-4aa3-a512-ed84a693801e", "sentences": [["Here", "we", "choose", "the", "interpolating", "densities", "\\", "-LRB-", "p_t^y", "-LRB-", "x", "-RRB-", "\\", "-RRB-", "for", "\\", "-LRB-", "t=2,3\\", "-RRB-", "as", "\\", "-LRB-", "p_t^y", "-LRB-", "x", "-RRB-", "=c_y\\", ",", "-LRB-", "p_Z", "-LRB-", "x", "-RRB-", "p_", "-LCB-", "X|Y=y", "-RCB-", "-LRB-", "x", "-RRB-", "-RRB-", "^", "-LCB-", "1/2", "-RCB-", ",", "\\", "-RRB-"]], "ner": [[]], "relations": [[]], "predicted_ner": [[]], "predicted_relations": [[]]}
{"doc_key": "2109.11375-0b8c69ee-9190-451d-9814-61ca6834119a", "sentences": [["We", "compare", "the", "results", "of", "the", "conditional", "SNF", "with", "a", "conditional", "INN", "with", "\\", "-LRB-", "L=8\\", "-RRB-", "layers", ",", "where", "each", "subnetwork", "has", "two", "hidden", "layers", "with", "128", "neurons", "."], ["Note", "that", "the", "conditional", "INN", "and", "the", "conditional", "SNF", "have", "the", "same", "number", "of", "parameters", "."], ["We", "train", "both", "networks", "with", "the", "Adam", "optimizer", "-LSB-", "26", "-RSB-", "with", "a", "batch", "size", "of", "6400", "for", "4000", "steps", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "loss", "function", "-LRB-", "REF", "-RRB-", "with", "\\", "-LRB-", "\\lambda", "=0\\", "-RRB-", "."]], "ner": [[[6, 7, "a"], [10, 11, "a"]], [[37, 38, "a"], [33, 34, "a"]], [[89, 89, "p"], [90, 90, "v"], [52, 53, "a"], [68, 69, "p"], [81, 82, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 7, "a"], [10, 11, "a"], [15, 15, "v"], [23, 23, "v"], [24, 25, "p"], [27, 27, "v"]], [[33, 34, "a"], [37, 38, "a"]], [[52, 52, "a"], [59, 60, "p"], [62, 62, "v"], [64, 64, "v"], [68, 69, "p"], [73, 77, "v"], [89, 90, "v"]]], "predicted_relations": [[], [], [[89, 89, 81, 82, "USED-FOR"], [90, 90, 89, 89, "USED-FOR"], [68, 69, 52, 53, "USED-FOR"]]]}
{"doc_key": "2109.11375-7f2f29d3-d812-4a5e-a5de-b29902d053cf", "sentences": [["We", "train", "a", "conditional", "SNF", "with", "\\", "-LRB-", "T=8\\", "-RRB-", "layers", "similarly", "to", "the", "previous", "example", "."], ["The", "layers", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t\\", "-RRB-", "for", "\\", "-LRB-", "t=1,3,5,7\\", "-RRB-", "are", "deterministic", "layers", "with", "conditional", "INNs", "with", "\\", "-LRB-", "L=1\\", "-RRB-", "layers", ",", "where", "the", "subnetworks", "has", "two", "hidden", "layers", "with", "64", "neurons", "in", "each", "hidden", "layer", "."], ["The", "layers", "\\", "-LRB-", "\\mathcal", "-LCB-", "K", "-RCB-", "_t\\", "-RRB-", "for", "\\", "-LRB-", "t=2,4,6,8\\", "-RRB-", "consist", "of", "10", "MCMC", "steps", "using", "the", "kernel", "\\", "-LRB-", "Q_t\\", "-RRB-", "as", "defined", "in", "-LRB-", "REF", "-RRB-", "."], ["Here", ",", "we", "set", "\\", "-LRB-", "\\sigma", "=0.4\\", "-RRB-", "."]], "ner": [[[3, 4, "a"]], [], [[85, 85, "p"], [78, 78, "a"]], [[101, 101, "v"], [100, 100, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "a"], [8, 8, "v"]], [[30, 30, "v"], [36, 37, "a"], [41, 41, "v"], [49, 49, "v"], [53, 53, "v"]], [[77, 77, "v"]], []], "predicted_relations": [[], [], [[85, 85, 78, 78, "USED-FOR"]], [[101, 101, 100, 100, "USED-FOR"]]]}
{"doc_key": "2109.11375-1d19c993-38f1-44b2-a74a-8510151f8941", "sentences": [["As", "a", "comparison", ",", "we", "also", "implement", "a", "conditional", "INN", "with", "\\", "-LRB-", "L=4\\", "-RRB-", "layers", ",", "where", "each", "subnetwork", "has", "two", "hidden", "layers", "with", "64", "neurons", "in", "each", "hidden", "layer", "."], ["Note", "that", "this", "conditional", "INN", "has", "exactly", "the", "same", "number", "of", "parameters", "as", "the", "conditional", "SNF", "."], ["We", "train", "both", "networks", "using", "the", "Adam", "optimizer", "-LSB-", "26", "-RSB-", "with", "a", "batch", "size", "of", "1600", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "loss", "function", "-LRB-", "REF", "-RRB-", "with", "\\", "-LRB-", "\\lambda", "=0\\", "-RRB-", "."], ["For", "the", "SNF", ",", "we", "run", "40", "epochs", ",", "which", "takes", "approximately", "50", "seconds", "."], ["Since", "for", "the", "conditional", "INN", "it", "takes", "longer", "until", "the", "loss", "saturates", ",", "we", "train", "the", "conditional", "INN", "for", "5000", "epochs", ",", "which", "takes", "approximately", "8", "minutes", "."], ["Each", "epoch", "consists", "of", "8", "steps", "of", "the", "Adam", "optimizer", "."]], "ner": [[[8, 9, "a"], [13, 13, "p"], [13, 13, "v"], [26, 30, "p"], [25, 25, "v"]], [[35, 36, "a"], [46, 47, "a"]], [[55, 56, "a"], [62, 63, "p"], [65, 65, "v"], [68, 69, "p"], [81, 82, "a"], [89, 89, "p"], [90, 90, "v"]], [], [[111, 112, "a"], [124, 125, "a"]], [[144, 145, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 9, "a"], [13, 13, "v"], [21, 21, "v"], [25, 25, "v"]], [[35, 36, "a"], [46, 47, "a"]], [[55, 55, "a"], [62, 63, "p"], [65, 65, "v"], [68, 69, "p"], [73, 76, "v"], [89, 90, "p"]], [[95, 95, "a"], [99, 99, "v"], [100, 100, "p"], [105, 105, "v"]], [[111, 112, "a"], [124, 125, "a"], [127, 127, "v"], [128, 128, "p"], [133, 133, "v"]], [[140, 140, "v"], [144, 144, "a"]]], "predicted_relations": [[[13, 13, 8, 9, "USED-FOR"], [13, 13, 13, 13, "USED-FOR"], [13, 13, 13, 13, "USED-FOR"], [25, 25, 13, 13, "USED-FOR"]], [], [[65, 65, 62, 63, "USED-FOR"], [65, 65, 68, 69, "USED-FOR"], [68, 69, 55, 56, "USED-FOR"], [89, 89, 81, 82, "USED-FOR"], [90, 90, 89, 89, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.11442-69fa295e-d8cb-4e07-b8f2-a3183489fca9", "sentences": [["In", "order", "to", "get", "training", "samples", "whose", "structure", "mimics", "that", "of", "data", "observed", "in", "the", "real", "world", ",", "we", "ensured", "that", "our", "data", "is", "segmented", "by", "sentence", "-LRB-", "finishing", "by", "a", "PUNfrt", "-RRB-", "or", "by", "line", "-LRB-", "in", "manuscripts", "without", "punctuation", "-RRB-", "."], ["To", "do", "so", ",", "we", "transform", "the", "dataset", "using", "Protogenie", "-LSB-", "11", "-RSB-", "which", "handles", "some", "form", "of", "normalisation", ":", "we", "normalise", "Roman", "numerals", "into", "Arabic", "numerals", "to", "reduce", "the", "complexity", "of", "the", "data", ",", "as", "well", "as", "the", "number", "of", "allowed", "numbers", "and", "we", "split", "the", "complex", "morphology", "into", "several", "simple", "categories", "-LRB-", "Case", ",", "Tense", ",", "etc", ".", "-RRB-", "."], ["The", "full", "corpus", "is", "then", "split", "into", "3", "different", "parts", ",", "for", "training", ",", "development", "and", "testing", ",", "with", "a", "80/10/10", "%", "ratio", "."]], "ner": [[], [[52, 52, "a"], [65, 66, "a"], [94, 95, "p"], [90, 91, "a"]], []], "relations": [[], [], []], "predicted_ner": [[], [[52, 52, "a"]], [[112, 112, "v"]]], "predicted_relations": [[], [[94, 95, 65, 66, "USED-FOR"], [94, 95, 90, 91, "USED-FOR"]], []]}
{"doc_key": "2109.11442-380fc9af-e7b1-43ea-bd49-ebde3a3d719f", "sentences": [["All", "models", "shared", "most", "of", "the", "same", "parameters", ":", "they", "used", "a", "single", "linear", "layer", ",", "LSTM", "cells", "for", "the", "hidden", "network", ",", "a", "character", "embedding", "using", "RNN", ",", "a", "dropout", "of", "0.32", ",", "learning", "rate", "of", "0.0049", ",", "patience", "for", "the", "learning", "rate", "evolution", "of", "2", ",", "a", "patience", "for", "early", "stopping", "of", "5", "."], ["We", "provide", "the", "configuration", "on", "our", "repository", "."], ["We", "used", "the", "Ranger", "optimizer", "that", "has", "shown", "less", "variation", "in", "training", "with", "better", "scoresOn", "this", "topic", ",", "see", "the", "discussion", "between", "TC", "and", "Enrique", "Manjavacas", "at", "https", ":", "//web.archive.org/web/20210914113014/https", ":", "//github.com/emanjavacas/pie/issues/76", ".."]], "ner": [[[16, 17, "a"], [24, 27, "a"], [30, 30, "a"], [49, 52, "p"], [54, 54, "v"], [34, 35, "a"], [42, 43, "a"], [39, 44, "a"], [49, 52, "a"]], [], [[67, 68, "a"]]], "relations": [[], [], []], "predicted_ner": [[[16, 16, "a"], [27, 27, "a"], [30, 30, "p"], [32, 32, "v"], [34, 35, "p"], [37, 37, "v"], [46, 46, "v"], [54, 54, "v"]], [], [[67, 67, "a"], [86, 86, "a"], [88, 89, "a"]]], "predicted_relations": [[[49, 52, 16, 17, "USED-FOR"], [49, 52, 24, 27, "USED-FOR"], [49, 52, 30, 30, "USED-FOR"], [49, 52, 34, 35, "USED-FOR"], [49, 52, 42, 43, "USED-FOR"], [49, 52, 39, 44, "USED-FOR"], [49, 52, 49, 52, "USED-FOR"], [54, 54, 49, 52, "USED-FOR"]], [], []]}
{"doc_key": "2109.11442-75a84c7d-26f9-4f6f-962c-e639ae5148a6", "sentences": [["The", "Character", "Embedding", "size", ",", "cemb_size", ",", "could", "be", "of", "100", ",", "150", ",", "200", "or", "300", "The", "number", "of", "layers", "for", "the", "Character", "Embeddings", "Encoder", ",", "cemb_layers", ",", "could", "be", "1", "or", "2", "."], ["The", "size", "of", "the", "hidden", "layer", ",", "that", "encodes", "most", "of", "the", "context", ",", "was", "a", "value", "in", "the", "set", "\\", "-LRB-", "150", ",", "200", ",", "250", ",", "300", ",", "350\\", "-RRB-", "."], ["We", "added", "a", "variation", "only", "for", "the", "lemma", "task", "at", "170", "."]], "ner": [[[1, 2, "a"], [3, 3, "p"], [10, 10, "v"], [12, 12, "v"], [14, 14, "v"], [16, 16, "v"], [20, 20, "p"], [31, 31, "v"], [33, 33, "v"], [3, 3, "p"], [12, 12, "v"], [14, 14, "v"], [16, 16, "v"]], [[36, 36, "p"], [57, 57, "v"], [59, 59, "v"], [63, 63, "v"], [39, 40, "a"], [36, 36, "p"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [63, 63, "v"], [65, 65, "v"]], [[78, 78, "v"], [75, 76, "c"]]], "relations": [[], [], []], "predicted_ner": [[[10, 10, "v"], [12, 12, "v"], [31, 31, "v"], [33, 33, "v"]], [[65, 65, "v"]], [[78, 78, "v"]]], "predicted_relations": [[[3, 3, 1, 2, "USED-FOR"], [10, 10, 3, 3, "USED-FOR"], [10, 10, 3, 3, "USED-FOR"], [12, 12, 3, 3, "USED-FOR"], [12, 12, 20, 20, "USED-FOR"], [12, 12, 3, 3, "USED-FOR"], [14, 14, 3, 3, "USED-FOR"], [14, 14, 20, 20, "USED-FOR"], [14, 14, 3, 3, "USED-FOR"], [20, 20, 1, 2, "USED-FOR"], [3, 3, 1, 2, "USED-FOR"], [12, 12, 3, 3, "USED-FOR"], [12, 12, 20, 20, "USED-FOR"], [12, 12, 3, 3, "USED-FOR"], [14, 14, 3, 3, "USED-FOR"], [14, 14, 20, 20, "USED-FOR"], [14, 14, 3, 3, "USED-FOR"]], [[36, 36, 39, 40, "USED-FOR"], [36, 36, 39, 40, "USED-FOR"]], [[75, 76, 78, 78, "USED-FOR"]]]}
{"doc_key": "2107.03069-afcbb2f1-5b44-430b-bd99-49378d9aa34b", "sentences": [["To", "ensure", "a", "reliable", "comparison", ",", "we", "perform", "all", "ASR", "and", "ST", "experiments", "under", "the", "same", "conditions", "and", "parameters", "."], ["Specifically", ",", "we", "try", "to", "use", "the", "same", "parameters", "as", "in", "the", "implementation", "by", "-LSB-", "19", "-RSB-", ",", "when", "possible", "."], ["In", "ASR", "trainings", "we", "use", "4", "CPUs", "and", "2", "workers", "to", "load", "the", "data", "."], ["We", "fixed", "a", "maximum", "of", "20000", "tokens", "per", "batch", "."], ["We", "used", "Adam", "optimizer", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "1", "\\cdot", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "with", "an", "inverse", "square", "root", "scheduler", "."], ["We", "applied", "a", "warm-up", "for", "the", "first", "10000", "updates", "."], ["We", "clipped", "the", "gradient", "to", "10", "to", "avoid", "exploding", "gradients", "."], ["We", "used", "label", "smoothed", "Cross-entropy", "as", "a", "loss", "function", ",", "with", "a", "smoothing", "factor", "of", "0.1", "."], ["We", "used", "an", "update", "frequency", "of", "16", ",", "simulating", "the", "use", "of", "16", "GPUs", "."], ["We", "fix", "a", "maximum", "of", "100000", "updates", "for", "every", "training", "."], ["In", "ST", "trainings", "we", "use", "the", "same", "parameters", "as", "for", "ASR", ",", "but", "for", "the", "learning", "rate", ",", "that", "is", "\\", "-LRB-", "2", "\\cdot", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "as", "done", "in", "-LSB-", "19", "-RSB-", "."], ["We", "conducted", "the", "training", "of", "all", "our", "experiments", "in", "an", "NVIDIA", "GeForce", "RTX", "2080", "Ti", "GPU", "."]], "ner": [[], [], [], [], [[68, 69, "a"], [72, 73, "p"], [79, 79, "v"]], [], [[107, 107, "v"]], [[117, 117, "a"], [125, 126, "p"], [128, 128, "v"]], [], [], [[171, 172, "p"], [180, 180, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[46, 46, "v"], [49, 49, "v"]], [[61, 61, "v"]], [[68, 68, "a"], [72, 73, "p"], [77, 77, "v"]], [[95, 95, "a"], [99, 99, "v"]], [[107, 107, "v"]], [[115, 117, "a"], [125, 126, "p"], [128, 128, "v"]], [[133, 134, "p"], [136, 136, "v"], [142, 142, "v"]], [[150, 150, "v"]], [[166, 166, "a"], [171, 172, "p"], [178, 178, "v"]], []], "predicted_relations": [[], [], [], [], [[72, 73, 68, 69, "USED-FOR"], [79, 79, 72, 73, "USED-FOR"]], [], [], [[125, 126, 117, 117, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2112.04803-2d6648e6-c709-478d-b0fe-d86afecef577", "sentences": [["Training", "Process", ":", "Each", "configuration", "of", "the", "model", "architecture", "is", "trained", "using", "Adam", "optimizer", "-LSB-", "15", "-RSB-", "with", "a", "learning", "rate", "of", "0.001", ",", "a", "batch", "size", "of", "64", "for", "maximum", "of", "20", "iterations", "."], ["We", "use", "the", "90:10", "splits", "for", "train", "and", "validation", "splits", "to", "find", "the", "optimal", "hyperparameters", "."]], "ner": [[[12, 13, "a"], [19, 20, "p"], [22, 22, "v"], [25, 26, "p"], [28, 28, "v"], [32, 32, "v"]], []], "relations": [[], []], "predicted_ner": [[[12, 12, "a"], [19, 20, "p"], [22, 22, "v"], [25, 26, "p"], [28, 28, "v"], [32, 32, "v"], [33, 33, "p"]], [[38, 38, "v"]]], "predicted_relations": [[[19, 20, 12, 13, "USED-FOR"], [25, 26, 12, 13, "USED-FOR"], [32, 32, 25, 26, "USED-FOR"]], []]}
{"doc_key": "2101.08122-8191af59-af6e-40e5-b094-86973852eb3f", "sentences": [["The", "parameters", "are", "optimized", "using", "the", "Adam", "optimization", "algorithm", "-LSB-", "25", "-RSB-", "with", "the", "suggested", "defaults", "for", "the", "hyperparameters", "-LRB-", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "1", "=", "0.9", ",", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "2=", "0.999", "-RRB-", "."], ["The", "training", "is", "stopped", "when", "the", "validation", "loss", "does", "not", "decrease", "by", "1", "%", "in", "between", "epochs", "."], ["We", "use", "a", "fixed", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "weight", "decay", "-LRB-", "\\", "-LRB-", "0.0001\\", "-RRB-", "-RRB-", "."], ["The", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "parameter", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "is", "set", "to", "1", "experimentally", "."], ["At", "each", "iteration", ",", "we", "sample", "5", "patch", "pairs", "-LRB-", "or", "triplets", "for", "pretext", "Task", "2", "-RRB-", "from", "each", "image", "to", "generate", "6350", "patch", "pairs", "per", "epoch", "."], ["Data", "augmentation", "-LRB-", "90", "degrees", "rotation", "and", "horizontal/vertical", "flips", "-RRB-", "are", "applied", "."]], "ner": [[[6, 8, "a"], [27, 27, "v"], [35, 35, "v"], [25, 25, "v"]], [[50, 50, "v"]], [[60, 61, "p"], [65, 65, "v"], [68, 69, "p"], [73, 73, "v"]], [[80, 80, "p"]], [[93, 93, "v"]], [], [[124, 125, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 8, "a"], [22, 22, "p"], [27, 27, "v"], [31, 31, "p"], [35, 35, "v"]], [[44, 45, "p"], [50, 51, "v"]], [[60, 61, "p"], [65, 65, "v"], [68, 69, "p"], [73, 73, "v"]], [[80, 80, "p"]], [[93, 93, "v"]], [[102, 102, "v"], [118, 118, "v"]], []], "predicted_relations": [[], [], [[65, 65, 68, 69, "USED-FOR"], [73, 73, 68, 69, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2101.08122-6b079aec-cdee-4682-bdf7-a9a1ab810ba6", "sentences": [["To", "assess", "the", "performance", "on", "the", "pretext", "tasks", ",", "we", "use", "the", "blind", "test", "set", "extracted", "from", "\\", "-LRB-", "U\\", "-RRB-", "."], ["For", "pretext", "Task", "1", ",", "we", "assess", "the", "success", "rate", "in", "the", "task", "itself", "in", "percentage", ",", "while", "for", "Task", "2", ",", "we", "consider", "the", "value", "of", "the", "loss", "."], ["We", "also", "run", "the", "pretext", "tasks", "on", "the", "12", "images", "composing", "OSCD", "test", "set", "to", "assess", "domain", "shifts", "."], ["Note", "that", "no", "OSCD", "labels", "are", "used", "at", "this", "stage", "."]], "ner": [[[19, 19, "a"]], [[23, 25, "a"], [30, 31, "a"], [50, 50, "a"]], [[63, 65, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [], [[60, 60, "v"]], [[74, 74, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2104.01371-cf7be5ee-bc0c-4c7a-9b14-65e2ae232b3f", "sentences": [["Optimization", ":", "We", "used", "Adam", "optimizer", "-LSB-", "21", "-RSB-", "with", "a", "linear", "scheduler", "that", "has", "warm-up", "steps", "."], ["The", "initial", "learning", "rate", "was", "set", "to", "be", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "BiMeanVAE", "and", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "Optimus", "."]], "ner": [[[4, 5, "a"]], [[19, 21, "p"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "a"]], [[20, 21, "p"], [28, 32, "v"], [35, 35, "a"], [39, 43, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2104.01436-fd6b4be9-53ba-4aa5-ad6b-dd5cfea0e936", "sentences": [["Hyperparameters", "such", "as", "learning", "rate", "and", "the", "number", "of", "epochs", "were", "tuned", "with", "the", "help", "of", "validation", "data", "with", "patience", "parameter", "set", "to", "4", "."], ["As", "we", "assumed", "no", "labeled", "data", "was", "available", "from", "target", "domain", ",", "we", "use", "the", "source", "domain", "validation", "set", "for", "tuning", "."], ["labeled", "data", "from", "target", "domain", "was", "used", "during", "testing", "only", "."], ["Learning", "rate", "search", "space", "was", "limited", "to", "\\", "-LRB-", "\\lbrace", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\rbrace", "\\", "-RRB-", "values", "only", "."], ["We", "trained", "BERT", "on", "a", "system", "with", "a", "`", "Nvidia", "Tesla", "P100", "'", "GPU", "with", "12GB", "GPU-RAM", ",", "96GB", "system", "RAM", "and", "56", "cores", "."], ["Our", "model", "GLEN", "was", "trained", "on", "CPU", "only", "with", "32GB", "RAM", "and", "20", "cores", "."], ["We", "used", "100", "as", "hidden", "dimension", "size", "for", "all", "experiments", "and", "300", "dimensional", "GloVe", "embeddings", "were", "used", "as", "initial", "input", "token-level", "features", "."], ["The", "number", "of", "parameters", "for", "GLEN", "was", "\\", "-LRB-", "\\approx", "664\\", "-RRB-", "k", "which", "is", "\\", "-LRB-", "\\approx", "165\\", "-RRB-", "times", "smaller", "than", "BERT", "in", "terms", "of", "number", "of", "parameters", "."], ["All", "results", "reported", "for", "GLEN", "and", "BERT", "are", "averaged", "across", "3-runs", ",", "each", "corresponding", "to", "a", "different", "random", "seed", "for", "the", "experiment", "while", "training", "."], ["Below", "we", "present", "the", "architecture", "details", "of", "our", "model", "GLEN", ":"]], "ner": [[[0, 0, "a"], [3, 4, "p"], [7, 9, "p"]], [], [], [], [[98, 98, "a"]], [[123, 123, "a"]], [[140, 142, "p"], [138, 138, "v"], [149, 150, "p"], [147, 148, "v"]], [[182, 182, "a"], [164, 164, "a"]], [[196, 196, "a"], [194, 194, "a"]], [[224, 224, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 4, "p"], [23, 23, "v"]], [], [], [[58, 59, "p"], [77, 80, "v"]], [[98, 98, "a"], [111, 111, "v"], [114, 114, "v"], [118, 118, "v"]], [[123, 123, "a"], [130, 130, "v"], [133, 133, "v"]], [[138, 138, "v"], [143, 145, "c"], [147, 148, "v"]], [[164, 164, "a"], [169, 169, "v"], [171, 171, "p"], [177, 177, "v"], [182, 182, "a"]], [[194, 194, "a"], [196, 196, "a"]], [[223, 223, "a"], [224, 224, "a"]]], "predicted_relations": [[[3, 4, 0, 0, "USED-FOR"], [7, 9, 0, 0, "USED-FOR"]], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2104.01437-67eb364c-c18a-4a34-80f6-7eb6a17bdc61", "sentences": [["where", "\\", "-LRB-", "\\bar", "-LCB-", "c", "-RCB-", ",", "\\xi", "\\", "-RRB-", "and", "\\", "-LRB-", "\\delta", "\\", "-RRB-", "are", "related", "to", "the", "SDE", "parameters", "as", "shown", "in", "equations", "-LRB-", "-RRB-", "-", "-LRB-", "-RRB-", ",", "cf", "."], ["."], ["-LRB-", "St", ",", "t", "-RRB-", "=", "4St", "e-t2", "-LRB-", "1", "-", "e-t", "-RRB-", ","]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "2104.01437-33216207-cb1e-4ee0-bd47-b2966f636f79", "sentences": [["Default", "training/testing", "parameters", "For", "GBM", ",", "the", "default", "parameters", "were", "\\", "-LRB-", "\\mu", "=0.05\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "=0.2\\", "-RRB-", "."], ["The", "CIR", "parameters", "were", "\\", "-LRB-", "\\bar", "-LCB-", "S", "-RCB-", "=0.1", ",", "S_t=0.1", ",", "\\kappa", "=0.1", ",", "\\gamma", "\\in", "\\lbrace", "0.1,0.3\\rbrace", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "\\gamma", "=0.1\\", "-RRB-", "corresponds", "to", "the", "case", "where", "the", "Feller", "condition", "is", "satisfied", "-LRB-", "\\", "-LRB-", "\\delta", "=", "4\\", "-RRB-", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=0.3\\", "-RRB-", "to", "the", "case", "where", "the", "Feller", "condition", "is", "violated", "\\", "-LRB-", "-LRB-", "\\delta", "=", "0.44", "-RRB-", "\\", "-RRB-", "."]], "ner": [[[4, 4, "a"], [12, 12, "p"], [13, 13, "v"], [18, 18, "p"], [19, 19, "v"]], [[23, 23, "a"], [32, 32, "v"], [34, 34, "v"], [37, 37, "v"], [42, 42, "v"], [50, 50, "v"], [32, 32, "v"], [34, 34, "v"], [37, 37, "v"], [42, 42, "v"], [50, 50, "v"], [36, 36, "p"], [32, 32, "v"], [34, 34, "v"], [37, 37, "v"], [42, 42, "v"], [50, 50, "v"], [39, 39, "p"], [49, 49, "p"], [73, 73, "p"], [32, 32, "v"], [34, 34, "v"], [37, 37, "v"], [42, 42, "v"], [50, 50, "v"], [42, 42, "v"], [74, 74, "v"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "a"], [13, 13, "v"], [19, 19, "v"]], [[39, 39, "p"], [41, 42, "v"], [49, 49, "p"], [50, 50, "v"], [67, 67, "v"], [73, 73, "p"], [74, 74, "v"], [90, 90, "v"]]], "predicted_relations": [[[12, 12, 4, 4, "USED-FOR"], [18, 18, 4, 4, "USED-FOR"], [19, 19, 12, 12, "USED-FOR"], [19, 19, 18, 18, "USED-FOR"]], [[32, 32, 36, 36, "USED-FOR"], [32, 32, 39, 39, "USED-FOR"], [34, 34, 36, 36, "USED-FOR"], [37, 37, 36, 36, "USED-FOR"], [37, 37, 39, 39, "USED-FOR"], [37, 37, 49, 49, "USED-FOR"], [42, 42, 36, 36, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [50, 50, 36, 36, "USED-FOR"], [50, 50, 39, 39, "USED-FOR"], [50, 50, 49, 49, "USED-FOR"], [32, 32, 36, 36, "USED-FOR"], [32, 32, 39, 39, "USED-FOR"], [34, 34, 36, 36, "USED-FOR"], [37, 37, 36, 36, "USED-FOR"], [37, 37, 39, 39, "USED-FOR"], [37, 37, 49, 49, "USED-FOR"], [42, 42, 36, 36, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [50, 50, 36, 36, "USED-FOR"], [50, 50, 39, 39, "USED-FOR"], [50, 50, 49, 49, "USED-FOR"], [36, 36, 23, 23, "USED-FOR"], [32, 32, 36, 36, "USED-FOR"], [32, 32, 39, 39, "USED-FOR"], [34, 34, 36, 36, "USED-FOR"], [37, 37, 36, 36, "USED-FOR"], [37, 37, 39, 39, "USED-FOR"], [37, 37, 49, 49, "USED-FOR"], [42, 42, 36, 36, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [50, 50, 36, 36, "USED-FOR"], [50, 50, 39, 39, "USED-FOR"], [50, 50, 49, 49, "USED-FOR"], [39, 39, 23, 23, "USED-FOR"], [49, 49, 23, 23, "USED-FOR"], [32, 32, 36, 36, "USED-FOR"], [32, 32, 39, 39, "USED-FOR"], [34, 34, 36, 36, "USED-FOR"], [37, 37, 36, 36, "USED-FOR"], [37, 37, 39, 39, "USED-FOR"], [37, 37, 49, 49, "USED-FOR"], [42, 42, 36, 36, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [50, 50, 36, 36, "USED-FOR"], [50, 50, 39, 39, "USED-FOR"], [50, 50, 49, 49, "USED-FOR"], [42, 42, 36, 36, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [74, 74, 73, 73, "USED-FOR"]]]}
{"doc_key": "2102.02274-166e80b0-2a6b-4054-9dbe-b8fb4754b6a3", "sentences": [["The", "training", "process", "for", "both", "environments", "uses", "the", "distributed", "actor-critic", "setup", "of", "the", "Importance", "Weighted", "Actor-Learner", "Architecture", "-LSB-", "15", "-RSB-", "-LRB-", "but", "other", "RL", "algorithms", "are", "also", "compatible", "-RRB-", "."], ["Each", "actor", "generates", "trajectories", ",", "which", "are", "sent", "to", "the", "learner", "in", "chunks", "of", "100", "environment", "steps", "."], ["The", "learner", "then", "optimizes", "the", "RL", "and", "belief", "losses", "jointly", "."], ["Further", "details", "on", "hyper-parameters", "used", "are", "given", "in", "Appendix", "."]], "ner": [[[13, 16, "a"]], [], [[53, 56, "a"]], [[62, 62, "a"], [62, 62, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[15, 16, "a"]], [[44, 44, "v"]], [[55, 56, "a"]], []], "predicted_relations": [[], [], [], [[62, 62, 62, 62, "USED-FOR"]]]}
{"doc_key": "2102.02274-f5eae6c5-d1bc-4dba-bc76-d07389eb5fcf", "sentences": [["We", "experiment", "with", "the", "two", "versions", "of", "the", "Tiger", "game", "to", "evaluate", "the", "ability", "to", "learn", "agents", "'", "beliefs", "and", "use", "these", "beliefs", "to", "learn", "the", "policies", "via", "RL", "."], ["We", "run", "these", "experiments", "following", "the", "same", "training", "method", "and", "architecture", "as", "detailed", "in", "Appendix", "."], ["In", "the", "first", "experiment", ",", "we", "match", "P2", "with", "an", "\u201c", "optimal", "\u201d", "P1", "in", "the", "version", "of", "the", "game", "with", "two", "players", "."], ["The", "input", "to", "the", "policy", "and", "value", "functions", "for", "P2", "is", "thus", "composed", "of", "samples", "\\", "-LRB-", "b_t^1", "-LRB-", "P2", "-RRB-", "\\", "-RRB-", "from", "its", "own", "belief", "model", "-LRB-", "thus", ",", "if", "the", "model", "is", "correct", ",", "the", "policy", "should", "be", "able", "to", "learn", "how", "to", "map", "these", "samples", "to", "the", "right", "actions", "-RRB-", "."], ["In", "the", "second", "experiment", ",", "we", "evaluate", "the", "second", "version", "of", "Tiger", "with", "three", "players", "."], ["We", "match", "P3", "against", "an", "optimal", "P2", ",", "and", "learn", "the", "policy", "and", "value", "conditioned", "on", "\\", "-LRB-", "b_t^2", "-LRB-", "P3", "-RRB-", "\\", "-RRB-", "."], ["We", "observe", "in", "Fig", "."], ["REF", "how", "in", "both", "cases", ",", "only", "the", "agents", "that", "learn", "from", "\\", "-LRB-", "K=10\\", "-RRB-", "samples", "can", "solve", "the", "problem", ",", "while", "agents", "that", "learn", "from", "\\", "-LRB-", "K=1\\", "-RRB-", "samples", "-LRB-", "i.e", "."], ["theoretically", "unable", "to", "learn", "the", "correct", "higher", "order", "beliefs", "-RRB-", "catastrophically", "fail", "."]], "ner": [[[8, 9, "a"], [28, 28, "a"]], [], [], [[74, 77, "a"], [87, 87, "v"]], [], [], [], [[185, 185, "p"], [200, 200, "p"], [185, 185, "v"], [200, 200, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "v"], [8, 9, "a"]], [], [[67, 67, "v"]], [], [[136, 136, "a"], [138, 138, "v"]], [], [], [[185, 185, "v"], [200, 200, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [[185, 185, 185, 185, "USED-FOR"], [200, 200, 185, 185, "USED-FOR"], [200, 200, 200, 200, "USED-FOR"], [185, 185, 185, 185, "USED-FOR"], [200, 200, 185, 185, "USED-FOR"], [200, 200, 200, 200, "USED-FOR"]], []]}
{"doc_key": "2101.09060-f9403dec-51c6-498d-bfda-af43d4cc9e25", "sentences": [["For", "the", "classification", "model", "\\", "-LRB-", "C\\", "-RRB-", "we", "use", "AlexNet", "and", "ResNet18", "backbones", "."], ["Specifically", ",", "Baseline", ",", "Rotation", "and", "Mixup", "are", "trained", "using", "SGD", "with", "\\", "-LRB-", "0.9\\", "-RRB-", "momentum", "for", "\\", "-LRB-", "30k\\", "-RRB-", "iterations", "."], ["We", "set", "the", "batch", "size", "to", "32", "images", "per", "source", "domain", ":", "since", "in", "all", "the", "testbed", "there", "are", "three", "source", "domains", "each", "data", "batch", "contains", "96", "images", "."], ["The", "learning", "rate", "and", "the", "weigh", "decay", "are", "respectively", "fixed", "to", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["Regarding", "the", "hyperparameters", "of", "the", "individual", "algorithms", ",", "we", "empirically", "set", "the", "Rotation", "auxiliary", "weight", "to", "\\", "-LRB-", "\\eta", "=", "0.5\\", "-RRB-", "and", "for", "Mixup", "\\", "-LRB-", "\\gamma", "=", "0.4\\", "-RRB-", "."]], "ner": [[[10, 10, "a"], [12, 12, "a"]], [[17, 17, "a"], [19, 19, "a"], [21, 21, "a"]], [], [], [[101, 101, "a"], [102, 103, "p"], [109, 109, "v"], [113, 113, "a"], [116, 116, "p"], [118, 118, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "p"], [10, 10, "a"], [12, 12, "a"]], [[19, 19, "a"], [21, 21, "a"], [25, 25, "a"], [29, 29, "v"], [31, 31, "p"], [35, 35, "v"]], [[42, 43, "p"], [45, 45, "v"], [58, 58, "v"], [65, 65, "v"]], [[69, 70, "p"], [73, 74, "p"], [81, 81, "v"], [86, 86, "v"]], [[109, 109, "v"], [113, 113, "a"], [116, 116, "p"], [118, 118, "v"]]], "predicted_relations": [[], [], [], [], [[102, 103, 101, 101, "USED-FOR"], [116, 116, 101, 101, "USED-FOR"], [116, 116, 113, 113, "USED-FOR"]]]}
{"doc_key": "2110.04544-9ae94cbe-a15d-4146-942f-7d2bfc83784a", "sentences": [["The", "first", "variant", "of", "CLIP-Adapter", "is", "adopted", "by", "default", "if", "not", "specified", ",", "which", "finetunes", "the", "image", "feature", "while", "freezes", "the", "classifier", "weight", "."], ["In", "other", "words", ",", "it", "only", "implements", "CLIP-Adapter", "for", "the", "visual", "adapter", "."], ["The", "results", "of", "other", "variants", "that", "activate", "text", "adapter", "are", "presented", "in", "Section", "REF", "."], ["We", "use", "the", "same", "training", "hyperparameters", "as", "CoOp", ",", "including", "a", "batch", "size", "of", "32", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "all", "datasets", "except", "for", "the", "residual", "ratio", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "."], ["We", "perform", "hyperparameter", "searching", "over", "different", "value", "selections", "of", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "for", "each", "dataset", "and", "report", "the", "best", "performance", "among", "all", "searching", "spaces", "."], ["We", "use", "ResNet-50", "-LSB-", "16", "-RSB-", "as", "the", "visual", "backbone", "-LRB-", "visual", "encoder", "-RRB-", "and", "BERT", "-LSB-", "22", "-RSB-", "as", "classifier", "weight", "generator", "-LRB-", "textual", "encoder", "-RRB-", "."], ["The", "hidden", "embedding", "dimensionality", "of", "both", "visual", "and", "text", "bottleneck", "layers", "is", "set", "to", "256", ",", "which", "is", "a", "quarter", "of", "the", "original", "embedding", "dimensionality", "."], ["In", "contrast", "to", "the", "learnable", "continuous", "prompts", "in", "CoOp", ",", "simple", "hand-crafted", "hard", "prompts", "are", "utilized", "as", "the", "text", "inputs", "of", "CLIP-Adapter", ",", "which", "is", "the", "same", "as", "CLIP", "."], ["For", "generic-category", "image", "datasets", ",", "such", "as", "ImageNet", ",", "we", "adopt", "\u201c", "a", "photo", "of", "a", "-LCB-", "class", "-RCB-", "\u201d", "as", "the", "hard", "prompt", "template", "."], ["For", "fine-grained", "classification", "datasets", ",", "we", "specify", "its", "corresponding", "domain", "keyword", "in", "the", "template", "for", "a", "better", "performance", ",", "for", "instance", ",", "\u201c", "a", "centered", "satellite", "photo", "of", "-LCB-", "class", "-RCB-", "''", "for", "EuroSAT", ",", "and", "similarly", "for", "other", "fine-grained", "datasets", "."]], "ner": [[[4, 4, "a"]], [[31, 31, "a"]], [], [[59, 59, "a"], [63, 64, "p"], [66, 66, "v"], [69, 70, "p"], [87, 88, "a"], [91, 91, "p"]], [[106, 106, "p"], [100, 102, "v"], [97, 98, "c"]], [[124, 124, "a"], [137, 137, "a"]], [], [[197, 197, "a"], [184, 184, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"]], [[31, 31, "a"]], [], [[63, 64, "p"], [66, 66, "v"], [69, 70, "p"], [75, 78, "v"], [81, 83, "c"], [87, 88, "p"], [91, 91, "p"]], [[106, 106, "p"]], [[124, 124, "a"], [137, 137, "a"]], [[164, 164, "v"], [169, 169, "v"]], [[197, 197, "a"]], [[213, 213, "a"]], [[265, 265, "a"]]], "predicted_relations": [[], [], [], [[63, 64, 59, 59, "USED-FOR"], [69, 70, 59, 59, "USED-FOR"], [91, 91, 87, 88, "USED-FOR"]], [[97, 98, 100, 102, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2112.04674-1fc3b18d-bda9-402a-acc5-2c0a8ea504c7", "sentences": [["When", "pretraining", "our", "DualFormer", "on", "ImageNet-1K", ",", "we", "mostly", "follow", "the", "settings", "of", "DeiT", "-LSB-", "46", "-RSB-", "and", "Swin", "-LSB-", "34", "-RSB-", "."], ["To", "be", "more", "specific", ",", "we", "employ", "an", "AdamW", "optimizer", "-LSB-", "27", "-RSB-", "for", "300", "epochs", "together", "with", "a", "cosine", "decay", "learning", "rate", "scheduler", "and", "20", "epochs", "of", "linear", "warm-up", "."], ["The", "batch", "size", "is", "set", "to", "1024", ",", "and", "the", "initial", "learning", "rate", "is", "0.001", "."], ["To", "avoid", "overfitting", ",", "a", "weight", "decay", "rate", "of", "0.05", "is", "used", "in", "our", "method", "."], ["We", "include", "most", "of", "the", "augmentation", "and", "regularization", "strategies", "of", "-LSB-", "46", "-RSB-", "in", "training", ",", "except", "for", "repeated", "augmentation", "and", "exponential", "moving", "average", "-LRB-", "EMA", "-RRB-", ",", "which", "has", "been", "verified", "ineffective", "in", "Swin", "-LSB-", "34", "-RSB-", "."]], "ner": [[[5, 5, "a"], [13, 13, "a"], [18, 18, "a"]], [[31, 32, "a"], [44, 45, "p"], [42, 46, "a"]], [[65, 66, "p"], [68, 68, "v"]], [[75, 77, "p"], [79, 79, "v"]], [[120, 120, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [13, 13, "a"], [18, 18, "a"]], [[31, 31, "a"], [37, 37, "v"], [38, 38, "p"], [42, 43, "a"], [48, 48, "v"], [49, 49, "p"], [51, 52, "a"]], [[55, 56, "p"], [60, 60, "v"], [65, 66, "p"], [68, 68, "v"]], [[75, 77, "p"], [79, 79, "v"], [84, 84, "a"]], [[107, 112, "a"], [120, 120, "a"]]], "predicted_relations": [[], [[44, 45, 31, 32, "USED-FOR"]], [], [[79, 79, 75, 77, "USED-FOR"]], []]}
{"doc_key": "2112.04674-535cf6c1-03f4-42c4-b934-76ddd0a4bb52", "sentences": [["For", "DualFormer-B", ",", "we", "also", "pretrain", "it", "on", "the", "larger", "version", "of", "ImageNet", ",", "i.e.", ",", "the", "ImageNet-21K", "dataset", "which", "contains", "14.2", "million", "images", "and", "22", "thousand", "classes", "."], ["Following", "Swin", "Transformer", "-LSB-", "34", "-RSB-", ",", "we", "utilize", "an", "AdamW", "optimizer", "for", "100", "epochs", "using", "a", "linear", "decay", "learning", "rate", "scheduler", "with", "a", "5-epoch", "linear", "warm-up", "strategy", "."], ["A", "batch", "size", "of", "1024", ",", "an", "initial", "learning", "rate", "of", "5e-4", ",", "and", "a", "weight", "decay", "of", "0.01", "are", "used", "."], ["We", "also", "employ", "a", "stochastic", "depth", "drop", "rate", "0.2", "to", "improve", "its", "generalization", "ability", "."]], "ner": [[[17, 18, "a"]], [[39, 40, "a"], [30, 31, "a"]], [[59, 60, "p"], [62, 62, "v"], [65, 67, "p"], [69, 69, "v"], [73, 74, "p"], [76, 76, "v"]], [[84, 87, "a"], [86, 87, "p"], [88, 88, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"], [12, 12, "a"], [17, 18, "a"], [21, 21, "v"], [25, 25, "v"]], [[30, 31, "a"], [39, 39, "a"], [42, 42, "v"], [43, 43, "p"], [46, 47, "a"], [53, 53, "v"]], [[59, 60, "p"], [62, 62, "v"], [66, 67, "p"], [69, 69, "v"], [73, 74, "p"], [76, 76, "v"]], [[84, 87, "p"], [88, 88, "v"]]], "predicted_relations": [[], [], [[69, 69, 65, 67, "USED-FOR"], [76, 76, 73, 74, "USED-FOR"]], []]}
{"doc_key": "2111.11113-8598d371-81bd-4cd2-b2d3-8552cfb353ce", "sentences": [["The", "neural", "networks", "were", "fitted", "to", "the", "training", "data", "using", "similar", "architectures", "."], ["For", "ProNet", ",", "we", "used", "an", "FNN-based", "encoder", "with", "two", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "ReLu", "as", "activation", "function", "."], ["For", "ProSeNet", ",", "we", "used", "an", "RNN-based", "encoder", "with", "two", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "tanh", "as", "activation", "function", "."], ["The", "FNN", "baseline", "had", "two", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "ReLu", "as", "activation", "function", "."], ["The", "RNN", "baseline", "had", "2", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "tanh", "as", "activation", "function", "."], ["A", "linear", "layer", "was", "added", "to", "the", "baseline", "models", "to", "obtain", "predictions", "of", "the", "right", "shape", "."]], "ner": [[], [[19, 20, "a"], [28, 28, "v"], [33, 34, "p"], [31, 31, "v"], [28, 28, "v"], [33, 34, "p"], [28, 28, "v"], [33, 34, "p"], [31, 31, "v"], [28, 28, "v"], [33, 34, "p"]], [[51, 51, "v"], [56, 57, "p"], [42, 43, "a"], [51, 51, "v"], [56, 57, "p"], [54, 54, "v"], [51, 51, "v"], [56, 57, "p"], [51, 51, "v"], [56, 57, "p"], [54, 54, "v"]], [[69, 69, "v"], [74, 75, "p"], [72, 72, "v"], [69, 69, "v"], [74, 75, "p"], [60, 61, "a"], [69, 69, "v"], [74, 75, "p"], [72, 72, "v"], [69, 69, "v"], [74, 75, "p"]], [[81, 81, "v"], [87, 87, "v"], [92, 93, "p"], [81, 81, "v"], [87, 87, "v"], [92, 93, "p"], [90, 90, "v"], [81, 81, "v"], [87, 87, "v"], [92, 93, "p"], [78, 79, "a"], [81, 81, "v"], [87, 87, "v"], [92, 93, "p"], [90, 90, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[14, 14, "a"], [19, 19, "a"], [22, 22, "v"], [28, 28, "v"], [31, 31, "a"]], [[37, 37, "a"], [45, 45, "v"], [51, 51, "v"], [54, 54, "a"]], [[60, 60, "a"], [63, 63, "v"], [69, 69, "v"], [72, 72, "a"]], [[78, 78, "a"], [81, 81, "v"], [87, 87, "v"], [90, 90, "a"]], []], "predicted_relations": [[], [[33, 34, 19, 20, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [33, 34, 19, 20, "USED-FOR"], [33, 34, 19, 20, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [31, 31, 33, 34, "USED-FOR"], [33, 34, 19, 20, "USED-FOR"]], [[56, 57, 42, 43, "USED-FOR"], [56, 57, 42, 43, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [56, 57, 42, 43, "USED-FOR"], [56, 57, 42, 43, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"], [54, 54, 56, 57, "USED-FOR"]], [[74, 75, 60, 61, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [74, 75, 60, 61, "USED-FOR"], [74, 75, 60, 61, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [72, 72, 74, 75, "USED-FOR"], [74, 75, 60, 61, "USED-FOR"]], [[92, 93, 78, 79, "USED-FOR"], [92, 93, 78, 79, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [92, 93, 78, 79, "USED-FOR"], [92, 93, 78, 79, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"], [90, 90, 92, 93, "USED-FOR"]], []]}
{"doc_key": "2111.11113-c4a407f8-5976-4d65-823e-08c8d213cd1b", "sentences": [["We", "trained", "all", "neural", "networks", "over", "400", "epochs", ",", "using", "a", "batch", "size", "of", "64", "for", "RNN", "and", "ProSeNet", ",", "and", "1024", "for", "FNN", "and", "ProNet", "."], ["For", "optimization", ",", "the", "Adam", "algorithm", "was", "used", "with", "default", "parameters", ",", "learning", "rate", "0.001", "and", "weight", "decay", "0.001", "."], ["The", "NLL", "was", "used", "as", "loss", "function", "."], ["For", "ProNet", "and", "ProSeNet", ",", "we", "selected", "parameters", "of", "the", "diversity", "regularization", "\\", "-LRB-", "-LRB-", "d_", "-LCB-", "\\textrm", "-LCB-", "min", "-RCB-", "-RCB-", ",", "\\lambda", "_", "-LCB-", "d", "-RCB-", "-RRB-", "\\", "-RRB-", "by", "performing", "3-fold", "cross-validation", "over", "a", "grid", "of", "points", "in", "the", "parameter", "space", "\\", "-LRB-", "\\lbrace", "1", ",", "2", ",", "3", ",", "4", ",", "5\\rbrace", "\\times", "\\lbrace", "0.00001", ",", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1\\rbrace", "\\", "-RRB-", "."], ["Note", "that", "these", "parameters", "were", "optimized", "for", "each", "combination", "of", "prototypes", "\\", "-LRB-", "n\\", "-RRB-", "and", "prediction", "prototypes", "\\", "-LRB-", "q\\", "-RRB-", "in", "our", "experiments", "."], ["The", "parameters", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "c", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "e", "-RCB-", "\\", "-RRB-", "were", "set", "to", "0.001", ",", "and", "we", "performed", "the", "projection", "step", ",", "see", "-LRB-", "REF", "-RRB-", ",", "every", "fifth", "epoch", "."]], "ner": [[], [[31, 32, "a"], [39, 40, "p"], [41, 41, "v"], [45, 45, "v"], [43, 44, "p"], [41, 41, "v"], [45, 45, "v"], [41, 41, "v"], [45, 45, "v"], [41, 41, "v"], [45, 45, "v"], [41, 41, "v"], [45, 45, "v"]], [[48, 48, "a"]], [[117, 117, "v"], [117, 117, "v"], [65, 66, "a"], [102, 102, "v"], [121, 121, "v"], [104, 104, "v"], [88, 88, "v"], [106, 106, "v"], [108, 108, "v"], [110, 110, "v"], [113, 113, "v"], [115, 115, "v"], [117, 117, "v"], [119, 119, "v"], [121, 121, "v"], [117, 117, "v"], [117, 117, "v"]], [], [[175, 175, "v"], [175, 175, "v"], [175, 175, "v"], [175, 175, "v"], [175, 175, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [6, 6, "v"], [7, 7, "p"], [11, 12, "p"], [14, 14, "v"], [16, 16, "a"], [18, 18, "a"], [21, 21, "v"], [23, 23, "a"], [25, 25, "a"]], [[31, 32, "a"], [39, 40, "p"], [41, 41, "v"], [43, 44, "p"], [45, 45, "v"]], [[48, 48, "a"]], [[56, 56, "a"], [58, 58, "a"], [65, 66, "p"], [88, 88, "v"], [89, 89, "a"], [115, 115, "v"], [117, 117, "v"]], [], [[155, 159, "p"], [165, 169, "p"], [175, 175, "v"], [190, 190, "v"]]], "predicted_relations": [[], [[39, 40, 31, 32, "USED-FOR"], [41, 41, 39, 40, "USED-FOR"], [41, 41, 43, 44, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"], [43, 44, 31, 32, "USED-FOR"], [41, 41, 39, 40, "USED-FOR"], [41, 41, 43, 44, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"], [41, 41, 39, 40, "USED-FOR"], [41, 41, 43, 44, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"], [41, 41, 39, 40, "USED-FOR"], [41, 41, 43, 44, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"], [41, 41, 39, 40, "USED-FOR"], [41, 41, 43, 44, "USED-FOR"], [45, 45, 43, 44, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2111.11113-9a45cc34-b9ea-446a-82ea-88231db48b81", "sentences": [["Since", "we", "used", "the", "full", "state", "representation", ",", "we", "could", "safely", "make", "the", "Markov", "assumption", "and", "estimate", "the", "behavior", "policy", "using", "FNN-based", "models", "."], ["For", "ProNet", ",", "we", "used", "an", "FNN-based", "encoder", "with", "two", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "ReLu", "as", "activation", "function", "."], ["The", "FNN", "baseline", "had", "two", "layers", "-LRB-", "each", "of", "size", "64", "-RRB-", "and", "ReLu", "as", "activation", "function", "."], ["A", "linear", "layer", "was", "added", "to", "obtain", "predictions", "of", "the", "right", "shape", "."], ["We", "trained", "all", "models", "over", "30", "epochs", ",", "using", "a", "batch", "size", "of", "128", "."], ["For", "optimization", ",", "the", "Adam", "algorithm", "was", "used", "with", "default", "parameters", ",", "learning", "rate", "0.001", "and", "weight", "decay", "0.001", "."], ["Again", ",", "we", "selected", "parameters", "of", "the", "diversity", "regularization", "\\", "-LRB-", "-LRB-", "d_", "-LCB-", "\\textrm", "-LCB-", "min", "-RCB-", "-RCB-", ",", "\\lambda", "_", "-LCB-", "d", "-RCB-", "-RRB-", "\\", "-RRB-", "by", "performing", "3-fold", "cross-validation", "over", "a", "grid", "of", "points", "in", "the", "parameter", "space", "\\", "-LRB-", "\\lbrace", "1", ",", "2", ",", "3", ",", "4", ",", "5\\rbrace", "\\times", "\\lbrace", "0.00001", ",", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1\\rbrace", "\\", "-RRB-", "."], ["The", "parameters", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "c", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "e", "-RCB-", "\\", "-RRB-", "were", "set", "to", "0.001", ",", "and", "we", "performed", "the", "projection", "step", "every", "fifth", "epoch", "."]], "ner": [[], [[30, 31, "a"], [34, 34, "p"], [39, 39, "v"], [36, 38, "c"], [39, 39, "v"], [36, 38, "c"], [44, 45, "p"], [42, 42, "v"], [34, 34, "p"], [39, 39, "v"], [36, 38, "c"], [39, 39, "v"], [36, 38, "c"], [44, 45, "p"], [42, 42, "v"]], [[52, 52, "p"], [57, 57, "v"], [54, 56, "c"], [57, 57, "v"], [54, 56, "c"], [62, 63, "p"], [60, 60, "v"], [48, 49, "a"], [52, 52, "p"], [57, 57, "v"], [54, 56, "c"], [57, 57, "v"], [54, 56, "c"], [62, 63, "p"], [60, 60, "v"]], [], [], [[97, 98, "a"], [105, 106, "p"], [107, 107, "v"], [111, 111, "v"], [109, 110, "p"], [107, 107, "v"], [111, 111, "v"], [107, 107, "v"], [111, 111, "v"]], [[172, 172, "v"], [172, 172, "v"], [120, 121, "a"], [157, 157, "v"], [176, 176, "v"], [159, 159, "v"], [143, 143, "v"], [161, 161, "v"], [163, 163, "v"], [165, 165, "v"], [168, 168, "v"], [170, 170, "v"], [172, 172, "v"], [174, 174, "v"], [176, 176, "v"]], [[204, 204, "v"], [204, 204, "v"], [204, 204, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[25, 25, "a"], [33, 33, "v"], [34, 34, "p"], [39, 39, "v"], [42, 42, "a"]], [[48, 48, "a"], [51, 51, "v"], [57, 57, "v"], [60, 60, "a"]], [], [[83, 83, "v"], [84, 84, "p"], [88, 89, "p"], [91, 91, "v"]], [[97, 98, "a"], [105, 106, "p"], [107, 107, "v"], [109, 110, "p"], [111, 111, "v"]], [[120, 121, "a"], [133, 138, "p"], [143, 143, "v"], [144, 144, "a"], [168, 168, "v"], [170, 170, "v"], [172, 172, "v"], [174, 174, "v"]], [[184, 188, "p"], [194, 198, "p"], [204, 204, "v"], [213, 213, "v"]]], "predicted_relations": [[], [[34, 34, 30, 31, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [44, 45, 30, 31, "USED-FOR"], [42, 42, 44, 45, "USED-FOR"], [42, 42, 44, 45, "USED-FOR"], [34, 34, 30, 31, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [39, 39, 44, 45, "USED-FOR"], [44, 45, 30, 31, "USED-FOR"], [42, 42, 44, 45, "USED-FOR"], [42, 42, 44, 45, "USED-FOR"]], [[52, 52, 48, 49, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [62, 63, 48, 49, "USED-FOR"], [60, 60, 62, 63, "USED-FOR"], [60, 60, 62, 63, "USED-FOR"], [52, 52, 48, 49, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [57, 57, 62, 63, "USED-FOR"], [62, 63, 48, 49, "USED-FOR"], [60, 60, 62, 63, "USED-FOR"], [60, 60, 62, 63, "USED-FOR"]], [], [], [[105, 106, 97, 98, "USED-FOR"], [107, 107, 105, 106, "USED-FOR"], [107, 107, 109, 110, "USED-FOR"], [111, 111, 109, 110, "USED-FOR"], [109, 110, 97, 98, "USED-FOR"], [107, 107, 105, 106, "USED-FOR"], [107, 107, 109, 110, "USED-FOR"], [111, 111, 109, 110, "USED-FOR"], [107, 107, 105, 106, "USED-FOR"], [107, 107, 109, 110, "USED-FOR"], [111, 111, 109, 110, "USED-FOR"]], [], []]}
{"doc_key": "2111.00974-a751484c-b825-43a2-b56b-6ad11f89acf7", "sentences": [["We", "set", "hyperparameters", "following", "the", "previous", "work", "-LSB-", "20", "-RSB-", ",", "either", "with", "or", "without", "augmented", "data", "."], ["For", "data", "augmentation", ",", "relation", "path", "rules", "of", "length", "1", "to", "6", "are", "mined", "and", "applied", ";", "see", "Section", "REF", ",", "\\", "-LRB-", "-LRB-", "1", "-RRB-", "\\", "-RRB-", "and", "Appendix", "."], ["The", "threshold", "values", "for", "data", "augmentation", "are", "set", "by", "grid", "search", "over", "\\", "-LRB-", "\\textit", "-LCB-", "topN", "-RCB-", "\\in", "\\lbrace", "5,50\\rbrace", "\\", "-RRB-", "and", "\\", "-LRB-", "\\textit", "-LCB-", "confTh", "-RCB-", "\\in", "\\lbrace", "0", ",", "0.6\\rbrace", "\\", "-RRB-", "."], ["These", "threshold", "values", "and", "early", "stopping", "of", "the", "training", "are", "determined", "by", "the", "MRR", "on", "the", "validation", "data", "."], ["See", "Appendix", "for", "the", "tuned", "values", "of", "hyperparameters", "and", "the", "selected", "thresholds", "."]], "ner": [[], [[19, 20, "a"]], [[53, 54, "a"], [65, 65, "p"], [69, 69, "v"], [69, 69, "v"], [77, 77, "p"], [81, 81, "v"], [83, 83, "v"], [83, 83, "v"]], [[91, 92, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[27, 27, "v"], [29, 29, "v"]], [[68, 69, "v"], [80, 83, "v"]], [], []], "predicted_relations": [[], [], [[65, 65, 53, 54, "USED-FOR"], [77, 77, 53, 54, "USED-FOR"]], [], []]}
{"doc_key": "2111.00974-4293149e-5a22-4563-9c22-99cccd59159c", "sentences": [["where", "\\", "-LRB-", "E\\", "-RRB-", "is", "the", "set", "of", "all", "entities", "in", "the", "KG", ",", "\\", "-LRB-", "f\\", "-RRB-", "represents", "the", "score", "function", "of", "the", "model", ",", "and", "\\", "-LRB-", "\\sigma", "\\", "-RRB-", "is", "the", "sigmoid", "function", "."], ["The", "label", "\\", "-LRB-", "y_", "-LCB-", "e^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "=", "1\\", "-RRB-", "if", "\\", "-LRB-", "-LRB-", "e_h", ",", "r", ",", "e^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "\\", "-RRB-", "is", "originally", "in", "the", "KG", "."], ["If", "\\", "-LRB-", "-LRB-", "e_h", ",", "r", ",", "e^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "\\", "-RRB-", "is", "an", "augmented", "triplet", ",", "then", "\\", "-LRB-", "y_", "-LCB-", "e^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "\\", "-RRB-", "is", "set", "to", "its", "weight", "-LRB-", "see", "Section", "REF", ",", "\\", "-LRB-", "-LRB-", "2", "-RRB-", "\\", "-RRB-", "-RRB-", "."], ["If", "the", "triplet", "is", "neither", "in", "the", "KG", "nor", "an", "augmented", "triplet", ",", "then", "\\", "-LRB-", "y_", "-LCB-", "e^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "=", "0\\", "-RRB-", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[], [], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.07091-12ef6050-0f99-4c44-8217-a055cc5b46b2", "sentences": [["For", "each", "of", "the", "experiments", ",", "we", "used", "a", "CNN", "as", "the", "base", "network", ",", "with", "different", "numbers", "of", "layers", "depending", "the", "dataset", "image", "sizes", "."], ["Figure", "REF", "shows", "the", "architectures", "of", "the", "base", "networks", "."], ["We", "construct", "the", "other", "models", "from", "the", "base", "networks", "as", "discussed", "in", "the", "main", "paper", "."], ["For", "the", "On", "and", "Off", "Center", "convolutions", "in", "OOCS-CNNs", ",", "we", "used", "kernels", "of", "size", "\\", "-LRB-", "5\\times", "5\\", "-RRB-", "for", "Imagenet", "and", "Norb", "datasets", "."], ["We", "used", "smaller", "kernels", "of", "size", "\\", "-LRB-", "3\\times", "3\\", "-RRB-", "for", "the", "MNIST", "dataset", ",", "since", "the", "images", "are", "of", "smaller", "size", "."], ["We", "calculated", "the", "On", "and", "Off", "resposes", "from", "the", "inputs", "and", "directly", "fed", "their", "summation", "to", "the", "network", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[9, 9, "a"]], [], [], [[73, 76, "c"], [54, 58, "a"], [73, 76, "c"]], [[91, 92, "c"], [91, 92, "c"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"]], [], [], [[60, 60, "a"], [70, 70, "v"], [73, 73, "a"], [75, 75, "a"]], [[87, 87, "v"], [91, 92, "a"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2106.07091-6426bb17-d848-4b71-b192-866050200017", "sentences": [["We", "had", "batch", "sizes", "of", "64", "in", "all", "experiments", "."], ["We", "used", "Adam", "optimiser", "-LSB-", "9", "-RSB-", "for", "experiments", "on", "Imagenet", "and", "Norb", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["In", "the", "experiment", "on", "Imagenet", ",", "we", "decreased", "the", "learning", "rate", "to", "half", "after", "10", "epochs", "which", "was", "mainly", "in", "favour", "of", "the", "baselines", "."], ["In", "the", "Imagenet", "experiments", "with", "ResNet-34", "we", "use", "SGD", "optimiser", "and", "start", "with", "a", "learning", "rate", "of", "0.1", ",", "which", "we", "decay", "by", "a", "factor", "of", "0.1", "every", "20", "epochs", "and", "we", "trained", "the", "networks", "for", "60", "epochs", "."], ["For", "scaling", "the", "gradient", "descent", "steps", ",", "we", "use", "a", "Nesterov-momentum", "of", "0.9", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [[12, 13, "a"], [26, 27, "p"], [26, 27, "p"]], [[47, 48, "p"], [47, 48, "p"]], [[77, 78, "p"], [80, 80, "v"], [89, 89, "v"], [71, 72, "a"], [77, 78, "p"], [80, 80, "v"], [89, 89, "v"]], [[112, 112, "p"], [114, 114, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 3, "p"], [5, 5, "v"]], [[12, 12, "a"], [20, 20, "a"], [22, 22, "a"], [26, 27, "p"], [31, 34, "v"]], [[42, 42, "a"], [47, 48, "p"], [50, 50, "v"], [52, 52, "v"], [53, 53, "p"]], [[65, 65, "a"], [68, 68, "a"], [71, 71, "a"], [77, 78, "p"], [80, 80, "v"], [89, 89, "v"], [91, 91, "v"], [92, 92, "p"], [99, 99, "v"], [100, 100, "p"]], [[105, 106, "a"], [112, 112, "a"], [114, 114, "v"]], []], "predicted_relations": [[], [[26, 27, 12, 13, "USED-FOR"], [26, 27, 12, 13, "USED-FOR"]], [], [[77, 78, 71, 72, "USED-FOR"], [77, 78, 71, 72, "USED-FOR"]], [[114, 114, 112, 112, "USED-FOR"]], []]}
{"doc_key": "2106.07020-194824ee-aa00-48f2-967b-dde6f309babf", "sentences": [["The", "training", "of", "all", "the", "neural", "network", "models", "was", "performed", "at", "a", "PC", "with", "GTX-1080Ti", "GPUs", ",", "using", "Keras", "-LSB-", "4", "-RSB-", "with", "a", "Tensorflow", "-LSB-", "5", "-RSB-", "backend", "."], ["For", "a", "simple", "regression", "model", ",", "the", "following", "training", "parameters", "were", "set", "."], ["An", "optimizer", "RMSprop", "was", "chosen", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "which", "was", "reduced", "with", "patience", "5", "."], ["There", "were", "20", "epochs", "with", "100", "steps", "per", "epoch", "."], ["The", "batch", "size", "was", "specified", "to", "be", "30", "with", "an", "image", "size", "of", "\\", "-LRB-", "256", "*", "256\\", "-RRB-", "pixels", "."], ["A", "model", "based", "on", "GAN", "training", "parameters", "was", "as", "follows", "."], ["Loss", "functions", "were", "chosen", "binary", "cross-entropy", "and", "MAE", "."], ["The", "optimizer", "was", "Adam", "."], ["The", "batch", "size", "and", "image", "size", "were", "the", "same", "as", "for", "the", "simple", "model", "."], ["The", "models", "were", "trained", "for", "600", "epochs", ",", "100", "steps", "per", "epoch", ",", "and", "the", "batch", "size", "of", "30", "."]], "ner": [[[18, 18, "a"], [24, 24, "a"]], [], [[45, 45, "a"], [50, 51, "p"], [55, 55, "v"]], [], [], [], [[111, 112, "a"], [114, 114, "a"]], [[119, 119, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[18, 18, "a"], [24, 24, "a"]], [], [[45, 45, "a"], [50, 51, "p"], [55, 55, "v"]], [[67, 67, "v"], [68, 68, "p"], [70, 70, "v"]], [[76, 77, "p"], [82, 82, "v"], [90, 92, "v"]], [[100, 100, "a"]], [[111, 112, "a"], [114, 114, "a"]], [[119, 119, "a"]], [[122, 123, "p"]], [[141, 141, "v"], [142, 142, "p"], [144, 144, "v"], [151, 152, "p"], [154, 154, "v"]]], "predicted_relations": [[], [], [[50, 51, 45, 45, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2105.02788-7e52b7ac-de8c-4d2a-a2da-9e8cb36a1489", "sentences": [["We", "first", "center", "and", "normalize", "the", "input", "mesh", "coordinates", "to", "fall", "within", "\\", "-LRB-", "-LSB-", "-1", ",", "1", "-RSB-", "\\", "-RRB-", "along", "the", "widest", "dimension", "-LRB-", "preserving", "the", "aspect", "ratio", "-RRB-", "."], ["For", "Convolutional", "Occupancy", "Networks", ",", "we", "uniformly", "sample", "5", "million", "surface", "points", "for", "the", "input", "point", "cloud", "and", "apply", "Gaussian", "noise", "with", "standard", "deviation", "of", "0.05", "."], ["For", "the", "ground", "truth", "occupancy", "points", ",", "we", "sample", "4.5", "million", "surface", "points", "and", "apply", "Gaussian", "noise", "with", "a", "standard", "deviation", "of", "0.01", "to", "help", "the", "model", "learn", "better", "surface", "details", "."], ["We", "augment", "this", "ground", "truth", "dataset", "with", "an", "additional", "500,000", "points", "sampled", "within", "the", "bounding", "box", "of", "the", "mesh", "."], ["The", "ground", "truth", "occupancy", "is", "calculated", "for", "each", "point", "in", "the", "dataset", "and", "used", "to", "train", "the", "model", "."], ["For", "SIREN", "we", "only", "need", "the", "ground", "truth", "occupancy", "points", ",", "but", "we", "sample", "20", "million", "near", "surface", "points", ",", "and", "20", "million", "points", "from", "the", "bounding", "box", "of", "the", "mesh", "."]], "ner": [[], [[33, 35, "a"], [46, 48, "p"], [40, 43, "v"], [51, 52, "p"], [54, 57, "v"], [51, 52, "p"]], [[68, 71, "v"], [74, 75, "p"], [61, 64, "a"], [68, 71, "v"], [74, 75, "p"], [78, 81, "v"], [61, 64, "p"]], [[100, 101, "v"]], [], [[136, 139, "a"], [131, 131, "a"], [136, 139, "p"], [144, 148, "v"], [151, 160, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[33, 35, "a"], [40, 40, "v"], [57, 57, "v"]], [[68, 68, "v"], [81, 81, "v"]], [[94, 96, "a"], [100, 100, "v"]], [], [[131, 131, "a"], [144, 144, "v"], [151, 151, "v"]]], "predicted_relations": [[], [[54, 57, 51, 52, "USED-FOR"], [54, 57, 51, 52, "USED-FOR"]], [[74, 75, 61, 64, "USED-FOR"], [74, 75, 61, 64, "USED-FOR"], [78, 81, 74, 75, "USED-FOR"], [78, 81, 74, 75, "USED-FOR"], [61, 64, 61, 64, "USED-FOR"]], [], [], [[136, 139, 136, 139, "USED-FOR"], [136, 139, 131, 131, "USED-FOR"]]]}
{"doc_key": "2104.10093-f9be83c6-be07-4e4e-9c7d-8d4738cbd7e9", "sentences": [["Neural", "network", "training", "is", "always", "done", "using", "the", "Adam-optimizer", "-LSB-", "23", "-RSB-", "with", "default", "settings", "-LRB-", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "-RRB-", "."], ["Depending", "on", "the", "benchmark", ",", "the", "learning", "rate", "is", "0.001", "-LRB-", "MNIST", "and", "CIFAR-10", "-RRB-", "or", "0.0001", "-LRB-", "CIFAR-100", "and", "CORe50", "-RRB-", "."]], "ner": [[[8, 8, "a"], [19, 19, "v"], [25, 25, "v"]], [[35, 36, "a"]]], "relations": [[], []], "predicted_ner": [[[8, 8, "a"]], [[35, 36, "p"], [38, 38, "v"], [40, 40, "a"], [42, 42, "a"], [45, 45, "v"], [47, 47, "a"], [49, 49, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2103.02691-ad3db01a-0d19-453f-8e7e-df682fcd2f7c", "sentences": [["For", "the", "intent", "classification", ",", "we", "employ", "the", "Bert-Base", "modelhttps", ":", "//storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip", "with", "12", "Transformer", "layers", ",", "768", "hidden", "states", ",", "and", "12", "self-attention", "heads", "."], ["The", "size", "of", "the", "hidden", "units", "in", "uni-direction", "LSTM", "is", "512", ",", "inner-attention", "hidden", "layer", "\\", "-LRB-", "d_w\\", "-RRB-", "is", "set", "to", "600", ",", "and", "the", "number", "of", "attention", "head", "\\", "-LRB-", "r\\", "-RRB-", "is", "5", "."], ["Furthermore", ",", "we", "use", "Adam", "optimizer", "with", "default", "values", "of", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2", "=", "0.99", "\\", "-RRB-", ",", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "1e-4\\", "-RRB-", "and", "\\", "-LRB-", "2e-5\\", "-RRB-", "for", "training", "the", "BiLSTM", "and", "fine-tuning", "the", "whole", "model", "respectively", "."], ["Each", "update", "is", "computed", "through", "a", "batch", "size", "of", "8", "or", "16", "training", "examples", "and", "the", "number", "of", "epochs", "per", "batch", "are", "32", ",", "25", ",", "16", ",", "and", "8", "epochs", "for", "10-shot", ",", "20-shot", ",", "30-shot", ",", "and", "full-data", "settings", ",", "respectively", "."], ["We", "apply", "the", "dropout", "as", "a", "regularization", "technique", "for", "our", "model", "to", "avoid", "over-fitting", "."], ["We", "apply", "dropout", "after", "output", "of", "each", "BiLSTM", "layer", "and", "output", "of", "each", "sub-layer", "BERT", "encoder", "layers", "."], ["We", "set", "the", "dropout", "rate", "as", "\\", "-LRB-", "0.1\\", "-RRB-", "for", "all", "dropout", "layers", "."]], "ner": [[[14, 15, "p"], [11, 11, "v"], [13, 13, "v"], [22, 22, "v"], [18, 19, "p"], [17, 17, "v"], [23, 24, "p"], [11, 11, "v"], [13, 13, "v"], [22, 22, "v"]], [[33, 34, "a"], [30, 31, "p"], [36, 36, "v"], [38, 40, "a"], [43, 43, "p"], [48, 48, "v"], [58, 58, "p"], [61, 61, "v"]], [[102, 102, "v"], [67, 68, "a"], [78, 78, "v"], [86, 86, "v"], [92, 93, "p"], [97, 97, "v"], [102, 102, "v"]], [], [[162, 162, "a"]], [[176, 176, "a"]], [[195, 195, "a"], [204, 204, "a"], [195, 196, "p"], [200, 200, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "v"], [14, 15, "p"], [17, 17, "v"], [18, 19, "p"], [22, 22, "v"]], [[34, 34, "a"], [36, 36, "v"], [48, 48, "v"], [61, 61, "v"]], [[67, 67, "a"], [78, 78, "v"], [83, 84, "p"], [86, 87, "v"], [92, 93, "p"], [97, 97, "v"], [102, 102, "v"], [107, 107, "a"]], [[121, 122, "p"], [124, 124, "v"], [126, 126, "v"], [137, 137, "v"], [139, 139, "v"], [141, 141, "v"], [144, 144, "v"], [145, 145, "p"]], [[162, 162, "a"], [169, 169, "a"]], [[176, 176, "a"], [181, 181, "a"]], [[195, 196, "p"], [200, 200, "v"], [202, 205, "c"]]], "predicted_relations": [[[13, 13, 18, 19, "USED-FOR"], [22, 22, 18, 19, "USED-FOR"], [17, 17, 18, 19, "USED-FOR"], [13, 13, 18, 19, "USED-FOR"], [22, 22, 18, 19, "USED-FOR"]], [[30, 31, 38, 40, "USED-FOR"], [43, 43, 33, 34, "USED-FOR"], [43, 43, 38, 40, "USED-FOR"], [48, 48, 43, 43, "USED-FOR"], [58, 58, 33, 34, "USED-FOR"], [58, 58, 38, 40, "USED-FOR"]], [[102, 102, 92, 93, "USED-FOR"], [86, 86, 92, 93, "USED-FOR"], [92, 93, 67, 68, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [102, 102, 92, 93, "USED-FOR"]], [], [], [], [[195, 196, 195, 195, "USED-FOR"], [200, 200, 195, 196, "USED-FOR"]]]}
{"doc_key": "2103.02691-9c49b67c-dc5c-4a09-b772-85cb418ea587", "sentences": [["For", "training", "argument", "similarity", ",", "we", "used", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "2e-5\\", "-RRB-", "and", "a", "batch", "size", "of", "16", "training", "samples", "."], ["Furthermore", ",", "the", "model", "uses", "the", "pre-computed", "300-dimensional", "word", "embeddings", "ConceptNet", "Numberbatch", "."], ["The", "number", "of", "hidden", "units", "in", "uni-direction", "LSTM", "is", "512", "and", "the", "number", "of", "attention", "heads", "is", "5", "."], ["The", "model", "is", "trained", "for", "8", "epochs", "."]], "ner": [[[7, 8, "a"], [11, 12, "p"], [16, 16, "v"], [20, 21, "a"], [16, 16, "v"]], [[37, 38, "a"]], [[41, 47, "a"], [41, 44, "p"], [49, 49, "v"], [52, 55, "a"], [52, 55, "p"], [57, 57, "v"]], [[64, 64, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"], [11, 12, "p"], [16, 16, "v"], [20, 21, "p"], [23, 23, "v"]], [[34, 34, "v"], [37, 37, "a"]], [[47, 47, "a"], [49, 49, "v"], [57, 57, "v"]], [[64, 64, "v"], [65, 65, "p"]]], "predicted_relations": [[[11, 12, 7, 8, "USED-FOR"], [16, 16, 11, 12, "USED-FOR"], [16, 16, 11, 12, "USED-FOR"]], [], [[41, 44, 41, 47, "USED-FOR"], [52, 55, 41, 47, "USED-FOR"], [52, 55, 52, 55, "USED-FOR"]], []]}
{"doc_key": "2102.06697-6809cac6-d88b-4af9-ad7f-b5c338c0e93d", "sentences": [["There", "are", "not", "much", "hyper-parameters", "need", "to", "be", "tuned", "in", "the", "training", "process", "of", "qKC", "."], ["Empirically", "we", "have", "noticed", "that", "the", "design", "of", "learning", "rate", "and", "batch", "size", "will", "affect", "the", "training", "process", "of", "qKC", "."], ["For", "the", "Adam", "optimiser", ",", "we", "use", "the", "default", "configuration", ":", "1", "-RRB-", "the", "coefficients", "used", "for", "computing", "running", "mean", "of", "gradient", "and", "its", "square", "are", "set", "as", "0.9", "and", "0.999", ",", "respectively", ",", "2", "-RRB-", "\\", "-LRB-", "eps\\", "-RRB-", "is", "set", "as", "1e-8", "for", "numerical", "stability", "and", "3", "-RRB-", "no", "L2", "penalty", "term", "."]], "ner": [[], [[24, 25, "a"], [27, 28, "a"]], [[39, 40, "a"], [51, 61, "p"], [65, 65, "v"], [67, 67, "v"], [75, 75, "p"], [80, 80, "v"], [88, 90, "p"]]], "relations": [[], [], []], "predicted_ner": [[[14, 14, "a"]], [[24, 25, "p"], [27, 28, "p"], [35, 35, "a"]], [[39, 39, "a"], [65, 65, "v"], [67, 67, "v"], [80, 80, "v"], [88, 88, "a"]]], "predicted_relations": [[], [], [[51, 61, 39, 40, "USED-FOR"], [75, 75, 39, 40, "USED-FOR"]]]}
{"doc_key": "2103.16337-3fec589f-1575-4f29-b1d5-35042aa927e2", "sentences": [["Using", "the", "dataset", "and", "the", "architecture", "described", "above", ",", "two", "GNNs", "are", "trained", "using", "each", "of", "the", "techniques", "described", "in", "\u00a7", "REF", "and", "\u00a7", "REF", ",", "with", "\\", "-LRB-", "k=4\\", "-RRB-", ",", "\\", "-LRB-", "p=2\\", "-RRB-", ",", "\\", "-LRB-", "q=1\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "=", "0.05\\", "-RRB-", "and", "\\", "-LRB-", "\\varepsilon", "=10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "."], ["Training", "is", "performed", "using", "Adam", "algorithm", "with", "60", "epochs", "and", "a", "fixed", "learning", "rate", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["Regarding", "the", "model", "distillation", ",", "rather", "than", "re-evaluating", "the", "MPN", "\\", "-LRB-", "F\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "for", "every", "sample", "\\", "-LRB-", "X\\", "-RRB-", "at", "each", "epoch", ",", "we", "precompute", "\\", "-LRB-", "F", "-LRB-", "X", ",", "\\omega", "-LRB-", "X", "-RRB-", "-RRB-", "\\", "-RRB-", "to", "save", "the", "computation", "time", "."]], "ner": [[[10, 10, "a"]], [[63, 64, "a"], [71, 72, "p"], [76, 76, "v"]], [[81, 82, "a"]]], "relations": [[], [], []], "predicted_ner": [[[9, 9, "v"], [10, 10, "a"], [29, 29, "v"], [34, 34, "v"], [39, 39, "v"], [46, 46, "v"]], [[63, 64, "a"], [66, 66, "v"], [67, 67, "p"], [71, 72, "p"], [76, 76, "v"]], [[81, 82, "a"], [88, 88, "a"]]], "predicted_relations": [[], [[71, 72, 63, 64, "USED-FOR"]], []]}
{"doc_key": "2103.16364-7ebfb3da-c758-434d-a24e-b3f31f9615d0", "sentences": [["To", "conduct", "a", "fair", "comparison", "with", "state-of-the-art", "methods", ",", "we", "use", "an", "ImageNet", "-LSB-", "22", "-RSB-", "pre-trained", "ResNet50", "-LSB-", "11", "-RSB-", "as", "our", "backbone", "network", "."], ["We", "report", "results", "of", "IBN-ResNet50", "-LSB-", "20", "-RSB-", "in", "Appendix", "."], ["An", "Adam", "optimizer", "with", "a", "weight", "decay", "rate", "of", "0.0005", "is", "used", "to", "optimize", "our", "networks", "."], ["The", "learning", "rate", "is", "set", "to", "0.00035", "with", "a", "warm-up", "scheme", "in", "the", "first", "10", "epochs", "."], ["No", "learning", "rate", "decay", "is", "used", "in", "the", "training", "."], ["The", "momentum", "encoder", "is", "updated", "with", "a", "momentum", "coefficient", "\\", "-LRB-", "\\alpha", "=0.999\\", "-RRB-", "."], ["We", "renew", "pseudo", "labels", "every", "400", "iterations", "and", "repeat", "this", "process", "for", "40", "epochs", "."], ["We", "use", "a", "batchsize", "of", "32", "where", "\\", "-LRB-", "N_P=8\\", "-RRB-", "and", "\\", "-LRB-", "N_K=4\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "\\tau", "_", "-LCB-", "a", "-RCB-", "=0.5\\", "-RRB-", ",", "\\", "-LRB-", "\\tau", "_", "-LCB-", "c", "-RCB-", "=0.07\\", "-RRB-", "and", "\\", "-LRB-", "N_", "-LCB-", "neg", "-RCB-", "=50\\", "-RRB-", "in", "the", "proxy", "contrastive", "baseline", "."], ["Our", "network", "is", "trained", "on", "4", "Nvidia", "1080", "GPUs", "under", "Pytorch", "framework", "."], ["The", "total", "training", "time", "is", "around", "2", "hours", "on", "Market-1501", "."], ["After", "training", ",", "only", "the", "momentum", "encoder", "is", "used", "for", "the", "inference", "."]], "ner": [[[12, 12, "a"], [17, 17, "a"]], [[30, 30, "a"], [30, 30, "a"]], [[38, 39, "a"], [42, 44, "p"], [46, 46, "v"]], [[55, 56, "p"], [60, 60, "v"], [63, 64, "a"], [69, 69, "p"], [68, 68, "v"]], [[72, 73, "p"]], [[88, 89, "p"], [93, 93, "v"]], [[109, 109, "p"]], [[114, 114, "a"], [120, 120, "p"], [120, 120, "v"], [125, 125, "p"], [125, 125, "v"]], [[160, 162, "a"], [137, 137, "v"], [147, 147, "v"], [156, 156, "v"]], [[169, 169, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[12, 12, "a"], [17, 17, "a"], [23, 24, "a"]], [[30, 30, "a"]], [[38, 38, "a"], [42, 44, "p"], [46, 46, "v"]], [[55, 56, "p"], [60, 60, "v"], [68, 68, "v"], [69, 69, "p"]], [[72, 74, "p"]], [[88, 89, "p"], [92, 92, "p"], [93, 93, "v"]], [[101, 101, "v"], [108, 108, "v"], [109, 109, "p"]], [[114, 114, "p"], [116, 116, "v"], [125, 125, "v"]], [[147, 147, "v"], [156, 156, "v"]], [[165, 165, "a"], [169, 169, "v"]], [[183, 183, "v"]], []], "predicted_relations": [[], [], [[46, 46, 42, 44, "USED-FOR"]], [[60, 60, 55, 56, "USED-FOR"], [60, 60, 69, 69, "USED-FOR"], [69, 69, 63, 64, "USED-FOR"], [68, 68, 69, 69, "USED-FOR"]], [], [[93, 93, 88, 89, "USED-FOR"]], [], [[120, 120, 120, 120, "USED-FOR"], [125, 125, 114, 114, "USED-FOR"], [125, 125, 120, 120, "USED-FOR"], [125, 125, 125, 125, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2106.04493-f7b61b72-392e-49c3-b940-61099d5e715e", "sentences": [["To", "train", "the", "CVNet", "used", "in", "the", "experiments", ",", "we", "employ", "3", "cerebellar", "quantization", "functions", "and", "use", "a", "memory", "size", "\\", "-LRB-", "A\\", "-RRB-", "of", "20000", "."], ["The", "embedding", "dimension", "\\", "-LRB-", "m\\", "-RRB-", "is", "chosen", "to", "be", "50", "."], ["Following", "the", "cerebellar", "embedding", "layer", "are", "fully", "connected", "layers", "having", "-LSB-", "32", ",", "128", ",", "32", "-RSB-", "hidden", "units", "with", "ReLU", "activations", "."], ["We", "maintain", "a", "target", "network", "which", "is", "updated", "every", "100K", "steps", "."], ["We", "use", "a", "batch", "size", "of", "32", "and", "run", "training", "for", "20", "epochs", ",", "with", "each", "epoch", "being", "one", "pass", "through", "the", "whole", "dataset", "."], ["We", "apply", "Adam", "optimizer", "with", "a", "constant", "step", "size", "\\", "-LRB-", "3e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "Lipschitz", "regularization", "parameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "chosen", "to", "be", "\\", "-LRB-", "1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "since", "we", "find", "that", "a", "small", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "already", "quite", "effective", "at", "bounding", "the", "Lipschitz", ",", "as", "demonstrated", "in", "Figure", "REF", "."], ["For", "context", "randomization", "we", "use", "a", "range", "\\", "-LRB-", "rg\\", "-RRB-", "of", "30", "minutes", "."]], "ner": [[[3, 3, "a"]], [], [], [], [], [[102, 103, "a"]], [[124, 124, "p"], [147, 147, "p"], [119, 120, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [11, 11, "v"], [18, 19, "p"], [22, 22, "p"], [25, 25, "v"]], [[28, 29, "p"], [32, 32, "p"], [38, 38, "v"]], [[51, 51, "v"], [53, 53, "v"], [55, 56, "v"], [60, 60, "a"]], [[72, 72, "v"]], [[78, 79, "p"], [81, 81, "v"], [86, 86, "v"], [87, 87, "p"], [93, 93, "v"]], [[102, 102, "a"], [111, 114, "v"]], [[119, 121, "p"], [124, 124, "p"], [133, 136, "v"], [147, 147, "p"]], [[177, 177, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[124, 124, 119, 120, "USED-FOR"], [147, 147, 119, 120, "USED-FOR"]], []]}
{"doc_key": "2106.04493-98cc8f42-1629-46e6-9920-44705cb32b61", "sentences": [["Finally", ",", "we", "illustrate", "the", "training", "progress", "under", "different", "discount", "factors", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "in", "Figure", "REF", "."], ["During", "training", "we", "record", "the", "average", "\\", "-LRB-", "V\\", "-RRB-", "for", "each", "input", "batch", "and", "we", "plot", "its", "change", "against", "the", "training", "steps", "."], ["The", "average", "value", "the", "function", "\\", "-LRB-", "V\\", "-RRB-", "converges", "to", "depends", "on", "the", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "being", "used", "."], ["The", "value", "is", "smaller", "with", "a", "smaller", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", ",", "in", "which", "case", "the", "convergence", "also", "happens", "faster", "."], ["Note", "that", "a", "smaller", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "implies", "a", "more", "aggressive", "discounting", "of", "future", "values", ",", "hence", "a", "shorter", "lookahead", "horizon", "beyond", "which", "any", "rewards", "are", "close", "to", "zero", "once", "brought", "to", "the", "present", "."], ["The", "training", "becomes", "easier", "in", "this", "case", "since", "it", "does", "not", "need", "to", "look", "far", "into", "the", "future", "."], ["In", "general", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "represents", "a", "trade-off", "between", "foresight", "and", "variance", "."], ["The", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "used", "in", "the", "experiments", "is", "chosen", "to", "be", "0.92", "which", "is", "determined", "by", "a", "randomized", "search", "based", "on", "out-of-sample", "simulations", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[13, 13, "p"]], [], [[60, 60, "p"]], [[75, 75, "p"]], [[94, 94, "p"]], [], [[148, 148, "p"]], [[162, 162, "p"], [173, 173, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "p"]], [], [[60, 60, "p"]], [[75, 75, "p"]], [[94, 94, "p"], [118, 118, "v"]], [], [[148, 148, "p"]], [[162, 162, "p"], [173, 173, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2105.09128-6b88536a-6fbb-468f-9d7d-6caa94a61bc1", "sentences": [["The", "experiments", "are", "implemented", "in", "Pytorch", "1.3.1", "and", "performed", "on", "an", "NVIDIA", "TITAN", "XP", "."], ["Ninety", "percent", "of", "the", "training", "images", "were", "selected", ",", "with", "a", "total", "of", "4,067", "image", "pairs", "."], ["Data", "augmentation", "is", "performed", "on", "the", "training", "images", "with", "random", "rotation", "of", "\\", "-LRB-", "90^", "-LCB-", "\\circ", "-LCB-", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "horizontal", "and", "vertical", "flip", "."], ["A", "single", "configuration", "was", "used", "for", "all", "experiments", "and", "all", "scale", "factors", "."], ["The", "Adam", "optimizer", "and", "L1", "loss", "were", "adopted", "-LSB-", "40", "-RSB-", "using", "default", "parameter", "values", "of", "zero", "weight", "decay", ",", "and", "a", "learning", "rate", "initialized", "to", "\\", "-LRB-", "10^", "-LCB-", "\u22124", "-RCB-", "\\", "-RRB-", "with", "step", "decay", "of", "\\", "-LRB-", "\\gamma", "=", "0.5\\", "-RRB-", "after", "500", "epochs", "."], ["The", "output", "SR", "image", "size", "for", "all", "experiments", "is", "\\", "-LRB-", "192", "\\times", "192\\", "-RRB-", "with", "a", "minibatch", "size", "of", "8", "batches", "."]], "ner": [[[5, 5, "a"]], [], [], [], [[74, 75, "a"], [90, 91, "p"], [115, 115, "v"], [95, 96, "p"], [108, 109, "p"], [77, 78, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[15, 16, "v"], [28, 28, "v"]], [[46, 51, "v"]], [], [[74, 74, "a"], [77, 78, "a"], [89, 89, "v"], [90, 91, "p"], [95, 96, "p"], [101, 104, "v"], [108, 109, "p"], [113, 113, "p"], [115, 115, "v"], [118, 118, "v"], [119, 119, "p"]], [[132, 132, "v"], [134, 134, "v"], [138, 139, "p"], [141, 141, "v"], [142, 142, "p"]]], "predicted_relations": [[], [], [], [], [[90, 91, 74, 75, "USED-FOR"], [90, 91, 77, 78, "USED-FOR"], [95, 96, 74, 75, "USED-FOR"], [95, 96, 77, 78, "USED-FOR"], [108, 109, 77, 78, "USED-FOR"]], []]}
{"doc_key": "2112.04421-9c2d70ae-09ab-465a-bac4-96691f371617", "sentences": [["We", "train", "our", "model", "using", "prediction", "methods", ",", "Global", "Rotation", "-LRB-", "\\", "-LRB-", "r_y\\", "-RRB-", "-RRB-", ",", "Local", "Rotation", "-LRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "-RRB-", ",", "Single", "Bin", ",", "Tricosine", ",", "Voting", "Bin", ",", "and", "Confidence", "Bins", "to", "predict", "one", "of", "two", "targets", ":", "global", "rotation", "-LRB-", "\\", "-LRB-", "r_y\\", "-RRB-", "-RRB-", "and", "location", "rotation", "-LRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "-RRB-", "."], ["Our", "models", "were", "first", "trained", "on", "a", "Nvidia", "V100", "GPU", "for", "1-D", "scalar", "based", "representation", "experiments", "and", "later", "on", "a", "Nvidia", "RTX3090", "GPU", "for", "all", "other", "experiments", "."], ["All", "models", "were", "trained", "with", "TensorFlow", "'s", "default", "Adam", "optimizer", "-LRB-", "lr=", "0.001", ",", "\\", "-LRB-", "\\beta", "1\\", "-RRB-", "=", "0.9", ",", "\\", "-LRB-", "\\beta", "2\\", "-RRB-", "=", "0.99", ",", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "=", "1e-7", "-RRB-", ",", "a", "batch", "size", "of", "25", ",", "and", "100", "total", "epochs", "."]], "ner": [[[8, 9, "a"], [17, 18, "a"], [27, 28, "a"], [30, 30, "a"], [32, 33, "a"], [36, 37, "a"]], [], [[103, 103, "p"], [104, 104, "v"], [112, 112, "v"], [120, 120, "v"], [128, 128, "v"], [100, 101, "a"], [132, 133, "p"], [135, 135, "v"], [139, 140, "p"], [138, 138, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [22, 22, "p"], [32, 33, "p"], [40, 40, "v"], [42, 42, "v"], [59, 59, "p"]], [[75, 75, "v"]], [[100, 100, "a"], [104, 104, "v"], [112, 112, "v"], [120, 120, "v"], [128, 128, "v"], [132, 133, "p"], [135, 135, "v"], [138, 138, "v"], [140, 140, "p"]]], "predicted_relations": [[], [], [[104, 104, 103, 103, "USED-FOR"], [128, 128, 139, 140, "USED-FOR"], [132, 133, 100, 101, "USED-FOR"], [135, 135, 132, 133, "USED-FOR"], [135, 135, 139, 140, "USED-FOR"], [138, 138, 139, 140, "USED-FOR"]]]}
{"doc_key": "2104.04087-eb30f948-d844-4398-a451-117e42109815", "sentences": [["The", "training", "goal", "of", "our", "system", "is", "to", "minimize", "the", "categorical", "cross-entropy", "."], ["As", "training", "algorithm", "we", "use", "Adam", "with", "a", "learning", "rate", "of", "0.0001", "."], ["We", "used", "sequence-to-sequence", "models", "in", "our", "work", "with", "RNN", "encoder", "and", "decoder", "."], ["The", "encoder", "and", "the", "decoder", "use", "GRU", "-LSB-", "19", "-RSB-", "units", "."], ["Our", "models", "use", "Bahdanau", "attention", "-LSB-", "7", "-RSB-", "for", "the", "attention", "mechanism", "."], ["The", "size", "of", "the", "hidden", "units", "is", "1024", "and", "the", "size", "of", "the", "batches", "is", "32", "."], ["The", "models", "are", "trained", "between", "5,000", "-", "30,000", "steps", "depending", "on", "the", "number", "of", "layers", "of", "each", "specific", "model", "and", "the", "size", "of", "the", "dataset", "."], ["We", "use", "the", "same", "input", "sequence", "length", "-LRB-", "100", "-RRB-", "and", "output", "sequence", "length", "-LRB-", "30", "-RRB-", "as", "Jiang", "et", "al", "."], ["-LSB-", "1", "-RSB-", "as", "99", "%", "of", "the", "examples", "in", "the", "datasets", "have", "both", "the", "diffs", "and", "commit", "messages", "length", "less", "than", "these", "thresholds", "."]], "ner": [[], [[18, 18, "a"], [24, 24, "v"]], [[28, 29, "a"], [34, 37, "a"]], [[45, 45, "a"]], [[54, 55, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [10, 11, "a"]], [[18, 18, "a"], [21, 22, "p"], [24, 24, "v"]], [[34, 34, "a"]], [[45, 45, "a"]], [[54, 55, "a"]], [[71, 71, "v"], [79, 79, "v"]], [[86, 86, "v"], [88, 88, "v"]], [[115, 115, "v"], [122, 122, "v"]], [[133, 134, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2102.00690-034bc9a0-9130-4ece-8d54-814aea224787", "sentences": [["We", "first", "evaluate", "the", "proposed", "monocular", "3D", "detection", "network", "on", "the", "KITTI", "benchmark", "-LSB-", "26", "-RSB-", "."], ["The", "dataset", "consists", "of", "7,481", "training", "frames", "and", "7,518", "test", "frames", "."], ["Chen", "et", "al", "."], ["-LSB-", "34", "-RSB-", "further", "splits", "the", "training", "set", "into", "3,712", "training", "frames", "and", "3,769", "validation", "frames", "."]], "ner": [[[11, 12, "a"]], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 8, "a"]], [[21, 21, "v"], [25, 25, "v"]], [], [[42, 42, "v"], [46, 46, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2107.05328-00fb3e9f-67cd-406a-9919-7f5c833cb023", "sentences": [["The", "base", "VGG", "model", "and", "method", "for", "visualizing", "are", "implemented", "following", "-LSB-", "38", "-RSB-", ",", "-LSB-", "6", "-RSB-", ",", "which", "does", "not", "have", "batch", "normalization", "."], ["For", "both", "SDP", "and", "sDprun", "we", "use", "the", "similar", "learning", "rate", "schedule", "adopted", "by", "-LSB-", "6", "-RSB-", ":", "fix", "the", "learning", "rate", "equals", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "at", "first", "50", "%", "epochs", ",", "then", "reduce", "the", "learning", "rate", "to", "0.1", "%", "of", "the", "base", "learning", "rate", "between", "50", "%", "and", "90", "%", "epochs", ",", "and", "keep", "reducing", "it", "to", "0.1", "%", "for", "the", "last", "10", "%", "epochs", "."], ["The", "minibatch", "size", "is", "128", "for", "all", "experiments", "in", "Section", "4.3", "."]], "ner": [[[2, 3, "a"], [7, 7, "a"]], [[35, 37, "a"], [35, 36, "p"], [46, 47, "p"], [63, 64, "p"], [71, 72, "p"], [52, 52, "v"], [66, 66, "v"], [86, 86, "v"], [58, 58, "p"], [79, 79, "p"], [93, 93, "p"]], [[96, 97, "a"], [96, 97, "p"], [99, 99, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 3, "a"]], [[28, 28, "a"], [30, 30, "a"], [35, 36, "p"], [46, 47, "p"], [52, 52, "v"], [56, 57, "v"], [58, 58, "p"], [63, 64, "p"], [66, 67, "v"], [71, 72, "p"], [74, 75, "v"], [77, 78, "v"], [79, 79, "p"], [86, 87, "v"], [91, 92, "v"], [93, 93, "p"]], [[96, 96, "a"], [96, 97, "p"], [99, 99, "v"]]], "predicted_relations": [[], [[46, 47, 35, 37, "USED-FOR"], [52, 52, 63, 64, "USED-FOR"], [52, 52, 58, 58, "USED-FOR"], [66, 66, 71, 72, "USED-FOR"], [66, 66, 79, 79, "USED-FOR"], [66, 66, 93, 93, "USED-FOR"], [86, 86, 93, 93, "USED-FOR"], [58, 58, 35, 37, "USED-FOR"]], [[96, 97, 96, 97, "USED-FOR"]]]}
{"doc_key": "2112.06660-7059ca4c-6e33-43db-b57c-be65d1a6b75c", "sentences": [["In", "our", "numerical", "experiments", ",", "all", "training", "and", "testing", "data", "are", "sampled", "uniformly", "in", "\\", "-LRB-", "\\Omega", "\\", "-RRB-", "-LRB-", "or", "\\", "-LRB-", "\\partial", "\\Omega", "\\", "-RRB-", "-RRB-", ",", "and", "all", "networks", "are", "trained", "by", "Adam", "optimizer", "."], ["The", "initial", "learning", "rate", "is", "set", "as", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "with", "a", "decay", "rate", "\\", "-LRB-", "5", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "each", "training", "epoch", "."], ["For", "visualization", "of", "the", "training", "process", ",", "we", "test", "our", "model", "every", "1000", "epochs", "in", "the", "training", "process", "."], ["The", "penalty", "parameter", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "for", "the", "orthogonality", "constraint", "-LRB-", "REF", "-RRB-", "is", "set", "as", "20", ",", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "for", "the", "boundary", "constraint", "-LRB-", "REF", "-RRB-", "and", "-LRB-", "REF", "-RRB-", "is", "set", "as", "\\", "-LRB-", "\\gamma", "=\\left\\lbrace", "\\begin", "-LCB-", "aligned", "-RCB-", "\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "if", "-RCB-", "~~i_", "-LCB-", "\\textup", "-LCB-", "epoch", "-RCB-", "-RCB-", "<", "0.1T_", "-LCB-", "\\max", "-RCB-", "\\\\10\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "if", "-RCB-", "~~0.1T_", "-LCB-", "\\max", "-RCB-", "<", "=i_", "-LCB-", "\\textup", "-LCB-", "epoch", "-RCB-", "-RCB-", "<", "0.2T_", "-LCB-", "\\max", "-RCB-", "\\\\50\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "if", "-RCB-", "~~", "0.2T_", "-LCB-", "\\max", "-RCB-", "<", "=i_", "-LCB-", "\\textup", "-LCB-", "epoch", "-RCB-", "-RCB-", "<", "0.25T_", "-LCB-", "\\max", "-RCB-", "\\\\100\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "if", "-RCB-", "~~", "0.25T_", "-LCB-", "\\max", "-RCB-", "<", "=i_", "-LCB-", "\\textup", "-LCB-", "epoch", "-RCB-", "-RCB-", "<", "0.5T_", "-LCB-", "\\max", "-RCB-", "\\\\200\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "if", "-RCB-", "~~", "0.5T_", "-LCB-", "\\max", "-RCB-", "<", "=i_", "-LCB-", "\\textup", "-LCB-", "epoch", "-RCB-", "-RCB-", "<", "0.75T_", "-LCB-", "\\max", "-RCB-", "\\\\500\\gamma", "_0", ",", "\\quad", "&", "\\textup", "-LCB-", "otherwise", "-RCB-", "\\end", "-LCB-", "aligned", "-RCB-", "\\right.\\", "-RRB-"]], "ner": [[[35, 36, "a"]], [[39, 41, "p"], [56, 57, "p"]], [], [[102, 103, "a"], [93, 94, "p"], [110, 110, "v"], [119, 120, "a"], [93, 94, "p"], [274, 274, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[35, 35, "a"]], [[40, 41, "p"], [56, 57, "p"], [60, 60, "v"]], [[83, 83, "a"], [85, 85, "v"]], [[93, 94, "p"], [97, 97, "p"], [110, 110, "v"], [114, 114, "p"]]], "predicted_relations": [[], [], [], [[110, 110, 93, 94, "USED-FOR"], [110, 110, 93, 94, "USED-FOR"]]]}
{"doc_key": "2112.06660-aea208da-9e5b-44fe-a9d8-235aa74caed4", "sentences": [["where", "\\", "-LRB-", "\\gamma", "_0=100\\", "-RRB-", "in", "all", "our", "tests", "and", "\\", "-LRB-", "T_", "-LCB-", "\\max", "-RCB-", "\\", "-RRB-", "represents", "the", "total", "epoch", "number", "."], ["We", "implement", "our", "code", "in", "TensorFlow", "-LRB-", "version", "1.14.0", "-RRB-", "on", "a", "work", "station", "-LRB-", "256-GB", "RAM", ",", "single", "NVIDIA", "GeForce", "GTX", "2080Ti", "12-GB", "-RRB-", "."]], "ner": [[[22, 23, "a"], [4, 4, "v"]], [[30, 30, "a"]]], "relations": [[], []], "predicted_ner": [[], [[33, 33, "v"], [40, 40, "v"], [48, 48, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2105.11210-d0c8eb98-cbab-4e91-9658-3d5c72db3224", "sentences": [["Pre-training", "Dataset", "."], ["Following", "LayoutLM", ",", "we", "pre-train", "StructuralLM", "on", "the", "IIT-CDIP", "Test", "Collection", "1.0", "-LSB-", "9", "-RSB-", "."], ["It", "is", "a", "large-scale", "scanned", "document", "image", "dataset", ",", "which", "contains", "more", "than", "6", "million", "documents", ",", "with", "more", "than", "11", "million", "scanned", "document", "images", "."], ["The", "pre-training", "dataset", "-LRB-", "IIT-CDIP", "Test", "Collection", "-RRB-", "only", "contains", "pure", "texts", "while", "missing", "their", "corresponding", "bounding", "boxes", "."], ["Therefore", ",", "we", "need", "to", "re-process", "the", "scanned", "document", "images", "to", "obtain", "the", "layout", "information", "of", "cells", "."], ["Like", "the", "pre-processing", "method", "of", "LayoutLM", ",", "we", "similarly", "process", "the", "dataset", "by", "using", "Tesseract", "https", ":", "//github.com/tesseract-ocr/tesseract", ",", "which", "is", "an", "open-source", "OCR", "engine", "."], ["We", "normalize", "the", "actual", "coordinates", "to", "integers", "in", "the", "range", "from", "0", "to", "1,000", ",", "and", "an", "empty", "bounding", "box", "\\", "-LRB-", "-LRB-", "0", ";", "0", ";", "0", ";", "0", "-RRB-", "\\", "-RRB-", "is", "attached", "to", "special", "tokens", "-LSB-", "CLS", "-RSB-", ",", "-LSB-", "SEP", "-RSB-", "and", "-LSB-", "PAD", "-RSB-", "."]], "ner": [[], [[11, 14, "a"], [4, 4, "a"], [8, 8, "a"]], [], [], [], [[96, 96, "a"], [87, 87, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[4, 4, "a"], [11, 13, "a"], [14, 14, "v"]], [[32, 32, "v"], [39, 39, "v"]], [[49, 51, "a"]], [], [[87, 87, "a"], [96, 96, "a"]], [[119, 119, "v"], [121, 121, "v"], [131, 137, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2105.11210-ddf960b5-4b8d-4a64-8aa9-4968dcdfedb6", "sentences": [["StructuralLM", "is", "pre-trained", "on", "16", "NVIDIA", "Tesla", "V100", "32GB", "GPUs", "for", "480K", "steps", ",", "with", "each", "mini-batch", "containing", "128", "sequences", "of", "maximum", "length", "512", "tokens", "."], ["The", "Adam", "optimizer", "is", "used", "with", "an", "initial", "learning", "rate", "of", "1e-5", "and", "a", "linear", "decay", "learning", "rate", "schedule", "."]], "ner": [[[0, 0, "a"], [5, 9, "a"]], [[27, 28, "p"], [37, 37, "v"], [33, 35, "c"], [40, 44, "v"]]], "relations": [[], []], "predicted_ner": [[[0, 0, "a"], [4, 4, "v"], [8, 8, "v"], [11, 11, "v"], [18, 18, "v"], [23, 23, "v"]], [[27, 27, "a"], [34, 35, "p"], [37, 37, "v"]]], "predicted_relations": [[], [[33, 35, 37, 37, "USED-FOR"]]]}
{"doc_key": "2105.11210-b598847c-1473-409a-87e9-74a9fb3504fc", "sentences": [["Hyperparameter", "N.", "For", "the", "cell", "position", "classification", "task", ",", "we", "test", "the", "performances", "of", "StructuralLM", "using", "different", "hyperparameter", "\\", "-LRB-", "N\\", "-RRB-", "during", "pre-training", "."], ["Considering", "that", "the", "complete", "pre-training", "takes", "too", "long", ",", "we", "pre-train", "StructuralLM", "for", "100k", "steps", "with", "a", "single", "GPU", "card", "to", "compare", "the", "performance", "of", "different", "\\", "-LRB-", "N\\", "-RRB-", "."], ["As", "shown", "in", "Figure", "REF", ",", "when", "the", "\\", "-LRB-", "N\\", "-RRB-", "is", "set", "as", "16", ",", "StructuralLM", "obtains", "the", "highest", "F1-score", "on", "the", "FUNSD", "dataset", "."], ["Therefore", ",", "we", "set", "\\", "-LRB-", "N\\", "-RRB-", "as", "16", "during", "the", "pre-training", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[14, 14, "a"], [1, 1, "p"], [20, 20, "p"]], [[36, 36, "a"], [53, 53, "p"]], [[73, 73, "a"], [66, 66, "p"], [71, 71, "v"], [76, 81, "c"]], [[89, 89, "p"], [92, 92, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[14, 14, "a"], [20, 20, "p"]], [[36, 36, "a"], [38, 38, "v"], [53, 53, "p"]], [[66, 66, "p"], [71, 71, "v"], [73, 73, "a"]], [[89, 89, "p"], [92, 92, "v"]], []], "predicted_relations": [[[20, 20, 14, 14, "USED-FOR"]], [], [[76, 81, 71, 71, "USED-FOR"]], [], []]}
{"doc_key": "2109.07383-043923c7-5ece-494c-8eb8-83f970c55e7a", "sentences": [["For", "machine", "translation", ",", "we", "experiment", "on", "the", "IWSLT", "\u2019", "14", "De-En", "and", "WMT", "\u2019", "14", "En-De", "tasks", "using", "the", "identical", "settings", "as", "-LSB-", "31", "-RSB-", "."], ["For", "language", "modeling", ",", "we", "experiment", "on", "the", "WikiText-103", "dataset", "-LSB-", "21", "-RSB-", "with", "the", "same", "settings", "as", "-LSB-", "0", "-RSB-", "."], ["We", "set", "the", "maximum", "number", "of", "tokens", "per", "sample", "to", "1,843", "to", "fit", "the", "memory", "constraints", "and", "apply", "gradient", "accumulation", "to", "keep", "the", "same", "batch", "size", "as", "-LSB-", "0", "-RSB-", "\u2019", "s", "work", "."], ["All", "models", "are", "trained", "with", "mixed", "precision", "on", "8", "NVIDIA", "RTX", "2080", "Ti", "GPUs", "except", "for", "IWSLT", "ones", ",", "which", "only", "take", "one", "GPU", "for", "training", "."]], "ner": [[], [[35, 35, "a"]], [[52, 57, "a"], [52, 57, "p"], [59, 59, "v"], [67, 68, "a"]], [[88, 89, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[35, 36, "a"]], [[59, 59, "v"], [67, 68, "a"], [73, 74, "p"]], [[91, 91, "v"], [105, 105, "v"]]], "predicted_relations": [[], [], [[52, 57, 52, 57, "USED-FOR"]], []]}
{"doc_key": "2106.07719-3a953d26-c614-4251-b8cd-d1c7df2b3c08", "sentences": [["We", "use", "the", "following", "settings", "for", "training", "."], ["The", "maximum", "sentence", "length", "for", "document", "was", "set", "to", "75", "tokens", "while", "that", "was", "set", "to", "16", "tokens", "for", "the", "query", "part", "."], ["After", "doing", "some", "experiments", ",", "we", "finalized", "the", "embedding", "dimensions", "to", "\\", "-LRB-", "M=32\\", "-RRB-", "."], ["We", "also", "employ", "6-layers", "BERT", "for", "document", "embedding", "and", "3-layers", "BERT", "for", "query", "embedding", "."], ["The", "3-layers", "BERT", "is", "called", "student", "model", "as", "it", "was", "trained", "from", "a", "6-layerss", "teacher", "model", "."]], "ner": [[], [[9, 11, "a"], [13, 13, "p"], [17, 17, "v"], [28, 28, "p"], [24, 24, "v"]], [[39, 40, "a"], [44, 44, "p"], [44, 44, "v"]], [[51, 51, "a"], [57, 57, "a"], [50, 50, "p"], [56, 56, "p"], [50, 50, "v"], [53, 54, "c"], [56, 56, "v"], [59, 60, "c"], [53, 53, "p"], [59, 59, "p"]], [[64, 64, "a"], [63, 63, "p"], [75, 75, "v"], [63, 63, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[17, 17, "v"], [24, 24, "v"]], [[44, 44, "v"]], [[51, 51, "a"], [57, 57, "a"]], [[64, 64, "a"], [67, 68, "a"]]], "predicted_relations": [[], [[13, 13, 9, 11, "USED-FOR"], [24, 24, 28, 28, "USED-FOR"]], [[44, 44, 39, 40, "USED-FOR"], [44, 44, 44, 44, "USED-FOR"], [44, 44, 44, 44, "USED-FOR"]], [[50, 50, 51, 51, "USED-FOR"], [56, 56, 51, 51, "USED-FOR"], [56, 56, 57, 57, "USED-FOR"], [50, 50, 50, 50, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [53, 54, 50, 50, "USED-FOR"], [53, 54, 56, 56, "USED-FOR"], [56, 56, 56, 56, "USED-FOR"], [59, 60, 56, 56, "USED-FOR"], [53, 53, 51, 51, "USED-FOR"], [53, 53, 57, 57, "USED-FOR"], [59, 59, 51, 51, "USED-FOR"], [59, 59, 57, 57, "USED-FOR"]], [[63, 63, 64, 64, "USED-FOR"], [63, 63, 63, 63, "USED-FOR"]]]}
{"doc_key": "2104.02555-12d20965-8196-473d-8efc-2e7daffb5729", "sentences": [["We", "use", "a", "\\", "-LRB-", "F=256\\", "-RRB-", "dimensional", "FDE", ",", "with", "the", "positional", "encoding", "being", "based", "on", "polar", "coordinates", ",", "i.e", "."], ["Fourier", "coefficients", "of", "same", "frequency", "have", "the", "same", "radius", "."], ["The", "FDE", "is", "passed", "to", "a", "causal-linear", "transformer", "-LSB-", "6", "-RSB-", "with", "8", "layers", ",", "8", "self-attention", "heads", ",", "a", "query", "and", "value", "dimensionality", "of", "32", ",", "dropout", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "attention", "dropout", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "and", "a", "dimensionality", "of", "the", "feed-forward", "network", "of", "1024", "."]], "ner": [[[8, 8, "a"], [5, 5, "p"], [5, 5, "v"]], [], [[33, 33, "a"], [38, 39, "a"], [45, 45, "p"], [44, 44, "v"], [47, 47, "v"], [48, 49, "p"], [44, 44, "v"], [47, 47, "v"], [52, 55, "p"], [57, 57, "v"], [59, 59, "p"], [67, 67, "p"], [63, 63, "v"], [71, 71, "v"], [66, 67, "p"], [63, 63, "v"], [71, 71, "v"], [76, 80, "p"], [82, 82, "v"]]], "relations": [[], [], []], "predicted_ner": [[[5, 5, "v"], [8, 8, "a"]], [], [[38, 39, "a"], [44, 44, "v"], [47, 47, "v"], [57, 57, "v"], [63, 63, "v"], [71, 71, "v"], [79, 80, "a"], [82, 82, "v"]]], "predicted_relations": [[[5, 5, 5, 5, "USED-FOR"], [5, 5, 5, 5, "USED-FOR"]], [], [[45, 45, 33, 33, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [48, 49, 33, 33, "USED-FOR"], [44, 44, 45, 45, "USED-FOR"], [52, 55, 33, 33, "USED-FOR"], [63, 63, 52, 55, "USED-FOR"], [63, 63, 66, 67, "USED-FOR"], [66, 67, 33, 33, "USED-FOR"], [63, 63, 52, 55, "USED-FOR"], [63, 63, 66, 67, "USED-FOR"]]]}
{"doc_key": "2104.02555-b55cd1b1-7e74-45c1-a18b-3335851e64c0", "sentences": [["This", "setup", "is", "trained", "auto-regressively", ",", "i.e", "."], ["with", "a", "triangular", "attention", "mask", "."], ["We", "use", "the", "rectified", "Adam", "optimizer", "-LRB-", "RAdam", "-RRB-", "-LSB-", "26", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "and", "weight", "decay", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "for", "100", "epochs", "."], ["The", "batch", "size", "is", "32", "."], ["We", "half", "the", "learning", "rate", "on", "plateauing", "validation", "loss", "."]], "ner": [[], [[10, 12, "a"]], [[21, 21, "a"], [28, 30, "p"], [34, 34, "v"], [37, 38, "p"], [42, 42, "v"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[10, 10, "v"]], [[17, 22, "a"], [29, 30, "p"], [34, 34, "v"], [37, 38, "p"], [42, 42, "v"], [45, 45, "v"], [46, 46, "p"]], [[49, 50, "p"], [52, 52, "v"]], [[57, 58, "p"], [60, 62, "a"]]], "predicted_relations": [[], [], [[28, 30, 21, 21, "USED-FOR"], [34, 34, 37, 38, "USED-FOR"], [37, 38, 21, 21, "USED-FOR"], [42, 42, 37, 38, "USED-FOR"]], [], []]}
{"doc_key": "2104.02555-adfc7b4f-17df-49b6-b7d2-fd49c0342865", "sentences": [["Like", "before", ",", "we", "consistently", "use", "\\", "-LRB-", "F=256\\", "-RRB-", "dimensional", "FDEs", ",", "and", "employ", "the", "linear", "encoder", "and", "decoder", "method", "by", "Katharopoulos", "et", "al", "."], ["-LSB-", "6", "-RSB-", "."], ["More", "specifically", ",", "we", "use", "4", "transformer", "layers", ",", "8", "self-attention", "heads", "per", "layer", ",", "a", "query", "and", "value", "dimensionality", "of", "32", ",", "dropout", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "attention", "dropout", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "and", "a", "dimensionality", "of", "the", "feed-forward", "network", "of", "1024", "."], ["The", "residual", "conv-block", "has", "\\", "-LRB-", "d_", "-LCB-", "\\text", "-LCB-", "conv", "-RCB-", "-RCB-", "=8\\", "-RRB-", "intermediate", "feature", "channels", "."]], "ner": [[[16, 20, "a"]], [], [[46, 49, "p"], [51, 51, "v"], [53, 53, "p"], [61, 61, "p"], [57, 57, "v"], [65, 65, "v"], [60, 61, "p"], [57, 57, "v"], [65, 65, "v"], [70, 74, "p"], [76, 76, "v"], [39, 39, "v"]], [[79, 80, "p"], [91, 91, "v"], [93, 95, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "v"], [11, 11, "a"]], [], [[35, 35, "v"], [36, 37, "p"], [39, 39, "v"], [51, 51, "v"], [53, 53, "p"], [57, 57, "v"], [60, 61, "p"], [65, 65, "v"], [73, 74, "a"], [76, 76, "v"]], [[79, 80, "a"], [84, 90, "a"], [91, 91, "v"]]], "predicted_relations": [[], [], [[57, 57, 46, 49, "USED-FOR"], [57, 57, 60, 61, "USED-FOR"], [57, 57, 46, 49, "USED-FOR"], [57, 57, 60, 61, "USED-FOR"]], [[91, 91, 79, 80, "USED-FOR"], [93, 95, 91, 91, "USED-FOR"]]]}
{"doc_key": "2104.02555-c6b61fec-30ce-44e5-b456-618e5c1c86e2", "sentences": [["All", "networks", "are", "optimized", "using", "RAdam", "-LSB-", "26", "-RSB-", ",", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "and", "weight", "decay", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "for", "300", "-LRB-", "MNIST", "-RRB-", ",", "120", "-LRB-", "Kanji", "-RRB-", ",", "and", "350", "-LRB-", "LoDoPaB", "-RRB-", "epochs", "."], ["The", "batch", "size", "is", "32", "."], ["We", "half", "the", "learning", "rate", "on", "plateauing", "validation", "loss", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[5, 5, "a"], [12, 14, "p"], [18, 18, "v"], [21, 22, "p"], [26, 26, "v"], [44, 44, "a"], [13, 14, "a"]], [[47, 48, "a"]], [[55, 56, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"], [13, 14, "p"], [18, 18, "v"], [21, 22, "p"], [26, 26, "v"], [29, 29, "v"], [31, 31, "a"], [34, 34, "v"], [36, 36, "a"], [40, 40, "v"], [42, 42, "a"]], [[47, 48, "p"], [50, 50, "v"]], [[55, 56, "p"]], []], "predicted_relations": [[[12, 14, 5, 5, "USED-FOR"], [12, 14, 13, 14, "USED-FOR"], [18, 18, 12, 14, "USED-FOR"], [18, 18, 21, 22, "USED-FOR"], [21, 22, 5, 5, "USED-FOR"], [26, 26, 21, 22, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.08336-b42953d6-5869-46ba-abd7-5daf8fb85adb", "sentences": [["The", "proposed", "network", "is", "implemented", "using", "the", "PyTorch", "framework", "and", "trained", "on", "12", "Nvidia", "Tesla", "P100-16GB", "GPUs", "using", "\\", "-LRB-", "\\mathtt", "-LCB-", "DistributedDataParallel", "-RCB-", "\\", "-RRB-", "."], ["The", "TorchSparse", "library", "-LSB-", "19", "-RSB-", "is", "used", "for", "sparse", "convolutions", "."], ["During", "training", ",", "the", "ground", "plane", "is", "first", "removed", "using", "RANSAC", "plane", "fitting", "followed", "by", "down-sampling", "using", "a", "voxel", "grid", "filter", "of", "\\", "-LRB-", "10cm\\", "-RRB-", "."], ["Finally", ",", "input", "point", "clouds", "are", "limited", "to", "a", "maximum", "of", "\\", "-LRB-", "35K\\", "-RRB-", "points", "."], ["To", "reduce", "overfitting", ",", "we", "apply", "the", "following", "data", "augmentations", "for", "training", "."], ["Random", "point", "jitter", "is", "introduced", "using", "Gaussian", "noise", "sampled", "from", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "\\mu", "=0", ",", "\\sigma", "=0.01", "-RRB-", "\\", "-RRB-", "clipped", "at", "\\", "-LRB-", "0.03m\\", "-RRB-", "."], ["Each", "point", "cloud", "is", "also", "randomly", "rotated", "about", "the", "\\", "-LRB-", "z\\", "-RRB-", "-axis", "by", "an", "angle", "between", "\\", "-LRB-", "\\pm", "180^", "-LCB-", "\\circ", "-RCB-", "\\", "-RRB-", "."], ["Note", "that", "ground", "plane", "removal", "is", "not", "used", "during", "evaluation", "to", "speed", "up", "inference", "time", "as", "it", "does", "not", "affect", "evaluation", "performance", "of", "our", "proposed", "method", "."]], "ner": [[[7, 8, "a"], [22, 22, "a"]], [[28, 29, "a"]], [[49, 51, "a"], [57, 59, "a"]], [], [], [[125, 125, "v"], [96, 98, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 8, "a"], [12, 12, "v"], [20, 23, "a"]], [], [[63, 63, "v"]], [[79, 79, "v"]], [], [[125, 125, "v"]], [], [[181, 181, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2109.08336-42772043-f9d7-4afa-8a0f-50b59df93539", "sentences": [["The", "dimensionality", "of", "the", "local", "features", "is", "set", "to", "16", "which", "results", "in", "a", "256", "dimension", "global", "descriptor", "for", "fair", "comparison", "with", "PointNetVLAD", "."], ["In", "the", "local", "consistency", "loss", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "lc", "-RCB-", "\\", "-RRB-", ",", "the", "margins", "\\", "-LRB-", "m_p\\", "-RRB-", "and", "\\", "-LRB-", "m_n\\", "-RRB-", "are", "set", "to", "0.1", "and", "2.0", ",", "respectively", "."], ["The", "local", "consistency", "loss", "is", "only", "applied", "to", "randomly", "sampled", "5192", "positive", "pairs", "similar", "to", "FCGF", "-LSB-", "22", "-RSB-", "."], ["The", "quadruplet", "loss", "margins", "are", "set", "to", "\\", "-LRB-", "\\alpha", "=0.5\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "=0.3\\", "-RRB-", "."], ["The", "distances", "for", "sampling", "positive", "and", "negative", "point", "cloud", "pairs", "are", "set", "to", "\\", "-LRB-", "\\tau", "_p=3", "m\\", "-RRB-", "and", "\\", "-LRB-", "\\tau", "_n=20", "m\\", "-RRB-", "."], ["For", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_g\\", "-RRB-", "we", "use", "2", "positives", ",", "9", "negatives", "and", "1", "other", "negative", "."], ["We", "train", "our", "model", "using", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.001", "and", "a", "multi-step", "scheduler", "to", "drop", "the", "learning", "rate", "by", "a", "factor", "of", "10", "after", "10", "epochs", "and", "train", "until", "convergence", "for", "a", "maximum", "of", "24", "hours", "."]], "ner": [[[22, 22, "a"]], [[26, 28, "a"]], [[63, 65, "a"]], [[91, 91, "c"], [98, 98, "v"], [97, 97, "c"], [83, 84, "a"]], [], [], [[158, 160, "p"], [162, 162, "v"], [154, 155, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "v"], [14, 14, "v"], [15, 15, "p"], [22, 22, "a"]], [[26, 28, "a"], [56, 56, "v"], [58, 58, "v"]], [[63, 65, "a"], [72, 72, "v"], [77, 77, "a"]], [[92, 92, "v"], [98, 98, "v"]], [], [[139, 139, "v"], [142, 142, "v"], [145, 145, "v"]], [[152, 152, "a"], [154, 154, "a"], [159, 160, "p"], [162, 162, "v"], [170, 171, "p"], [176, 176, "v"], [178, 178, "v"], [179, 179, "p"], [188, 188, "v"]]], "predicted_relations": [[], [], [], [[91, 91, 98, 98, "USED-FOR"], [97, 97, 98, 98, "USED-FOR"]], [], [], [[158, 160, 154, 155, "USED-FOR"], [162, 162, 158, 160, "USED-FOR"]]]}
{"doc_key": "2109.08218-c0ebdc01-7113-4971-a347-7126d817e53c", "sentences": [["where", "the", "matrix", "\\", "-LRB-", "B\\", "-RRB-", "is", "shared", "between", "all", "tasks", ",", "while", "\\", "-LRB-", "\\sigma", "_i\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "_i\\", "-RRB-", "are", "specific", "to", "each", "task", "."], ["We", "refer", "to", "this", "collection", "of", "tasks", "as", "MTRegression", "."], ["The", "task", "is", "defined", "so", "that", "loss", "functions", "of", "various", "tasks", "have", "significantly", "different", "scale", ",", "posing", "a", "testbed", "for", "multi-task", "optimization", "."], ["The", "input", "and", "output", "dimensions", "are", "250", "and", "100", ",", "respectively", ",", "and", "the", "elements", "of", "\\", "-LRB-", "B\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "_i\\", "-RRB-", "are", "sampled", "independently", "from", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "0", ",", "10", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "0", ",", "3.5", "-RRB-", "\\", "-RRB-", ",", "respectively", "."], ["In", "our", "experiments", ",", "we", "set", "\\", "-LRB-", "\\sigma", "_i", "=", "i\\", "-RRB-", "and", "\\", "-LRB-", "n", "=", "10\\", "-RRB-", "."], ["The", "dataset", "has", "9000", "training", "samples", "and", "1000", "testing", "samples", ",", "where", "each", "sample", "has", "an", "input", "value", "and", "a", "label", "for", "each", "of", "the", "\\", "-LRB-", "n\\", "-RRB-", "tasks", "."]], "ner": [[], [[39, 39, "a"]], [], [[70, 70, "v"], [72, 72, "v"], [103, 103, "v"]], [[135, 135, "v"], [140, 140, "p"], [142, 142, "v"]], [[172, 172, "p"], [146, 146, "a"], [149, 150, "p"], [148, 148, "v"], [153, 154, "p"], [152, 152, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[39, 39, "a"]], [], [[70, 70, "v"], [72, 72, "v"], [103, 103, "v"], [117, 117, "v"]], [[142, 142, "v"]], [[148, 148, "v"], [152, 152, "v"]]], "predicted_relations": [[], [], [], [], [], [[149, 150, 146, 146, "USED-FOR"], [148, 148, 149, 150, "USED-FOR"], [148, 148, 153, 154, "USED-FOR"], [153, 154, 146, 146, "USED-FOR"], [152, 152, 149, 150, "USED-FOR"], [152, 152, 153, 154, "USED-FOR"]]]}
{"doc_key": "2109.08218-845cc7a4-e603-406e-847e-0f6f40ded84e", "sentences": [["Following", "-LSB-", "4", "-RSB-", ",", "we", "train", "a", "fully", "connected", "network", "made", "of", "a", "shared", "trunk", "with", "4", "fully-connected", "layers", ",", "ReLU", "activations", ",", "and", "a", "hidden", "size", "of", "100", ",", "followed", "by", "\\", "-LRB-", "n\\", "-RRB-", "one-layer", "task-specific", "output", "heads", "that", "produce", "the", "prediction", "for", "each", "task", "."], ["Each", "task", "'s", "loss", "function", "is", "a", "standard", "squared", "error", "between", "model", "output", "and", "ground-truth", "."], ["In", "each", "experiment", "the", "network", "is", "trained", "to", "minimize", "the", "weighted", "sum", "of", "the", "\\", "-LRB-", "n\\", "-RRB-", "task", "losses", ":", "\\", "-LRB-", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^n", "w_i", "L_i\\", "-RRB-", ",", "where", "\\", "-LRB-", "w_i\\", "-RRB-", "is", "determined", "differently", "by", "each", "method", "evaluated", "."]], "ner": [[[8, 10, "a"], [26, 27, "p"], [29, 29, "v"]], [[57, 58, "a"]], [[75, 76, "a"]]], "relations": [[], [], []], "predicted_ner": [[[17, 17, "v"], [21, 21, "a"], [26, 27, "p"], [29, 29, "v"]], [], []], "predicted_relations": [[[26, 27, 8, 10, "USED-FOR"], [29, 29, 26, 27, "USED-FOR"]], [], []]}
{"doc_key": "2109.08218-c02d08e2-7c73-4111-bec2-60c9e0b1c557", "sentences": [["The", "PubChem", "BioAssay", "-LRB-", "PCBA", "-RRB-", "dataset", "-LSB-", "36", "-RSB-", "contains", "data", "for", "128", "virtual", "screening", "tasks", "."], ["Virtual", "screening", "-LSB-", "32", "-RSB-", "is", "the", "process", "of", "predicting", "whether", "a", "candidate", "molecule", "will", "bind", "to", "a", "biological", "target", "in", "order", "to", "identify", "promising", "compounds", "for", "new", "drugs", "."], ["The", "128", "tasks", "are", "binary", "classification", "of", "candidate", "molecules", "as", "either", "active", "or", "inactive", "for", "128", "different", "biological", "targets", "."], ["In", "total", ",", "about", "440K", "candidate", "molecules", "are", "labeled", ",", "though", "each", "molecule", "is", "labeled", "for", "an", "average", "of", "78", "tasks", ",", "yielding", "over", "34", "million", "labeled", "candidate/target", "pairs", "."], ["The", "classes", "are", "not", "balanced", ";", "on", "average", ",", "only", "about", "2", "%", "of", "input", "molecules", "will", "bind", "to", "a", "given", "target", "."], ["We", "use", "the", "PCBA", "data", "hosted", "in", "the", "DeepChem", "-LSB-", "29", "-RSB-", "repository", "."]], "ner": [[[1, 6, "a"]], [[18, 19, "a"]], [], [], [], [[129, 129, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 6, "a"], [13, 13, "v"]], [], [[49, 49, "v"], [63, 63, "v"]], [[72, 72, "v"], [87, 87, "v"], [92, 93, "v"]], [[109, 110, "v"]], [[124, 125, "a"], [129, 129, "a"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2109.08218-e4b11844-d48f-4d29-8568-fa4e76386218", "sentences": [["Each", "input", "molecule", "is", "featurized", "as", "a", "2048-length", "binary", "vector", "using", "RDKit", "-LSB-", "19", "-RSB-", "to", "compute", "ECFP", "features", "-LSB-", "31", "-RSB-", "-LRB-", "radius", "4", "-RRB-", "."], ["We", "use", "the", "Pyramidal", "architecture", "of", "-LSB-", "30", "-RSB-", ":", "a", "fully-connected", "network", "made", "of", "a", "2-layer", "shared", "feature", "extractor", "and", "1-layer", "task-specific", "output", "heads", "."], ["The", "feature", "extractor", "layers", "have", "2000", "and", "100", "units", ",", "respectively", "."], ["Our", "loss", "function", "is", "the", "weighted", "sum", "of", "the", "cross-entropy", "classification", "loss", "for", "each", "task", "."], ["To", "account", "for", "class", "imbalance", ",", "we", "scale", "the", "loss", "for", "each", "class", "by", "a", "factor", "inversely", "proportional", "to", "the", "number", "of", "samples", "of", "that", "class", "."]], "ner": [[[11, 11, "a"], [17, 18, "a"]], [[30, 31, "a"]], [[60, 60, "v"]], [[70, 76, "a"]], [[84, 85, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 7, "v"], [11, 11, "a"], [24, 24, "v"]], [], [[58, 58, "v"], [60, 60, "v"]], [[66, 67, "a"], [74, 76, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2106.03917-c8add176-ce98-4235-8371-8f310833bafe", "sentences": [["For", "rotation-based", "self-supervised", "training", ",", "we", "follow", "the", "objective", "formulated", "in", "-LSB-", "21", "-RSB-", "."], ["The", "setup", "is", "mostly", "the", "same", "as", "for", "the", "standard", "training", "."], ["The", "only", "difference", "is", "that", "we", "reduce", "the", "batch", "size", "to", "16", "so", "that", "the", "extra", "rotated", "images", "used", "during", "the", "training", "can", "still", "fit", "into", "the", "GPU", "memory", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], [[35, 36, "p"], [38, 38, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2106.03917-f869ece7-c979-4059-81ec-b3a8459b81f1", "sentences": [["For", "OE-based", "training", ",", "we", "by", "default", "fine-tune", "the", "standard", "models", "with", "OE/EnergyOE/MixupOE", "objective", "for", "10", "epochs", "so", "that", "only", "minimal", "extra", "computation", "is", "introduced", "."], ["The", "fine-tuning", "also", "adopts", "cosine", "learning", "rate", "schedule", "with", "the", "learning", "rate", "being", "\\", "-LRB-", "0.001\\", "-RRB-", "."], ["When", "training", "from", "scratch", ",", "we", "follow", "the", "setup", "for", "standard", "training", "."], ["Regardless", "of", "the", "specific", "objective", ",", "we", "use", "32", "as", "the", "batch", "size", "of", "outliers", "-LRB-", "i.e.", ",", "the", "samples", "drawn", "from", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "out", "-RCB-", "-RCB-", "^", "-LCB-", "\\text", "-LCB-", "OE", "-RCB-", "-RCB-", "\\", "-RRB-", "-RRB-", "which", "fits", "within", "our", "GPU", "'s", "memory", "."]], "ner": [[[9, 10, "a"], [12, 13, "a"]], [[30, 33, "a"], [31, 32, "p"], [36, 37, "p"], [41, 41, "v"]], [], [[68, 71, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[15, 15, "v"], [16, 16, "p"]], [[36, 37, "p"], [41, 41, "v"]], [], [[65, 65, "v"], [68, 69, "p"]]], "predicted_relations": [[], [[36, 37, 30, 33, "USED-FOR"]], [], []]}
{"doc_key": "2106.03847-d5ccf7a6-b06d-4002-8086-c9a051edc947", "sentences": [["We", "used", "the", "same", "hyperparameter", "configurations", "as", "in", "the", "Pytorch", "-LSB-", "26", "-RSB-", "implementation", "of", "StyleGAN2-ada", "-LSB-", "10", "-RSB-", ",", "while", "we", "did", "not", "use", "the", "adaptive", "augmentation", "capabilities", "."], ["We", "used", "a", "fixed", "mapping", "depth", "of", "8", "layers", "during", "all", "our", "experiments", "."], ["The", "hyperparameters", "were", "chosen", "by", "a", "random", "search", "and", "are", "presented", "in", "the", "attached", "code", "."]], "ner": [[[15, 15, "a"]], [[34, 35, "p"], [37, 38, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[9, 9, "a"], [15, 15, "a"]], [[37, 37, "v"], [38, 38, "p"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2109.02753-0b91abf5-0f44-4bf6-8293-5f796f8b1d69", "sentences": [["Our", "system", "is", "developed", "based", "on", "Huggingface", "Transformershttps", ":", "//github.com/huggingface/transformers", "."], ["The", "mention", "extraction", "model", "is", "trained", "for", "one", "epoch", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "1e-5\\", "-RRB-", "and", "a", "batch", "size", "of", "32", "."], ["The", "IS", "assignment", "model", "is", "trained", "for", "three", "epochs", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "3e-5\\", "-RRB-", "and", "a", "batch", "size", "of", "32", "."], ["Both", "models", "are", "initialized", "using", "pre-trained", "RoBERTa\\", "-LRB-", "_", "-LCB-", "LARGE", "-RCB-", "\\", "-RRB-", "contextual", "embeddings", "."], ["They", "have", "24", "transformer", "blocks", ",", "1024", "hidden", "units", ",", "16", "self-attention", "heads", ",", "and", "around", "355M", "parameters", "."]], "ner": [[], [], [], [], [[94, 94, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[18, 18, "v"], [19, 19, "p"], [22, 23, "p"], [27, 27, "v"], [31, 32, "p"], [34, 34, "v"]], [[43, 43, "v"], [44, 44, "p"], [47, 48, "p"], [52, 52, "v"], [56, 57, "p"], [59, 59, "v"]], [], [[80, 80, "v"], [84, 84, "v"], [85, 86, "p"], [88, 88, "v"], [94, 94, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2112.07522-578c9d0a-5770-473c-882b-affeb8f2bbb5", "sentences": [["-LSB-", "7", "-RSB-", "show", "that", "large", "model", "size", "is", "necessary", "for", "strong", "few-shot", "performance", "."], ["We", "use", "ALBERT-XXLarge-v2", "-LSB-", "33", "-RSB-", "\u2013", "of", "size", "223M", "parameters", "\u2013", "as", "our", "large", "PLM", ",", "which", "is", "adapted", "to", "be", "an", "LMTurker", "\\", "-LRB-", "A\\", "-RRB-", "of", "\\", "-LRB-", "\\mathcal", "-LCB-", "T", "-RCB-", "\\", "-RRB-", "with", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "\\", "-RRB-", "."], ["With", "parameter", "reuse", ",", "ALBERT-XXLarge-v2", "outperforms", "larger", "models", "like", "the", "334M", "BERT-large", "-LSB-", "13", "-RSB-", "."], ["In", "contrast", ",", "\\", "-LRB-", "\\mathcal", "-LCB-", "S", "-RCB-", "\\", "-RRB-", "must", "be", "small", "to", "be", "deployable", "in", "practical", "scenarios", "."], ["We", "use", "TinyBERT-General-4L-312D", "-LSB-", "29", "-RSB-", ",", "which", "has", "14.5M", "parameters", ",", "but", "performs", "comparably", "to", "BERT-base", "-LRB-", "110M", "-RRB-", "."]], "ner": [[], [[17, 17, "a"]], [[66, 66, "a"], [73, 73, "a"]], [], [[101, 101, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[17, 17, "a"], [24, 24, "v"]], [[66, 66, "a"], [72, 72, "v"], [73, 73, "a"]], [], [[101, 101, "a"], [108, 108, "v"], [115, 115, "a"], [117, 117, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2110.05098-e9c99b38-0c18-45e1-b941-98fe26757dac", "sentences": [["Except", "ASF", "module", "-LRB-", "REF", "-RRB-", ",", "all", "weights", "of", "our", "SurroundNet", "are", "initialized", "randomly", "."], ["Adam", "optimizer", "is", "adopted", "to", "optimize", "the", "whole", "network", "."], ["The", "learning", "rate", "is", "set", "to", "0.001", ",", "and", "the", "momentum", "is", "0.9", "."], ["In", "every", "mini-batch", ",", "we", "randomly", "crop", "32", "dark-light", "patch", "pairs", ",", "each", "of", "which", "has", "two", "paired", "128", "*", "128", "images", "."], ["We", "set", "epoch", "to", "100", "on", "synthetic", "dataset", ",", "and", "fine-tune", "epoch", "is", "set", "to", "3500", "on", "LOL", "dataset", "."], ["For", "ablation", "experiments", ",", "all", "the", "training", "epochs", "are", "set", "to", "100", "unless", "otherwise", "stated", "."], ["All", "models", "are", "trained", "on", "the", "platform", "with", "Nvidia", "GTX", "2080Ti", "GPU", "."]], "ner": [[], [[16, 17, "a"]], [[27, 28, "p"], [32, 32, "v"], [36, 36, "p"], [38, 38, "v"]], [[42, 42, "a"], [47, 47, "v"], [58, 60, "v"]], [[65, 65, "a"], [74, 74, "a"], [69, 70, "p"], [67, 67, "v"], [80, 81, "p"], [78, 78, "v"], [67, 67, "v"]], [[94, 94, "v"], [84, 85, "p"], [94, 94, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"]], [[16, 16, "a"]], [[27, 28, "p"], [32, 32, "v"], [36, 36, "p"], [38, 38, "v"]], [[47, 47, "v"], [56, 56, "v"], [58, 58, "v"], [60, 60, "v"]], [[65, 65, "p"], [67, 67, "v"], [78, 78, "v"]], [[89, 90, "p"], [94, 94, "v"]], []], "predicted_relations": [[], [], [[32, 32, 36, 36, "USED-FOR"]], [], [[69, 70, 65, 65, "USED-FOR"], [69, 70, 74, 74, "USED-FOR"], [80, 81, 65, 65, "USED-FOR"], [80, 81, 74, 74, "USED-FOR"], [78, 78, 80, 81, "USED-FOR"]], [], []]}
{"doc_key": "2110.11191-8d9806d1-2f50-4e9d-8c52-e91c914ebe79", "sentences": [["Training", "configurations", "."], ["We", "train", "the", "networks", "using", "Adam", "-LSB-", "21", "-RSB-", "optimizer", "with", "\\", "-LRB-", "\\alpha", "=", "2", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.5\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "for", "all", "datasets", "with", "a", "minibatch", "size", "of", "32", "."], ["Since", "we", "rely", "on", "the", "WGAN-GP", "loss", "-LSB-", "12", "-RSB-", ",", "we", "set", "\\", "-LRB-", "n_", "-LCB-", "critic", "-RCB-", "=", "5\\", "-RRB-", ",", "which", "sets", "the", "number", "of", "iterations", "of", "the", "discriminator", "per", "generator", "iteration", "."]], "ner": [[], [[8, 8, "a"], [16, 16, "p"], [32, 32, "v"], [40, 40, "v"], [45, 45, "p"], [32, 32, "v"]], [[68, 68, "a"], [83, 83, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[8, 8, "a"], [16, 16, "p"], [18, 18, "v"], [20, 23, "v"], [32, 32, "v"], [40, 40, "v"], [47, 50, "v"], [58, 59, "p"], [61, 61, "v"]], [[68, 69, "a"], [78, 81, "a"], [83, 83, "v"]]], "predicted_relations": [[], [[16, 16, 8, 8, "USED-FOR"], [40, 40, 45, 45, "USED-FOR"], [45, 45, 8, 8, "USED-FOR"]], []]}
{"doc_key": "2110.11191-275b6144-940a-457d-947b-c88a98b34ca7", "sentences": [["Noise", "injection", "details", "."], ["The", "noise", "injector", "described", "in", "Section", "3.4.1", "samples", "a", "random", "noise", "\\", "-LRB-", "\\mathbf", "-LCB-", "r", "-RCB-", "_l\\", "-RRB-", "using", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "0", ",", "1", "-RRB-", "\\", "-RRB-", "."], ["Each", "joint", "at", "resolution", "level", "\\", "-LRB-", "l\\", "-RRB-", "has", "a", "respective", "weight", "to", "each", "channel", "and", "receives", "a", "different", "noise", "added", "channel-wise", "."], ["This", "operation", "is", "applied", "to", "every", "generator", "'s", "layer", "."]], "ner": [[[0, 1, "a"]], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[], [[31, 33, "v"]], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2103.06450-5d39bb3f-1ca0-4280-b59f-fd26ac4613b0", "sentences": [["\\", "-LRB-", "N\\", "-RRB-", "-LRB-", "number", "of", "layers", "-RRB-", "=", "6", "\\", "-LRB-", "d_", "-LCB-", "model", "-RCB-", "\\", "-RRB-", "=", "260", "\\", "-LRB-", "h\\", "-RRB-", "-LRB-", "number", "of", "heads", "-RRB-", "=", "4", "\\", "-LRB-", "d_", "-LCB-", "ff", "-RCB-", "\\", "-RRB-", "-LRB-", "inner-layer", "of", "positionwise", "feed-forward", "network", "-RRB-", "=", "1024", "Activation", "function", "inside", "feed-forward", "layer", "=", "GELU", "-LSB-", "11", "-RSB-", "dropout", "=", "0.5"]], "ner": [[[5, 7, "a"], [26, 28, "a"], [55, 55, "p"], [59, 59, "a"], [61, 61, "v"]]], "relations": [[]], "predicted_ner": [[[10, 10, "v"], [20, 20, "v"], [31, 31, "v"], [34, 37, "a"], [43, 45, "a"], [48, 48, "v"], [55, 55, "a"], [61, 61, "v"]]], "predicted_relations": [[[55, 55, 26, 28, "USED-FOR"]]]}
{"doc_key": "2103.06450-4cbe48a2-b7ae-43d5-b6fe-43e642c59f44", "sentences": [["The", "model", "was", "implemented", "in", "PyTorch", "-LSB-", "20", "-RSB-", ",", "and", "training", "was", "carried", "out", "using", "8", "NVIDIA", "2080Ti", "GPUs", "."], ["For", "full", "page", "datasets", "a", "mini-batch", "size", "of", "56", "combined", "with", "a", "gradient", "accumulation", "factor", "of", "2", "was", "used", ",", "yielding", "an", "effective", "batch-size", "of", "112", "."], ["Single-line", "datasets", "had", "batch", "sizes", "as", "high", "as", "200", ",", "but", "were", "adjusted", "downwards", "when", "using", "higher", "angles", "of", "image", "rotation", "."], ["ADAM", "optimizer", "-LSB-", "13", "-RSB-", "was", "employed", "with", "a", "fixed", "learning", "rate", "-LRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "-RRB-", "of", "0.0002", ",", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "\\", "-RRB-", "=", "0.9", "and", "\\", "-LRB-", "\\beta", "_", "-LCB-", "2", "-RCB-", "\\", "-RRB-", "=", "0.999", "."]], "ner": [[[5, 5, "a"]], [], [], [[70, 71, "a"], [80, 81, "p"], [90, 90, "v"], [102, 102, "v"], [114, 114, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "a"], [16, 16, "v"]], [[26, 27, "p"], [29, 29, "v"], [33, 35, "p"], [37, 37, "v"], [44, 44, "p"], [46, 46, "v"]], [[56, 56, "v"]], [[70, 70, "a"], [80, 81, "p"], [85, 85, "p"], [90, 90, "v"], [102, 102, "v"], [114, 114, "v"]]], "predicted_relations": [[], [], [], [[80, 81, 70, 71, "USED-FOR"]]]}
{"doc_key": "2103.06450-794839d7-d43e-4998-a3fc-f4682cf8d883", "sentences": [["While", "all", "images", "in", "a", "batch", "must", "have", "the", "same", "size", ";", "we", "also", "set", "all", "batches", "to", "have", "the", "same", "image", "size", ",", "padding", "smaller", "images", "as", "needed", "."], ["This", "helps", "during", "training", "because", "any", "impending", "GPU", "OOM", "errors", "surface", "quickly", "at", "the", "beginning", "of", "the", "run", "."], ["It", "also", "makes", "the", "validation", "/", "test", "results", "agnostic", "of", "the", "batching", "scheme", "since", "the", "images", "will", "always", "be", "the", "same", "size", "regardless", "of", "how", "they", "are", "grouped", "."], ["Smaller", "images", "within", "a", "batch", "are", "centered", "during", "validation", "and", "testing", "."], ["Padding", "color", "can", "be", "either", "the", "max", "of", "4", "corner", "pixels", "or", "simply", "0", "-LRB-", "black", "-RRB-", ",", "the", "choice", "having", "no", "impact", "on", "model", "accuracy", "."]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [], [[98, 98, "v"], [103, 103, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.11626-81b73f97-9f53-4a07-bc63-447081e02c32", "sentences": [["In", "CoMPM", ",", "CoM", "uses", "a", "pre-trained", "GPT2-medium", "as", "the", "initial", "state", "and", "PM", "uses", "a", "pre-trained", "distilRoBERTa", "as", "the", "initial", "state", "."], ["We", "use", "the", "pre-trained", "model", "from", "the", "huggingface", "library", "https", ":", "//github.com/huggingface/transformers", "."], ["The", "optimizer", "is", "AdamW", "and", "the", "learning", "rate", "is", "1e-5", "as", "an", "initial", "value", "."], ["The", "learning", "rate", "scheduler", "used", "for", "training", "is", "get_linear_schedule_with_warmup", ",", "and", "the", "maximum", "value", "of", "10", "is", "used", "for", "the", "gradient", "clipping", "."], ["We", "select", "the", "model", "with", "the", "best", "performance", "on", "the", "validation", "set", "."], ["All", "experiments", "are", "conducted", "on", "one", "V100", "GPU", "with", "32GB", "memory", "."]], "ner": [[[7, 7, "a"], [17, 17, "a"]], [], [[39, 39, "a"], [42, 43, "p"], [45, 45, "v"]], [[52, 53, "p"], [59, 59, "a"], [63, 64, "p"], [66, 66, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [7, 7, "a"], [17, 17, "a"]], [], [[39, 39, "a"], [42, 43, "p"], [45, 45, "v"]], [[52, 53, "p"], [59, 59, "a"], [66, 66, "v"], [71, 72, "a"]], [], [[92, 92, "v"], [96, 96, "v"]]], "predicted_relations": [[], [], [[42, 43, 39, 39, "USED-FOR"], [45, 45, 42, 43, "USED-FOR"]], [[66, 66, 63, 64, "USED-FOR"]], [], []]}
{"doc_key": "2102.00086-dd180550-076d-46bd-8993-28199affaa65", "sentences": [["For", "all", "the", "experiments", ",", "we", "fine-tune", "RoBERTa-large", "-LSB-", "26", "-RSB-", "over", "the", "corresponding", "corpus", "with", "one", "GTX2080", "Ti", "."], ["We", "use", "the", "default", "hyperparameters", "as", "provided", "in", "the", "HuggingFace", "Transformers", "library", "-LSB-", "46", "-RSB-", ",", "with", "two", "major", "changes", ":", "we", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "8", "batch", "size", "in", "all", "experiments", "."]], "ner": [[[7, 7, "a"]], [[44, 45, "p"], [57, 58, "a"], [57, 58, "p"], [56, 56, "v"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "a"], [16, 16, "v"], [17, 17, "a"]], [[37, 37, "v"], [44, 45, "p"], [49, 51, "v"], [56, 56, "v"], [57, 58, "p"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.15535-3848fd0b-0207-464d-8217-770cfe81a0b9", "sentences": [["We", "use", "the", "default", "setting", "in", "Deep", "Graph", "Library", "-LSB-", "37", "-RSB-", "Apache", "License", "2.0.", "for", "model", "hyper-parameters", "."], ["We", "use", "the", "Adam", "optimizer", "with", "initial", "learning", "rate", "of", "0.01", "and", "weight", "decay", "of", "5e-4", "to", "train", "all", "models", "for", "400", "epoch", "by", "minimizing", "the", "cross", "entropy", "loss", ",", "with", "early", "stopping", "on", "the", "validation", "set", "."]], "ner": [[[6, 8, "a"]], [[22, 23, "a"], [25, 27, "p"], [29, 29, "v"], [31, 32, "p"], [34, 34, "v"], [45, 47, "a"]]], "relations": [[], []], "predicted_ner": [[], [[22, 22, "a"], [26, 27, "p"], [29, 29, "v"], [31, 32, "p"], [34, 34, "v"], [40, 40, "v"], [41, 41, "p"], [45, 47, "a"]]], "predicted_relations": [[], [[25, 27, 22, 23, "USED-FOR"], [29, 29, 31, 32, "USED-FOR"], [31, 32, 22, 23, "USED-FOR"], [34, 34, 25, 27, "USED-FOR"], [34, 34, 31, 32, "USED-FOR"]]]}
{"doc_key": "2109.15222-d47f9c7a-e219-43dc-ab86-26b6aa411e9c", "sentences": [["We", "use", "an", "encoder-decoder", "architecture", "with", "ResNet-18", "without", "the", "classification", "layers", "as", "the", "encoder", ",", "two", "1x1", "convolutions", "in", "the", "bottleneck", "to", "reduce", "the", "number", "of", "channels", "and", "a", "simpler", "ResNet-based", "decoder", "."], ["The", "final", "activation", "is", "sigmoid", "and", "we", "use", "binary-crossentropy", "loss", "for", "all", "models", "besides", "NSA", "-LRB-", "continuous", "-RRB-", "for", "which", "we", "use", "ReLU", "activation", "and", "mean", "squared", "error", "loss", "as", "the", "labels", "are", "unbounded", "."], ["The", "models", "are", "trained", "on", "batches", "of", "size", "64", "using", "Adam", "with", "a", "cosine-annealing", "learning", "rate", "that", "decays", "from", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "over", "320", "epochs", "."], ["For", "non-aligned", "objects", ",", "the", "loss", "takes", "longer", "to", "converge", ",", "so", "we", "use", "560", "epochs", "for", "the", "hazelnut", ",", "metal", "nut", ",", "and", "screw", "classes", "in", "the", "MVTec", "AD", "dataset", "."], ["For", "rCXR", ",", "we", "use", "240", "epochs", "."], ["The", "same", "training", "hyperparameters", "are", "used", "for", "all", "variants", "of", "the", "self-supervised", "task", "."], ["Hyperparameters", "for", "the", "self-supervised", "task", "are", "given", "in", "the", "supplementary", "material", "."], ["Note", "that", "in", "our", "implementation", "of", "FPI", "and", "CutPaste", "we", "also", "use", "object", "masks", "and", "the", "patch", "sizes", "are", "sampled", "from", "a", "truncated", "Gamma", "distribution", "rather", "than", "a", "uniform", "distribution", "as", "described", "in", "and", "to", "allow", "for", "a", "more", "fair", "comparison", "with", "NSA", "."]], "ner": [[[3, 4, "a"], [6, 6, "a"], [16, 17, "a"]], [[37, 37, "a"], [41, 42, "a"], [55, 56, "a"], [58, 61, "a"]], [[78, 78, "a"], [81, 83, "a"]], [], [], [], [], [[180, 180, "a"], [182, 182, "a"], [186, 187, "a"], [196, 198, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [15, 15, "v"], [16, 16, "v"], [30, 30, "a"]], [[37, 37, "a"], [41, 42, "a"], [47, 47, "a"], [55, 56, "a"], [58, 61, "a"]], [[76, 76, "v"], [78, 78, "a"], [81, 81, "a"], [82, 83, "p"], [89, 93, "v"], [98, 101, "v"], [105, 105, "v"], [106, 106, "p"]], [[122, 122, "v"], [123, 123, "p"], [126, 126, "a"], [136, 137, "a"]], [[141, 141, "a"], [145, 145, "v"], [146, 146, "p"]], [], [], [[180, 180, "a"], [182, 182, "a"], [216, 216, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2109.15222-4fa14577-339b-4955-9178-44eeeb1bfee0", "sentences": [["The", "rCXR", "images", "also", "have", "a", "high", "resolution", "of", "\\", "-LRB-", "1024\\times", "1024\\", "-RRB-", "pixels", "but", "are", "grayscale", "."], ["We", "resize", "them", "to", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "pixels", "for", "training", "and", "apply", "a", "random", "rotation", "of", "up", "to", "3", "degrees", ",", "center-crop", "to", "\\", "-LRB-", "230\\times", "230\\", "-RRB-", "pixels", "and", "take", "a", "random", "crop", "of", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "pixels", "."], ["For", "testing", "we", "use", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "center-crops", "of", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "resampled", "images", "."]], "ner": [[], [[40, 41, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[12, 12, "v"]], [[25, 25, "v"], [27, 27, "v"], [40, 40, "v"], [48, 48, "v"], [60, 60, "v"]], [[71, 71, "v"], [77, 77, "v"], [79, 79, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2110.09424-87dd1524-5421-49b0-83f5-9319145d1f15", "sentences": [["Two", "diagnostic", "classifiers", "are", "used", "to", "retrieve", "the", "protected", "variables", "from", "the", "network", "latent", "representation", ",", "Logistic", "Regression", "-LRB-", "LR", "-RRB-", "and", "XGBoost", "."], ["During", "our", "initial", "experiments", ",", "we", "conducted", "a", "grid", "search", "on", "the", "hyperparameters", "of", "the", "two", "algorithms", ",", "but", "observed", "little", "variation", "on", "the", "performance", "of", "XGBoost", "classifier", "."], ["Because", "the", "hyperparameter", "search", "was", "very", "extensive", "for", "this", "classifier", ",", "we", "decided", "to", "select", "a", "set", "of", "average", "values", "for", "the", "parameters", ":", "loss", "reduction", "split", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "is", "fixed", "to", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "regularization", "parameter", "\\", "-LRB-", "\\alpha", "\\in", "\\lbrace", "0.3", ",", "0.5\\rbrace", "\\", "-RRB-", "and", "number", "of", "estimators", "is", "500", "."], ["For", "LR", ",", "we", "observed", "more", "variation", "in", "the", "output", "depending", "on", "the", "regularization", "parameter", "."], ["We", "thus", "run", "a", "hyperparameter", "search", "each", "time", ",", "selecting", "the", "best", "value", "in", "the", "range", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "...", "10^4\\", "-RRB-", ",", "depending", "on", "the", "performance", "on", "the", "validation", "set", ",", "and", "both", "\\", "-LRB-", "\\ell", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "norms", "were", "tested", "."]], "ner": [[[22, 22, "a"]], [[50, 50, "a"]], [[93, 94, "p"], [100, 100, "v"], [102, 102, "v"], [77, 79, "p"], [90, 90, "v"], [93, 94, "p"], [100, 100, "v"], [102, 102, "v"], [106, 108, "p"], [110, 110, "v"], [93, 94, "p"]], [[125, 126, "p"], [125, 126, "p"], [125, 126, "p"]], [[151, 151, "v"], [176, 176, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 0, "v"], [22, 22, "a"]], [[39, 39, "v"], [50, 50, "a"]], [[77, 79, "p"], [82, 82, "p"], [90, 90, "v"], [93, 94, "p"], [97, 97, "p"], [99, 102, "v"], [110, 110, "v"]], [], [[132, 133, "c"], [146, 148, "v"], [151, 151, "v"], [167, 168, "v"], [173, 174, "p"]]], "predicted_relations": [[], [], [[100, 100, 93, 94, "USED-FOR"], [100, 100, 93, 94, "USED-FOR"], [100, 100, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"], [90, 90, 93, 94, "USED-FOR"], [90, 90, 93, 94, "USED-FOR"], [90, 90, 93, 94, "USED-FOR"], [100, 100, 93, 94, "USED-FOR"], [100, 100, 93, 94, "USED-FOR"], [100, 100, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"], [102, 102, 93, 94, "USED-FOR"]], [], []]}
{"doc_key": "2108.10274-34711420-0fe6-4ca5-9c02-962de102a2fd", "sentences": [["We", "use", "BiLSTMs", "with", "one", "hidden", "layer", "of", "100", "dimensions", ",", "100-dimensional", "randomly", "initialised", "word", "embeddings", ",", "a", "label", "embedding", "size", "of", "100", "."], ["We", "train", "our", "models", "with", "RMSProp", ",", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "a", "batch", "size", "of", "128", ",", "and", "early", "stopping", "on", "the", "validation", "set", "of", "the", "main", "task", "with", "a", "patience", "of", "3", "."]], "ner": [[[2, 2, "a"], [5, 6, "p"], [8, 8, "v"], [11, 11, "v"], [22, 22, "v"], [9, 9, "c"], [14, 15, "p"], [11, 11, "v"], [12, 13, "c"], [18, 20, "p"], [8, 8, "v"], [11, 11, "v"], [22, 22, "v"]], [[29, 29, "a"], [32, 33, "p"], [37, 37, "v"], [41, 42, "p"], [44, 44, "v"], [59, 59, "p"], [61, 61, "v"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [5, 6, "p"], [8, 8, "v"], [9, 9, "p"], [11, 11, "v"], [22, 22, "v"]], [[27, 27, "a"], [29, 29, "a"], [32, 33, "p"], [37, 37, "v"], [41, 42, "p"], [44, 44, "v"], [47, 48, "a"], [61, 61, "v"]]], "predicted_relations": [[[5, 6, 2, 2, "USED-FOR"], [22, 22, 18, 20, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [14, 15, 2, 2, "USED-FOR"], [12, 13, 8, 8, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 22, 22, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 8, 8, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 22, 22, "USED-FOR"], [18, 20, 2, 2, "USED-FOR"], [22, 22, 18, 20, "USED-FOR"]], [[32, 33, 29, 29, "USED-FOR"], [41, 42, 29, 29, "USED-FOR"]]]}
{"doc_key": "2112.01527-35640403-e7f3-4fb9-8d56-44a5729aa506", "sentences": [["Semantic", "segmentation", "."], ["We", "follow", "the", "same", "settings", "as", "-LSB-", "13", "-RSB-", "to", "train", "our", "models", ",", "except", ":", "1", "-RRB-", "a", "learning", "rate", "multiplier", "of", "0.1", "is", "applied", "to", "both", "CNN", "and", "Transformer", "backbones", "instead", "of", "only", "applying", "it", "to", "CNN", "backbones", "in", "-LSB-", "13", "-RSB-", ",", "2", "-RRB-", "both", "ResNet", "and", "Swin", "backbones", "use", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "0.05\\", "-RRB-", ",", "instead", "of", "using", "different", "learning", "rates", "in", "-LSB-", "13", "-RSB-", "."]], "ner": [[[0, 1, "a"]], [[51, 51, "a"], [26, 26, "v"], [67, 68, "p"], [53, 53, "a"], [22, 24, "a"]]], "relations": [[], []], "predicted_ner": [[], [[15, 15, "a"], [22, 24, "p"], [26, 26, "v"], [31, 31, "a"], [33, 33, "a"], [41, 41, "a"], [51, 51, "a"], [53, 53, "a"], [58, 59, "p"], [63, 63, "v"], [67, 68, "p"], [72, 72, "v"], [79, 80, "p"]]], "predicted_relations": [[], [[67, 68, 51, 51, "USED-FOR"], [67, 68, 53, 53, "USED-FOR"]]]}
{"doc_key": "2107.11262-b86627b9-3eb6-43d5-ae79-8a73d114be23", "sentences": [["For", "our", "experiments", ",", "we", "fixed", "the", "LR", "image", "resolution", "to", "\\", "-LRB-", "8\\times", "8\\", "-RRB-", "and", "experimented", "with", "\\", "-LRB-", "128", "\\times", "128\\", "-RRB-", "and", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "for", "the", "HR", "image", "resolution\u2014we", "ablate", "the", "effect", "of", "LR", "image", "resolution", "in", "sec", "."], ["REF", "."], ["We", "train", "our", "networks", "with", "Adam", "-LSB-", "20", "-RSB-", "and", "TTUR", "-LSB-", "13", "-RSB-", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "generator", "and", "\\", "-LRB-", "4", "\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "discriminator", "."], ["We", "also", "used", "\\", "-LRB-", "R^1\\", "-RRB-", "regularization", "-LSB-", "27", "-RSB-", "with", "\\", "-LRB-", "\\gamma", "=0.5\\", "-RRB-", ",", "with", "a", "batch", "size", "of", "8", "."], ["Spectral", "normalization", "-LSB-", "28", "-RSB-", "was", "used", "in", "all", "the", "layers", "of", "both", "\\", "-LRB-", "G\\", "-RRB-", "and", "\\", "-LRB-", "D\\", "-RRB-", "."], ["In", "eq", "."], ["REF", ",", "we", "use", "\\", "-LRB-", "\\epsilon", "=0\\", "-RRB-", "to", "push", "the", "downscaled", "version", "of", "the", "generated", "image", "to", "be", "as", "close", "as", "possible", "to", "the", "LR", "target", "."], ["We", "set", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "cyc", "-RCB-", "=1\\", "-RRB-", "when", "trained", "on", "\\", "-LRB-", "128", "\\times", "128\\", "-RRB-", ",", "and", "to", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "cyc", "-RCB-", "=0.1\\", "-RRB-", "for", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [[54, 54, "a"], [59, 59, "a"]], [[109, 109, "p"], [110, 110, "v"], [110, 110, "v"], [100, 100, "v"]], [[120, 121, "a"]], [], [[152, 152, "p"], [153, 153, "v"]], [[205, 205, "v"], [184, 184, "v"], [205, 205, "v"], [205, 205, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[14, 14, "v"], [21, 21, "v"], [23, 23, "v"], [28, 28, "v"], [30, 30, "v"]], [], [[52, 52, "a"], [54, 54, "a"], [59, 59, "a"], [66, 67, "p"], [71, 74, "v"], [83, 83, "v"]], [[100, 100, "v"], [109, 109, "p"], [110, 110, "v"], [115, 116, "p"], [118, 118, "v"]], [[120, 121, "a"]], [], [], [[179, 183, "p"], [184, 184, "v"], [191, 191, "v"], [193, 193, "v"], [200, 204, "p"], [210, 211, "v"]], []], "predicted_relations": [[], [], [], [[110, 110, 109, 109, "USED-FOR"], [110, 110, 109, 109, "USED-FOR"]], [], [], [[153, 153, 152, 152, "USED-FOR"]], [], []]}
{"doc_key": "2112.00133-a2c3b7b7-a441-45eb-9046-6acc4ebc9b29", "sentences": [["We", "conduct", "experiments", "on", "64", "TPU-v3", "chips", "with", "a", "batch", "size", "of", "8192", "."], ["We", "use", "Adam", "optimizer", "-LSB-", "27", "-RSB-", "-LRB-", "\\", "-LRB-", "\\beta", "_1", "=", "0.9", ",", "\\beta", "_2", "=", "0.99\\", "-RRB-", "-RRB-", "with", "a", "linear", "learning", "rate", "decay", "."], ["The", "initial", "learning", "rate", "is", "6.4e-4", "."], ["The", "weight", "decay", "is", "set", "to", "5e-5", "throughout", "the", "training", "."], ["BatchNorm", "momentum", "is", "set", "to", "0.9", "."], ["To", "estimate", "the", "clipping", "bound", "\\", "-LRB-", "B\\", "-RRB-", "for", "activation", "of", "non-binary", "quantized", "layers", ",", "we", "follow", "the", "method", "in", "-LSB-", "0", "-RSB-", "and", "use", "exponentially", "moving", "average", "-LRB-", "\\", "-LRB-", "\\alpha", "=0.9\\", "-RRB-", "-RRB-", "of", "maximum", "value", "in", "a", "batch", "."]], "ner": [[], [[16, 17, "a"], [27, 27, "v"], [32, 32, "v"], [37, 40, "a"], [27, 27, "v"], [27, 27, "v"]], [[43, 45, "p"], [47, 47, "v"]], [[50, 51, "a"], [50, 51, "p"], [55, 55, "v"]], [[65, 65, "v"], [60, 61, "a"], [60, 61, "p"], [65, 65, "v"], [65, 65, "v"]], [[100, 100, "v"], [100, 100, "v"], [93, 95, "a"], [100, 100, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "v"], [5, 5, "a"], [9, 10, "p"], [12, 12, "v"]], [[16, 16, "a"], [27, 27, "v"], [32, 32, "v"], [37, 40, "p"]], [[44, 45, "p"], [47, 47, "v"]], [[50, 51, "p"], [55, 55, "v"], [56, 58, "c"]], [[60, 61, "a"], [65, 65, "v"]], [[74, 74, "p"], [93, 95, "a"], [100, 100, "v"]]], "predicted_relations": [[], [], [[47, 47, 43, 45, "USED-FOR"]], [[55, 55, 50, 51, "USED-FOR"]], [[60, 61, 60, 61, "USED-FOR"]], []]}
{"doc_key": "2107.04225-f57c9c8e-4bf3-4c10-87b6-29d4d57d11ca", "sentences": [["A", "model", "was", "trained", "with", "our", "training", "split", "dataset", "only", "."], ["We", "used", "the", "pretrained", "weight", "from", "TSAV", "to", "initialize", "the", "backbone", "for", "audio", "and", "video", "branch", "."], ["The", "model", "was", "optimized", "using", "Adam", "optimizer", "and", "a", "learning", "rate", "of", "0.0005", "."], ["Random", "brightness", "augmentation", "was", "applied", "for", "each", "input", "clip", "."], ["The", "mini-batch", "size", "was", "set", "to", "32", "."], ["The", "training", "and", "validating", "processes", "were", "performed", "using", "two", "GPU", "to", "allocate", "each", "of", "the", "teacher", "and", "student", "networks", "to", "one", "GPU", "."]], "ner": [[[1, 1, "a"]], [[14, 17, "a"]], [[29, 29, "a"], [33, 34, "p"], [37, 38, "p"], [40, 40, "v"]], [], [[53, 54, "p"], [58, 58, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 8, "a"]], [[17, 17, "a"]], [[33, 33, "a"], [37, 38, "p"], [40, 40, "v"]], [], [[53, 54, "p"], [58, 58, "v"]], [[68, 68, "v"], [80, 80, "v"]]], "predicted_relations": [[], [], [[33, 34, 29, 29, "USED-FOR"], [40, 40, 37, 38, "USED-FOR"]], [], [], []]}
{"doc_key": "2112.12731-114a0743-b5a1-41de-b119-52230ea8c853", "sentences": [["Following", "the", "pre-training", "setting", "of", "ERNIE", "3.0", ",", "ERNIE", "3.0", "Titan", "includes", "the", "universal", "representation", "module", "and", "the", "task-specific", "representation", "modules", ",", "which", "both", "use", "the", "Transformer-XL", "structure", "."], ["We", "adopt", "a", "structure", "with", "12", "layers", ",", "768", "hidden", "units", ",", "and", "12", "heads", "for", "the", "task-specific", "representation", "modules", "."], ["We", "adopt", "a", "structure", "with", "48", "layers", ",", "12288", "hidden", "units", ",", "and", "192", "heads", "for", "the", "universal", "representation", "modules", "."], ["We", "found", "that", "continually", "increasing", "the", "hidden", "size", "would", "make", "it", "difficult", "to", "load", "the", "parameter", "of", "output", "embedding", "in", "a", "single", "machine", "with", "eight", "cards", "with", "32GB", "memory", "."], ["In", "order", "to", "further", "increase", "the", "model", "capacity", ",", "we", "choose", "to", "scale", "the", "parameters", "of", "the", "point-wise", "feed-forward", "network", "alternatively", "."], ["The", "inner", "layer", "of", "the", "universal", "representation", "modules", "has", "a", "dimensional", "of", "196608", ",", "which", "is", "16", "times", "the", "hidden", "size", "of", "the", "model", "."], ["The", "total", "number", "of", "parameters", "of", "ERNIE", "3.0", "Titan", "is", "over", "260", "billion", "."]], "ner": [[[26, 27, "a"]], [[38, 39, "p"], [37, 37, "v"], [43, 43, "p"], [34, 34, "v"], [42, 42, "v"]], [[59, 60, "p"], [58, 58, "v"], [64, 64, "p"], [63, 63, "v"]], [], [[118, 120, "a"]], [[133, 133, "p"], [135, 135, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 6, "a"], [10, 10, "a"], [26, 26, "a"]], [[34, 34, "v"], [37, 37, "v"], [42, 42, "v"]], [[55, 55, "v"], [58, 58, "v"], [63, 63, "v"]], [[95, 95, "v"], [98, 98, "v"]], [[119, 120, "a"]], [[135, 135, "v"], [139, 139, "v"]], [[154, 156, "a"], [159, 159, "v"]]], "predicted_relations": [[], [[37, 37, 43, 43, "USED-FOR"], [42, 42, 43, 43, "USED-FOR"]], [[63, 63, 64, 64, "USED-FOR"]], [], [], [[135, 135, 133, 133, "USED-FOR"]], []]}
{"doc_key": "2112.12731-e218e7b0-730b-4b08-a8cc-bc41609696f1", "sentences": [["We", "use", "Adam", "-LSB-", "30", "-RSB-", "with", "learning", "rate", "of", "1e-4", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.95\\", "-RRB-", ",", "L2", "weight", "decay", "of", "0.1", ",", "We", "also", "clip", "the", "global", "norm", "of", "the", "gradient", "at", "1.0", "to", "improve", "the", "stability", "of", "pre-training", "."], ["The", "maximum", "sequence", "length", "of", "context", "and", "the", "memory", "length", "of", "language", "generation", "is", "512", "and", "128", ",", "respectively", "."], ["We", "use", "progressive", "learning", "to", "speed", "up", "convergence", "in", "the", "first", "4000", "steps", "and", "linear", "decay", "of", "the", "learning", "rate", "."], ["ERNIE", "3.0", "Titan", "is", "implemented", "on", "the", "PaddlePaddle", "framework", "and", "uses", "parallelism", "techniques", "that", "facilitate", "the", "efficient", "training", "of", "large", "models", "that", "do", "not", "fit", "in", "the", "memory", "of", "a", "single", "GPU", "."], ["We", "will", "give", "the", "detail", "of", "these", "in", "the", "next", "section", "."]], "ner": [[[2, 2, "a"], [7, 8, "p"], [10, 10, "v"], [15, 15, "v"], [21, 21, "v"], [24, 26, "p"], [28, 28, "v"], [34, 38, "p"], [40, 40, "v"], [7, 8, "p"]], [[49, 53, "a"], [56, 60, "a"]], [[86, 87, "p"], [70, 71, "a"], [80, 80, "p"], [79, 79, "v"], [86, 87, "p"], [82, 83, "v"]], [[89, 91, "a"], [96, 96, "a"], [100, 101, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 8, "p"], [10, 10, "v"], [24, 26, "p"], [28, 28, "v"], [40, 40, "v"]], [[62, 62, "v"], [64, 64, "v"]], [[70, 71, "a"], [79, 79, "v"], [86, 87, "p"]], [[89, 90, "a"], [91, 91, "a"], [96, 97, "a"]], []], "predicted_relations": [[[7, 8, 2, 2, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [24, 26, 2, 2, "USED-FOR"], [28, 28, 24, 26, "USED-FOR"], [7, 8, 2, 2, "USED-FOR"]], [], [[80, 80, 70, 71, "USED-FOR"], [79, 79, 80, 80, "USED-FOR"]], [], []]}
{"doc_key": "2103.16110-6cec4ab8-69d6-4268-8ed4-f2287073958d", "sentences": [["Dataset", "."], ["For", "a", "fair", "comparison", ",", "we", "follow", "the", "same", "settings", "as", "the", "Top-1", "FashionBERT", "-LSB-", "20", "-RSB-", "and", "pre-train", "the", "proposed", "Kaleido-BERT", "on", "the", "Fashion-Genhttps", ":", "//fashion-gen.com/", "dataset", "."], ["It", "contains", "67,666", "fashion", "products", "accompanied", "with", "text", "descriptions", "."], ["Each", "product", "includes", "one", "to", "six", "images", "from", "different", "angles", "."], ["Among", "all", "the", "image-text", "pairs", ",", "like", "-LSB-", "20", "-RSB-", ",", "we", "use", "260,480", "for", "training", ",", "and", "35,528", "for", "testing", "."]], "ner": [[], [[15, 15, "a"], [23, 23, "a"]], [], [], [[67, 67, "p"], [65, 65, "v"], [72, 72, "p"], [70, 70, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[15, 15, "a"], [23, 23, "a"]], [[33, 33, "v"]], [[44, 44, "v"], [46, 46, "v"]], [[65, 65, "v"], [70, 70, "v"]]], "predicted_relations": [[], [], [], [], [[65, 65, 67, 67, "USED-FOR"], [70, 70, 67, 67, "USED-FOR"]]]}
{"doc_key": "2103.16110-50a8c171-4320-4f2d-bc5c-c622719277eb", "sentences": [["Implementation", "Details", "."], ["Our", "Kaleido-BERT", "has", ":", "L=12", ",", "H=768", ",", "A=12", "."], ["L", "is", "number", "of", "stacked", "Transformer", "blocks", "."], ["H", "denotes", "the", "hidden", "activation", ",", "and", "A", "means", "the", "number", "of", "attention", "heads", "."], ["We", "implement", "our", "model", "with", "Tensorflow", "and", "use", "8", "*", "Tesla", "V100", "for", "pre-training", "."], ["The", "Adam", "optimizer", "is", "applied", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "2e-5\\", "-RRB-", "and", "weight", "decay", "\\", "-LRB-", "1e-4\\", "-RRB-", "."], ["We", "adopt", "a", "warming-up", "strategy", "for", "the", "first", "5K", "steps", "."]], "ner": [[], [[4, 4, "a"], [7, 7, "p"], [7, 7, "v"], [11, 11, "v"], [9, 9, "p"], [9, 9, "v"], [11, 11, "p"], [7, 7, "v"], [11, 11, "v"]], [[13, 13, "p"]], [[21, 21, "p"], [28, 28, "p"]], [], [[52, 53, "a"], [58, 59, "p"], [63, 63, "v"], [66, 67, "p"], [70, 70, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[4, 4, "a"], [7, 7, "v"], [9, 9, "v"]], [[13, 13, "p"]], [[21, 21, "a"], [24, 25, "p"], [28, 28, "p"]], [[39, 39, "a"], [44, 44, "v"]], [[52, 52, "a"], [58, 59, "p"], [63, 63, "v"], [66, 67, "p"], [70, 70, "v"]], [[81, 81, "v"]]], "predicted_relations": [[], [[7, 7, 4, 4, "USED-FOR"], [7, 7, 7, 7, "USED-FOR"], [7, 7, 7, 7, "USED-FOR"], [7, 7, 7, 7, "USED-FOR"], [7, 7, 9, 9, "USED-FOR"], [7, 7, 11, 11, "USED-FOR"], [11, 11, 7, 7, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [9, 9, 4, 4, "USED-FOR"], [9, 9, 7, 7, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [11, 11, 4, 4, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"], [7, 7, 7, 7, "USED-FOR"], [7, 7, 9, 9, "USED-FOR"], [7, 7, 11, 11, "USED-FOR"], [11, 11, 7, 7, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 11, 11, "USED-FOR"]], [], [], [], [[58, 59, 52, 53, "USED-FOR"], [63, 63, 58, 59, "USED-FOR"], [66, 67, 52, 53, "USED-FOR"], [70, 70, 66, 67, "USED-FOR"]], []]}
{"doc_key": "2103.16102-57ea5a77-5493-48f2-8f97-8555e9c9c619", "sentences": [["All", "of", "our", "codes", "are", "written", "based", "on", "PyTorchhttps", ":", "//pytorch.org/", "."], ["To", "extract", "the", "word", "definition", "of", "candidate", "answers", ",", "we", "use", "NLTK", "toolkit", "-LSB-", "0", "-RSB-", "."], ["The", "transformer", "encoder", "we", "used", "is", "pretrained", "ALBERT-xxlarge-v2", "modelhttps", ":", "//github.com/huggingface/transformers", "."], ["Since", "the", "code", "of", "DUMA", "is", "not", "open-source", ",", "we", "reimplement", "it", "by", "only", "using", "one", "co-attention", "layer", "where", "the", "attention", "heads", "are", "64", "and", "the", "dimension", "of", "Query", ",", "Key", "and", "Value", "are", "all", "64", ",", "because", "it", "is", "pointed", "that", "more", "co-attention", "layers", "do", "not", "improve", "the", "performance", "-LSB-", "17", "-RSB-", "."], ["The", "setting", "is", "also", "applied", "to", "our", "WN-DUMA", "for", "fair", "comparison", "."]], "ner": [[], [[23, 24, "a"]], [], [[45, 45, "a"], [61, 62, "p"], [64, 64, "v"], [76, 76, "v"], [67, 73, "p"], [64, 64, "v"], [76, 76, "v"]], [[102, 102, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[45, 45, "a"], [56, 56, "v"], [64, 64, "v"], [76, 76, "v"]], [[102, 102, "a"]]], "predicted_relations": [[], [], [], [[61, 62, 45, 45, "USED-FOR"], [67, 73, 45, 45, "USED-FOR"]], []]}
{"doc_key": "2102.10739-f910a206-b310-4ac0-9d4f-c48fb3a98b2a", "sentences": [["Training", "hyper-parameters", "."], ["For", "both", "fully", "and", "semi-supervised", "node", "classification", "tasks", "on", "the", "citation", "networks", ",", "Cora", ",", "Citeseer", "and", "Pubmed", ",", "we", "train", "our", "DGC", "following", "the", "hyper-parameters", "in", "SGC", "-LSB-", "23", "-RSB-", "."], ["Specifically", ",", "we", "train", "DGC", "for", "100", "epochs", "using", "Adam", "-LSB-", "7", "-RSB-", "with", "learning", "rate", "0.2", "."], ["For", "weight", "decay", ",", "as", "in", "SGC", ",", "we", "tune", "this", "hyperparameter", "on", "each", "dataset", "using", "hyperopt", "-LSB-", "0", "-RSB-", "for", "10,000", "trails", "."], ["For", "the", "large-scale", "inductive", "learning", "task", "on", "the", "Reddit", "network", ",", "we", "also", "follow", "the", "protocols", "of", "SGC", "-LSB-", "23", "-RSB-", ",", "where", "we", "use", "L-BFGS", "-LSB-", "12", "-RSB-", "optimizer", "for", "2", "epochs", "with", "no", "weight", "decay", "."]], "ner": [[], [[30, 30, "a"]], [[44, 44, "a"], [49, 50, "p"], [51, 51, "v"]], [[59, 59, "a"], [54, 55, "p"]], [[102, 102, "a"], [94, 94, "a"], [112, 113, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[16, 16, "a"], [18, 18, "a"], [20, 20, "a"], [25, 25, "a"], [30, 30, "a"]], [[39, 39, "a"], [41, 41, "v"], [42, 42, "p"], [44, 44, "a"], [49, 50, "p"], [51, 51, "v"]], [[54, 55, "a"], [59, 59, "a"], [69, 69, "a"], [74, 74, "v"]], [[85, 86, "a"], [94, 94, "a"], [102, 102, "a"], [108, 108, "v"], [109, 109, "p"], [112, 113, "p"]]], "predicted_relations": [[], [], [[49, 50, 44, 44, "USED-FOR"]], [], [[112, 113, 102, 102, "USED-FOR"], [112, 113, 94, 94, "USED-FOR"]]]}
{"doc_key": "2101.11212-6f922916-eeb7-4d48-9d68-7aed05520049", "sentences": [["For", "stage-II", ",", "we", "construct", "graphs", "with", "5.4M", "and", "0.6M", "edges", "for", "BBN", "and", "OntoNotes", "respectively", "."], ["Curvature", "constant", "of", "the", "hyperbolic", "space", "is", "set", "to", "\\", "-LRB-", "K=1\\", "-RRB-", "."], ["All", "the", "models", "are", "trained", "using", "Adam", "optimizer", "-LSB-", "9", "-RSB-", "with", "learning", "rate", "=", "0.001", "."]], "ner": [[], [[21, 22, "a"], [28, 28, "v"]], [[37, 38, "a"], [43, 44, "p"], [46, 46, "v"]]], "relations": [[], [], []], "predicted_ner": [[[7, 7, "v"], [9, 9, "v"], [12, 12, "a"], [14, 14, "a"]], [[28, 28, "v"]], [[37, 37, "a"], [43, 44, "p"], [46, 46, "v"]]], "predicted_relations": [[], [], [[43, 44, 37, 38, "USED-FOR"]]]}
{"doc_key": "2107.11635-396a00f3-4996-4723-bb03-d4923b0ee384", "sentences": [["Following", "previous", "works", "-LSB-", "18", "-RSB-", ",", "-LSB-", "19", "-RSB-", ",", "-LSB-", "39", "-RSB-", ",", "-LSB-", "52", "-RSB-", ",", "we", "adopt", "ResNet34", "and", "ResNet50", "-LSB-", "16", "-RSB-", "as", "the", "backbone", "network", "when", "working", "on", "the", "5", "standard", "datasets", "and", "on", "the", "3", "big", "ImageNet", "subsets", ",", "respectively", "."], ["The", "\u201c", "representation", "learning", "\u201d", "head", "-LRB-", "RL-head", "-RRB-", "and", "the", "\u201c", "clustering", "\u201d", "head", "-LRB-", "C-head", "-RRB-", "are", "two-layer", "neural", "networks", "with", "ReLU", "activations", "."], ["The", "length", "of", "the", "output", "vector", "of", "the", "RL-head", "is", "128", "."], ["The", "temperature", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "-LRB-", "Eq", "."], ["REF", "-RRB-", "is", "fixed", "at", "0.1", "."], ["To", "reduce", "variance", "in", "learning", ",", "we", "train", "our", "model", "with", "10", "C-subheadsThe", "final", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "cluster", "-RCB-", "-RCB-", "\\", "-RRB-", "in", "Eq", "."], ["is", "the", "average", "of", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "cluster", "-RCB-", "-RCB-", "\\", "-RRB-", "of", "these", "C-subheads", "."], ["similar", "to", "-LSB-", "19", "-RSB-", "."], ["This", "only", "adds", "little", "extra", "computation", "to", "our", "model", "."], ["However", ",", "unlike", "-LSB-", "18", "-RSB-", ",", "-LSB-", "19", "-RSB-", ",", "-LSB-", "52", "-RSB-", ",", "we", "do", "not", "use", "an", "auxiliary", "\u201c", "over-clustering", "\u201d", "head", "to", "exploit", "additional", "information", "from", "data", "since", "we", "think", "our", "RL-head", "can", "do", "that", "effectively", "."]], "ner": [[[21, 21, "a"], [23, 23, "a"]], [[71, 72, "a"]], [[84, 84, "v"]], [[87, 87, "a"]], [[101, 101, "v"]], [], [[156, 156, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[21, 21, "a"], [23, 23, "a"], [35, 35, "v"], [41, 41, "v"], [43, 43, "a"]], [[71, 71, "a"]], [[84, 84, "v"]], [], [[101, 101, "v"]], [[112, 112, "a"], [114, 114, "v"]], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2107.11635-dc88a739-39d7-41c9-a1c6-1a2f87a74711", "sentences": [["To", "train", "CRLC-semi", ",", "we", "use", "a", "SGD", "optimizer", "with", "an", "initial", "learning", "rate", "=", "0.1", ",", "momentum", "=", "0.9", ",", "Nesterov", "=", "False", ",", "and", "weight", "decay", "=", "5e-4", "."], ["Similar", "to", "-LSB-", "35", "-RSB-", ",", "we", "adjust", "the", "learning", "rate", "at", "each", "epoch", "using", "a", "cosine", "decay", "schedule", "-LSB-", "27", "-RSB-", "computed", "as", "follows", ":", "\\", "-LRB-", "\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "t", "-RCB-", "=\\text", "-LCB-", "\\text", "-LCB-", "lr", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "min", "-RCB-", "-RCB-", "+", "-LRB-", "\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "init", "-RCB-", "-RCB-", "-\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "min", "-RCB-", "-RCB-", "-RRB-", "\\times", "\\frac", "-LCB-", "1+\\cos", "\\left", "-LRB-", "\\frac", "-LCB-", "t", "-RCB-", "-LCB-", "T", "-RCB-", "\\pi", "\\right", "-RRB-", "-RCB-", "-LCB-", "2", "-RCB-", "\\", "-RRB-"]], "ner": [[[7, 8, "a"], [15, 15, "v"], [17, 17, "p"], [19, 19, "v"], [21, 21, "p"], [23, 23, "v"], [26, 27, "p"], [29, 29, "v"]], [[47, 49, "a"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [7, 7, "a"], [12, 13, "p"], [15, 15, "v"], [19, 19, "v"], [21, 21, "a"], [26, 27, "p"], [29, 29, "v"]], [[40, 41, "p"]]], "predicted_relations": [[[15, 15, 17, 17, "USED-FOR"], [15, 15, 21, 21, "USED-FOR"], [17, 17, 7, 8, "USED-FOR"], [21, 21, 7, 8, "USED-FOR"], [23, 23, 21, 21, "USED-FOR"], [26, 27, 7, 8, "USED-FOR"], [29, 29, 17, 17, "USED-FOR"], [29, 29, 21, 21, "USED-FOR"], [29, 29, 26, 27, "USED-FOR"]], []]}
{"doc_key": "2107.11635-91e8f4ee-f80d-48de-aabf-889c1685c9a4", "sentences": [["where", "\\", "-LRB-", "\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "init", "-RCB-", "-RCB-", "=0.1\\", "-RRB-", ",", "\\", "-LRB-", "\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "min", "-RCB-", "-RCB-", "=0.001\\", "-RRB-", ",", "\\", "-LRB-", "\\text", "-LCB-", "lr", "-RCB-", "_", "-LCB-", "t", "-RCB-", "\\", "-RRB-", "is", "the", "learning", "rate", "at", "epoch", "\\", "-LRB-", "t\\", "-RRB-", "over", "\\", "-LRB-", "T\\", "-RRB-", "epochs", "in", "total", "."], ["\\", "-LRB-", "T\\", "-RRB-", "is", "2000", "and", "1000", "for", "CIFAR10", "and", "CIFAR100", ",", "respectively", "."], ["The", "number", "of", "labeled", "and", "unlabeled", "samples", "in", "each", "batch", "is", "64", "and", "512", ",", "respectively", "."], ["In", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "CRLC-semi", "-RCB-", "-RCB-", "\\", "-RRB-", "-LRB-", "Eq", "."], ["12", "in", "the", "main", "text", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "1", "-RCB-", "=1\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "2", "-RCB-", "=5\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "3", "-RCB-", "=1\\", "-RRB-", "."]], "ner": [[[47, 48, "a"], [14, 14, "v"], [30, 30, "v"], [14, 14, "v"], [14, 14, "v"], [58, 58, "a"]], [[66, 66, "a"]], [[80, 88, "a"], [90, 90, "v"], [84, 85, "p"], [92, 92, "v"]], [], [[127, 127, "v"], [129, 129, "v"], [150, 150, "v"], [139, 139, "v"], [127, 127, "v"], [129, 129, "v"], [150, 150, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[14, 14, "v"], [30, 30, "v"], [47, 48, "p"], [53, 53, "p"], [58, 58, "p"]], [[66, 66, "p"], [69, 69, "v"], [71, 71, "v"], [73, 73, "a"], [75, 75, "a"]], [[90, 90, "v"], [92, 92, "v"]], [], [[115, 115, "v"], [124, 128, "p"], [134, 138, "p"], [145, 149, "p"]]], "predicted_relations": [[], [], [[90, 90, 84, 85, "USED-FOR"], [84, 85, 80, 88, "USED-FOR"], [92, 92, 84, 85, "USED-FOR"]], [], []]}
{"doc_key": "2108.06084-14e7a938-470c-4cc5-b365-641901a7ee46", "sentences": [["We", "evaluate", "two", "sets", "of", "training", "parameters", "."], ["The", "first", "set", "follows", "the", "Megatron-LM", "work", ":", "batch", "size", "512", ",", "300K", "total", "training", "steps", "-LRB-", "157B", "tokens", "-RRB-", ",", "and", "learning", "rate", "\\", "-LRB-", "1.5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "with", "a", "linear", "warmup", "of", "3K", "steps", "and", "a", "single", "cycle", "cosine", "decay", "over", "the", "remaining", "297K", "steps", "-LRB-", "with", "minimum", "learning", "rate", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "-RRB-", "."], ["The", "second", "parameter", "set", "tests", "a", "more", "aggressive", "training", "strategy", ":", "batch", "size", "4K", "-LRB-", "\\", "-LRB-", "8\\times", "\\", "-RRB-", "larger", "-RRB-", ",", "37.5K", "total", "training", "steps", "-LRB-", "157B", "tokens", "-RRB-", ",", "and", "learning", "rate", "\\", "-LRB-", "6\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "-LRB-", "\\", "-LRB-", "4\\times", "\\", "-RRB-", "larger", "-RRB-", "with", "a", "linear", "warmup", "of", "3K", "steps", "and", "a", "single", "cycle", "cosine", "decay", "over", "the", "remaining", "34.5K", "steps", "-LRB-", "same", "minimum", "learning", "rate", "-RRB-", "."], ["For", "sequence", "length/context", "size", ",", "we", "mainly", "use", "1K", "which", "is", "the", "default", "for", "GPT-2", "."], ["But", "we", "also", "test", "2K", "-LRB-", "on", "the", "smaller", "117M", "model", "with", "batch", "size", "512", "and", "157B", "tokens", "-RRB-", "which", "is", "the", "default", "for", "GPT-3", "-LSB-", "4", "-RSB-", "."], ["All", "experiments", "are", "performed", "with", "mixed", "precision/FP16", "training", ",", "Adam", "optimizer", "-LRB-", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", ",", "\\", "-LRB-", "\\epsilon", "=", "1\\times", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "-RRB-", "-LSB-", "10", "-RSB-", ",", "weight", "decay", "of", "0.01", ",", "checkpoint", "activation", ",", "same", "random", "seed", "-LRB-", "for", "Python", ",", "NumPy", ",", "PyTorch", ",", "and", "CUDA", "-RRB-", ",", "and", "gradient", "clipping", "."]], "ner": [[], [[13, 13, "a"], [16, 17, "p"], [18, 18, "v"], [21, 23, "p"], [20, 20, "v"], [30, 31, "p"], [62, 63, "p"], [61, 63, "p"]], [[86, 87, "p"], [88, 88, "v"], [99, 101, "p"], [98, 98, "v"], [108, 109, "p"], [148, 149, "p"], [147, 149, "p"]], [], [[180, 181, "p"], [182, 182, "v"]], [[206, 207, "a"], [214, 214, "v"], [222, 222, "v"], [227, 227, "p"], [241, 242, "a"], [241, 242, "p"], [244, 244, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"]], [[16, 17, "p"], [18, 18, "v"], [20, 20, "v"], [25, 25, "v"], [30, 31, "p"], [43, 44, "a"], [46, 46, "v"], [52, 53, "a"], [57, 57, "v"], [62, 63, "p"]], [[86, 87, "p"], [88, 88, "v"], [98, 98, "v"], [103, 103, "v"], [108, 109, "p"], [129, 130, "a"], [132, 132, "v"], [138, 139, "a"], [143, 143, "v"], [148, 149, "p"]], [[160, 160, "v"], [166, 166, "a"]], [[172, 172, "v"], [177, 177, "v"], [182, 182, "v"], [184, 184, "v"], [192, 192, "a"]], [[206, 206, "a"], [214, 214, "v"], [222, 222, "v"], [241, 242, "p"], [244, 244, "v"], [246, 247, "c"], [258, 258, "a"], [265, 266, "a"]]], "predicted_relations": [[], [[18, 18, 21, 23, "USED-FOR"], [21, 23, 13, 13, "USED-FOR"], [20, 20, 16, 17, "USED-FOR"], [20, 20, 21, 23, "USED-FOR"], [30, 31, 13, 13, "USED-FOR"], [62, 63, 13, 13, "USED-FOR"], [61, 63, 13, 13, "USED-FOR"]], [[88, 88, 86, 87, "USED-FOR"], [88, 88, 99, 101, "USED-FOR"], [98, 98, 99, 101, "USED-FOR"], [98, 98, 108, 109, "USED-FOR"]], [], [], [[222, 222, 227, 227, "USED-FOR"], [227, 227, 206, 207, "USED-FOR"], [241, 242, 206, 207, "USED-FOR"], [244, 244, 241, 242, "USED-FOR"]]]}
{"doc_key": "2103.04513-edf639f2-01cb-4803-a70e-d9eb7b57df83", "sentences": [["On", "MNIST", "we", "use", "Adam", "optimizer", ",", "learning", "rate", "of", "0.001", ",", "batch", "size", "of", "128", ",", "and", "epochs", "of", "50", "for", "both", "the", "generator", "and", "the", "discriminator", "."], ["The", "loss", "weights", "are", "set", "as", "\\", "-LRB-", "\\alpha", "=1\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=1\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\gamma", "=10\\", "-RRB-", "."], ["On", "SVHN", "we", "use", "batch", "size", "of", "64", "and", "epochs", "of", "40", "for", "both", "the", "generator", "and", "the", "discriminator", "."], ["The", "Adam", "optimizer", "parameterized", "with", "learning", "rate", "of", "0.0002", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "of", "0.5", ",", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "of", "0.999", "is", "used", "for", "the", "generator", ",", "and", "the", "Momentum", "optimizer", "parameterized", "with", "initial", "learning", "rate", "of", "0.1", "and", "momentum", "of", "0.9", "is", "used", "for", "the", "discriminator", ",", "the", "learning", "rate", "of", "the", "discriminator", "decays", "by", "a", "factor", "of", "10", "at", "epoch", "20", "and", "30", "."], ["The", "loss", "weights", "are", "set", "as", "\\", "-LRB-", "\\alpha", "=1\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=1\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\gamma", "=10\\", "-RRB-", "."], ["On", "CIFAR-10", "we", "use", "batch", "size", "of", "128", "and", "steps", "of", "80000", "for", "both", "the", "generator", "and", "the", "discriminator", "."], ["The", "Adam", "optimizer", "parameterized", "with", "learning", "rate", "of", "0.0002", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "of", "0.5", ",", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "of", "0.999", "is", "used", "for", "the", "generator", ",", "and", "the", "Momentum", "optimizer", "parameterized", "with", "initial", "learning", "rate", "of", "0.1", "and", "momentum", "of", "0.9", "is", "used", "for", "the", "discriminator", ",", "the", "learning", "rate", "of", "the", "discriminator", "decays", "by", "a", "factor", "of", "10", "at", "epoch", "100", "and", "150", "."], ["The", "loss", "weights", "are", "set", "as", "\\", "-LRB-", "\\alpha", "=5\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=4\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\gamma", "=10\\", "-RRB-", "."]], "ner": [[[4, 5, "a"], [7, 8, "p"], [10, 10, "v"], [1, 1, "c"], [1, 1, "a"], [12, 13, "a"], [18, 18, "a"], [1, 1, "c"], [1, 1, "c"], [1, 1, "c"]], [[30, 31, "a"], [38, 38, "v"], [44, 44, "v"], [38, 38, "v"], [44, 44, "v"], [38, 38, "v"], [44, 44, "v"], [38, 38, "v"], [44, 44, "v"], [51, 51, "v"], [51, 51, "v"], [51, 51, "v"]], [[55, 55, "c"], [55, 55, "c"], [55, 55, "c"], [55, 55, "c"], [55, 55, "c"], [55, 55, "a"], [58, 59, "a"], [63, 63, "a"], [55, 55, "c"], [55, 55, "c"], [55, 55, "c"]], [[75, 76, "a"], [79, 80, "p"], [113, 114, "p"], [128, 129, "p"], [82, 82, "v"], [90, 90, "v"], [99, 99, "v"], [108, 109, "a"], [112, 114, "p"], [116, 116, "v"], [118, 118, "p"], [120, 120, "v"], [116, 116, "v"], [116, 116, "v"], [90, 90, "v"], [116, 116, "v"], [116, 116, "v"], [138, 138, "v"], [138, 138, "v"], [138, 138, "v"]], [], [[171, 171, "a"], [174, 175, "a"], [171, 171, "c"], [171, 171, "c"], [171, 171, "v"], [171, 171, "v"], [171, 171, "v"], [171, 171, "c"], [179, 179, "a"]], [[191, 192, "a"], [195, 196, "p"], [229, 230, "p"], [244, 245, "p"], [198, 198, "v"], [206, 206, "v"], [215, 215, "v"], [224, 225, "a"], [228, 230, "p"], [232, 232, "v"], [234, 234, "p"], [236, 236, "v"], [232, 232, "v"], [232, 232, "v"], [206, 206, "v"], [232, 232, "v"], [232, 232, "v"], [254, 254, "v"], [254, 254, "v"], [254, 254, "v"]], [[262, 263, "a"], [270, 270, "v"], [276, 276, "v"], [283, 283, "v"], [283, 283, "v"], [283, 283, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [4, 4, "a"], [7, 8, "p"], [10, 10, "v"], [12, 13, "p"], [15, 15, "v"], [18, 18, "p"], [20, 20, "v"]], [[30, 31, "p"], [37, 38, "v"], [44, 44, "v"], [50, 50, "p"], [51, 51, "v"]], [[55, 55, "a"], [58, 59, "p"], [61, 61, "v"], [63, 63, "p"], [65, 65, "v"]], [[75, 75, "a"], [79, 80, "p"], [82, 82, "v"], [86, 87, "p"], [90, 90, "v"], [95, 96, "p"], [99, 99, "v"], [108, 108, "a"], [113, 114, "p"], [116, 116, "v"], [120, 120, "v"], [128, 129, "p"], [138, 138, "v"], [143, 143, "v"]], [[146, 147, "p"], [153, 153, "p"], [153, 154, "v"], [159, 160, "v"], [166, 166, "p"], [167, 167, "v"]], [[171, 171, "a"], [174, 175, "p"], [177, 177, "v"], [181, 181, "v"]], [[191, 191, "a"], [195, 196, "p"], [198, 198, "v"], [202, 203, "p"], [206, 206, "v"], [211, 212, "p"], [215, 215, "v"], [224, 224, "a"], [229, 230, "p"], [232, 232, "v"], [234, 234, "p"], [236, 236, "v"], [244, 245, "p"], [254, 254, "v"], [257, 257, "v"], [259, 259, "v"]], [[262, 263, "p"], [269, 270, "v"], [275, 276, "p"], [282, 282, "p"]]], "predicted_relations": [[[7, 8, 1, 1, "USED-FOR"]], [], [], [[113, 114, 75, 76, "USED-FOR"], [82, 82, 79, 80, "USED-FOR"], [112, 114, 75, 76, "USED-FOR"], [116, 116, 128, 129, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 118, 118, "USED-FOR"], [120, 120, 128, 129, "USED-FOR"], [120, 120, 112, 114, "USED-FOR"], [116, 116, 128, 129, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 118, 118, "USED-FOR"], [116, 116, 128, 129, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 118, 118, "USED-FOR"], [116, 116, 128, 129, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 118, 118, "USED-FOR"], [116, 116, 128, 129, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 118, 118, "USED-FOR"]], [], [[171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"], [171, 171, 171, 171, "USED-FOR"]], [[229, 230, 191, 192, "USED-FOR"], [198, 198, 195, 196, "USED-FOR"], [228, 230, 191, 192, "USED-FOR"], [232, 232, 244, 245, "USED-FOR"], [232, 232, 228, 230, "USED-FOR"], [232, 232, 234, 234, "USED-FOR"], [236, 236, 244, 245, "USED-FOR"], [236, 236, 228, 230, "USED-FOR"], [232, 232, 244, 245, "USED-FOR"], [232, 232, 228, 230, "USED-FOR"], [232, 232, 234, 234, "USED-FOR"], [232, 232, 244, 245, "USED-FOR"], [232, 232, 228, 230, "USED-FOR"], [232, 232, 234, 234, "USED-FOR"], [232, 232, 244, 245, "USED-FOR"], [232, 232, 228, 230, "USED-FOR"], [232, 232, 234, 234, "USED-FOR"], [232, 232, 244, 245, "USED-FOR"], [232, 232, 228, 230, "USED-FOR"], [232, 232, 234, 234, "USED-FOR"]], []]}
{"doc_key": "2109.11797-ed748a59-524f-464f-af80-51c558fcb931", "sentences": [["We", "report", "experiments", "results", "of", "different", "training", "settings", ",", "including", "-LRB-", "1", "-RRB-", "zero-shot", "setting", ",", "where", "no", "training", "data", "is", "available", ",", "-LRB-", "2", "-RRB-", "few-shot", "setting", ",", "where", "\\", "-LRB-", "K\\", "-RRB-", "training", "instances", "are", "available", "-LRB-", "\\", "-LRB-", "K=1,2,4,8,16\\", "-RRB-", "-RRB-", ",", "and", "-LRB-", "3", "-RRB-", "fully", "supervised", "setting", ",", "where", "full", "training", "set", "is", "available", "."]], "ner": [[[13, 14, "a"], [26, 27, "a"], [32, 32, "p"], [41, 41, "p"], [11, 11, "v"], [41, 41, "v"], [24, 24, "v"], [41, 41, "v"], [41, 41, "v"], [41, 41, "v"], [41, 41, "v"], [49, 51, "a"]]], "relations": [[]], "predicted_ner": [[[32, 32, "p"]]], "predicted_relations": [[[41, 41, 13, 14, "USED-FOR"], [41, 41, 26, 27, "USED-FOR"], [41, 41, 32, 32, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 32, 32, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 32, 32, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 32, 32, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 32, 32, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"]]]}
{"doc_key": "2110.05960-33d34a2a-2417-4c4b-a49a-5317082f1124", "sentences": [["All", "models", "are", "trained", "for", "\\", "-LRB-", "T=10^5\\", "-RRB-", "iterations", "-LRB-", "for", "GeoMNIST", "-RRB-", "or", "\\", "-LRB-", "T=3\\times", "10^5\\", "-RRB-", "iterations", "-LRB-", "for", "CIFAR", "-RRB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.005\\", "-RRB-", "and", "a", "batch", "size", "of", "1", "under", "the", "softmax", "cross-entropy", "loss", "."], ["Models", "on", "GeoMNIST", "converged", "with", "training", "and", "validation", "losses", "to", "zero", ",", "and", "those", "on", "CIFAR", "to", "validation", "accuracies", "greater", "than", "\\", "-LRB-", "90\\", "%", "\\", "-RRB-", "."]], "ner": [[[32, 32, "v"]], []], "relations": [[], []], "predicted_ner": [[[7, 7, "v"], [12, 12, "a"], [18, 18, "v"], [23, 23, "a"], [27, 28, "p"], [32, 32, "v"], [36, 37, "p"], [39, 39, "v"], [42, 44, "a"]], [[48, 48, "a"], [56, 56, "v"], [61, 61, "a"], [69, 70, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.13802-6c0d93ea-7daa-40a8-b06e-a6e5f68af07e", "sentences": [["We", "use", "Hedwighttps", ":", "//github.com/castorini/hedwig", ",", "an", "open-source", "deep", "learning", "toolkit", "with", "a", "number", "of", "implemented", "of", "document", "classification", "models", "."], ["We", "use", "a", "Tesla", "K80", "GPU", "for", "all", "models", "requiring", "GPU", "for", "train", ",", "and", "use", "amazon", "EC2-t2.micro", "and", "EC2-c", "type", "machine", "when", "only", "CPU", "is", "needed", "."], ["We", "use", "PyTorch", "1.5", "as", "the", "backend", "framework", ",", "and", "gensim", "-LSB-", "17", "-RSB-", "package", "for", "computing", "the", "node", "feature", "vectors", "using", "word2vec", "."]], "ner": [[[2, 4, "a"]], [[24, 26, "a"], [37, 38, "a"], [40, 42, "a"]], [[51, 52, "a"], [71, 71, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[71, 71, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2107.12930-813f0d13-d92f-4d5c-b847-cf266da949f1", "sentences": [["We", "use", "the", "original", "BERT", "implementation", "of", "devlin-etal-2019-bert", "."], ["For", "the", "development", "experiments", ",", "we", "train", "our", "BERT", "model", "for", "500,000", "steps", "with", "a", "sequence", "length", "of", "128", "."], ["We", "use", "whole", "word", "masking", "and", "the", "default", "hyperparameters", "and", "model", "architecture", "of", "BERTBASE", "-LSB-", "8", "-RSB-", "except", "a", "lower", "batch", "size", "of", "32", "in", "order", "to", "train", "on", "NVIDIA", "RTX", "6000", "GPUs", "with", "24", "GB", "RAM", "."], ["This", "corresponds", "to", "a", "bidirectional", "transformer", "-LSB-", "35", "-RSB-", "with", "12", "layers", ",", "12", "attention", "heads", ",", "a", "hidden", "layer", "size", "of", "768", ",", "and", "GELU", "activations", "-LSB-", "15", "-RSB-", "."]], "ner": [[[4, 4, "a"]], [[17, 17, "a"], [24, 25, "p"], [27, 27, "v"]], [[31, 33, "p"], [49, 50, "p"], [52, 52, "v"], [42, 42, "a"]], [[77, 77, "v"], [80, 80, "v"], [77, 77, "v"], [80, 80, "v"], [85, 87, "p"], [89, 89, "v"], [92, 92, "v"], [71, 72, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "a"], [7, 7, "a"]], [[17, 18, "a"], [20, 20, "v"], [27, 27, "v"]], [[42, 42, "a"], [52, 52, "v"], [63, 64, "v"]], [[77, 77, "v"], [78, 78, "p"], [80, 80, "v"], [85, 87, "p"], [89, 89, "v"], [92, 92, "v"]]], "predicted_relations": [[], [[24, 25, 17, 17, "USED-FOR"], [27, 27, 24, 25, "USED-FOR"]], [[31, 33, 42, 42, "USED-FOR"], [49, 50, 42, 42, "USED-FOR"]], [[80, 80, 85, 87, "USED-FOR"], [80, 80, 85, 87, "USED-FOR"]]]}
{"doc_key": "2104.06317-4edfa5d7-2c6f-4276-a2cd-e088b44ca0d4", "sentences": [["Our", "task", "is", "to", "first", "train", "the", "node", "embeddings", "and", "then", "directly", "evaluate", "its", "node", "classification", "ability", "."], ["We", "set", "the", "same", "experimental", "settings", "as", "the", "SOTA", "-LSB-", "29", "-RSB-", ",", "-LSB-", "9", "-RSB-", "and", "report", "the", "mean", "classi\ufb01cation", "results", "on", "the", "testing", "set", "after", "50", "runs", "of", "training", "followed", "by", "a", "linear", "model", "."], ["We", "initialize", "the", "parameters", "using", "Xavier", "initialization", "-LSB-", "5", "-RSB-", "and", "train", "the", "model", "using", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "0.001", "."], ["We", "follow", "the", "same", "settings", "as", "DGI", "does", "and", "set", "the", "number", "of", "epochs", "to", "2000", "."], ["We", "vary", "the", "the", "batch", "size", "from", "50", "to", "2000", ",", "and", "the", "early", "stopping", "with", "a", "patience", "of", "20", "is", "adopted", "."], ["The", "embedding", "dimension", "is", "set", "to", "512", "."], ["Unlike", "DGI", ",", "we", "use", "two", "layers", "of", "GCN", "."], ["We", "set", "the", "step", "of", "random", "walk", "as", "25", ",", "soft-margin", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "as", "0.9", ",", "dropout", "rate", "as", "0.7", "."]], "ner": [[], [], [[60, 61, "a"], [70, 71, "a"], [77, 79, "p"], [81, 81, "v"]], [], [], [[124, 125, "p"], [129, 129, "v"]], [[139, 139, "a"]], [[146, 147, "a"], [144, 144, "p"], [149, 149, "v"], [151, 151, "a"], [158, 158, "v"], [160, 161, "a"], [160, 161, "p"], [163, 163, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[45, 45, "v"]], [[60, 60, "a"], [70, 70, "a"], [78, 79, "p"], [81, 81, "v"]], [[89, 89, "a"], [96, 96, "p"], [98, 98, "v"]], [[104, 105, "p"], [107, 107, "v"], [109, 109, "v"], [113, 114, "a"], [119, 119, "v"]], [[129, 129, "v"]], [[132, 132, "a"], [136, 136, "v"], [139, 139, "a"]], [[146, 147, "a"], [149, 149, "v"], [151, 151, "a"], [154, 154, "p"], [158, 158, "v"], [160, 161, "p"], [163, 163, "v"]]], "predicted_relations": [[], [], [[77, 79, 60, 61, "USED-FOR"], [77, 79, 70, 71, "USED-FOR"], [81, 81, 77, 79, "USED-FOR"]], [], [], [[129, 129, 124, 125, "USED-FOR"]], [], [[149, 149, 144, 144, "USED-FOR"], [158, 158, 160, 161, "USED-FOR"], [160, 161, 146, 147, "USED-FOR"], [160, 161, 151, 151, "USED-FOR"], [160, 161, 160, 161, "USED-FOR"], [163, 163, 160, 161, "USED-FOR"]]]}
{"doc_key": "2104.06411-0b4174bf-561b-43ad-8af5-633969586bb0", "sentences": [["Seeing", "from", "this", "figure", ",", "our", "method", "was", "significantly", "sensitive", "to", "the", "hyper", "parameter", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "."], ["A", "wrong", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "such", "as", "\\", "-LRB-", "\\eta", "=1\\", "-RRB-", "in", "the", "four-rooms", "domain", "could", "deteriorate", "the", "performance", "of", "the", "method", "."], ["This", "may", "incur", "a", "cost", "for", "tuning", "hyper", "parameters", "."], ["To", "solve", "this", "problem", ",", "we", "must", "fit", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "to", "optimal", "value", "."], ["The", "environmental", "rewards", "of", "goals", "were", "1", "and", "10,000", "for", "four-rooms", "and", "pinball", ",", "respectively", "."], ["The", "best", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "was", "0.01", "for", "four-rooms", "and", "100", "for", "pinball", "."], ["Both", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "were", "one-hundredth", "of", "the", "environmental", "rewards", "."]], "ner": [[[12, 13, "a"], [16, 16, "p"]], [[24, 24, "p"], [31, 31, "p"], [32, 32, "v"], [36, 37, "c"], [36, 36, "c"]], [], [[66, 66, "p"]], [[79, 79, "v"], [83, 83, "c"], [85, 85, "c"], [74, 75, "a"]], [[93, 93, "p"], [97, 97, "v"], [99, 99, "c"], [101, 101, "v"], [103, 103, "c"]], [[108, 108, "p"], [115, 116, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[44, 44, "a"]], [], [], [[79, 79, "v"], [81, 81, "v"], [85, 85, "a"]], [[97, 97, "v"], [101, 101, "v"], [102, 103, "c"], [103, 103, "a"]], []], "predicted_relations": [[[16, 16, 12, 13, "USED-FOR"]], [[32, 32, 24, 24, "USED-FOR"], [32, 32, 31, 31, "USED-FOR"], [36, 37, 32, 32, "USED-FOR"]], [], [], [], [[101, 101, 93, 93, "USED-FOR"]], []]}
{"doc_key": "2101.11302-25a93dce-5627-4c6a-a807-154f6cf914ab", "sentences": [["We", "use", "the", "Ranger", "optimizer", ",", "an", "adapted", "version", "of", "Adam", "-LSB-", "14", "-RSB-", "with", "improved", "stability", "at", "the", "beginning", "of", "training", "\u2013", "by", "accounting", "for", "the", "variance", "in", "adaptive", "learning", "rates", "-LSB-", "21", "-RSB-", "\u2013", "and", "improved", "robustness", "and", "convergence", "speed", "-LSB-", "40", "-RSB-", ",", "-LSB-", "39", "-RSB-", "."], ["We", "use", "a", "batch", "size", "of", "16", "and", "a", "learning", "rate", "of", "3e-5", "to", "which", "we", "apply", "cosine", "annealing", "."], ["For", "meta-training", ",", "we", "perform", "100", "epochs", "of", "100", "episodes", "and", "perform", "evaluation", "with", "5", "different", "seeds", "on", "the", "meta-validation", "set", "after", "each", "epoch", "."], ["One", "epoch", "consists", "of", "100", "update", "steps", "where", "each", "update", "step", "consists", "of", "a", "batch", "of", "4", "episodes", "."], ["Early-stopping", "with", "a", "patience", "of", "3", "epochs", "is", "performed", "to", "avoid", "overfitting", "."], ["For", "the", "non-episodic", "baselines", ",", "we", "train", "for", "10", "epochs", "on", "the", "auxiliary", "languages", "while", "validating", "after", "each", "epoch", "."], ["All", "models", "are", "created", "using", "the", "PyTorch", "library", "-LSB-", "29", "-RSB-", "and", "trained", "on", "a", "single", "24Gb", "NVIDIA", "Titan", "RTX", "GPU", "."]], "ner": [[[3, 4, "a"], [10, 10, "a"]], [[53, 54, "p"], [56, 56, "v"], [59, 60, "p"], [62, 62, "v"], [67, 68, "p"]], [], [], [], [], [[153, 153, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [10, 10, "a"]], [[53, 54, "p"], [56, 56, "v"], [59, 60, "p"], [62, 62, "v"], [67, 68, "a"]], [[75, 75, "v"], [76, 76, "p"], [78, 78, "v"], [79, 79, "p"], [84, 84, "v"]], [[95, 95, "v"], [99, 99, "v"], [111, 111, "v"]], [[114, 114, "a"], [119, 119, "v"], [120, 120, "p"]], [[135, 135, "v"], [136, 136, "p"]], [[163, 163, "v"]]], "predicted_relations": [[], [[62, 62, 59, 60, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2104.11747-53081947-0696-4b94-ae6a-3340fe4d126b", "sentences": [["We", "train", "all", "models", "with", "the", "Adam", "-LSB-", "14", "-RSB-", "optimizer", "for", "four", "epochs", "with", "a", "batch", "size", "of", "16", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "0.0005\\", "-RRB-", "."], ["Focal", "loss", "-LSB-", "17", "-RSB-", "with", "\\", "-LRB-", "\\beta", "=", "1\\", "-RRB-", "is", "used", "for", "classification", "of", "edges", "and", "nodes", ",", "weight", "decay", "is", "set", "to", "0.01", "and", "weights", "are", "initialized", "randomly", "."], ["In", "all", "experiments", ",", "graphs", "with", "\\", "-LRB-", "T=3\\", "-RRB-", "timesteps", "are", "considered", "."]], "ner": [[[6, 6, "a"], [22, 23, "p"], [27, 27, "v"]], [[30, 31, "a"], [38, 38, "p"], [40, 40, "v"], [51, 52, "a"], [51, 52, "p"], [56, 56, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"], [12, 12, "v"], [13, 13, "p"], [16, 17, "p"], [19, 19, "v"], [22, 23, "p"], [27, 27, "v"]], [[30, 31, "a"], [51, 52, "p"], [56, 56, "v"]], [[71, 71, "v"]]], "predicted_relations": [[[22, 23, 6, 6, "USED-FOR"], [27, 27, 22, 23, "USED-FOR"]], [[38, 38, 30, 31, "USED-FOR"], [51, 52, 30, 31, "USED-FOR"], [56, 56, 51, 52, "USED-FOR"]], []]}
{"doc_key": "2110.15358-e4a4c5de-6dbc-47f9-92ee-96d512226a91", "sentences": [["As", "in", "-LSB-", "80", "-RSB-", ",", "-LSB-", "15", "-RSB-", ",", "we", "use", "a", "pre-trained", "Faster", "R-CNN", "model", "-LSB-", "29", "-RSB-", "that", "is", "trained", "on", "4,000", "video", "frames", "randomly", "sampled", "from", "the", "training", "set", "with", "object", "masks", "and", "attribute", "annotations", "to", "generate", "object", "proposals", "for", "each", "frame", "."], ["We", "train", "the", "language", "program", "parser", "with", "1,000", "programs", "for", "all", "question", "types", "."], ["All", "deep", "modules", "-LRB-", "concept", "learner", "and", "program", "executor", "-RRB-", "are", "trained", "using", "Adam", "optimizer", "for", "40", "epochs", "on", "8", "Nvidia", "1080Ti", "GPUs", "and", "the", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "camera", "matrix", "is", "optimized", "from", "20", "training", "videos", "."], ["We", "set", "\\", "-LRB-", "\\Delta", "t=0.004\\text", "-LCB-", "s", "-RCB-", ",", "D=256", ",", "C=64", ",", "K=10", ",", "S=10\\", "-RRB-", ",", "and", "\\", "-LRB-", "T=128\\", "-RRB-", "for", "CLEVRER", "-LSB-", "80", "-RSB-", "and", "\\", "-LRB-", "T=20\\", "-RRB-", "for", "Real-Billiard", "-LSB-", "64", "-RSB-", "."], ["In", "addition", "to", "our", "standard", "model", "that", "grounds", "object", "properties", "from", "question-answer", "pairs", ",", "we", "also", "train", "a", "variant", "-LRB-", "VRDP", "\\", "-LRB-", "\\dag", "\\", "-RRB-", "-RRB-", "on", "CLEVRER", "with", "an", "explicit", "rule-based", "program", "executor", "-LSB-", "80", "-RSB-", "and", "object", "attribute", "supervisions", "-LRB-", "attribute", "annotation", "in", "4000", "frames", "learned", "by", "the", "Faster", "R-CNN", "model", "-RRB-", "."]], "ner": [[[14, 16, "a"]], [], [[74, 75, "a"]], [[106, 106, "v"]], [[132, 132, "v"], [135, 135, "a"], [120, 120, "p"], [122, 122, "p"], [124, 124, "p"], [126, 126, "p"], [132, 132, "p"], [142, 142, "p"], [135, 135, "c"], [142, 142, "v"], [145, 145, "c"]], [[201, 203, "a"], [178, 178, "a"], [178, 178, "c"], [170, 170, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[15, 16, "a"], [24, 24, "v"]], [[54, 54, "v"]], [[74, 74, "a"], [77, 77, "v"], [78, 78, "p"], [80, 80, "v"], [86, 87, "p"], [93, 97, "v"]], [[106, 106, "v"]], [[132, 132, "v"], [135, 135, "a"], [142, 142, "v"], [145, 145, "a"]], [[178, 178, "a"], [196, 196, "v"], [202, 203, "a"]]], "predicted_relations": [[], [], [], [], [[132, 132, 120, 120, "USED-FOR"], [132, 132, 122, 122, "USED-FOR"], [132, 132, 124, 124, "USED-FOR"], [132, 132, 126, 126, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [132, 132, 142, 142, "USED-FOR"], [132, 132, 132, 132, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"], [135, 135, 132, 132, "USED-FOR"], [142, 142, 124, 124, "USED-FOR"], [142, 142, 126, 126, "USED-FOR"], [142, 142, 132, 132, "USED-FOR"], [142, 142, 142, 142, "USED-FOR"], [145, 145, 132, 132, "USED-FOR"], [145, 145, 142, 142, "USED-FOR"]], []]}
{"doc_key": "2110.15358-72384e8c-f67a-439b-a2c9-d1e02d1fb37f", "sentences": [["For", "the", "physical", "model", ",", "we", "use", "the", "L-BFGS", "optimizer", "-LSB-", "57", "-RSB-", "with", "an", "adaptive", "learning", "rate", "to", "optimize", "all", "physical", "parameters", "."], ["The", "optimization", "terminates", "when", "it", "reaches", "a", "certain", "number", "of", "steps", "or", "the", "loss", "is", "less", "than", "a", "certain", "value", "."], ["In", "all", "experiments", ",", "the", "number", "of", "the", "optimization", "step", "is", "set", "to", "20", "."], ["The", "loss", "threshold", "is", "set", "to", "0.0005", "for", "the", "learning", "of", "collision-independent", "parameters", "-LRB-", "i.e.", ",", "initial", "velocity", ",", "initial", "location", ",", "and", "initial", "angle", "-RRB-", ",", "and", "0.0002", ",", "0.001", ",", "0.01", "for", "the", "optimization", "of", "collision-dependent", "parameters", "-LRB-", "mass", "and", "restitution", "-RRB-", "on", "-LSB-", "0", ",", "40", "-RSB-", ",", "-LSB-", "0", ",", "80", "-RSB-", ",", "and", "-LSB-", "0", ",", "128", "-RSB-", "frames", ",", "respectively", "."]], "ner": [[[8, 9, "a"]], [], [[58, 58, "v"]], [[61, 62, "p"], [66, 66, "v"], [69, 72, "c"], [88, 88, "v"], [90, 90, "v"], [92, 92, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "a"], [16, 17, "p"]], [], [[58, 58, "v"]], [[61, 62, "p"], [66, 66, "v"], [88, 88, "v"], [90, 90, "v"], [92, 92, "v"], [112, 115, "v"], [119, 121, "v"]]], "predicted_relations": [[], [], [], [[69, 72, 66, 66, "USED-FOR"], [69, 72, 88, 88, "USED-FOR"], [69, 72, 90, 90, "USED-FOR"], [69, 72, 92, 92, "USED-FOR"]]]}
{"doc_key": "2105.14779-b6f4e89a-03d2-43c6-9cf9-cd0b8782cb81", "sentences": [["We", "trained", "the", "end-to-end", "ASR", "using", "a", "Noam", "-LSB-", "30", "-RSB-", "optimizer", "for", "50", "epochs", "with", "a", "learning", "rate", "of", "5", "with", "\\", "-LRB-", "20,000\\", "-RRB-", "warmup", "steps", "and", "dropout-rate", "of", "0.1", "."], ["The", "trade-off", "weights", ",", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", ",", "for", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "\\", "-RRB-", ",", "we", "use", "a", "value", "of", "\\", "-LRB-", "\\alpha", "=\\", "-RRB-", "0.3", "."], ["The", "number", "of", "encoder", ",", "decoder", "layers", "and", "attention-heads", "differed", "based", "on", "the", "choice", "of", "large/small", "architecture", "."], ["As", "for", "the", "text", "tokenization", ",", "we", "used", "word-piece", "byte-pair-encoding", "-LRB-", "BPE", "-RRB-", "-LSB-", "31", "-RSB-", "for", "the", "multilingual", "ASR", "."]], "ner": [[[17, 18, "p"], [20, 20, "v"], [26, 27, "p"], [29, 29, "p"], [31, 31, "v"]], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "a"], [7, 7, "a"], [13, 13, "v"], [14, 14, "p"], [17, 18, "p"], [20, 20, "v"], [24, 24, "v"], [26, 27, "p"], [29, 29, "p"], [31, 31, "v"]], [[39, 39, "p"], [60, 60, "p"], [63, 63, "v"]], [], [[92, 95, "a"]]], "predicted_relations": [[[20, 20, 26, 27, "USED-FOR"], [31, 31, 26, 27, "USED-FOR"], [31, 31, 29, 29, "USED-FOR"]], [], [], []]}
{"doc_key": "2105.14779-1aa7966d-fbed-49ff-8563-0ae885819855", "sentences": [["Large", "ASR", "Architecture", ":", "For", "the", "large", "ASR", "-LRB-", "with", "\\", "-LRB-", "\\approx", "1,000\\", "-RRB-", "hours", "of", "speech", "-RRB-", ",", "we", "used", "12", "encoder", "layers", "and", "6", "decoder", "layers", "each", "with", "2,048", "encoder/decoder", "units", "from", "FFN", "and", "8", "attention", "heads", "with", "512", "transformation", "dimensions", "."], ["For", "the", "architecture", ",", "we", "used", "31", "CNN", "kernals", "."], ["For", "multilingual", "dialectal", "ASR", ",", "we", "opt", "for", "an", "BPE", "of", "\\", "-LRB-", "10K\\", "-RRB-", "."]], "ner": [[[0, 2, "a"], [23, 24, "p"], [22, 22, "v"], [27, 28, "p"], [26, 26, "v"], [32, 33, "p"], [31, 31, "v"], [38, 39, "p"], [37, 37, "v"], [42, 43, "p"], [41, 41, "v"]], [[52, 53, "p"], [51, 51, "v"]], [[64, 64, "p"], [68, 68, "v"]]], "relations": [[], [], []], "predicted_ner": [[[13, 13, "v"], [22, 22, "v"], [26, 26, "v"], [31, 31, "v"], [35, 35, "a"], [37, 37, "v"], [41, 41, "v"]], [[51, 51, "v"], [52, 52, "a"]], [[68, 68, "v"]]], "predicted_relations": [[[23, 24, 0, 2, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 27, 28, "USED-FOR"], [27, 28, 0, 2, "USED-FOR"], [26, 26, 23, 24, "USED-FOR"], [26, 26, 27, 28, "USED-FOR"], [32, 33, 0, 2, "USED-FOR"], [37, 37, 32, 33, "USED-FOR"]], [], [[68, 68, 64, 64, "USED-FOR"]]]}
{"doc_key": "2105.14779-7804c498-d6de-4a6b-96ec-b87d9f96d6f8", "sentences": [["Small", "ASR", "Architecture", ":", "For", "exploring", "the", "influence", "of", "different", "character", "space", "representation", ",", "we", "designed", "small-scale", "ASR", "using", "8/4", "encoder/decoder", "layers", "each", "with", "2048", "FFN", "units", "."], ["As", "for", "the", "attention", "modules", ",", "we", "used", "4", "attention", "head", "with", "a", "dimension", "of", "256", "."], ["For", "the", "task", ",", "we", "opt", "for", "15", "CNN", "module", "kernals", "."]], "ner": [[[0, 2, "a"], [20, 21, "p"], [19, 19, "v"], [25, 26, "p"], [24, 24, "v"], [19, 19, "v"]], [[37, 38, "p"], [36, 36, "v"], [41, 41, "p"], [43, 43, "v"]], [[53, 55, "p"], [52, 52, "v"]]], "relations": [[], [], []], "predicted_ner": [[[19, 19, "v"], [24, 24, "v"], [25, 25, "a"]], [[36, 36, "v"], [43, 43, "v"]], [[52, 52, "v"], [53, 53, "a"]]], "predicted_relations": [[[20, 21, 0, 2, "USED-FOR"], [19, 19, 20, 21, "USED-FOR"], [19, 19, 25, 26, "USED-FOR"], [24, 24, 20, 21, "USED-FOR"], [24, 24, 25, 26, "USED-FOR"], [19, 19, 20, 21, "USED-FOR"], [19, 19, 25, 26, "USED-FOR"]], [[36, 36, 37, 38, "USED-FOR"], [36, 36, 41, 41, "USED-FOR"], [43, 43, 41, 41, "USED-FOR"]], []]}
{"doc_key": "2105.14761-16e5bf6d-fb2c-4993-96a5-2298ede46732", "sentences": [["There", "is", "relatively", "little", "existing", "work", "about", "document-level", "MT", "using", "pre-training", "."], ["Although", "Flat-Transformer+BERT", "gives", "a", "state-of-the-art", "scores", "on", "TED", "and", "Europarl", ",", "the", "score", "on", "News", "is", "worse", "than", "previous", "non-pretraining", "model", "HAN", "-LSB-", "28", "-RSB-", "."], ["G-Transformer+BERT", "improves", "the", "scores", "by", "margin", "of", "0.20", ",", "1.62", ",", "and", "0.47", "s-BLEU", "points", "on", "TED", ",", "News", ",", "and", "Europarl", ",", "respectively", "."], ["It", "shows", "that", "with", "a", "better", "contextual", "representation", ",", "we", "can", "further", "improve", "document-level", "MT", "on", "pretraining", "settings", "."]], "ner": [[], [[13, 13, "a"], [33, 33, "a"]], [[38, 38, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[19, 19, "a"], [21, 21, "a"], [26, 26, "a"], [33, 33, "a"]], [[45, 45, "v"], [47, 47, "v"], [50, 50, "v"], [51, 51, "a"], [54, 54, "a"], [56, 56, "a"], [59, 59, "a"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2105.14761-785ac252-8bce-44aa-9186-a1b11ae2c513", "sentences": [["We", "generate", "the", "corresponding", "group", "tag", "sequence", "dynamically", "in", "the", "model", "according", "to", "the", "special", "sentence-mark", "tokens", "<", "s", ">", "and", "<", "/s", ">", "."], ["Taking", "a", "document", "\u201c", "<", "s", ">", "there", "is", "no", "public", "transport", "."], ["<", "/s", ">", "<", "s", ">", "local", "people", "struggle", "to", "commute", "."], ["<", "/s", ">", "\u201d", "as", "an", "example", ",", "a", "group-tag", "sequence", "\\", "-LRB-", "G=\\lbrace", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2\\rbrace", "\\", "-RRB-", "is", "generated", "according", "to", "Eq", "REF", ",", "where", "1", "starts", "on", "the", "first", "<", "s", ">", "and", "ends", "on", "the", "first", "<", "/s", ">", ",", "2", "the", "second", ",", "and", "so", "on", "."], ["The", "model", "can", "be", "trained", "either", "randomly", "initialized", "or", "fine-tuned", "."]], "ner": [[[10, 10, "a"]], [], [], [], [[131, 131, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2105.14761-93b649b1-afa2-4262-8ea3-1c73492fe6a3", "sentences": [["Randomly", "Initialized", "."], ["We", "use", "the", "same", "settings", "as", "Transformer", "to", "train", "G-Transformer", ",", "using", "label-smoothing", "of", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "dropout", "of", "\\", "-LRB-", "0.3\\", "-RRB-", ",", "Adam", "optimizer", ",", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "5e-4\\", "-RRB-", "with", "4000", "warmup", "steps", "."], ["To", "encourage", "inferencing", "the", "translation", "from", "the", "context", ",", "we", "apply", "a", "word-dropout", "-LSB-", "4", "-RSB-", "with", "a", "probability", "of", "\\", "-LRB-", "0.3\\", "-RRB-", "on", "both", "the", "source", "and", "the", "target", "inputs", "."]], "ner": [[], [[9, 9, "a"], [12, 12, "a"], [29, 30, "a"], [26, 26, "v"]], [[64, 64, "p"], [68, 68, "v"], [58, 58, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [[9, 9, "a"], [12, 12, "a"], [15, 15, "a"], [19, 19, "v"], [22, 22, "a"], [26, 26, "v"], [29, 29, "a"], [34, 35, "p"], [39, 39, "v"], [42, 42, "v"], [43, 43, "p"]], [[58, 58, "a"], [68, 68, "v"]]], "predicted_relations": [[], [], [[64, 64, 58, 58, "USED-FOR"]]]}
{"doc_key": "2105.14761-08020ee1-b0fb-4850-a5ff-5bb89fd747ea", "sentences": [["Fine-tuned", "on", "Sentence-Level", "Transformer", "."], ["We", "use", "the", "parameters", "of", "an", "existing", "sentence-level", "Transformer", "to", "initialize", "G-Transformer", "."], ["We", "copy", "the", "parameters", "of", "the", "multi-head", "attention", "in", "Transformer", "to", "the", "group", "multi-head", "attention", "in", "G-Transformer", ",", "leaving", "the", "global", "multi-head", "attention", "and", "the", "gates", "randomly", "initialized", "."], ["For", "the", "global", "multi-head", "attention", "and", "the", "gates", ",", "we", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "5e-4\\", "-RRB-", ",", "while", "for", "other", "components", ",", "we", "use", "a", "smaller", "learning", "rate", "of", "\\", "-LRB-", "1e-4\\", "-RRB-", "."], ["All", "the", "parameters", "are", "jointly", "trained", "using", "Adam", "optimizer", "with", "4000", "warmup", "steps", "."], ["We", "apply", "a", "word-dropout", "with", "a", "probability", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "on", "both", "the", "source", "and", "the", "target", "inputs", "."]], "ner": [[[2, 3, "a"]], [], [], [[59, 60, "p"], [76, 77, "p"], [64, 64, "v"], [81, 81, "v"]], [[91, 92, "a"], [95, 96, "p"], [94, 94, "v"]], [[101, 101, "p"], [108, 108, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[16, 16, "a"]], [[34, 34, "a"]], [[59, 60, "p"], [64, 64, "v"], [76, 77, "p"], [81, 81, "v"]], [[91, 91, "a"], [94, 94, "v"]], [[101, 101, "a"], [108, 108, "v"]]], "predicted_relations": [[], [], [], [[64, 64, 59, 60, "USED-FOR"], [81, 81, 76, 77, "USED-FOR"]], [[95, 96, 91, 92, "USED-FOR"], [94, 94, 95, 96, "USED-FOR"]], []]}
{"doc_key": "2105.14761-9ec21086-6352-4f12-8f00-9466e096a87d", "sentences": [["Fine-tuned", "on", "mBART25", "."], ["Similar", "as", "the", "fine-tuning", "on", "sentence-level", "Transformer", ",", "we", "also", "copy", "parameters", "from", "mBART25", "-LSB-", "23", "-RSB-", "to", "G-Transformer", ",", "leaving", "the", "global", "multi-head", "attention", "and", "the", "gates", "randomly", "initialized", "."], ["We", "following", "the", "settings", "-LSB-", "23", "-RSB-", "to", "train", "the", "model", ",", "using", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "3e-5\\", "-RRB-", "and", "2500", "warmup", "steps", "."], ["Here", ",", "we", "do", "not", "apply", "word-dropout", ",", "which", "empirically", "shows", "a", "damage", "to", "the", "performance", "."]], "ner": [[[2, 2, "a"]], [[17, 17, "a"], [7, 10, "a"]], [[48, 49, "a"], [52, 53, "p"], [57, 57, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[17, 17, "a"], [22, 22, "a"]], [[48, 48, "a"], [52, 53, "p"], [57, 57, "v"], [60, 60, "v"]], [[70, 70, "a"]]], "predicted_relations": [[], [], [[52, 53, 48, 49, "USED-FOR"], [57, 57, 52, 53, "USED-FOR"]], []]}
{"doc_key": "2110.13223-0f646d64-7765-4779-8959-8603a31bc98e", "sentences": [["For", "the", "experiments", "which", "refer", "to", "all", "171", "tasks", "-LRB-", "rather", "than", "just", "the", "12", "we", "focus", "on", "in", "NOOCh", ",", "we", "use", "an", "Adam", "optimizer", "with", "1e-3", "learning", "rate", "and", "batch", "size", "16", "."], ["All", "other", "training", "parameters", "are", "the", "same", "as", "noted", "elsewhere", "."]], "ner": [[[24, 25, "a"], [28, 29, "p"], [27, 27, "v"], [31, 32, "p"], [33, 33, "v"]], []], "relations": [[], []], "predicted_ner": [[[7, 7, "v"], [14, 14, "v"], [19, 19, "a"], [24, 24, "a"], [27, 27, "v"], [28, 29, "p"], [31, 32, "p"], [33, 33, "v"]], []], "predicted_relations": [[[28, 29, 24, 25, "USED-FOR"], [27, 27, 28, 29, "USED-FOR"], [31, 32, 24, 25, "USED-FOR"]], []]}
{"doc_key": "2110.13285-a7e1c09f-af83-4c6d-836b-c294d5f08cab", "sentences": [["We", "train", "our", "generative", "flow", "and", "solve", "inverse", "problems", "using", "Adam", "-LSB-", "8", "-RSB-", "."], ["CelebA", "images", "are", "resized", "to", "\\", "-LRB-", "32\\times", "32\\", "-RRB-", "resolution", "and", "we", "use", "the", "test", "set", "to", "evaluate", "each", "method", "."], ["Additionally", ",", "our", "generative", "flow", "uses", "\\", "-LRB-", "K=2\\", "-RRB-", "and", "\\", "-LRB-", "L=5\\", "-RRB-", ",", "and", "duplicate", "\\", "-LRB-", "K\\", "-RRB-", "for", "scales", "\\", "-LRB-", "2\\times", "2\\", "-RRB-", "and", "\\", "-LRB-", "1\\times", "1\\", "-RRB-", "\u2014we", "use", "14", "coupling", "layers", "in", "total", "."], ["We", "train", "the", "generative", "flow", "with", "a", "batch", "size", "of", "32", "and", "stop", "the", "training", "process", "after", "100", "epochs", "."], ["Then", ",", "we", "solve", "each", "inverse", "problem", "with", "1500", "iterations", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "0.005\\", "-RRB-", "."], ["All", "experiments", "were", "made", "in", "a", "GeForce", "GTX", "750", "Ti", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[10, 10, "a"], [3, 4, "a"]], [[15, 16, "a"]], [[45, 45, "p"], [57, 57, "p"], [40, 41, "a"], [50, 50, "p"], [60, 60, "p"], [75, 76, "p"]], [[83, 84, "a"], [87, 88, "p"], [98, 98, "p"]], [[117, 117, "v"], [109, 109, "p"], [112, 113, "p"]], [[126, 129, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [10, 10, "a"]], [[15, 15, "a"], [23, 23, "v"]], [[40, 41, "a"], [45, 45, "v"], [50, 50, "v"], [57, 57, "p"], [63, 64, "v"], [70, 70, "v"], [74, 74, "v"], [75, 76, "p"]], [[83, 84, "a"], [87, 88, "p"], [90, 90, "v"], [97, 97, "v"], [98, 98, "p"]], [[108, 108, "v"], [109, 109, "p"], [112, 113, "p"], [117, 117, "v"]], [], []], "predicted_relations": [[], [], [[45, 45, 40, 41, "USED-FOR"], [57, 57, 40, 41, "USED-FOR"], [50, 50, 40, 41, "USED-FOR"]], [[98, 98, 83, 84, "USED-FOR"]], [], [], []]}
{"doc_key": "2110.05208-f54e039d-1e1f-4f83-967e-fd755ab62510", "sentences": [["For", "a", "fair", "comparison", "with", "CLIP", ",", "we", "train", "our", "DeCLIP-ResNet50", "and", "DeCLIP-ViT-B/32", "from", "scratch", "for", "32", "epochs", "."], ["Unless", "otherwise", "specified", ",", "we", "use", "full", "data", ",", "i.e.", ",", "88M", "image-text", "pairs", ",", "to", "obtain", "the", "best", "performance", "."], ["The", "input", "resolution", "of", "the", "image", "encoder", "is", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", ",", "and", "the", "maximum", "context", "length", "of", "the", "text", "encoder", "is", "76", "."], ["The", "learnable", "temperature", "parameter", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "is", "initialized", "to", "0.07", "."], ["The", "loss", "weights", "of", "additional", "supervision", "\\", "-LRB-", "-LCB-", "\\alpha", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "\\beta", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "-LCB-", "\\gamma", "-RCB-", "\\", "-RRB-", "are", "all", "set", "to", "0.2", "."], ["More", "details", "can", "be", "found", "in", "Appendix", "."]], "ner": [[[10, 10, "a"], [12, 12, "a"]], [], [[41, 42, "a"], [42, 42, "p"]], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [10, 10, "a"], [16, 16, "v"], [17, 17, "p"]], [[30, 30, "v"]], [[51, 51, "v"], [64, 64, "v"]], [[68, 69, "p"], [78, 78, "v"]], [[81, 82, "p"], [113, 113, "v"]], []], "predicted_relations": [[], [], [[42, 42, 41, 42, "USED-FOR"]], [], [], []]}
{"doc_key": "2112.01021-7562f34b-ba96-4c69-9302-91e99b405653", "sentences": [["For", "training", ",", "we", "use", "batch", "sizes", "of", "256", ",", "64", "for", "-LCB-", "Colored", "MNIST", ",", "Corrupted", "CIFAR-10", "-RCB-", "and", "-LCB-", "BFFHQ", ",", "BAR", "-RCB-", ",", "respectively", "."], ["We", "use", "learning", "rates", "of", "0.001", ",", "0.0001", "for", "-LCB-", "Colored", "MNIST", ",", "Corrupted", "CIFAR-10", ",", "BFFHQ", "-RCB-", "and", "BAR", ",", "respectively", "."], ["Also", ",", "we", "use", "cosine", "annealing", "from", "initial", "learning", "rates", "\\", "-LRB-", "lr\\", "-RRB-", "to", "\\", "-LRB-", "lr", "*", "0.1^3\\", "-RRB-", "for", "learning", "rate", "scheduling", "-LSB-", "26", "-RSB-", "for", "all", "datasets", "."], ["Note", "that", ",", "we", "do", "not", "use", "random", "horizontal", "flipping", "for", "ColoredMNIST", "."], ["Additionally", ",", "the", "original", "image", "size", "of", "BFFHQ", "is", "128", "but", "we", "resize", "them", "to", "224", "by", "following", "the", "previous", "work", "-LSB-", "21", "-RSB-", "."]], "ner": [[[13, 14, "a"], [8, 8, "v"], [16, 17, "a"], [10, 10, "v"], [21, 21, "a"], [23, 23, "a"], [10, 10, "v"]], [[38, 39, "a"], [41, 42, "a"], [44, 44, "a"], [33, 33, "v"], [47, 47, "a"], [35, 35, "v"]], [[73, 74, "p"], [73, 74, "p"], [55, 56, "a"], [63, 63, "v"], [68, 68, "v"], [68, 70, "v"]], [], [[103, 103, "a"], [100, 101, "p"], [111, 111, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 6, "p"], [8, 8, "v"], [10, 10, "v"], [21, 21, "a"]], [[30, 31, "p"], [33, 33, "v"], [35, 35, "v"], [42, 42, "a"]], [[55, 56, "a"], [59, 60, "p"], [63, 63, "p"], [68, 68, "p"], [70, 70, "v"], [79, 81, "c"]], [], [[103, 103, "a"], [105, 105, "v"], [111, 111, "v"]]], "predicted_relations": [[], [], [[73, 74, 55, 56, "USED-FOR"], [73, 74, 55, 56, "USED-FOR"], [68, 68, 73, 74, "USED-FOR"], [68, 68, 73, 74, "USED-FOR"], [68, 70, 73, 74, "USED-FOR"], [68, 70, 73, 74, "USED-FOR"]], [], [[100, 101, 103, 103, "USED-FOR"]]]}
{"doc_key": "2112.01021-52ae0cc0-c265-4198-8919-841968237ba0", "sentences": [["In", "contrastive", "learning", ",", "we", "use", "Normalized", "Temperature-scaled", "Cross", "Entropy", "NT-Xent", "-LSB-", "4", "-RSB-", "with", "a", "temperature", "parameter", "0.01", "."], ["For", "projection", "head", "\\", "-LRB-", "H\\", "-RRB-", ",", "2-layer", "MLP", "and", "a", "linear", "layer", "with", "the", "dimensions", "from", "the", "input", "to", "the", "output", "as", "-LSB-", "512", ",", "512", ",", "128", "-RSB-", "and", "-LSB-", "100", ",", "100", "-RSB-", "for", "-LCB-", "Corrupted", "CIFAR-10", ",", "BFFHQ", ",", "BAR", "-RCB-", "and", "Colored", "MNIST", "respectively", ",", "following", "-LSB-", "4", "-RSB-", "for", "the", "most", "of", "the", "settings", "."]], "ner": [[[6, 10, "a"], [16, 16, "p"], [18, 18, "v"]], [[28, 29, "a"], [32, 33, "a"], [36, 36, "p"], [59, 64, "c"], [67, 68, "c"]]], "relations": [[], []], "predicted_ner": [[[6, 9, "a"], [10, 10, "a"], [18, 18, "v"]], [[29, 29, "a"], [45, 45, "v"], [47, 47, "v"], [49, 49, "v"], [53, 53, "v"], [55, 55, "v"], [60, 60, "a"], [62, 62, "a"], [68, 68, "a"]]], "predicted_relations": [[[16, 16, 6, 10, "USED-FOR"]], [[36, 36, 28, 29, "USED-FOR"], [36, 36, 32, 33, "USED-FOR"]]]}
{"doc_key": "2102.06589-66098563-2e7f-48f8-b081-60e64bd21219", "sentences": [["In", "order", "to", "maintain", "a", "guarantee", ",", "the", "PAC-Bayes", "upper", "bound", "in", "Theorem", "REF", "requires", "a", "loss", "function", "bounded", "between", "0", "and", "1", "."], ["However", ",", "the", "losses", "we", "use", "are", "not", "bounded", "in", "general", "."], ["Let", "\\", "-LRB-", "N_\\theta", "\\", "-RRB-", "be", "an", "arbitrary", "network", "parameterized", "by", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "and", "\\", "-LRB-", "N_\\theta", "-LRB-", "z", "-RRB-", "\\", "-RRB-", "be", "the", "output", "of", "the", "network", "given", "sample", "\\", "-LRB-", "z", "\\in", "\\", "-RRB-", "."], ["Consider", "arbitrary", "loss", "\\", "-LRB-", "f\\", "-RRB-", ",", "which", "maps", "the", "network", "'s", "output", "to", "a", "real", "number", "."], ["If", "\\", "-LRB-", "\\Vert", "N_\\theta", "-LRB-", "z", "-RRB-", "\\Vert", "\\le", "r", ",", "\\forall", "\\", "\\theta", "\\in", ",", "\\forall", "\\", "z", "\\in", "\\", "-RRB-", ",", "then", "we", "can", "perform", "a", "linear", "scaling", "of", "\\", "-LRB-", "f\\", "-RRB-", "to", "map", "it", "onto", "the", "interval", "\\", "-LRB-", "-LSB-", "0,1", "-RSB-", "\\", "-RRB-", "."], ["We", "define", "the", "minimum", "and", "maximum", "value", "achievable", "by", "loss", "function", "\\", "-LRB-", "f\\", "-RRB-", "as", "follows", "Mf", ":", "=", "z", ",", ",", "N", "-LRB-", "z", "-RRB-", "rf", "-LRB-", ",", "z", "-RRB-"]], "ner": [[[22, 22, "v"]], [], [], [], [[141, 141, "v"], [106, 106, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [20, 20, "v"], [22, 22, "v"]], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2102.06529-bb0bae20-0ed5-4516-8cdd-4358805b9920", "sentences": [["The", "model", "used", "in", "both", "experiments", "is", "a", "frrcnn", "network", "with", "a", "rn152", "backbone", "pre-trained", "on", "ImageNet", "."], ["Models", "were", "fine-tuned", "using", "the", "StyleCOCO", "training", "and", "validation", "datasets", "\u2014", "or", "a", "subset", "thereof", "in", "the", "case", "of", "expntrain", "."], ["Default", "training", "parameters", "from", "PyTorch", "were", "used", "except", "where", "modifications", "were", "shown", "to", "improve", "performance", "and", "those", "non-default", "parameters", "are", "listed", "below", "."], ["2", "layers", "of", "the", "backbone", "were", "made", "trainable", "and", "the", "remaining", "3", "were", "frozen", "to", "retain", "the", "pre-trained", "ImageNet", "weights", "."], ["Models", "were", "trained", "for", "15", "epochs", ",", "though", "early", "stopping", "-LRB-", "patience=3.0", "-RRB-", "was", "employed", "in", "order", "to", "avoid", "overfitting", "."]], "ner": [[[8, 9, "a"], [13, 13, "p"], [12, 12, "v"]], [[23, 23, "a"], [24, 24, "a"]], [[40, 40, "a"]], [[66, 66, "p"], [62, 62, "v"], [73, 73, "v"]], [[94, 94, "v"], [91, 92, "a"], [94, 94, "p"], [94, 94, "v"], [88, 88, "p"], [87, 87, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 9, "a"], [12, 12, "v"], [16, 16, "a"]], [[23, 23, "a"], [37, 37, "a"]], [[43, 43, "a"]], [[62, 62, "v"], [73, 73, "v"], [80, 80, "a"]], [[87, 87, "v"], [88, 88, "p"], [91, 92, "a"], [94, 94, "v"]]], "predicted_relations": [[[13, 13, 8, 9, "USED-FOR"], [12, 12, 13, 13, "USED-FOR"]], [], [], [[62, 62, 66, 66, "USED-FOR"]], [[94, 94, 94, 94, "USED-FOR"], [94, 94, 91, 92, "USED-FOR"], [94, 94, 94, 94, "USED-FOR"], [88, 88, 91, 92, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"]]]}
{"doc_key": "2102.06529-8b123f9d-a221-41cd-9cb5-62f5e7d2ee94", "sentences": [["The", "model", "was", "optimized", "using", "sgd", ",", "using", "an", "initial", "learning", "rate", "of", "0.005", ",", "a", "momentum", "of", "0.9", ",", "and", "weight", "decay", "of", "0.0005", "."], ["The", "learning", "rate", "was", "adjusted", "over", "the", "course", "of", "the", "training", "using", "a", "stepped", "learning", "rate", "scheduler", ",", "which", "multiplied", "the", "rate", "by", "0.2", "every", "5", "epochs", "."], ["A", "warm-up", "period", "of", "5,000", "iterations", "was", "also", "implemented", "to", "ease", "into", "the", "initial", "learning", "rate", "."], ["The", "resulting", "learning", "rate", "curve", "is", "shown", "in", "fig", ":", "learningrate", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[5, 5, "a"], [9, 11, "p"], [13, 13, "v"], [16, 16, "p"], [18, 18, "v"], [21, 22, "p"], [24, 24, "v"]], [[40, 42, "p"], [45, 52, "v"]], [[67, 69, "p"], [55, 56, "p"], [58, 59, "v"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [10, 11, "p"], [13, 13, "v"], [16, 16, "p"], [18, 18, "v"], [21, 22, "p"], [24, 24, "v"]], [[27, 28, "p"], [49, 49, "v"], [51, 51, "v"], [52, 52, "p"]], [[58, 58, "v"], [68, 69, "p"]], [[81, 81, "p"]], []], "predicted_relations": [[[9, 11, 5, 5, "USED-FOR"], [13, 13, 9, 11, "USED-FOR"], [16, 16, 5, 5, "USED-FOR"], [21, 22, 5, 5, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [], [[58, 59, 55, 56, "USED-FOR"]], [], []]}
{"doc_key": "2106.03279-eab2e292-932d-4181-a05c-c25f74053316", "sentences": [["Across", "all", "three", "examples", ",", "we", "consider", "the", "discounted", "setting", "where", "the", "discount", "factor", "is", "\\", "-LRB-", "\\gamma", "=", "0.95\\", "-RRB-", "."], ["The", "learning", "rate", "is", "set", "to", "be", "\\", "-LRB-", "\\alpha", "=", "0.01\\", "-RRB-", "."], ["The", "number", "of", "demonstrated", "trajectories", "is", "set", "to", "be", "100", "in", "both", "the", "random", "and", "near-optimal", "settings", "."]], "ner": [[[8, 9, "a"], [12, 13, "p"], [19, 19, "v"]], [[23, 24, "p"], [33, 33, "v"]], [[37, 40, "p"], [45, 45, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "v"], [12, 13, "p"], [17, 17, "p"], [19, 19, "v"]], [[23, 24, "p"], [31, 31, "p"], [33, 33, "v"]], [[45, 45, "v"]]], "predicted_relations": [[], [], [[45, 45, 37, 40, "USED-FOR"]]]}
{"doc_key": "2108.11430-4a910470-65af-4e6f-b5f6-d3d99bc77b15", "sentences": [["We", "train", "all", "models", "for", "200", "epochs", "using", "RAdam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.002", ",", "an", "exponential", "decay", "rate", "of", "0.98", "per", "epoch", ",", "and", "a", "weight", "decay", "of", "5e-4", "."], ["On", "CIFAR-10/100", ",", "images", "are", "augmented", "by", "random", "horizontal", "flips", "and", "random", "crops", "with", "4", "paddings", "."], ["On", "TinyImageNet", ",", "StanfordDogs-120", ",", "and", "StanfordCars-196", ",", "additional", "color", "jitter", "is", "added", "."], ["Mini-batch", "sizes", "are", "64", ",", "128", ",", "64", ",", "and", "64", "for", "our", "3-layer", "CNN", ",", "ResNet-18", ",", "DenseNet-121", ",", "and", "MobileNetV2", ",", "respectively", "."]], "ner": [[[12, 14, "p"], [16, 16, "v"], [19, 21, "p"], [23, 23, "v"], [24, 25, "c"], [29, 30, "p"], [32, 32, "v"], [32, 32, "v"]], [[41, 43, "a"], [45, 46, "a"], [48, 48, "v"], [35, 35, "a"]], [[60, 61, "a"], [52, 52, "a"], [54, 54, "a"], [57, 57, "a"]], [[78, 79, "a"], [68, 68, "v"], [72, 72, "v"], [75, 75, "v"], [81, 81, "a"], [70, 70, "v"], [83, 83, "a"], [68, 68, "v"], [72, 72, "v"], [75, 75, "v"], [86, 86, "a"], [68, 68, "v"], [72, 72, "v"], [75, 75, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "v"], [6, 6, "p"], [8, 8, "a"], [13, 14, "p"], [16, 16, "v"], [19, 21, "p"], [23, 23, "v"], [29, 30, "p"], [32, 32, "v"]], [[48, 48, "v"]], [[52, 52, "a"], [54, 54, "a"], [57, 57, "a"]], [[65, 66, "p"], [68, 68, "v"], [70, 70, "v"], [72, 72, "v"], [75, 75, "v"], [79, 79, "a"], [81, 81, "a"], [83, 83, "a"], [86, 86, "a"]]], "predicted_relations": [[[16, 16, 19, 21, "USED-FOR"], [23, 23, 19, 21, "USED-FOR"], [24, 25, 23, 23, "USED-FOR"], [24, 25, 32, 32, "USED-FOR"], [24, 25, 32, 32, "USED-FOR"], [32, 32, 29, 30, "USED-FOR"], [32, 32, 29, 30, "USED-FOR"]], [], [], []]}
{"doc_key": "2105.07636-a9688629-1cf2-4b24-ba1a-311872b9f9fe", "sentences": [["Unlike", "previous", "works", "like", "-LRB-", "Ruff", "et", "al.", ",", "2018", ";", "Goyal", "et", "al.", ",", "2020", "-RRB-", ",", "we", "uniformly", "use", "an", "SGD", "optimizer", "with", "batch_size", "=", "256", "."], ["Although", ",", "training", "for", "each", "class", "represent", "a", "completely", "different", "problem", ",", "we", "adopt", "this", "to", "maintain", "consistency", "and", "isolate", "out", "the", "effect", "of", "optimizers", "for", "DOC", "vs.", "DOC\\", "-LRB-", "^3\\", "-RRB-", "performances", "."], ["For", "DOC", "we", "fix", "the", "total", "number", "of", "iterations", "for", "gradient", "updates", "to", "300", "."], ["Except", "for", "class", "`", "DOG", "'", "and", "`", "Truck", "'", "we", "use", "400", "and", "50", "respectively", "."], ["For", "DOC\\", "-LRB-", "^3\\", "-RRB-", "we", "fix", "it", "to", "350", "."], ["This", "is", "in", "the", "same", "range", "as", "-LRB-", "Ruff", "et", "al.", ",", "2018", "-RRB-", ",", "and", "hence", "incurs", "similar", "computation", "complexity", "as", "the", "baseline", "DOCC", "and", "DROCC", "algorithms", "."], ["Finally", "for", "DOC\\", "-LRB-", "^3\\", "-RRB-", "we", "fix", "\\", "-LRB-", "\\Delta", "=", "0\\", "-RRB-", "."]], "ner": [[[22, 23, "a"], [25, 25, "p"], [27, 27, "v"]], [[55, 55, "a"], [57, 57, "a"]], [[64, 64, "a"], [68, 74, "p"], [76, 76, "v"], [68, 74, "p"]], [[90, 90, "v"], [92, 92, "v"]], [[96, 96, "a"], [104, 104, "v"]], [], [[137, 137, "a"], [147, 147, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[22, 22, "a"], [25, 25, "p"], [27, 27, "v"]], [], [[76, 76, "v"]], [[90, 90, "v"], [92, 92, "v"]], [[104, 104, "v"]], [[130, 130, "a"], [132, 132, "a"]], [[147, 147, "v"]]], "predicted_relations": [[[25, 25, 22, 23, "USED-FOR"]], [], [[68, 74, 64, 64, "USED-FOR"], [68, 74, 64, 64, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2110.12072-e61236d2-3b6c-48f9-a051-f00d6d761c13", "sentences": [["For", "knowledge", "distillation", "on", "the", "ImageNet", "dataset", ",", "we", "run", "all", "distillation", "for", "50", "epochs", "with", "a", "batch", "size", "of", "128", ",", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "for", "training", "from", "scratch", "and", "\\", "-LRB-", "0.00001\\", "-RRB-", "for", "fine-tuning", ",", "with", "milestones", "at", "\\", "-LRB-", "-LSB-", "20", ",", "30", ",", "40", "-RSB-", "\\", "-RRB-", "of", "a", "decreasing", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "SGD", "optimizer", "with", "\\", "-LRB-", "0.9\\", "-RRB-", "momentum", "is", "used", "to", "update", "the", "model", "parameters", ",", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "is", "applied", "."], ["For", "basic", "knowledge", "distillation", ",", "we", "set", "the", "temperature", "to", "1", "and", "the", "coefficients", "of", "the", "cross-entropy", "loss", "and", "KL-divergence", "loss", "both", "to", "\\", "-LRB-", "0.5\\", "-RRB-", "."], ["For", "KDIGA", ",", "we", "keep", "the", "same", "setting", "as", "that", "of", "the", "basic", "KD", ",", "and", "set", "the", "coefficient", "of", "the", "input", "gradient", "alignment", "term", "to", "\\", "-LRB-", "\\frac", "-LCB-", "10^3", "-RCB-", "-LCB-", "B", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "B\\", "-RRB-", "is", "the", "batch", "size", "of", "the", "inputs", "."], ["For", "experiments", "on", "the", "CIFAR-10", "dataset", ",", "we", "run", "distillation", "for", "200", "epochs", "with", "a", "batch", "size", "of", "125", ",", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "with", "milestones", "at", "\\", "-LRB-", "-LSB-", "100", ",", "150", "-RSB-", "\\", "-RRB-", "of", "a", "decreasing", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "SGD", "optimizer", "with", "a", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "0.0002\\", "-RRB-", "is", "used", "to", "update", "the", "parameters", "."], ["We", "set", "the", "coefficients", "of", "the", "cross-entropy", "loss", "and", "the", "KL-divergence", "loss", "both", "to", "\\", "-LRB-", "0.5\\", "-RRB-", ",", "and", "the", "coefficient", "for", "the", "input", "gradient", "alignment", "to", "\\", "-LRB-", "\\frac", "-LCB-", "10", "-RCB-", "-LCB-", "B", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "B\\", "-RRB-", "is", "the", "batch", "size", "."]], "ner": [[[5, 6, "a"]], [[68, 69, "a"], [75, 75, "p"], [86, 87, "p"], [68, 69, "a"]], [[97, 99, "a"]], [[125, 125, "a"]], [[179, 180, "a"]], [[227, 228, "a"], [231, 231, "p"], [239, 240, "p"], [227, 228, "a"]], [[256, 264, "p"], [274, 279, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [5, 6, "a"], [11, 11, "a"], [13, 13, "v"], [14, 14, "p"], [17, 18, "p"], [20, 20, "v"], [24, 25, "p"], [29, 29, "v"], [38, 38, "v"], [64, 64, "v"]], [[73, 73, "v"], [75, 75, "p"], [86, 87, "p"], [91, 91, "v"]], [[98, 99, "a"], [104, 104, "p"], [106, 106, "v"], [112, 113, "a"], [115, 116, "a"], [121, 121, "v"]], [[125, 125, "a"], [137, 137, "a"], [165, 165, "p"], [169, 170, "p"]], [[179, 180, "a"], [184, 184, "a"], [186, 186, "v"], [187, 187, "p"], [190, 191, "p"], [193, 193, "v"], [197, 198, "p"], [202, 202, "v"], [223, 223, "v"]], [[231, 231, "p"], [235, 235, "v"], [239, 240, "p"], [244, 244, "v"]], [[259, 260, "a"], [263, 264, "a"], [269, 269, "v"], [277, 279, "c"], [300, 301, "p"]]], "predicted_relations": [[], [[75, 75, 68, 69, "USED-FOR"], [75, 75, 68, 69, "USED-FOR"], [86, 87, 68, 69, "USED-FOR"], [86, 87, 68, 69, "USED-FOR"]], [], [], [], [[239, 240, 227, 228, "USED-FOR"], [239, 240, 227, 228, "USED-FOR"]], []]}
{"doc_key": "2111.09808-ee09f5d3-9307-4257-9c45-e07a9bf2d566", "sentences": [["The", "convolutional", "architecture", "uses", "convolution", "with", "64", "\\", "-LRB-", "3", "\\times", "3\\", "-RRB-", "filters", ",", "followed", "by", "\\", "-LRB-", "2", "\\times", "2\\", "-RRB-", "Max-Pooling", ",", "then", "128", "\\", "-LRB-", "3", "\\times", "3\\", "-RRB-", "filters", "with", "\\", "-LRB-", "2", "\\times", "2\\", "-RRB-", "Max-Pooling", ",", "and", "finally", "128", "\\", "-LRB-", "3", "\\times", "3\\", "-RRB-", "filters", "with", "\\", "-LRB-", "2", "\\times", "2\\", "-RRB-", "Max-Pooling", "."], ["The", "network", "is", "complete", "with", "two", "fully", "connected", "layers", ",", "one", "with", "256", "units", ",", "and", "the", "output", "layer", "with", "\\", "-LRB-", "C\\", "-RRB-", "units", "equal", "to", "the", "number", "of", "classes", ",", "and", "a", "softmax", "activation", "."], ["All", "layers", "except", "the", "output", "use", "a", "ReLU", "activation", ",", "and", "we", "insert", "Batch", "Normalization", "layers", "between", "Convolutional", "and", "Max-Pooling", "layers", "."]], "ner": [[[1, 2, "a"], [4, 4, "p"]], [[96, 96, "v"], [68, 70, "p"], [97, 97, "p"]], [[106, 106, "v"], [107, 107, "p"], [112, 113, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "v"], [9, 11, "v"], [19, 19, "v"], [23, 23, "a"], [26, 26, "v"], [29, 31, "v"], [37, 37, "v"], [41, 41, "a"], [45, 45, "v"], [48, 50, "v"], [56, 56, "v"], [60, 60, "a"]], [[67, 67, "v"], [72, 72, "v"], [74, 74, "v"], [84, 84, "v"], [96, 97, "a"]], [[106, 107, "a"], [118, 118, "a"]]], "predicted_relations": [[], [], [[106, 106, 107, 107, "USED-FOR"]]]}
{"doc_key": "2111.09733-e4884a68-de0c-4d4e-9409-19430e9573a9", "sentences": [["We", "augment", "the", "training", "dataset", "with", "randomly", "rotated", "by", "90,180,270", "degrees", "and", "horizontal", "flip", "."], ["The", "training", "image", "patches", "with", "the", "size", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "are", "extracted", "as", "input", "\\", "-LRB-", "I_", "-LCB-", "in", "-RCB-", "\\", "-RRB-", "of", "our", "network", "."], ["The", "network", "is", "trained", "for", "\\", "-LRB-", "7.5", "\\times", "10^5\\", "-RRB-", ",", "\\", "-LRB-", "1.5", "\\times", "10^6\\", "-RRB-", "steps", "on", "Haze4k", "-LSB-", "19", "-RSB-", "and", "RESIDE", "-LSB-", "15", "-RSB-", "respectively.We", "use", "Adam", "optimizer", "with", "initial", "learning", "rate", "of", "\\", "-LRB-", "2", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "adopt", "the", "CyclicLR", "to", "adjust", "the", "learning", "rate", ",", "where", "on", "the", "triangular", "mode", ",", "the", "value", "of", "gamma", "is", "1.0", ",", "base", "momentum", "is", "0.8", ",", "max", "momentum", "is", "0.9", ",", "base", "learning", "rate", "is", "initial", "learning", "rate", "and", "max", "learning", "rate", "is", "\\", "-LRB-", "3", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["PyTorch", "-LSB-", "20", "-RSB-", "was", "used", "to", "implement", "our", "models", "with", "4", "RTX", "3080", "GPU", "with", "total", "batchsize", "of", "40", "."]], "ner": [[], [], [[75, 76, "a"], [78, 80, "p"], [130, 132, "p"], [112, 112, "p"], [114, 114, "v"], [116, 117, "p"], [119, 119, "v"], [121, 122, "p"], [124, 124, "v"], [134, 136, "p"], [96, 96, "a"], [106, 107, "p"], [64, 64, "a"], [69, 69, "a"]], [[149, 149, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[24, 24, "v"], [26, 26, "v"], [42, 42, "a"]], [[51, 51, "v"], [53, 53, "v"], [58, 58, "v"], [60, 60, "v"], [64, 64, "a"], [69, 69, "a"], [75, 75, "a"], [79, 80, "p"], [84, 84, "v"], [86, 88, "v"], [96, 96, "a"], [100, 101, "p"], [112, 112, "p"], [114, 114, "v"], [119, 119, "v"], [124, 124, "v"], [131, 132, "p"], [134, 136, "p"], [140, 140, "v"]], [[149, 149, "a"], [160, 160, "v"], [168, 168, "v"]]], "predicted_relations": [[], [], [[78, 80, 64, 64, "USED-FOR"], [78, 80, 69, 69, "USED-FOR"], [130, 132, 75, 76, "USED-FOR"], [130, 132, 96, 96, "USED-FOR"], [130, 132, 64, 64, "USED-FOR"], [112, 112, 75, 76, "USED-FOR"], [112, 112, 96, 96, "USED-FOR"], [112, 112, 64, 64, "USED-FOR"], [114, 114, 130, 132, "USED-FOR"], [114, 114, 116, 117, "USED-FOR"], [116, 117, 75, 76, "USED-FOR"], [116, 117, 96, 96, "USED-FOR"], [116, 117, 64, 64, "USED-FOR"], [116, 117, 69, 69, "USED-FOR"], [119, 119, 130, 132, "USED-FOR"], [119, 119, 112, 112, "USED-FOR"], [119, 119, 116, 117, "USED-FOR"], [121, 122, 96, 96, "USED-FOR"], [121, 122, 64, 64, "USED-FOR"], [121, 122, 69, 69, "USED-FOR"], [124, 124, 130, 132, "USED-FOR"], [124, 124, 116, 117, "USED-FOR"], [124, 124, 134, 136, "USED-FOR"], [134, 136, 96, 96, "USED-FOR"], [134, 136, 64, 64, "USED-FOR"], [106, 107, 75, 76, "USED-FOR"], [106, 107, 96, 96, "USED-FOR"], [106, 107, 64, 64, "USED-FOR"], [106, 107, 69, 69, "USED-FOR"]], []]}
{"doc_key": "2106.08556-4e029c3d-0fc8-4f5f-8b75-dbc18228d6d9", "sentences": [["The", "proposed", "models", "were", "implemented", "in", "PyTorch", "-LSB-", "23", "-RSB-", ",", "and", "Hugging", "Face", "Transformers", "-LSB-", "32", "-RSB-", "."], ["The", "Deep", "Graph", "Library", "-LRB-", "DGL", "-RRB-", "-LSB-", "31", "-RSB-", "was", "used", "for", "implementing", "the", "Coref-GNN", "."], ["The", "trainable", "parameters", "were", "optimized", "by", "Adam", "-LSB-", "13", "-RSB-", "."], ["The", "learning", "rate", "of", "the", "GCN", "component", "was", "1e-3", ",", "and", "that", "of", "BART", "was", "set", "at", "2e-5", "."], ["We", "trained", "each", "model", "for", "20", "epochs", "and", "selected", "the", "best", "checkpoints", "on", "the", "validation", "set", "with", "ROUGE-2", "score", "."], ["All", "experiments", "were", "run", "on", "a", "single", "Tesla", "V100", "GPU", "with", "16GB", "memory", "."]], "ner": [[[6, 6, "a"], [12, 14, "a"]], [], [[42, 42, "a"]], [], [[83, 83, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[20, 25, "a"], [34, 34, "a"]], [[42, 42, "a"]], [[48, 49, "p"], [52, 52, "a"], [55, 55, "v"], [60, 60, "a"], [64, 64, "v"]], [[71, 71, "v"], [72, 72, "p"]], [[97, 97, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2112.05646-c71335ec-af21-4251-b32b-a5989e375af5", "sentences": [["Following", "recent", "trends", "-LSB-", "11", "-RSB-", ",", "-LSB-", "2", "-RSB-", ",", "-LSB-", "30", "-RSB-", ",", "-LSB-", "23", "-RSB-", ",", "the", "model", "is", "trained", "on", "the", "MS1MV2", "dataset", "-LSB-", "11", "-RSB-", ",", "which", "is", "the", "same", "data", "used", "to", "train", "the", "teacher", "model", "."], ["The", "MS1MV2", "is", "a", "refined", "version", "of", "MS-Celeb-1M", "-LSB-", "19", "-RSB-", "and", "contains", "5.8M", "images", "of", "85k", "identities", "."], ["For", "the", "teacher", "network", ",", "the", "images", "are", "used", "unmodified", ",", "while", "for", "the", "student", "network", ",", "with", "a", "probability", "of", "0.5", ",", "synthetic", "masks", "with", "random", "colors", "and", "random", "small", "deviations", "in", "shape", "are", "added", "."], ["The", "synthetic", "masked", "images", "were", "created", "by", "mapping", "a", "template", "mask", "image", "on", "the", "extracted", "landmarks", "used", "for", "pre-processing", "with", "small", "variations", "in", "the", "mapped", "key", "points", "."], ["All", "the", "images", "are", "aligned", "and", "cropped", "to", "112x112x3", "using", "MTCNN", "-LSB-", "42", "-RSB-", "and", "then", "normalized", "to", "have", "pixel", "values", "between", "-1", "and", "1", "."], ["The", "simulated", "mask", "approach", "will", "be", "publicly", "provided", "to", "ensure", "comparability", "and", "reproducibility", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[25, 26, "a"]], [[50, 50, "a"]], [[83, 83, "v"]], [], [[137, 137, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[25, 26, "a"]], [[44, 44, "a"], [50, 50, "a"], [56, 56, "v"], [59, 59, "v"]], [[83, 83, "v"]], [], [[135, 135, "v"], [137, 137, "a"], [149, 149, "v"], [151, 151, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2102.05399-6f6aa4bb-fbd4-486f-a38b-a01adae353bd", "sentences": [["We", "train", "the", "method", "for", "11", "epochs", "at", "a", "batch", "size", "of", "1", "and", "a", "learning", "rate", "of", "0.0031", "."], ["The", "momentum", "and", "weight", "decay", "values", "are", "set", "to", "0.9", "and", "0.0001", "respectively", "."], ["The", "learning", "rate", "is", "decayed", "by", "10", "times", "at", "epochs", "4", ",", "8", "and", "10", "."], ["We", "adopt", "multi-scaled", "training", "approach", "where", "the", "shorter", "edge", "is", "randomly", "sampled", "from", "six", "different", "scales", "of", "1200,1000,800,600", "and", "400", "."], ["The", "network", "is", "trained", "on", "an", "NVIDIA", "Tesla", "V100", "GPU", ",", "32", "GB", "memory", "."], ["Following", "are", "the", "training", "trajectories", "for", "the", "-LRB-", "1", "-RRB-", "complete", "network", "-LRB-", "Fig", "REF", "-RRB-", ",", "and", "-LRB-", "2", "-RRB-", "the", "light", "enhancement", "module", "-LRB-", "Fig", "REF", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[[3, 3, "a"], [6, 6, "p"], [5, 5, "v"], [9, 10, "p"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"]], [[21, 21, "p"], [29, 29, "v"], [23, 24, "p"], [31, 31, "v"]], [[43, 43, "p"], [35, 36, "p"], [40, 40, "v"], [48, 48, "v"], [42, 48, "c"]], [[57, 58, "p"], [67, 67, "v"], [67, 67, "v"], [67, 67, "v"], [67, 67, "v"], [69, 69, "v"]], [[80, 80, "p"], [77, 79, "v"], [84, 84, "p"], [82, 83, "v"]], [[94, 94, "v"], [89, 90, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "v"], [6, 6, "p"], [9, 10, "p"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"]], [[29, 29, "v"], [31, 31, "v"]], [[35, 36, "p"], [40, 40, "v"], [44, 44, "v"], [46, 46, "v"], [48, 48, "v"]], [[63, 63, "v"], [69, 69, "v"]], [[82, 83, "v"]], [], []], "predicted_relations": [[[6, 6, 3, 3, "USED-FOR"], [5, 5, 6, 6, "USED-FOR"], [18, 18, 15, 16, "USED-FOR"]], [[31, 31, 23, 24, "USED-FOR"]], [[40, 40, 43, 43, "USED-FOR"], [48, 48, 43, 43, "USED-FOR"], [42, 48, 40, 40, "USED-FOR"], [42, 48, 48, 48, "USED-FOR"]], [[67, 67, 57, 58, "USED-FOR"], [67, 67, 57, 58, "USED-FOR"], [67, 67, 57, 58, "USED-FOR"], [67, 67, 57, 58, "USED-FOR"]], [], [], []]}
{"doc_key": "2103.12095-f53f422d-51bb-4a02-814c-b17472eb03d6", "sentences": [["All", "the", "models", "are", "optimized", "with", "Adam", "using", "the", "\\", "-LRB-", "\\ell", "_1\\", "-RRB-", "loss", "as", "the", "cost", "function", "associated", "with", "the", "HR", "predictions", "."], ["In", "each", "epoch", ",", "we", "compute", "the", "validation", "loss", "."], ["After", "training", "is", "complete", ",", "we", "load", "the", "model", "weights", "that", "yielded", "the", "lowest", "validation", "loss", "."], ["Training", "was", "done", "using", "a", "batch", "size", "of", "64", "over", "100", "epochs", "for", "PCE-LSTM", "and", "DeepConvLSTM", "."], ["FFNN", "showed", "slower", "convergence", "and", "hence", "was", "trained", "for", "200", "epochs", "."], ["Subject", "9", "of", "the", "PAMAP2", "dataset", "was", "not", "included", "in", "the", "analysis", "because", "the", "corresponding", "time", "series", "is", "shorter", "than", "the", "length", "of", "the", "training", "segment", "-LRB-", "102s", "-RRB-", "."]], "ner": [[[6, 6, "a"]], [], [], [[65, 65, "a"], [57, 58, "p"], [60, 60, "v"], [67, 67, "a"], [57, 58, "p"], [60, 60, "v"], [63, 63, "p"]], [[69, 69, "a"], [79, 79, "p"], [78, 78, "v"]], [[85, 86, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [], [], [[57, 58, "p"], [60, 60, "v"], [62, 62, "v"], [63, 63, "p"], [65, 65, "a"], [67, 67, "a"]], [[69, 69, "a"], [78, 78, "v"], [79, 79, "p"]], [[85, 86, "a"], [108, 108, "v"]]], "predicted_relations": [[], [], [], [[60, 60, 63, 63, "USED-FOR"], [60, 60, 63, 63, "USED-FOR"], [63, 63, 65, 65, "USED-FOR"], [63, 63, 67, 67, "USED-FOR"]], [[79, 79, 69, 69, "USED-FOR"], [78, 78, 79, 79, "USED-FOR"]], []]}
{"doc_key": "2111.13445-bbf4c299-0cef-412c-9737-583252c4038a", "sentences": [["Here", "we", "discuss", "the", "general", "hyperparameters", "and", "experimental", "setup", "used", "for", "the", "full", "and", "linear", "finetuning", "experiments", "."], ["Regarding", "data", "loading", "image", "augmentation", "settings", ",", "we", "are", "careful", "to", "match", "them", "to", "the", "ones", "used", "in", "the", "original", "upstream", "training", "protocol", "."], ["Specifically", ",", "this", "affects", "the", "choice", "of", "whether", "to", "use", "Bicubic", "or", "Bilinear", "image", "interpolation", "for", "image", "resizing", ";", "for", "example", ",", "RigL", "models", "were", "trained", "using", "Bicubic", "interpolation", ",", "whereas", "the", "other", "pruning", "methods", "considered", "used", "the", "Biliniar", "interpolation", "."], ["All", "ResNet", "and", "MobileNet", "models", "considered", "were", "trained", "using", "standard", "ImageNet-specific", "values", "for", "the", "normalization", "mean", "and", "standard", "deviation", "."], ["In", "the", "case", "of", "full", "finetuning", ",", "we", "used", "dataset-specific", "normalization", "values", "for", "the", "downstream", "tasks", ";", "these", "were", "obtained", "by", "loading", "the", "dataset", "once", "with", "standard", "data", "augmentations", "and", "computing", "the", "means", "and", "variances", "of", "the", "resulting", "data", "."], ["For", "linear", "finetuning", ",", "we", "use", "standard", "ImageNet", "normalization", "values", "."], ["For", "both", "full", "and", "linear", "finetuning", ",", "we", "use", "the", "same", "training", "hyperparameters", "as", "-LSB-", "51", "-RSB-", ";", "specifically", ",", "we", "train", "for", "150", "epochs", ",", "decreasing", "the", "initial", "learning", "rate", "by", "a", "factor", "of", "10", "every", "50", "epochs", "."], ["We", "use", "0.01", "as", "the", "initial", "learning", "rate", "for", "all", "linear", "finetuning", "experiments", ";", "for", "full", "finetuning", ",", "we", "empirically", "found", "0.001", "to", "be", "the", "initial", "learning", "rate", "which", "gives", "comparable", "results", "for", "most", "datasets", "except", "Aircraft", "and", "Cars", ",", "for", "which", "we", "use", "0.01", "."], ["Our", "experiments", "were", "conducted", "using", "PyTorch", "1.8.1", "and", "NVIDIA", "GPUs", "."], ["All", "full", "finetuning", "experiments", "on", "the", "ResNet50", "backbone", "were", "repeated", "three", "times", "and", "all", "linear", "finetuning", "experiments", "five", "times", "."]], "ner": [[], [], [[69, 70, "a"]], [[93, 93, "a"]], [], [[150, 150, "a"]], [], [[196, 196, "v"], [238, 238, "v"], [215, 215, "v"], [196, 196, "v"], [238, 238, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[80, 81, "a"]], [[84, 84, "a"], [86, 86, "a"]], [], [[150, 150, "a"]], [[177, 177, "v"], [178, 178, "p"], [183, 184, "p"], [189, 189, "v"], [191, 191, "v"], [192, 192, "p"]], [[196, 196, "v"], [200, 201, "p"], [215, 215, "v"], [220, 221, "p"], [238, 238, "v"]], [], [[257, 257, "a"], [261, 261, "v"], [268, 268, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2105.10430-b6abc2cd-f8d2-4404-a1fa-741aaba466c5", "sentences": [["As", "described", "above", ",", "we", "adapt", "DeepLOB", "-LSB-", "34", "-RSB-", "as", "our", "encoder", "and", "further", "details", "of", "the", "architecture", "and", "hyperparameters", "can", "be", "found", "in", "their", "work", "."], ["In", "terms", "of", "the", "decoder", ",", "we", "use", "a", "single", "LSTM", "with", "64", "units", "for", "both", "Seq2Seq", "and", "Attention", ",", "denoted", "as", "DeepLOB-Seq2Seq", "and", "DeepLOB-Attention", "respectively", "."], ["We", "include", "a", "wide", "variety", "of", "benchmark", "algorithms", "in", "the", "experiment", ",", "including", "a", "support", "vector", "machine", "-LRB-", "SVM", "-LSB-", "27", "-RSB-", "-RRB-", ",", "a", "multi-layer", "perceptron", "-LRB-", "MLP", "-LSB-", "27", "-RSB-", "-RRB-", ",", "a", "convolutional", "network", "-LRB-", "CNN-I", "-LSB-", "26", "-RSB-", "-RRB-", ",", "a", "LSTM", "-LRB-", "-LSB-", "27", "-RSB-", "-RRB-", ",", "a", "variant", "convolutional", "network", "-LRB-", "CNN-II", "-LSB-", "28", "-RSB-", "-RRB-", ",", "as", "well", "as", "an", "Attention-augmented-Bilinear-Network", "with", "one", "hidden", "layer", "-LRB-", "B", "-LRB-", "TABL", "-RRB-", "-LSB-", "25", "-RSB-", "-RRB-", "and", "two", "hidden", "layers", "-LRB-", "C", "-LRB-", "TABL", "-RRB-", "-LSB-", "25", "-RSB-", "-RRB-", "."], ["Note", "that", "these", "benchmark", "algorithms", "produce", "a", "single-point", "estimation", "and", "the", "authors", "did", "not", "test", "on", "all", "prediction", "horizons", "available", "for", "the", "FI-2010", "dataset", "."]], "ner": [[[6, 6, "a"]], [[50, 50, "a"], [52, 52, "a"], [38, 38, "a"], [41, 41, "p"], [40, 40, "v"]], [[100, 100, "a"], [73, 73, "a"], [83, 83, "a"], [93, 93, "a"], [112, 112, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[38, 38, "a"], [40, 40, "v"], [44, 44, "a"], [46, 46, "a"], [50, 50, "a"], [52, 52, "a"]], [[90, 91, "a"], [93, 93, "a"], [100, 100, "a"], [112, 112, "a"], [122, 122, "a"], [124, 124, "v"], [137, 137, "v"], [138, 139, "p"], [141, 141, "a"]], []], "predicted_relations": [[], [[40, 40, 41, 41, "USED-FOR"]], [], []]}
{"doc_key": "2106.01112-8f2b76b3-41ed-4a4b-b419-bcb03031ffc4", "sentences": [["For", "all", "the", "experiments", "involving", "training", ",", "we", "run", "the", "experiments", "five", "times", "with", "different", "random", "seeds", "for", "model", "weights", "initialization", "to", "reduce", "the", "risk", "of", "randomness", "."], ["The", "experiments", "are", "performed", "on", "a", "single", "Tesla", "V100", "32GB", "GPU", "with", "a", "batch", "size", "of", "512", "."], ["The", "model", "is", "trained", "for", "20", "epochs", "and", "its", "parameters", "are", "optimized", "using", "the", "Adam", "optimizer", "."], ["The", "average", "run", "time", "for", "each", "epoch", "is", "around", "8", "hours", "and", "15", "minutes", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.002", "and", "decays", "by", "a", "factor", "of", "0.5", "per", "epoch", "."], ["A", "dropout", "of", "0.5", "is", "also", "applied", "."]], "ner": [[], [[35, 38, "a"], [41, 42, "a"], [41, 42, "p"], [44, 44, "v"]], [[60, 61, "a"], [52, 52, "a"], [52, 52, "p"], [51, 51, "v"]], [], [[79, 81, "p"], [85, 85, "v"], [92, 92, "v"], [92, 92, "v"]], [[99, 99, "v"], [97, 97, "p"], [99, 99, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[11, 11, "v"]], [[37, 37, "v"], [41, 42, "p"], [44, 44, "v"]], [[51, 51, "v"], [52, 52, "p"], [60, 60, "a"]], [[72, 72, "v"], [75, 75, "v"]], [[80, 81, "p"], [85, 85, "v"], [92, 92, "v"]], [[97, 97, "p"], [99, 99, "v"]]], "predicted_relations": [[], [[41, 42, 35, 38, "USED-FOR"]], [[52, 52, 52, 52, "USED-FOR"], [51, 51, 52, 52, "USED-FOR"]], [], [], [[99, 99, 97, 97, "USED-FOR"], [99, 99, 97, 97, "USED-FOR"]]]}
{"doc_key": "2106.01112-40bb728f-79b2-4c1a-88eb-b1354aefa455", "sentences": [["For", "Empathetic", "Dialogue", "and", "DailyDialog", ",", "the", "context", "window", "length", ",", "\\", "-LRB-", "M\\", "-RRB-", "is", "set", "to", "4", ",", "because", "these", "two", "datasets", "contain", "relatively", "short", "conversations", "-LRB-", "4.31", "and", "7.90", "average", "number", "of", "utterances", "per", "dialogue", "respectively", "-RRB-", "."], ["A", "context", "window", "size", "of", "4", "ensures", "each", "utterance", "is", "connected", "to", "all", "the", "remaining", "utterances", "in", "most", "of", "the", "dialogues", "."], ["The", "utterances", "may", "provide", "important", "contextual", "information", "to", "each", "other", "within", "a", "dialogue", "."], ["For", "ConvAI2", ",", "\\", "-LRB-", "M\\", "-RRB-", "is", "set", "to", "2", "to", "avoid", "introducing", "too", "much", "irrelavant", "context", "information", "."], ["This", "is", "because", "most", "of", "the", "conversations", "in", "ConvAI2", "are", "about", "two", "people", "getting", "to", "know", "each", "other", "and", "there", "are", "frequent", "topic", "changes", "in", "the", "conversations", "."], ["\\", "-LRB-", "M\\", "-RRB-", "serves", "as", "an", "important", "hyperparameter", "to", "control", "the", "influence", "of", "an", "utterance", "on", "the", "rest", "in", "a", "dialogue", "."]], "ner": [[[7, 9, "a"], [13, 13, "a"], [13, 13, "p"], [18, 18, "v"], [29, 29, "v"], [1, 4, "c"]], [[46, 46, "v"]], [], [[82, 82, "a"], [82, 82, "p"], [87, 87, "v"], [78, 78, "c"]], [[105, 105, "c"]], [[127, 127, "a"], [127, 127, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [7, 9, "p"], [13, 13, "p"], [18, 18, "v"], [22, 22, "v"], [29, 29, "v"], [31, 31, "v"]], [[46, 46, "v"]], [], [[78, 78, "a"], [82, 82, "p"], [87, 87, "v"]], [[105, 105, "a"], [108, 108, "v"]], []], "predicted_relations": [[[13, 13, 7, 9, "USED-FOR"], [18, 18, 13, 13, "USED-FOR"], [29, 29, 13, 13, "USED-FOR"]], [], [], [[87, 87, 82, 82, "USED-FOR"], [78, 78, 87, 87, "USED-FOR"]], [], []]}
{"doc_key": "2108.02319-e90104a5-836b-45d7-863d-1d8a4b4fe9f7", "sentences": [["We", "evaluate", "our", "model", "using", "the", "PyTorch", "deep", "learning", "library", "-LSB-", "20", "-RSB-", "on", "a", "machine", "equipped", "with", "32", "CPU", "cores", "-LRB-", "Intel", "Xeon", "Silver", "4110", "CPU", "@", "2.10GHz", "-RRB-", ",", "188GB", "RAM", ",", "and", "eight", "GPU", "cores", "-LRB-", "GeForce", "GTX", "1080TI", "-RRB-", "with", "11GB", "VRAM", "."]], "ner": [[[6, 9, "a"], [22, 28, "a"], [39, 41, "a"]]], "relations": [[]], "predicted_ner": [[[3, 3, "a"], [18, 18, "v"], [31, 31, "v"], [35, 35, "v"], [44, 44, "v"]]], "predicted_relations": [[]]}
{"doc_key": "2108.02319-59a6ec57-846b-4a7a-a007-36a8b6dc33a1", "sentences": [["We", "use", "ADAM", "-LSB-", "21", "-RSB-", "for", "optimization", ",", "where", "we", "reduce", "the", "learning", "rate", "by", "a", "factor", "of", "0.1", "starting", "from", "0.001", "if", "the", "validation", "performance", "does", "not", "improve", "for", "five", "epochs", "."]], "ner": [[[2, 2, "a"], [13, 14, "p"], [22, 22, "v"], [19, 19, "v"], [11, 18, "c"]]], "relations": [[]], "predicted_ner": [[[2, 2, "a"], [13, 14, "p"], [19, 19, "v"], [22, 22, "v"], [31, 31, "v"], [32, 32, "p"]]], "predicted_relations": [[[13, 14, 2, 2, "USED-FOR"], [11, 18, 22, 22, "USED-FOR"], [11, 18, 19, 19, "USED-FOR"]]]}
{"doc_key": "2109.12846-b867835a-0f05-4e4f-b079-ef6c8a700d60", "sentences": [["We", "evaluated", "HAGEN", "on", "two", "real-world", "benchmarks", "in", "Chicago", "and", "Los", "Angeles", "by", "CrimeForecaster", "-LSB-", "19", "-RSB-", "."], ["In", "our", "experiments", ",", "we", "use", "the", "same", "\u201c", "train-validation-test", "\u201d", "setting", "as", "the", "previous", "work", "-LSB-", "19", "-RSB-", ",", "-LSB-", "9", "-RSB-", "."], ["We", "chronologically", "split", "the", "dataset", "as", "6.5", "months", "for", "training", ",", "0.5", "months", "for", "the", "validation", ",", "and", "1", "month", "for", "testing", "."], ["For", "the", "vital", "hyperparameters", "in", "HAGEN", ",", "we", "use", "two", "stacked", "layers", "of", "RNNs", "."], ["Within", "each", "RNN", "layer", ",", "we", "set", "64", "as", "the", "size", "of", "the", "hidden", "dimension", "."], ["Moreover", ",", "we", "set", "the", "subgraph", "size", "of", "the", "sparsity", "operation", "as", "50", "and", "the", "saturation", "rate", "as", "3", "."], ["For", "the", "learning", "objective", ",", "we", "fix", "the", "trade-off", "parameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "as", "\\", "-LRB-", "0.01\\", "-RRB-", ",", "similar", "to", "the", "common", "practice", "of", "other", "regularizers", "."]], "ner": [[[2, 2, "a"], [13, 13, "a"]], [[27, 27, "a"]], [[48, 49, "v"], [53, 54, "v"], [60, 61, "v"]], [[70, 70, "a"]], [[90, 94, "p"], [87, 87, "v"]], [[101, 106, "p"], [108, 108, "v"], [111, 112, "p"], [114, 114, "v"]], [[124, 125, "p"], [134, 134, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [13, 13, "a"]], [], [[48, 48, "v"], [53, 53, "v"], [60, 60, "v"]], [[70, 70, "a"], [74, 74, "v"], [78, 78, "a"]], [[82, 82, "a"], [87, 87, "v"]], [[108, 108, "v"], [111, 112, "p"], [114, 114, "v"]], [[128, 129, "p"], [134, 134, "v"]]], "predicted_relations": [[], [], [], [], [], [[108, 108, 101, 106, "USED-FOR"], [108, 108, 111, 112, "USED-FOR"], [114, 114, 111, 112, "USED-FOR"]], []]}
{"doc_key": "2103.01644-9d16f1b2-a5de-48fd-b976-320e2ac0c8da", "sentences": [["The", "proposed", "network", "is", "trained", "for", "70", "epochs", "with", "Adam", "optimizer", "-LSB-", "15", "-RSB-", "and", "set", "the", "initial", "learning", "rate", "to", "\\", "-LRB-", "5e-4\\", "-RRB-", "."], ["We", "then", "reduce", "the", "learning", "rate", "at", "epoch", "5", "and", "20", "by", "\\", "-LRB-", "\\gamma", "=0.1\\", "-RRB-", "."], ["We", "optimise", "the", "network", "by", "minimising", ":", "\\", "-LRB-", "\\mathcal", "-LCB-", "J", "-RCB-", "=", "\\alpha", "\\mathcal", "-LCB-", "J", "-RCB-", "_1", "+", "\\beta", "\\mathcal", "-LCB-", "J", "-RCB-", "_2\\", "-RRB-"]], "ner": [[[9, 10, "a"], [17, 19, "p"], [23, 23, "v"]], [[40, 40, "p"], [41, 41, "v"]], [[49, 49, "a"], [58, 58, "p"], [65, 65, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "v"], [7, 7, "p"], [9, 9, "a"], [18, 19, "p"], [23, 23, "v"]], [[30, 31, "p"], [36, 36, "v"], [40, 40, "p"], [41, 41, "v"]], [[65, 65, "p"]]], "predicted_relations": [[[17, 19, 9, 10, "USED-FOR"], [23, 23, 17, 19, "USED-FOR"]], [[41, 41, 40, 40, "USED-FOR"]], [[58, 58, 49, 49, "USED-FOR"], [65, 65, 49, 49, "USED-FOR"]]]}
{"doc_key": "2110.02497-4a49bd1e-31b8-4476-8ffe-597396ec961a", "sentences": [["In", "contrast", ",", "inputs", "for", "the", "ImageNet", "supervised", "learning", "task", "are", "of", "shape", "\\", "-LRB-", "3", "\\times", "H", "\\times", "W\\", "-RRB-", "."], ["This", "presents", "a", "challenge", "for", "pretraining", "using", "the", "ImageNet", "task", ",", "since", "input", "shapes", "for", "the", "ImageNet", "task", "and", "our", "RL", "tasks", "are", "different", "."], ["We", "work", "around", "this", "issue", "by", "slightly", "modifying", "the", "ImageNet", "task", "and", "altering", "the", "pretraining", "network", "architecture", "."], ["Given", "a", "single", "input", "image", "and", "label", "pair", "\\", "-LRB-", "-LRB-", "\\textbf", "-LCB-", "I", "-RCB-", ",", "y", "-RRB-", "\\", "-RRB-", ",", "the", "standard", "loss", "used", "for", "ImageNet", "training", "is", "the", "cross-entropy", "loss", "between", "the", "predicted", "and", "true", "class", "label", "."], ["In", "our", "pretraining", "setup", ",", "a", "single", "datapoint", "consists", "of", "\\", "-LRB-", "F\\", "-RRB-", "random", "samples", "from", "the", "ImageNet", "dataset", ":", "\\", "-LRB-", "\\lbrace", "-LRB-", "\\textbf", "-LCB-", "I", "-RCB-", "_1", ",", "y_1", "-RRB-", ",", "-LRB-", "\\textbf", "-LCB-", "I", "-RCB-", "_2", ",", "y_2", "-RRB-", "\\ldots", "-LRB-", "\\textbf", "-LCB-", "I", "-RCB-", "_F", ",", "y_F", "-RRB-", "\\rbrace", "\\", "-RRB-", "."], ["We", "then", "feed", "all", "\\", "-LRB-", "F\\", "-RRB-", "inputs", "\\", "-LRB-", "\\lbrace", "\\textbf", "-LCB-", "I", "-RCB-", "_1", ",", "\\textbf", "-LCB-", "I", "-RCB-", "_2", ",", "\\ldots", "\\textbf", "-LCB-", "I", "-RCB-", "_f", "\\rbrace", "\\", "-RRB-", "into", "our", "network", "at", "once", ",", "resulting", "in", "an", "input", "shape", "of", "\\", "-LRB-", "3F", "\\times", "H", "\\times", "W\\", "-RRB-", "."], ["Notably", ",", "this", "input", "shape", "is", "identical", "to", "that", "which", "will", "be", "used", "during", "RL", "training", "."], ["The", "network", "is", "tasked", "with", "classifying", "all", "\\", "-LRB-", "F\\", "-RRB-", "inputs", "at", "once", ",", "so", "our", "pretraining", "setup", "uses", "the", "following", "loss", "for", "a", "single", "datapoint", ":", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "-LRB-", "\\theta", "-RRB-", "=", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "F", "-RCB-", "\\sum", "_", "-LCB-", "i=0", "-RCB-", "^F", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "CE", "-RCB-", "-LRB-", "y_i", ",", "f_", "-LCB-", "i", ",", "\\theta", "-RCB-", "-LRB-", "\\hat", "-LCB-", "y", "-RCB-", "|", "\\textbf", "-LCB-", "I", "-RCB-", "_i", "-RRB-", "-RRB-", "\\", "-RRB-"]], "ner": [[[6, 9, "a"]], [], [], [[95, 96, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [15, 15, "v"], [17, 17, "p"]], [], [], [[95, 96, "a"]], [[123, 124, "a"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2110.02497-ba677c23-2073-4d9a-8a5d-b62f000bca33", "sentences": [["In", "order", "to", "solve", "this", "issue", "of", "\u201c", "signal", "mixing", "''", ",", "our", "final", "network", "architecture", "consists", "of", "grouped", "convolutional", "layers", "."], ["A", "grouped", "convolution", "with", "\\", "-LRB-", "N\\", "-RRB-", "groups", "will", "take", "a", "set", "of", "\\", "-LRB-", "kN\\", "-RRB-", "channels", "as", "input", ",", "and", "apply", "\\", "-LRB-", "N\\", "-RRB-", "independent", "convolutions", "on", "channels", "\\", "-LRB-", "\\lbrace", "1", ",", "\\ldots", "k\\rbrace", ",", "\\lbrace", "k", "+", "1", ",", "\\ldots", "2k\\rbrace", ",", "\\ldots", "\\lbrace", "-LRB-", "N-1", "-RRB-", "k", "+", "1", ",", "\\ldots", ",", "N", "k\\rbrace", "\\", "-RRB-", "."], ["Given", "an", "input", "of", "size", "\\", "-LRB-", "3F", "\\times", "H", "\\times", "W\\", "-RRB-", ",", "we", "utilize", "a", "grouped", "convolution", "with", "\\", "-LRB-", "N", "=", "F\\", "-RRB-", "groups", "in", "order", "to", "apply", "a", "different", "convolutional", "filter", "to", "each", "\\", "-LRB-", "3", "\\times", "H", "\\times", "W\\", "-RRB-", "input", "image", "in", "parallel", "."]], "ner": [[], [[23, 24, "a"], [28, 28, "p"], [48, 48, "p"], [73, 73, "p"], [81, 81, "p"], [60, 60, "p"], [63, 63, "p"], [75, 75, "p"], [82, 82, "p"]], [[103, 104, "a"], [108, 108, "p"], [110, 110, "v"], [125, 125, "v"], [95, 95, "p"], [127, 127, "p"], [95, 95, "v"], [127, 127, "v"], [97, 97, "p"], [129, 129, "p"], [97, 97, "v"], [129, 129, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[93, 93, "v"], [125, 125, "v"], [127, 127, "p"]]], "predicted_relations": [[], [[28, 28, 23, 24, "USED-FOR"], [48, 48, 23, 24, "USED-FOR"], [60, 60, 23, 24, "USED-FOR"]], [[110, 110, 108, 108, "USED-FOR"], [110, 110, 95, 95, "USED-FOR"], [110, 110, 127, 127, "USED-FOR"], [110, 110, 97, 97, "USED-FOR"], [125, 125, 127, 127, "USED-FOR"], [127, 127, 103, 104, "USED-FOR"], [95, 95, 108, 108, "USED-FOR"], [95, 95, 95, 95, "USED-FOR"], [95, 95, 97, 97, "USED-FOR"], [127, 127, 127, 127, "USED-FOR"], [127, 127, 129, 129, "USED-FOR"], [129, 129, 103, 104, "USED-FOR"], [97, 97, 95, 95, "USED-FOR"], [97, 97, 97, 97, "USED-FOR"], [129, 129, 127, 127, "USED-FOR"], [129, 129, 129, 129, "USED-FOR"]]]}
{"doc_key": "2110.02497-b369a94f-7f22-4672-9cde-05347f443fbb", "sentences": [["In", "our", "experiments", "we", "select", "\\", "-LRB-", "F", "=", "3\\", "-RRB-", ",", "following", "previous", "work", "on", "DeepMind", "Control", "tasks", "-LSB-", "5", "-RSB-", "."], ["Figure", "REF", "and", "Figure", "REF", "outline", "our", "network", "architecture", "in", "detail", "."], ["Using", "this", "setup", ",", "we", "observe", "faster", "convergence", "and", "higher", "accuracy", "during", "ImageNet", "pretraining", "."], ["For", "all", "RL", "experiments", "with", "ImageNet", "pretraining", ",", "we", "pretrain", "our", "fully", "parallel", "network", "for", "400", "epochs", "on", "100", "ImageNet", "classes", "."], ["We", "select", "100", "random", "classes", "from", "those", "used", "in", "the", "ImageNet-R", "dataset", "-LSB-", "7", "-RSB-", ",", "which", "consists", "of", "visually", "dissimilar", "classes", "."], ["Since", "the", "networks", "used", "in", "RL", "training", "are", "not", "usually", "as", "powerful", "as", "those", "used", "to", "solve", "ImageNet", ",", "we", "do", "not", "want", "to", "spend", "inordinate", "amounts", "of", "time", "learning", "to", "separate", "closely", "related", "classes", ",", "such", "as", "\u201c", "Norwich", "terrier", "''", "and", "\u201c", "Norfolk", "terrier", "''", "."]], "ner": [[[16, 18, "a"]], [], [[47, 48, "a"]], [[55, 56, "a"], [66, 66, "p"], [65, 65, "v"], [70, 70, "p"], [68, 68, "v"]], [[76, 76, "p"], [93, 93, "p"], [74, 74, "v"], [82, 83, "a"]], [[129, 129, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[47, 47, "a"]], [[55, 55, "a"], [65, 65, "v"], [66, 66, "p"], [68, 68, "v"], [69, 69, "a"]], [[74, 74, "v"], [82, 83, "a"]], [[112, 112, "a"]]], "predicted_relations": [[], [], [], [[66, 66, 55, 56, "USED-FOR"], [65, 65, 66, 66, "USED-FOR"], [65, 65, 70, 70, "USED-FOR"], [70, 70, 55, 56, "USED-FOR"], [68, 68, 66, 66, "USED-FOR"], [68, 68, 70, 70, "USED-FOR"]], [[76, 76, 82, 83, "USED-FOR"], [93, 93, 82, 83, "USED-FOR"], [74, 74, 76, 76, "USED-FOR"]], []]}
{"doc_key": "2112.02221-40c7bfea-7f5c-4c91-bc07-37d8bbe64a05", "sentences": [["Training", "has", "been", "done", "on", "GPU", "and", "we", "used", "NVIDIA", "Ge", "Force", "1080", "TI", "GPU", "for", "training", "."], ["We", "used", "a", "system", "that", "has", "64GB", "RAM", ",", "1TB", "hard", "disk", "along", "with", "250GB", "SSD", "."], ["The", "total", "number", "of", "epochs", "during", "training", "are", "200", "and", "one", "epoch", "length", "is", "1000", "."], ["RPN", "overlap", "is", "0.7", "and", "IOU", "is", "set", "to", "0.5", "during", "non-maximum", "suppression", "."], ["The", "learning", "rate", "is", "set", "to", "1e-5", "."]], "ner": [[[5, 5, "a"], [14, 14, "a"], [9, 14, "a"]], [[21, 21, "a"]], [[39, 39, "a"], [46, 47, "p"]], [[51, 52, "a"], [56, 56, "a"], [61, 63, "c"]], [[66, 67, "p"], [71, 71, "v"], [66, 67, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[24, 24, "v"], [27, 27, "v"], [32, 32, "v"]], [[43, 43, "v"], [45, 45, "v"], [49, 49, "v"]], [[51, 51, "a"], [54, 54, "v"], [60, 60, "v"], [61, 63, "c"]], [[66, 67, "p"], [71, 71, "v"]]], "predicted_relations": [[], [], [], [], [[71, 71, 66, 67, "USED-FOR"]]]}
{"doc_key": "2112.02215-9883fe0f-aced-4c64-81c5-532e79be1733", "sentences": [["Here", "we", "report", "the", "fixed", "set", "of", "hyper", "parameters", "used", "by", "all", "methods", "."], ["These", "were", "determined", "based", "on", "two", "factors", ":", "-LRB-", "1", "-RRB-", "the", "commonly", "used", "settings", "across", "the", "RL", "literature", "-LRB-", "for", "example", "64x64", "architecture", "and", "batch", "size", "64", "is", "most", "commonly", "used", "across", "many", "different", "problems", "and", "methods", "-RRB-", ",", "and", "by", "sampling", "random", "combinations", "from", "a", "large", "grid", "of", "hyper", "parameters", "and", "comparing", "results", "trends", "to", "narrow", "down", "the", "set", "of", "hyper", "parameters", "to", "consider", "to", "consistently", "well-performing", "values", "and", "reasonable", "ranges", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[], [[19, 19, "v"], [36, 36, "v"], [41, 41, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2112.02215-c4c5a39d-fd84-4711-8ef0-1ef9b1bdd25c", "sentences": [["For", "PARL", ",", "a", "common", "set", "of", "hyper-parameters", "were", "used", "across", "all", "five", "settings", "."], ["The", "discount", "factor", "was", "set", "to", "0.75", ",", "learning-rate", "was", "set", "to", "0.001", ",", "and", "the", "sample-averaging", "approach", "used", "was", "quantile", "sampling", "with", "3", "demand-samples", "per", "step", "."]], "ner": [[[1, 1, "a"]], [[16, 17, "p"], [21, 21, "v"], [23, 23, "p"], [27, 27, "v"], [31, 32, "p"], [35, 36, "v"], [39, 41, "p"], [38, 38, "v"]]], "relations": [[], []], "predicted_ner": [[[1, 1, "a"], [12, 12, "v"]], [[16, 17, "p"], [21, 21, "v"], [23, 23, "p"], [27, 27, "v"], [35, 36, "a"], [38, 38, "v"]]], "predicted_relations": [[], [[21, 21, 23, 23, "USED-FOR"]]]}
{"doc_key": "2112.02214-bebe50df-d39b-41e3-89d0-3a0a93b1e14c", "sentences": [["All", "the", "experiments", "are", "implemented", "using", "PyTorch", "."], ["In", "the", "training", "stage", ",", "the", "optimization", "function", "is", "Adam", ",", "with", "a", "constant", "learning", "rate", "of", "1e-4", "and", "a", "batch", "size", "of", "1", "."], ["We", "train", "our", "model", "for", "100", "epochs", "and", "apply", "it", "to", "the", "testing", "data", "directly", "."]], "ner": [[], [[17, 17, "a"], [22, 23, "p"], [25, 25, "v"], [28, 29, "p"], [31, 31, "v"]], [[39, 39, "p"], [38, 38, "v"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"]], [[17, 17, "a"], [22, 23, "p"], [25, 25, "v"], [28, 29, "p"], [31, 31, "v"]], [[36, 36, "a"], [38, 38, "v"], [39, 39, "p"]]], "predicted_relations": [[], [[22, 23, 17, 17, "USED-FOR"], [25, 25, 22, 23, "USED-FOR"], [28, 29, 17, 17, "USED-FOR"]], [[38, 38, 39, 39, "USED-FOR"]]]}
{"doc_key": "2105.04983-85f6a526-bda1-4f19-ade1-4c2ba62039c9", "sentences": [["We", "employed", "the", "TT-RNN", "model", "in", "the", "recurrent", "layer", "to", "compress", "the", "weight", "matrix", "\\", "-LRB-", "\\mathbf", "-LCB-", "W", "-RCB-", "^", "-LCB-", "xh", "-RCB-", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "M", "\\times", "P", "-RCB-", "\\", "-RRB-", "by", "reshaping", "and", "expressing", "it", "in", "the", "TT-format", ",", "in", "accordance", "to", "the", "dimensions", "of", "the", "input", "tensors", "\\", "-LRB-", "\\ten", "-LCB-", "X", "-RCB-", "_t\\", "-RRB-", ",", "such", "that", "\\", "-LRB-", "P=2", "\\times", "2", "\\times", "5", "\\times", "6", "\\times", "4\\", "-RRB-", "and", "\\", "-LRB-", "M=", "4\\times", "4", "\\times", "4\\times", "4", "\\times", "4\\", "-RRB-", "."], ["An", "illustration", "of", "the", "interaction", "between", "\\", "-LRB-", "\\ten", "-LCB-", "X", "-RCB-", "_t\\", "-RRB-", "and", "the", "tensorized", "\\", "-LRB-", "\\mathbf", "-LCB-", "W", "-RCB-", "^", "-LCB-", "xh", "-RCB-", "\\", "-RRB-", "is", "shown", "in", "Fig", "."], ["REF", "in", "Tensor", "Network", "form", "."]], "ner": [[[3, 4, "a"], [12, 13, "p"]], [], []], "relations": [[], [], []], "predicted_ner": [[[3, 4, "a"]], [], []], "predicted_relations": [[[12, 13, 3, 4, "USED-FOR"]], [], []]}
{"doc_key": "2105.04983-36498402-febf-4f31-9620-44659a9b25d7", "sentences": [["The", "so", "established", "TT-RNN", "model", "was", "trained", "using", "stochastic", "gradient", "descent", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "over", "20", "epochs", ",", "with", "a", "batch", "size", "of", "66", ",", "and", "using", "the", "categorical", "cross-entropy", "loss", "function", "."], ["The", "TT-ranks", "\\", "-LRB-", "-LRB-", "R_1", ",", "R_2", ",", "R_3", ",", "R_4", "-RRB-", "\\", "-RRB-", "for", "the", "TT-RNN", "model", "were", "empirically", "found", "to", "be", "optimal", "for", "rank", "\\", "-LRB-", "R_i", "=", "6\\", "-RRB-", ",", "\\", "-LRB-", "i=1", ",", "\\dots", ",", "4\\", "-RRB-", "."], ["It", "was", "also", "found", "that", "higher", "values", "of", "\\", "-LRB-", "R_i\\", "-RRB-", "would", "result", "in", "over-fitting", ",", "and", "lower", "values", "in", "under-fitting", "."], ["In", "turn", ",", "this", "suggests", "that", "the", "TT-ranks", "may", "be", "used", "for", "regularization", "in", "addition", "to", "compression", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[3, 4, "a"], [13, 14, "p"], [26, 26, "p"], [25, 25, "v"], [30, 31, "p"], [33, 33, "v"], [38, 41, "a"]], [[60, 61, "a"], [44, 44, "a"], [72, 72, "p"], [74, 74, "v"], [79, 83, "c"]], [[96, 96, "p"]], [[116, 116, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [8, 10, "a"], [13, 14, "p"], [18, 21, "v"], [25, 25, "v"], [26, 26, "p"], [30, 31, "p"], [33, 33, "v"], [38, 39, "a"]], [[60, 61, "a"]], [], [], []], "predicted_relations": [[[13, 14, 3, 4, "USED-FOR"], [26, 26, 3, 4, "USED-FOR"], [25, 25, 26, 26, "USED-FOR"], [30, 31, 3, 4, "USED-FOR"], [33, 33, 26, 26, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"]], [[72, 72, 60, 61, "USED-FOR"], [74, 74, 72, 72, "USED-FOR"], [79, 83, 74, 74, "USED-FOR"]], [], [], []]}
{"doc_key": "2106.12423-9d7c94cb-2767-4811-ab23-a8ba3be62b53", "sentences": [["We", "used", "8", "GPUs", "for", "all", "our", "training", "runs", "and", "continued", "the", "training", "until", "the", "discriminator", "had", "seen", "a", "total", "of", "25M", "real", "images", "when", "training", "from", "scratch", ",", "or", "5M", "images", "when", "using", "transfer", "learning", "."], ["Figure", "REF", "shows", "the", "hyperparameters", "used", "in", "each", "experiment", "."], ["We", "performed", "the", "baseline", "runs", "-LRB-", "configs", "a\u2013c", "-RRB-", "using", "the", "corresponding", "standard", "configurations", "by", "Karras", "et", "al", "."], ["-LSB-", "32", "-RSB-", ",", "-LSB-", "30", "-RSB-", ":", "StyleGAN2", "config", "F", "-LRB-", "\u201c", "stylegan2", "\u201d", "in", "the", "official", "implementation", "-RRB-", "for", "the", "high-resolution", "datasets", "in", "Figure", "REF", ",", "left", ";", "and", "ADA", "256\\", "-LRB-", "\\times", "\\", "-RRB-", "256", "baseline", "-LRB-", "\u201c", "paper256", "\u201d", "-RRB-", "for", "the", "low-resolution", "ablations", "in", "Figure", "REF", "and", "Figure", "REF", ",", "right", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "v"], [21, 21, "v"], [30, 30, "v"]], [], [], [[74, 74, "a"], [79, 79, "a"], [103, 103, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.12423-5e2ace66-dd1d-4370-bb05-e8f907d473d6", "sentences": [["Many", "of", "our", "hyperparameters", ",", "including", "discriminator", "capacity", "and", "learning", "rate", ",", "batch", "size", ",", "and", "generator", "moving", "average", "decay", ",", "are", "inherited", "directly", "from", "the", "baseline", "configurations", ",", "and", "kept", "unchanged", "in", "all", "experiments", "."], ["In", "configs", "c", "and", "d", ",", "we", "disable", "noise", "inputs", "-LSB-", "31", "-RSB-", ",", "path", "length", "regularization", "-LSB-", "32", "-RSB-", ",", "and", "mixing", "regularization", "-LSB-", "31", "-RSB-", "."], ["In", "config", "d", ",", "we", "also", "decrease", "the", "mapping", "network", "depth", "to", "2", "and", "set", "the", "minibatch", "standard", "deviation", "group", "size", "to", "4", "as", "recommended", "in", "the", "StyleGAN2-ADA", "documentation", "-LRB-", "\u201c", "auto8", "\u201d", "-RRB-", "."], ["The", "introduction", "of", "explicit", "normalization", "in", "config", "d", "allows", "us", "to", "use", "a", "higher", "learning", "rate", ",", "0.0030", ",", "for", "the", "generator", "in", "all", "subsequent", "configurations", "."], ["In", "Figure", "REF", ",", "right", ",", "we", "show", "results", "for", "path", "length", "regularization", "with", "weight", "0.5", "and", "mixing", "regularization", "with", "probability", "0.5", "."]], "ner": [[[6, 7, "a"], [9, 10, "a"], [12, 13, "a"], [16, 19, "a"], [9, 10, "a"]], [[44, 45, "a"], [50, 52, "a"], [58, 59, "a"]], [[72, 74, "a"], [80, 84, "a"]], [[113, 114, "a"], [113, 114, "a"]], [[136, 138, "a"], [140, 140, "p"], [141, 141, "v"], [147, 147, "v"], [143, 144, "a"], [146, 146, "p"], [141, 141, "v"], [147, 147, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 10, "p"], [12, 13, "p"], [17, 19, "a"]], [[58, 59, "a"]], [[76, 76, "v"], [80, 80, "a"], [86, 86, "v"], [91, 91, "a"], [95, 95, "a"]], [[113, 114, "p"], [116, 116, "v"]], [[136, 138, "a"], [141, 141, "v"], [143, 144, "a"], [147, 147, "v"]]], "predicted_relations": [[], [], [], [], [[140, 140, 136, 138, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"]]]}
{"doc_key": "2109.08569-835dfa3d-1663-41e9-9c7d-d1d5cf7a894a", "sentences": [["We", "train", "the", "model", "for", "200K", "steps", "using", "a", "batch", "size", "of", "140", "."], ["We", "use", "20K", "steps", "for", "BERT", "warmup", ",", "10K", "steps", "for", "decoder", "warmup", ",", "and", "a", "max", "position", "of", "512", "."], ["We", "use", "4", "Nvidia", "Quadro", "RTX", "5000", "GPUs", "."], ["We", "use", "the", "checkpoint", "with", "highest", "ROUGE", "score", "on", "validation", "set", "for", "testing", "."]], "ner": [[[3, 3, "a"], [9, 10, "p"], [12, 12, "v"], [6, 6, "p"], [5, 5, "v"]], [[19, 20, "p"], [16, 17, "v"], [25, 26, "p"], [22, 23, "v"], [30, 31, "p"], [33, 33, "v"], [17, 17, "p"], [23, 23, "p"]], [[42, 42, "p"], [37, 41, "v"]], [[47, 47, "p"], [49, 54, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "v"], [9, 10, "p"], [12, 12, "v"]], [[16, 16, "v"], [19, 20, "a"], [22, 22, "v"], [25, 26, "a"], [30, 31, "p"], [33, 33, "v"]], [[37, 37, "v"]], []], "predicted_relations": [[[9, 10, 3, 3, "USED-FOR"], [12, 12, 9, 10, "USED-FOR"], [6, 6, 3, 3, "USED-FOR"], [5, 5, 6, 6, "USED-FOR"]], [[16, 17, 19, 20, "USED-FOR"], [16, 17, 17, 17, "USED-FOR"], [16, 17, 23, 23, "USED-FOR"], [22, 23, 19, 20, "USED-FOR"], [22, 23, 25, 26, "USED-FOR"], [22, 23, 17, 17, "USED-FOR"], [22, 23, 23, 23, "USED-FOR"]], [], []]}
{"doc_key": "2101.03958-22e38b28-22c9-41f5-b9cd-06f438866980", "sentences": [["Meta-Training", "details", ":", "We", "search", "over", "programs", "with", "maximum", "20", "nodes", ",", "not", "including", "inputs", "or", "parameter", "nodes", "."], ["A", "full", "list", "of", "node", "types", "is", "provided", "in", "Appendix", "."], ["We", "use", "a", "population", "size", "of", "300", ",", "tournament", "size", "of", "25", ",", "and", "choose", "these", "parameters", "based", "on", "the", "ones", "used", "in", "-LSB-", "30", "-RSB-", "."], ["Mutations", "occur", "with", "probability", "\\", "-LRB-", "0.95\\", "-RRB-", "."], ["Otherwise", "a", "new", "random", "program", "is", "sampled", "."], ["The", "search", "is", "done", "over", "300", "CPUs", "and", "run", "for", "roughly", "72", "hours", ",", "at", "which", "point", "around", "\\", "-LRB-", "20,000\\", "-RRB-", "programs", "have", "been", "evaluated", "."], ["The", "search", "is", "distributed", "such", "that", "any", "free", "CPU", "is", "allocated", "to", "a", "proposed", "individual", "such", "that", "there", "are", "no", "idle", "CPUs", "."], ["Further", "meta-training", "details", "are", "in", "Appendix", "."]], "ner": [[[0, 0, "a"]], [], [[33, 34, "p"], [36, 36, "v"], [38, 39, "p"], [41, 41, "v"], [36, 36, "v"]], [[63, 63, "v"]], [], [[79, 79, "v"], [79, 79, "v"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "v"]], [], [[36, 36, "v"], [38, 39, "p"], [41, 41, "v"]], [[63, 63, "v"]], [], [[79, 79, "v"], [85, 85, "v"], [94, 94, "v"]], [], []], "predicted_relations": [[], [], [[36, 36, 33, 34, "USED-FOR"], [36, 36, 38, 39, "USED-FOR"], [41, 41, 38, 39, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"], [36, 36, 38, 39, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2101.03958-d448a188-5c4a-418c-9bd5-30429af89693", "sentences": [["Training", "environments", ":", "The", "choice", "of", "training", "environments", "greatly", "affects", "the", "learned", "algorithms", "and", "their", "generalization", "performance", "."], ["At", "the", "same", "time", ",", "our", "training", "environments", "should", "be", "not", "too", "computationally", "expensive", "to", "run", "as", "we", "will", "be", "evaluating", "thousands", "of", "RL", "algorithms", "."], ["We", "use", "a", "range", "of", "4", "classical", "control", "tasks", "-LRB-", "CartPole", ",", "Acrobat", ",", "MountainCar", ",", "LunarLander", "-RRB-", "and", "a", "set", "of", "12", "multitask", "gridworld", "style", "environments", "from", "MiniGrid", "-LSB-", "7", "-RSB-", "."], ["These", "environments", "are", "computationally", "cheap", "to", "run", "but", "also", "chosen", "to", "cover", "a", "diverse", "set", "of", "situations", "."], ["This", "includes", "dense", "and", "sparse", "reward", ",", "long", "time", "horizon", ",", "and", "tasks", "requiring", "solving", "a", "sequence", "of", "subgoals", "such", "as", "picking", "up", "a", "key", "and", "unlocking", "a", "door", "."], ["More", "details", "are", "in", "Appendix", "."]], "ner": [[], [], [[54, 54, "a"], [56, 56, "a"], [58, 58, "a"], [60, 60, "a"], [72, 72, "a"]], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[49, 49, "v"], [54, 54, "a"], [56, 56, "a"], [58, 58, "a"], [66, 66, "v"], [72, 72, "a"]], [], [], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2101.03958-48991234-330a-4584-8a2f-efb6b3ec7d60", "sentences": [["The", "training", "environments", "always", "include", "CartPole", "as", "an", "initial", "hurdle", "."], ["If", "an", "algorithm", "succeeds", "on", "CartPole", "-LRB-", "normalized", "training", "performance", "greater", "than", "\\", "-LRB-", "0.6\\", "-RRB-", "-RRB-", ",", "it", "then", "proceeds", "to", "a", "harder", "set", "of", "training", "environments", "."], ["For", "our", "experiments", ",", "we", "choose", "these", "training", "environments", "by", "sampling", "a", "set", "of", "3", "environments", "and", "leave", "the", "rest", "as", "test", "environments", "."], ["For", "learning", "from", "scratch", "we", "also", "compare", "the", "effect", "of", "number", "of", "training", "environments", "on", "the", "learned", "algorithm", "by", "comparing", "training", "on", "just", "CartPole", "versus", "training", "on", "CartPole", "and", "LunarLander", "."]], "ner": [[[5, 5, "a"]], [[16, 16, "a"], [18, 20, "a"]], [], [[87, 87, "a"], [91, 91, "a"], [93, 93, "a"], [74, 77, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[16, 16, "a"], [25, 25, "v"]], [[54, 54, "v"]], [[87, 87, "a"], [91, 91, "a"], [93, 93, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2101.03958-b416e933-cc59-4b0c-8104-c79cb4cde162", "sentences": [["RL", "Training", "details", ":", "For", "training", "the", "RL", "agent", ",", "we", "use", "the", "same", "hyperparameters", "across", "all", "training", "and", "test", "environments", "except", "as", "noted", "."], ["All", "neural", "networks", "are", "MLPs", "of", "size", "-LRB-", "256", ",", "256", "-RRB-", "with", "ReLU", "activations", "."], ["We", "use", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "is", "decayed", "linearly", "from", "1", "to", "\\", "-LRB-", "0.05\\", "-RRB-", "over", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "3", "-RCB-", "\\", "-RRB-", "steps", "for", "the", "classical", "control", "tasks", "and", "over", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "5", "-RCB-", "\\", "-RRB-", "steps", "for", "the", "MiniGrid", "tasks", "."]], "ner": [[], [[31, 31, "p"], [38, 38, "v"]], [[44, 45, "a"], [48, 49, "p"], [53, 53, "v"]], [[58, 58, "p"], [65, 65, "v"], [74, 74, "v"], [93, 93, "v"], [69, 69, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[33, 33, "v"], [35, 35, "v"], [38, 38, "a"]], [[44, 44, "a"], [48, 49, "p"], [53, 53, "v"]], [[65, 65, "v"], [69, 69, "v"]]], "predicted_relations": [[], [], [], [[74, 74, 58, 58, "USED-FOR"]]]}
{"doc_key": "2111.10794-b53bde29-1155-4680-a465-aa8a885b2c43", "sentences": [["To", "validate", "the", "performance", "of", "our", "method", "on", "various", "datasets", ",", "we", "conduct", "experiments", "on", "not", "only", "COCO", "and", "ImageNet", ",", "which", "are", "mainly", "used", "in", "the", "other", "methods", ",", "but", "also", "Tiny", "ImageNet", ",", "which", "is", "a", "relatively", "small", "dataset", "."], ["COCO", "-LSB-", "15", "-RSB-", "consists", "of", "about", "118K", "training", "images", "which", "containing", "common", "objects", "in", "complex", "everyday", "scenes", "."], ["ImageNet", "-LSB-", "7", "-RSB-", "consists", "of", "about", "1.28M", "training", "images", "in", "1K", "image", "classes", "."], ["Tiny", "ImageNet", "-LSB-", "14", "-RSB-", "is", "a", "miniature", "of", "ImageNet", "."], ["It", "consists", "of", "100K", "training", "images", "of", "size", "64\\", "-LRB-", "\\times", "\\", "-RRB-", "64", "in", "200", "image", "classes", "."]], "ner": [[[17, 17, "a"], [19, 19, "a"], [33, 33, "a"], [32, 33, "a"]], [[42, 42, "a"]], [[61, 61, "a"]], [[77, 77, "a"], [85, 85, "a"], [76, 77, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [17, 17, "a"], [19, 19, "a"], [33, 33, "a"]], [[42, 42, "a"], [49, 49, "v"]], [[61, 61, "a"], [68, 68, "v"], [72, 72, "v"]], [[77, 77, "a"], [85, 85, "a"]], [[90, 90, "v"], [100, 100, "v"], [102, 102, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2111.10794-35af87fa-53fc-473a-9479-cf946f2a4beb", "sentences": [["The", "pre-training", "setup", "mostly", "follows", "DenseCL", "-LSB-", "22", "-RSB-", "."], ["A", "ResNet-50", "-LSB-", "11", "-RSB-", "is", "adopted", "as", "a", "backbone", "."], ["SGD", "optimizer", "is", "utilized", "and", "its", "weight", "decay", "and", "momentum", "are", "set", "to", "0.0001", "and", "0.9", ",", "respectively", "."], ["The", "initial", "learning", "rates", "are", "set", "to", "0.5", ",", "0.3", ",", "and", "0.03", "in", "Tiny", "ImageNet", ",", "COCO", ",", "and", "ImageNet", ",", "respectively", "and", "cosine", "annealing", "schedule", "is", "used", "."], ["The", "batch", "size", "is", "set", "to", "256", ",", "using", "8", "V100", "GPUs", "."], ["The", "number", "of", "training", "epochs", "are", "set", "to", "200", ",", "800", ",", "and", "200", "in", "Tiny", "ImageNet", ",", "COCO", ",", "and", "ImageNet", ",", "respectively", "."]], "ner": [[[5, 5, "a"]], [[11, 11, "a"]], [[21, 22, "a"], [27, 28, "p"], [34, 34, "v"], [30, 30, "p"], [36, 36, "v"]], [[64, 66, "a"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[11, 11, "a"]], [[21, 21, "a"], [27, 28, "p"], [30, 30, "p"], [34, 34, "v"], [36, 36, "v"]], [[42, 43, "p"], [47, 47, "v"], [49, 49, "v"], [52, 52, "v"], [57, 57, "a"], [60, 60, "a"]], [[71, 72, "p"], [76, 76, "v"], [79, 79, "v"], [80, 80, "v"]], [[91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [97, 99, "c"], [98, 99, "a"], [101, 101, "a"], [104, 104, "a"]]], "predicted_relations": [[], [], [[27, 28, 21, 22, "USED-FOR"], [34, 34, 27, 28, "USED-FOR"], [34, 34, 30, 30, "USED-FOR"], [30, 30, 21, 22, "USED-FOR"]], [], [], []]}
{"doc_key": "2110.05626-8a0e4e5b-63e6-4431-ad35-26a30feb390f", "sentences": [["We", "train", "models", "using", "SGD", "with", "initial", "learning", "rate", "of", "0.1", "and", "use", "cosine", "annealing", "learning", "rate", "scheduling", "-LSB-", "20", "-RSB-", "."], ["We", "train", "all", "models", "for", "100", "epochs", "and", "perform", "evaluation", "on", "the", "model", "saved", "at", "the", "epoch", "which", "has", "the", "highest", "accuracy", "on", "the", "test", "set", "."], ["For", "ResNet-18", "models", "on", "CIFAR-10", ",", "we", "run", "3", "trials", "."], ["For", "each", "trial", ",", "all", "models", "are", "seeded", "to", "the", "same", "seed", "."], ["For", "all", "other", "models", "we", "run", "a", "single", "trial", "."]], "ner": [[[4, 4, "a"], [6, 8, "p"], [10, 10, "v"], [13, 17, "a"]], [], [[50, 50, "a"], [53, 53, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [7, 8, "p"], [10, 10, "v"], [13, 14, "a"]], [[27, 27, "v"], [28, 28, "p"]], [[50, 50, "a"], [53, 53, "a"], [57, 57, "v"]], [], []], "predicted_relations": [[[6, 8, 4, 4, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2107.04082-63c33472-5999-4fda-a0b7-14d8cb9af7f5", "sentences": [["-LSB-", "itemsep=0em", "-RSB-", "Time-stride", "layer", ":", "reduce", "input", "sequence", "length", "by", "\\", "-LRB-", "R=4\\", "-RRB-", "times", "-LRB-", "80", "input", "dimension", ",", "320", "output", "dimension", "-RRB-", "."], ["Linear", "layer", ":", "320", "input", "dimension", ",", "512", "output", "dimension", "."]], "ner": [[[3, 4, "a"], [13, 13, "p"], [13, 13, "v"], [18, 19, "p"], [21, 21, "v"], [22, 23, "p"]], [[26, 27, "a"], [30, 31, "p"], [29, 29, "v"], [34, 35, "p"], [33, 33, "v"]]], "relations": [[], []], "predicted_ner": [[[3, 3, "a"], [13, 13, "v"], [17, 17, "v"], [21, 21, "v"]], [[29, 29, "v"], [33, 33, "v"]]], "predicted_relations": [[[13, 13, 3, 4, "USED-FOR"], [13, 13, 13, 13, "USED-FOR"], [13, 13, 13, 13, "USED-FOR"], [13, 13, 18, 19, "USED-FOR"], [21, 21, 13, 13, "USED-FOR"], [21, 21, 22, 23, "USED-FOR"]], [[30, 31, 26, 27, "USED-FOR"], [29, 29, 30, 31, "USED-FOR"]]]}
{"doc_key": "2107.04082-d27090b4-4573-417d-bfc4-865efa34af33", "sentences": [["-LSB-", "itemsep=0em", "-RSB-", "Linear", "layer", ":", "512", "input", "dimension", ",", "1024", "output", "dimension", "."], ["1D", "Convolution", "layer", ":", "1024", "input", "dimension", ",", "1024", "output", "dimension", ",", "kernel", "size", "48", ",", "filter", "groups", "16", "."], ["Transformers", ":", "24", "layers", ",", "1024", "input", "dimension", ",", "16", "attention", "head", ",", "4096", "feedforward", "dimension", ",", "GELU", "activation", "function", ",", "pre-layer", "norm", "-LSB-", "30", "-RSB-", "."], ["Linear", "layer", ":", "1024", "input", "dimension", ",", "768", "output", "dimension", "."]], "ner": [[[3, 4, "a"], [7, 8, "p"], [6, 6, "v"], [10, 10, "v"], [11, 12, "p"], [10, 10, "v"], [7, 8, "p"], [10, 10, "v"], [11, 12, "p"], [10, 10, "v"], [7, 8, "p"], [10, 10, "v"]], [[19, 20, "p"], [18, 18, "v"], [22, 22, "v"], [23, 24, "p"], [18, 18, "v"], [22, 22, "v"], [14, 16, "a"], [19, 20, "p"], [18, 18, "v"], [22, 22, "v"], [23, 24, "p"], [18, 18, "v"], [22, 22, "v"], [26, 27, "p"], [28, 28, "v"], [30, 31, "p"], [32, 32, "v"], [19, 20, "p"], [18, 18, "v"], [22, 22, "v"], [32, 32, "v"]], [[40, 41, "p"], [39, 39, "v"], [39, 39, "v"], [40, 41, "p"], [39, 39, "v"], [39, 39, "v"], [43, 43, "v"], [34, 34, "a"], [37, 37, "p"], [36, 36, "v"], [40, 41, "p"], [39, 39, "v"], [44, 45, "p"], [43, 43, "v"], [48, 49, "p"], [47, 47, "v"], [52, 53, "p"], [51, 51, "v"], [55, 56, "p"]], [[61, 62, "a"], [65, 66, "p"], [64, 64, "v"], [69, 70, "p"], [64, 64, "v"], [68, 68, "v"], [65, 66, "p"], [64, 64, "v"], [69, 70, "p"], [64, 64, "v"], [65, 66, "p"], [64, 64, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "v"], [10, 10, "v"]], [[18, 18, "v"], [22, 22, "v"], [28, 28, "v"], [32, 32, "v"]], [[36, 36, "v"], [39, 39, "v"], [43, 43, "v"], [47, 47, "v"], [51, 51, "v"]], [[64, 64, "v"], [68, 68, "v"]]], "predicted_relations": [[[7, 8, 3, 4, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [7, 8, 3, 4, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [7, 8, 3, 4, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"], [10, 10, 11, 12, "USED-FOR"], [10, 10, 7, 8, "USED-FOR"]], [[19, 20, 14, 16, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [23, 24, 14, 16, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [19, 20, 14, 16, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [23, 24, 14, 16, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [19, 20, 14, 16, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [18, 18, 19, 20, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"], [22, 22, 23, 24, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"]], [[40, 41, 34, 34, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [40, 41, 34, 34, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [37, 37, 34, 34, "USED-FOR"], [36, 36, 40, 41, "USED-FOR"], [36, 36, 40, 41, "USED-FOR"], [36, 36, 37, 37, "USED-FOR"], [36, 36, 40, 41, "USED-FOR"], [40, 41, 34, 34, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [39, 39, 40, 41, "USED-FOR"], [44, 45, 34, 34, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"], [48, 49, 34, 34, "USED-FOR"], [47, 47, 40, 41, "USED-FOR"], [47, 47, 40, 41, "USED-FOR"], [47, 47, 40, 41, "USED-FOR"], [47, 47, 44, 45, "USED-FOR"], [47, 47, 48, 49, "USED-FOR"], [47, 47, 52, 53, "USED-FOR"], [51, 51, 48, 49, "USED-FOR"], [51, 51, 52, 53, "USED-FOR"]], [[65, 66, 61, 62, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [68, 68, 69, 70, "USED-FOR"], [68, 68, 69, 70, "USED-FOR"], [65, 66, 61, 62, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [65, 66, 61, 62, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"]]]}
{"doc_key": "2107.04082-0ccfa98e-dbd7-449f-b147-77b19d7d09ea", "sentences": [["For", "masking", "over", "the", "latent", "speech", "representation", "\\", "-LRB-", "Z\\", "-RRB-", ",", "we", "sample", "\\", "-LRB-", "p=0.065\\", "-RRB-", "as", "the", "starting", "indices", "and", "we", "mask", "the", "next", "\\", "-LRB-", "M=5\\", "-RRB-", "frames", "."], ["Overall", ",", "this", "model", "has", "300", "million", "parameters", "."]], "ner": [[[1, 1, "a"], [16, 16, "p"], [16, 16, "v"], [29, 29, "p"], [29, 29, "v"]], [[36, 36, "a"], [40, 40, "p"], [38, 39, "v"]]], "relations": [[], []], "predicted_ner": [[[29, 29, "v"]], [[38, 38, "v"]]], "predicted_relations": [[[16, 16, 16, 16, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [29, 29, 29, 29, "USED-FOR"], [29, 29, 16, 16, "USED-FOR"], [29, 29, 29, 29, "USED-FOR"]], [[40, 40, 36, 36, "USED-FOR"], [38, 39, 40, 40, "USED-FOR"]]]}
{"doc_key": "2107.04082-82572813-9321-43c9-9fd4-8310948f1279", "sentences": [["wav2vec", "2.0", "En", "is", "trained", "on", "English", "only", ",", "XLSR-7", "is", "trained", "with", "7", "languages", "-LRB-", "en", ",", "es", ",", "fr", ",", "de", ",", "ru", ",", "my", ",", "ja", "-RRB-", "."], ["We", "resample", "the", "data", "with", "\\", "-LRB-", "\\alpha", "=0.5\\", "-RRB-", "."], ["XLSR-25", "is", "trained", "with", "all", "25", "languages", "."], ["We", "resample", "the", "data", "with", "\\", "-LRB-", "\\alpha", "=0.5\\", "-RRB-", "."]], "ner": [[[0, 2, "a"], [9, 9, "a"]], [[38, 38, "p"], [39, 39, "v"], [38, 38, "p"], [39, 39, "v"]], [[42, 42, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[0, 2, "a"], [9, 9, "a"], [13, 13, "v"]], [[39, 39, "v"]], [[42, 42, "a"], [47, 47, "v"]], [[58, 58, "v"]]], "predicted_relations": [[], [[39, 39, 38, 38, "USED-FOR"], [39, 39, 38, 38, "USED-FOR"], [39, 39, 38, 38, "USED-FOR"], [39, 39, 38, 38, "USED-FOR"]], [], []]}
{"doc_key": "2107.04082-9ed49669-1c64-4308-a4fd-c4ebaf5562ad", "sentences": [["We", "set", "the", "diversity", "loss", "hyperparameter", "\\", "-LRB-", "\\lambda", "=", "0.1\\", "-RRB-", "for", "all", "experiments", "."], ["All", "models", "are", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "31", "-RSB-", "with", "learning", "rate", "\\", "-LRB-", "lr=1e-3\\", "-RRB-", "for", "wav2vec", "2.0", "En", "and", "\\", "-LRB-", "lr=5e-3\\", "-RRB-", "for", "XLSR-", "-LCB-", "7,25", "-RCB-", "up", "to", "300000", "updates", "."], ["We", "also", "add", "weight", "decay", "\\", "-LRB-", "1e-2\\", "-RRB-", "with", "\\", "-LRB-", "\\ell", "^2\\", "-RRB-", "weight", "penalty", "."], ["We", "anneal", "the", "learning", "rate", "by", "using", "a", "linear", "decay", "learning", "schedule", ",", "with", "warm-up", "step", "up", "to", "32000", "updates", "and", "linearly", "decay", "to", "0", "after", "that", "."], ["We", "crop", "the", "input", "sequence", "length", "up", "to", "2000", "samples", "-LRB-", "equals", "to", "20", "seconds", "-RRB-", "."], ["For", "each", "update", "step", ",", "wav2vec", "2.0", "En", "calculates", "the", "gradient", "from", "18", "hours", "of", "data", ",", "and", "XLSR-", "-LCB-", "7,25", "-RCB-", "calculates", "the", "gradient", "from", "36", "hours", "of", "data", "."]], "ner": [[[3, 4, "a"], [5, 5, "p"], [10, 10, "v"]], [[22, 23, "a"], [28, 29, "p"], [32, 32, "v"], [41, 41, "v"]], [[56, 57, "p"], [60, 60, "v"]], [[74, 75, "p"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [8, 8, "p"], [10, 10, "v"], [12, 14, "c"]], [[22, 22, "a"], [28, 29, "p"], [32, 32, "v"], [41, 41, "v"], [50, 50, "v"]], [[56, 57, "a"], [60, 60, "v"], [65, 66, "v"], [68, 69, "p"]], [[74, 75, "p"], [79, 80, "a"], [89, 89, "v"], [92, 93, "a"], [95, 95, "v"]], [[107, 107, "v"], [112, 112, "v"]], [[121, 123, "a"], [128, 128, "v"], [142, 142, "v"]]], "predicted_relations": [[[5, 5, 3, 4, "USED-FOR"], [10, 10, 5, 5, "USED-FOR"]], [[28, 29, 22, 23, "USED-FOR"], [32, 32, 28, 29, "USED-FOR"], [41, 41, 28, 29, "USED-FOR"]], [[60, 60, 56, 57, "USED-FOR"]], [], [], []]}
{"doc_key": "2108.04556-b28503e6-f219-43fd-83da-9b17b3839284", "sentences": [["We", "train", "CLSEBERT", "using", "Transformer", "with", "12", "layers", ",", "768", "hidden", "sizes", "and", "12", "attention", "heads", "."], ["CLSEBERT", "is", "trained", "on", "8", "NVIDIA", "Tesla", "V100", "with", "32GB", "memory", "."], ["The", "lengths", "of", "sequences", "containing", "special", "tokens", "in", "NL", ",", "PL", "and", "AST", "are", "set", "to", "96", ",", "160", "and", "256", ",", "respectively", "."], ["The", "batch", "size", "is", "set", "to", "128", "."], ["The", "learning", "rate", "is", "set", "to", "1e-4", "."], ["We", "use", "an", "Adam", "optimizer", "to", "optimize", "parameters", "of", "the", "model", "."], ["Finally", ",", "the", "model", "is", "trained", "with", "110K", "steps", "."], ["All", "experiments", "are", "implemented", "by", "PyTorchhttps", ":", "//pytorch.org/", "."]], "ner": [[[2, 2, "a"], [4, 4, "a"], [7, 7, "p"], [6, 6, "v"], [13, 13, "v"], [10, 11, "p"], [14, 15, "p"]], [[17, 17, "a"]], [], [], [], [[72, 73, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [6, 6, "v"], [7, 7, "p"], [9, 9, "v"], [10, 11, "p"], [13, 13, "v"]], [[17, 17, "a"], [21, 21, "v"], [26, 26, "v"]], [[45, 45, "v"], [47, 47, "v"], [49, 49, "v"]], [[54, 55, "p"], [59, 59, "v"]], [[62, 63, "p"], [67, 67, "v"]], [[72, 72, "a"]], [[88, 88, "v"]], []], "predicted_relations": [[[7, 7, 2, 2, "USED-FOR"], [7, 7, 4, 4, "USED-FOR"], [6, 6, 7, 7, "USED-FOR"], [6, 6, 10, 11, "USED-FOR"], [13, 13, 14, 15, "USED-FOR"], [10, 11, 2, 2, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2105.06423-951882e2-13c1-4c3b-8617-1152d72230cb", "sentences": [["Training", "Setting", "on", "ImageNet", "."], ["All", "networks", "are", "trained", "using", "8", "GPUs", "with", "a", "mini-batch", "of", "32", "per", "GPU", "."], ["We", "train", "all", "the", "architectures", "from", "scratch", "for", "100", "epochs", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "weight", "decay", "1e-4", "."], ["The", "base", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "and", "is", "multiplied", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "after", "\\", "-LRB-", "30,60\\", "-RRB-", "and", "90", "epochs", "."], ["The", "fine-tuning", "procedure", "uses", "the", "same", "configuration", "except", "that", "the", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["The", "coefficient", "of", "sparse", "regularization", "\\", "-LRB-", "\\lambda", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_2\\", "-RRB-", "are", "set", "to", "7e-5", "and", "3.5e-5", "."], ["Besides", ",", "the", "covariance", "matrix", "in", "the", "proposed", "BW", "technique", "is", "calculated", "within", "each", "GPU", "."], ["Like", "-LSB-", "33", "-RSB-", ",", "we", "also", "use", "group-wise", "decorrelation", "with", "group", "size", "16", "across", "the", "network", "to", "improve", "the", "efficiency", "of", "BW", "."]], "ner": [[], [], [[41, 41, "v"], [46, 46, "v"]], [], [[94, 94, "v"]], [[116, 116, "v"], [118, 118, "v"]], [], [[149, 149, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[10, 10, "v"], [14, 14, "p"], [16, 16, "v"]], [[28, 28, "v"], [29, 29, "p"], [31, 36, "a"], [38, 38, "p"], [41, 41, "v"], [44, 45, "p"], [46, 46, "v"]], [[50, 51, "p"], [57, 57, "v"], [65, 65, "v"], [70, 70, "v"], [73, 73, "v"], [74, 74, "p"]], [[87, 88, "p"], [94, 94, "v"]], [[104, 105, "p"], [110, 111, "p"], [116, 116, "v"], [118, 118, "v"]], [[128, 129, "a"]], [[149, 149, "v"], [150, 152, "c"], [158, 158, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2105.06423-3808f176-34dc-47d9-bc54-be7019b59d90", "sentences": [["Training", "setting", "on", "CIFAR-10", "and", "CIFAR-100", "."], ["We", "train", "all", "models", "on", "CIFAR-10", "and", "CIFAR-100", "with", "a", "batch", "size", "of", "64", "on", "a", "single", "GPU", "for", "160", "epochs", "with", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "weight", "decay", "1e-4", "."], ["The", "initial", "learning", "rate", "is", "0.1", "and", "is", "decreased", "by", "10", "times", "at", "80", "and", "120", "epoch", "."], ["The", "coefficient", "of", "sparse", "regularization", "\\", "-LRB-", "\\lambda", "_1\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_2\\", "-RRB-", "are", "set", "to", "4e-5", "and", "8e-5", "for", "CIFAR-10", "dataset", "and", "7e-6", "and", "1.4e-5", "for", "CIFAR-100", "dataset", "."]], "ner": [[[3, 3, "a"], [5, 5, "a"]], [[12, 12, "a"], [14, 14, "a"], [29, 29, "a"], [32, 32, "v"], [35, 36, "a"], [37, 37, "v"]], [[40, 42, "a"], [44, 44, "v"]], [[80, 80, "a"], [87, 87, "a"], [58, 58, "p"], [58, 58, "p"], [58, 58, "p"], [60, 61, "a"], [76, 76, "v"], [85, 85, "v"], [80, 81, "c"], [83, 83, "v"], [87, 88, "c"], [78, 78, "v"], [80, 81, "c"], [85, 85, "v"], [87, 88, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"]], [[12, 12, "a"], [14, 14, "a"], [17, 18, "p"], [20, 20, "v"], [26, 26, "v"], [27, 27, "p"], [29, 29, "p"], [32, 32, "v"], [35, 36, "p"], [37, 37, "v"]], [[41, 42, "p"], [44, 44, "v"], [49, 49, "v"], [52, 52, "v"], [54, 54, "v"]], [[76, 76, "v"], [78, 78, "v"], [83, 83, "v"], [85, 85, "v"]]], "predicted_relations": [[], [], [], [[80, 81, 76, 76, "USED-FOR"], [80, 81, 85, 85, "USED-FOR"], [80, 81, 83, 83, "USED-FOR"], [80, 81, 78, 78, "USED-FOR"], [80, 81, 85, 85, "USED-FOR"], [87, 88, 76, 76, "USED-FOR"], [87, 88, 85, 85, "USED-FOR"], [87, 88, 83, 83, "USED-FOR"], [87, 88, 78, 78, "USED-FOR"], [87, 88, 85, 85, "USED-FOR"], [80, 81, 76, 76, "USED-FOR"], [80, 81, 85, 85, "USED-FOR"], [80, 81, 83, 83, "USED-FOR"], [80, 81, 78, 78, "USED-FOR"], [80, 81, 85, 85, "USED-FOR"], [87, 88, 76, 76, "USED-FOR"], [87, 88, 85, 85, "USED-FOR"], [87, 88, 83, 83, "USED-FOR"], [87, 88, 78, 78, "USED-FOR"], [87, 88, 85, 85, "USED-FOR"]]]}
{"doc_key": "2111.09999-2cff8754-85be-4f37-8bb9-63e1d29ad972", "sentences": [["Large", "Scale", "Visual", "Recognition", "-LRB-", "ImageNet", "-LSB-", "15", "-RSB-", "-RRB-", "."], ["ImageNet", "is", "a", "highly", "popular", "real-world", "dataset", "with", "a", "million", "high-resolution", "images", "of", "a", "large", "variety", "of", "objects", "used", "for", "training", "state-of-the-art", "deep", "perception", "models", "."], ["The", "goal", "is", "to", "recognize", "visual", "scenes", "among", "1,000", "different", "classes", "."], ["This", "is", "one", "of", "the", "most", "popular", "dataset", "in", "computer", "vision", "for", "benchmarks", "state-of-the-art", "models", "."], ["In", "this", "task", ",", "we", "utilized", "state-of-the-art", "pre-trained", "models", "available", "from", "Pytorch", "Deep", "Learning", "library", "-LSB-", "42", "-RSB-", ";", "notably", ",", "these", "models", "are", "used", "as", "base", "models", "by", "many", "Machine", "Learning", "practitioners", "for", "transfer", "learning", "to", "build", "systems", "for", "different", "visual", "tasks", "."]], "ner": [[[5, 5, "a"]], [[11, 11, "a"]], [], [], [[76, 79, "a"], [71, 73, "a"], [99, 100, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[11, 11, "a"]], [[45, 45, "v"]], [[51, 51, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2111.09999-488bd853-2062-46f2-a3d8-f5b33efb74b7", "sentences": [["-LSB-", "h", "!", "-RSB-"], ["Inputs", ":", "a", "batch", "of", "images", "\\", "-LRB-", "\\lbrace", "\\mathbf", "-LCB-", "x", "-RCB-", "^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^m\\", "-RRB-", "with", "batch", "size", "\\", "-LRB-", "m\\", "-RRB-", ",", "source", "label", "\\", "-LRB-", "\\lbrace", "y^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "source", "-RCB-", "-RCB-", "\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^m\\", "-RRB-", ",", "target", "label", "\\", "-LRB-", "\\lbrace", "y^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "target", "-RCB-", "-RCB-", "\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^m\\", "-RRB-", ",", "model", "\\", "-LRB-", "p_M\\", "-RRB-", ",", "latent", "vector", "\\", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "\\", "-RRB-", ",", "the", "hyper-parameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "to", "balance", "the", "loss", ",", "natural", "generator", "\\", "-LRB-", "G_", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", ",", "and", "the", "thresholds", "to", "detect", "TnT", "\\", "-LRB-", "\\tau", "_\\text", "-LCB-", "batch", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\tau", "_\\text", "-LCB-", "val", "-RCB-", "\\", "-RRB-", "for", "batch", "and", "validation", "set", "respectively", "."], ["Initialization", ":", "\\", "-LRB-", "ASR", "<", "\\tau", "_\\text", "-LCB-", "val", "-RCB-", "\\", "-RRB-", "Sample", "a", "batch", "of", "images", "\\", "-LRB-", "\\lbrace", "\\mathbf", "-LCB-", "x", "-RCB-", "^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^m\\", "-RRB-", "Sample", "a", "latent", "variable", "\\", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "\\sim", "p", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "-RRB-", "\\", "-RRB-", "\\", "-LRB-", "-LCB-", "\\delta", "-RCB-", "=", "G_", "-LCB-", "\\theta", "-RCB-", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "-RRB-", "\\", "-RRB-", "a", "flower", "patch", "Generate", "the", "mask", "\\", "-LRB-", "\\textbf", "-LCB-", "m", "-RCB-", "\\", "-RRB-", "based", "on", "\\", "-LRB-", "-LCB-", "\\delta", "-RCB-", "\\", "-RRB-", "\\", "-LRB-", "-LCB-", "\\delta", "-RCB-", "^", "-LCB-", "\\prime", "-RCB-", "\\leftarrow", "\\text", "-LCB-", "bgremoval", "-RCB-", "-LRB-", "-LCB-", "\\delta", "-RCB-", ",", "\\textbf", "-LCB-", "m", "-RCB-", "-RRB-", "\\", "-RRB-", "Background", "removal", "\\", "-LRB-", "i=1", ",", "...", ",", "m\\", "-RRB-", "\\", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "=", "-LRB-", "1-\\textbf", "-LCB-", "m", "-RCB-", "-RRB-", "\\odot", "\\mathbf", "-LCB-", "x", "-RCB-", "^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "+\\textbf", "-LCB-", "m", "-RCB-", "\\odot", "-LCB-", "\\delta", "-RCB-", "^", "-LCB-", "\\prime", "-RCB-", "\\", "-RRB-", "\\", "-LRB-", "y^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "argmax", "-RCB-", "-RCB-", "="]], "ner": [[], [[7, 9, "a"], [38, 39, "a"], [64, 65, "a"], [90, 90, "a"], [96, 97, "a"], [108, 108, "a"], [111, 111, "p"], [111, 111, "v"], [119, 120, "a"], [132, 135, "a"], [117, 117, "a"]], [[177, 179, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [[111, 111, 7, 9, "USED-FOR"], [111, 111, 38, 39, "USED-FOR"], [111, 111, 64, 65, "USED-FOR"], [111, 111, 90, 90, "USED-FOR"], [111, 111, 96, 97, "USED-FOR"], [111, 111, 108, 108, "USED-FOR"], [111, 111, 119, 120, "USED-FOR"], [111, 111, 132, 135, "USED-FOR"], [111, 111, 117, 117, "USED-FOR"], [111, 111, 111, 111, "USED-FOR"]], []]}
{"doc_key": "2111.09999-a72b0a91-2f25-4bdb-abd3-42e3a1e34bd6", "sentences": [["\\", "-LRB-", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", "has", "not", "converged", "\\", "-LRB-", "t=1", ",", "...", ",", "n_\\text", "-LCB-", "critic", "-RCB-", "\\", "-RRB-", "\\", "-LRB-", "i=1", ",", "...", ",", "m\\", "-RRB-", "Sample", "real", "data", "\\", "-LRB-", "\\mathbf", "-LCB-", "x", "-RCB-", "\\sim", "\\mathbb", "-LCB-", "P", "-RCB-", "_r\\", "-RRB-", ",", "latent", "variable", "\\", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "\\sim", "p", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "a", "random", "number", "\\", "-LRB-", "\\epsilon", "\\sim", "U", "-LSB-", "0,1", "-RSB-", "\\", "-RRB-", "Get", "the", "fake", "sample", "\\", "-LRB-", "\\tilde", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "\\leftarrow", "G_", "-LCB-", "\\theta", "-RCB-", "-LRB-", "\\textbf", "-LCB-", "z", "-RCB-", "-RRB-", "\\", "-RRB-", "\\", "-LRB-", "\\hat", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "\\leftarrow", "\\epsilon", "\\mathbf", "-LCB-", "x", "-RCB-", "+", "-LRB-", "1-\\epsilon", "-RRB-", "\\tilde", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "\\", "-RRB-", "\\", "-LRB-", "L^\\text", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\leftarrow", "D_", "-LCB-", "\\omega", "-RCB-", "-LRB-", "\\tilde", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "-RRB-", "-", "D_", "-LCB-", "\\omega", "-RCB-", "-LRB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RRB-", "+", "\\lambda", "-LRB-", "\\Vert", "-LCB-", "\\nabla", "_", "-LCB-", "\\hat", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "-RCB-", "D", "-LRB-", "\\hat", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "-RRB-", "-RCB-", "\\Vert", "_2", "-", "1", "-RRB-", "^2", "\\", "-RRB-"]], "ner": [[[144, 144, "p"], [158, 158, "p"], [3, 3, "p"], [95, 95, "p"], [167, 167, "p"]]], "relations": [[]], "predicted_ner": [[]], "predicted_relations": [[]]}
{"doc_key": "2102.07954-b1146922-e160-4afd-87f9-ea1533b2aa19", "sentences": [["We", "exactly", "follow", "the", "training", "settings", "in", "-LSB-", "44", "-RSB-", "https", ":", "//github.com/facebookresearch/AttentiveNAS", "."], ["Specifically", ",", "we", "train", "our", "supernets", "for", "360", "epochs", "with", "cosine", "learning", "rate", "decay", "."], ["We", "adopt", "SGD", "training", "on", "64", "GPUs", "."], ["The", "mini-batch", "size", "is", "32", "per", "GPU", "."], ["We", "use", "momeutm", "of", "0.9", ",", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "dropout", "of", "\\", "-LRB-", "0.2\\", "-RRB-", ",", "stochastic", "layer", "dropout", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "."], ["The", "base", "learning", "rate", "is", "set", "as", "0.1", "and", "is", "linearly", "scaled", "up", "for", "every", "256", "training", "samples", "."], ["We", "use", "AutoAugment", "-LSB-", "7", "-RSB-", "for", "data", "augmentation", "and", "set", "label", "smoothing", "coefficient", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "."]], "ner": [[], [[24, 27, "a"]], [[31, 32, "a"]], [[38, 39, "p"], [41, 41, "v"]], [[49, 49, "v"], [51, 52, "a"], [63, 63, "a"], [72, 72, "a"], [67, 67, "v"], [76, 76, "v"], [70, 72, "a"], [67, 67, "v"], [76, 76, "v"]], [[80, 82, "p"], [86, 86, "v"], [86, 86, "v"]], [[115, 115, "v"], [100, 100, "a"], [109, 111, "p"], [115, 115, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[19, 19, "a"], [21, 21, "v"], [22, 22, "p"]], [[31, 32, "a"], [34, 34, "v"]], [[38, 39, "p"], [41, 41, "v"]], [[47, 47, "a"], [49, 49, "v"], [51, 52, "p"], [56, 59, "v"], [63, 63, "a"], [67, 67, "v"], [70, 72, "a"], [76, 76, "v"]], [[80, 82, "p"], [86, 86, "v"], [94, 94, "v"]], [[100, 100, "a"], [105, 106, "c"], [109, 111, "p"], [115, 115, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[109, 111, 100, 100, "USED-FOR"]]]}
{"doc_key": "2103.02225-bbed2f8d-0827-4ca1-9c63-2560c53069e6", "sentences": [["For", "VD-DDPG", ",", "we", "set", "the", "KL", "weight", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "as", "1000", "and", "the", "clip", "value", "\\", "-LRB-", "c\\", "-RRB-", "as", "0.2", "."], ["The", "latent", "variable", "dimension", "-LRB-", "\\", "-LRB-", "z\\", "-RRB-", "dim", "-RRB-", "is", "set", "to", "50", "and", "the", "representation", "dimension", "is", "set", "to", "100", "."], ["We", "collect", "trajectories", "experiences", "in", "the", "first", "5000", "time", "steps", "and", "then", "pre-train", "the", "trajectory", "model", "-LRB-", "along", "with", "the", "representation", "model", "-RRB-", "and", "the", "conditional", "VAE", "for", "15000", "time", "steps", ",", "after", "which", "we", "start", "the", "training", "of", "the", "actor", "."], ["All", "the", "time", "steps", "above", "are", "counted", "into", "the", "total", "time", "steps", "for", "a", "fair", "comparison", "."], ["The", "trajectory", "return", "model", "-LRB-", "along", "with", "the", "representation", "model", "-RRB-", "is", "trained", "every", "10", "time", "steps", "for", "the", "pre-train", "process", "and", "is", "trained", "every", "50", "time", "steps", "in", "the", "rest", "of", "training", ",", "which", "already", "ensures", "a", "good", "performance", "in", "our", "experiments", "."], ["The", "actor", "network", "and", "the", "conditional", "VAE", "are", "trained", "every", "1", "time", "step", "."]], "ner": [[[1, 1, "a"], [6, 7, "p"], [14, 14, "v"], [17, 18, "p"], [24, 24, "v"]], [[27, 29, "p"], [40, 40, "v"], [43, 44, "p"], [48, 48, "v"]], [[64, 65, "a"], [57, 59, "v"], [78, 80, "v"], [75, 76, "a"]], [], [[134, 134, "v"], [128, 129, "p"], [139, 141, "p"], [134, 136, "v"]], [[154, 155, "a"], [163, 165, "v"], [158, 159, "a"], [163, 165, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [6, 7, "p"], [14, 14, "v"], [17, 18, "p"], [21, 21, "p"], [24, 24, "v"]], [[27, 29, "p"], [40, 40, "v"], [48, 48, "v"]], [[57, 57, "v"], [78, 78, "v"]], [], [[110, 112, "a"], [123, 123, "v"], [134, 134, "v"]], [[154, 155, "a"], [163, 163, "v"]]], "predicted_relations": [[[6, 7, 1, 1, "USED-FOR"], [14, 14, 6, 7, "USED-FOR"]], [[40, 40, 43, 44, "USED-FOR"], [48, 48, 43, 44, "USED-FOR"]], [], [], [[134, 134, 128, 129, "USED-FOR"], [134, 134, 139, 141, "USED-FOR"], [134, 136, 139, 141, "USED-FOR"]], []]}
{"doc_key": "2110.03921-89e3f773-34f9-4be7-8eaa-388a48d6de55", "sentences": [["We", "train", "ViDT", "for", "50", "epochs", "using", "AdamW", "-LSB-", "12", "-RSB-", "with", "the", "same", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "its", "body", ",", "neck", "and", "head", "."], ["The", "learning", "rate", "is", "decayed", "by", "cosine", "annealing", "with", "batch", "size", "of", "16", ",", "weight", "decay", "of", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "gradient", "clipping", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["In", "contrast", ",", "ViDT", "-LRB-", "w.o", "."], ["Neck", "-RRB-", "is", "trained", "for", "150", "epochs", "using", "AdamW", "with", "the", "initial", "learning", "rate", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "by", "cosine", "annealing", "."], ["The", "remaining", "configuration", "is", "the", "same", "as", "for", "ViDT", "."]], "ner": [[[7, 7, "a"], [14, 16, "p"]], [[48, 49, "p"], [62, 63, "p"], [67, 67, "v"], [40, 41, "a"]], [], [[85, 85, "a"], [88, 90, "p"], [102, 103, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [5, 5, "p"], [7, 7, "a"], [15, 16, "p"], [20, 23, "v"]], [[35, 36, "p"], [40, 41, "a"], [43, 44, "p"], [46, 46, "v"], [48, 49, "p"], [54, 57, "v"], [62, 63, "a"], [67, 67, "v"]], [[73, 73, "a"]], [[82, 82, "v"], [83, 83, "p"], [85, 85, "a"], [89, 90, "p"], [95, 98, "v"], [102, 103, "a"]], [[113, 113, "a"]]], "predicted_relations": [[[14, 16, 7, 7, "USED-FOR"]], [[48, 49, 40, 41, "USED-FOR"], [62, 63, 40, 41, "USED-FOR"], [67, 67, 62, 63, "USED-FOR"]], [], [[88, 90, 85, 85, "USED-FOR"]], []]}
{"doc_key": "2111.14556-b1def44c-b37d-4742-9d5a-9aa6d4c2a1b9", "sentences": [["ImageNet", "."], ["ImageNet", "2012", "-LSB-", "12", "-RSB-", "comprises", "1.28", "million", "training", "images", "and", "50,000", "validation", "images", "from", "1000", "different", "classes", "."], ["For", "ResNet-based", "models", ",", "we", "follow", "the", "training", "schedule", "in", "-LSB-", "53", "-RSB-", "and", "train", "all", "the", "models", "for", "100", "epochs", "."], ["We", "use", "SGD", "with", "batchsize", "256", "on", "8", "GPUs", "."], ["Cosine", "learning", "rate", "is", "adopted", "with", "the", "base", "learning", "rate", "set", "to", "0.1", "."], ["We", "apply", "standard", "data", "augmentation", ",", "including", "random", "cropping", ",", "random", "horizontal", "flipping", "and", "normalization", "."], ["We", "use", "label", "smoothing", "with", "coefficient", "0.1", "."], ["For", "experiments", "on", "Transformer-based", "models", ",", "including", "PVT", "and", "Swin-Transformer", ",", "we", "follow", "training", "configurations", "in", "the", "original", "paper", "."]], "ner": [[[0, 0, "a"]], [[2, 2, "a"]], [[22, 23, "a"]], [[45, 45, "p"]], [[60, 65, "v"]], [[77, 79, "v"], [81, 81, "v"], [70, 71, "p"]], [[88, 89, "v"], [85, 86, "p"]], [[104, 105, "p"], [94, 95, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[2, 3, "a"], [8, 8, "v"], [13, 13, "v"], [17, 17, "v"]], [[40, 40, "v"], [41, 41, "p"]], [[45, 45, "a"], [47, 47, "p"], [48, 48, "v"], [50, 50, "v"]], [[53, 55, "p"], [65, 65, "v"]], [], [[85, 86, "a"], [89, 89, "v"]], [[98, 98, "a"], [100, 100, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2111.14556-781f7e07-3e5e-4806-9ea2-326331ca6105", "sentences": [["COCO", "."], ["COCO", "dataset", "-LSB-", "30", "-RSB-", "is", "a", "standard", "object", "detection", "benchmark", "and", "we", "use", "a", "subset", "of", "80k", "samples", "as", "training", "set", "and", "35k", "for", "validation", "."], ["For", "ResNet", "and", "SAN", "models", ",", "we", "train", "the", "network", "by", "SGD", "and", "8", "GPU", "are", "used", "with", "a", "batchsize", "of", "16", "."], ["For", "PVT", "and", "Swin-Transformer", "models", ",", "we", "train", "the", "network", "by", "adamw", "."], ["Backbone", "networks", "are", "respectively", "pretrained", "on", "ImageNet", "dataset", "following", "the", "same", "training", "configurations", "in", "the", "original", "paper", "."], ["We", "follow", "the", "``", "1x", "''", "learning", "schedule", "to", "train", "the", "whole", "network", "for", "12", "epochs", "and", "divide", "the", "learning", "rate", "by", "10", "at", "the", "8th", "and", "11th", "epoch", "respectively", "."], ["For", "several", "transformer-based", "models", ",", "we", "follow", "the", "configurations", "in", "the", "original", "paper", ",", "and", "additionally", "experiment", "``", "3x", "''", "schedule", "with", "36", "epochs", "."], ["We", "apply", "standard", "data", "augmentation", ",", "that", "is", "resize", ",", "random", "flip", "and", "normalize", "."], ["Learning", "rate", "is", "set", "at", "0.01", "and", "linear", "warmup", "is", "used", "in", "the", "first", "500", "iterations", "."], ["We", "follow", "the", "``", "1x", "''", "learning", "schedule", "training", "the", "whole", "network", "for", "12", "epochs", "and", "divide", "the", "learning", "rate", "by", "10", "at", "the", "8th", "and", "11th", "epoch", "respectively", "."], ["For", "several", "transformer-based", "models", ",", "we", "follow", "the", "configurations", "in", "the", "original", "paper", ",", "and", "test", "with", "``", "3x", "''", "schedule", "."], ["All", "mAP", "results", "in", "the", "main", "paper", "are", "tested", "with", "input", "image", "size", "-LRB-", "3", ",", "1333", ",", "800", "-RRB-", "."]], "ner": [[], [[2, 3, "a"]], [[30, 30, "a"], [32, 32, "a"], [40, 40, "a"]], [[53, 53, "a"], [55, 55, "a"]], [[71, 72, "a"]], [[98, 98, "p"], [102, 103, "p"]], [[137, 137, "p"], [136, 136, "v"], [136, 136, "v"], [115, 117, "c"]], [[142, 143, "a"]], [], [[185, 185, "p"], [189, 190, "p"]], [[202, 204, "c"]], [[233, 235, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[2, 3, "a"], [19, 19, "v"], [25, 25, "v"]], [[30, 30, "a"], [40, 40, "a"], [42, 42, "v"], [48, 48, "p"], [50, 50, "v"]], [[53, 53, "a"], [63, 63, "a"]], [[65, 66, "a"], [71, 72, "a"]], [[87, 87, "v"], [89, 90, "p"], [97, 97, "v"], [98, 98, "p"], [102, 103, "p"], [105, 105, "v"], [108, 108, "v"], [110, 110, "v"]], [[136, 136, "v"], [137, 137, "p"]], [[147, 147, "a"], [152, 152, "a"]], [[154, 155, "p"], [159, 159, "v"], [161, 162, "a"], [168, 168, "v"]], [[184, 184, "v"], [185, 185, "p"], [189, 190, "p"], [192, 192, "v"], [195, 195, "v"], [197, 197, "v"]], [], [[237, 241, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[136, 136, 137, 137, "USED-FOR"], [136, 136, 137, 137, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2111.14556-a0039091-2d8f-443a-a04c-4adf4b39bf1f", "sentences": [["ADE20K", "."], ["ADE20K", "-LSB-", "55", "-RSB-", "is", "a", "widely-used", "semantic", "segmentation", "dataset", ",", "containing", "150", "categories", "."], ["ADE20K", "has", "25K", "images", ",", "with", "20K", "for", "training", ",", "2K", "for", "validation", ",", "and", "another", "3K", "for", "testing", "."], ["For", "two", "baseline", "models", ",", "PVT", "and", "Swin-Transformer", ",", "we", "follow", "the", "training", "configurations", "in", "their", "original", "paper", "respectively", "."], ["For", "PVT", ",", "we", "implement", "the", "backbone", "models", "on", "the", "basis", "of", "Semantic", "FPN", "-LSB-", "25", "-RSB-", "."], ["We", "optimize", "the", "models", "using", "AdamW", "with", "an", "initial", "learning", "rate", "of", "1e-4", "for", "80k", "iterations", "."], ["For", "Swin-Transformer", ",", "we", "implement", "the", "backbone", "models", "on", "the", "basis", "of", "UperNet", "-LSB-", "48", "-RSB-", "."], ["We", "use", "the", "AdamW", "optimizer", "with", "an", "initial", "learning", "rate", "of", "6e-5", "and", "a", "linear", "warmup", "of", "1,500", "iterations", "."], ["Models", "are", "trained", "for", "a", "total", "of", "160K", "iterations", "."], ["We", "randomly", "resize", "and", "crop", "the", "image", "to", "512", "\u00d7", "512", "for", "training", ",", "and", "rescale", "to", "have", "a", "shorter", "side", "of", "512", "pixels", "during", "testing", "."]], "ner": [[[0, 0, "a"]], [[2, 2, "a"]], [[17, 17, "a"]], [[42, 42, "a"], [44, 44, "a"]], [[58, 58, "a"], [63, 64, "p"]], [], [[98, 99, "p"], [93, 93, "a"]], [[113, 113, "p"], [123, 127, "v"]], [[136, 137, "v"]], [[140, 151, "v"], [154, 164, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[2, 2, "a"], [14, 14, "v"]], [[17, 17, "a"], [19, 19, "v"], [23, 23, "v"], [27, 27, "v"], [33, 33, "v"]], [[38, 38, "v"], [42, 42, "a"], [44, 44, "a"]], [[58, 58, "a"], [69, 70, "a"]], [[80, 80, "a"], [84, 85, "p"], [87, 87, "v"], [89, 89, "v"]], [[93, 93, "a"], [104, 104, "a"]], [[112, 112, "a"], [120, 120, "v"], [123, 124, "a"], [126, 126, "v"]], [[136, 136, "v"]], [[147, 147, "v"], [149, 149, "v"], [161, 161, "v"]]], "predicted_relations": [[], [], [], [], [[63, 64, 58, 58, "USED-FOR"]], [], [[98, 99, 93, 93, "USED-FOR"]], [], [], []]}
{"doc_key": "2111.02394-9b0f4a23-f44c-4ce8-8b8d-9a1bb179b60c", "sentences": [["Following", "previous", "methods", "-LSB-", "44", "-RSB-", ",", "-LSB-", "39", "-RSB-", ",", "-LSB-", "6", "-RSB-", ",", "-LSB-", "43", "-RSB-", ",", "we", "pre-train", "our", "models", "on", "IC17-MLT", "for", "300", "epochs", ",", "in", "which", "images", "are", "cropped", "and", "resized", "to", "640", "\\", "-LRB-", "\\times", "\\", "-RRB-", "640", "pixels", "."], ["We", "then", "finetune", "the", "models", "for", "600", "epochs", "."], ["The", "dilation", "size", "\\", "-LRB-", "s\\", "-RRB-", "is", "set", "to", "9", "in", "our", "experiments", "unless", "explicitly", "stated", "."], ["All", "models", "are", "optimized", "by", "Adam", "with", "batch", "size", "16", "on", "4", "GPUs", "."], ["We", "adopt", "a", "\u201c", "poly", "''", "learning", "rate", "schedule", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "1", "\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["Training", "data", "augmentations", "include", "random", "scale", ",", "random", "flip", ",", "random", "rotation", ",", "random", "crop", ",", "and", "random", "blur", "."]], "ner": [[], [], [], [[78, 78, "a"]], [[93, 94, "p"], [99, 100, "p"]], [[114, 115, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[22, 22, "a"], [24, 24, "a"], [26, 26, "v"], [27, 27, "p"], [37, 37, "v"], [43, 43, "v"]], [[52, 52, "v"], [53, 53, "p"]], [[56, 57, "p"], [65, 65, "v"]], [[78, 78, "a"], [80, 81, "p"], [82, 82, "v"], [84, 84, "v"]], [[99, 100, "p"], [104, 104, "v"], [106, 109, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2111.02358-bb2dab9a-d562-456f-a294-4219a3fa3e16", "sentences": [["Our", "models", "adopt", "the", "same", "network", "configuration", "as", "ViT", "-LSB-", "11", "-RSB-", "and", "BEiT", "-LSB-", "1", "-RSB-", "."], ["VLMo-Base", "consists", "of", "12-layer", "Transformer", "blocks", "with", "768", "hidden", "size", "and", "12", "attention", "heads", "."], ["VLMo-Large", "is", "a", "24-layer", "Transformer", "network", "with", "1024", "hidden", "size", "and", "16", "attention", "heads", "."], ["The", "intermediate", "size", "of", "feed-forward", "networks", "is", "3072", "and", "4096", "for", "base-size", "and", "large-size", "models", ",", "respectively", "."], ["For", "images", ",", "the", "input", "resolution", "is", "\\", "-LRB-", "224", "\\times", "224\\", "-RRB-", "and", "the", "patch", "size", "is", "\\", "-LRB-", "16", "\\times", "16\\", "-RRB-", "during", "pre-training", "."], ["We", "apply", "RandAugment", "-LSB-", "8", "-RSB-", "to", "the", "input", "images", "."], ["The", "tokenizer", "of", "the", "uncased", "version", "of", "BERT", "is", "employed", "to", "tokenize", "the", "text", "."], ["The", "maximum", "text", "sequence", "length", "is", "set", "to", "40", "."]], "ner": [[[8, 8, "a"], [13, 13, "a"]], [[18, 18, "a"]], [[33, 33, "a"]], [[61, 61, "p"], [49, 53, "a"]], [[70, 71, "a"], [81, 82, "a"]], [[95, 95, "a"]], [[117, 117, "p"], [105, 111, "a"]], [[121, 121, "p"], [127, 127, "v"], [120, 123, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [8, 8, "a"], [13, 13, "a"]], [[18, 18, "a"], [21, 21, "v"], [22, 23, "a"], [25, 25, "v"], [29, 29, "v"]], [[33, 33, "a"], [36, 36, "v"], [37, 38, "a"], [40, 40, "v"], [44, 44, "v"]], [[52, 53, "a"], [55, 55, "v"], [57, 57, "v"]], [[75, 75, "v"], [77, 77, "v"], [86, 86, "v"], [88, 88, "v"]], [[95, 95, "a"]], [[111, 111, "a"]], [[127, 127, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[117, 117, 105, 111, "USED-FOR"]], [[121, 121, 120, 123, "USED-FOR"], [127, 127, 121, 121, "USED-FOR"]]]}
{"doc_key": "2111.02358-03215bf9-d280-402e-934b-cde9a31f661f", "sentences": [["We", "pretrain", "the", "models", "for", "200k", "steps", "with", "1024", "batch", "size", "."], ["We", "utilize", "AdamW", "-LSB-", "28", "-RSB-", "optimizer", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.98\\", "-RRB-", "."], ["The", "peak", "learning", "is", "2e-4", "for", "the", "base-size", "model", ",", "5e-5", "for", "the", "large-size", "model", "."], ["Weight", "decay", "is", "set", "to", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["We", "use", "linear", "warmup", "over", "the", "first", "\\", "-LRB-", "2.5\\", "-RRB-", "k", "steps", "and", "linear", "decay", "."]], "ner": [[], [[14, 14, "a"], [23, 23, "v"], [29, 29, "v"]], [], [[48, 49, "a"], [55, 55, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [8, 8, "v"], [9, 10, "p"]], [[14, 14, "a"]], [[36, 36, "v"], [42, 42, "v"]], [[48, 49, "p"], [55, 55, "v"]], [[60, 61, "a"], [67, 67, "v"], [69, 69, "v"], [69, 70, "p"], [72, 73, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2106.04149-ba42a299-c75f-4ce7-ab57-4ff7a192ab92", "sentences": [["We", "adopted", "-LSB-", "22", "-RSB-", "a", "two-layer", "ReLU", "Multi-Layer", "Perceptron", "-LRB-", "MLP", "-RRB-", "for", "classification", "tasks", "on", "4", "UCI", "datasets", ",", "trained", "for", "1000", "episodes", "with", "batch-size", "64", "and", "Adam", "-LSB-", "15", "-RSB-", "optimizer", "."], ["We", "report", "the", "best", "performance", "for", "each", "smooth", "rate", "under", "a", "set", "of", "learning", "rate", "settings", ",", "\\", "-LRB-", "-LSB-", "0.0007", ",", "0.001", ",", "0.005", ",", "0.01", ",", "0.05", "-RSB-", "\\", "-RRB-", "."]], "ner": [[[29, 29, "a"]], [[55, 55, "v"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [63, 63, "v"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "a"], [8, 12, "a"], [17, 17, "v"], [23, 23, "v"], [24, 24, "p"], [26, 26, "p"], [27, 27, "v"], [29, 29, "a"]], [[48, 49, "p"], [55, 55, "v"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [63, 63, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.04149-7a8bb1f5-4c8b-407e-8c6a-f8be8f39f9b6", "sentences": [["We", "adopted", "-LSB-", "22", "-RSB-", "a", "two-layer", "ReLU", "Multi-Layer", "Perceptron", "-LRB-", "MLP", "-RRB-", "for", "classification", "tasks", "on", "4", "UCI", "datasets", ",", "trained", "for", "1000", "episodes", "with", "batch-size", "64", "and", "Adam", "-LSB-", "15", "-RSB-", "optimizer", "."], ["We", "report", "the", "best", "performance", "for", "each", "smooth", "rate", "under", "a", "set", "of", "learning", "rate", "settings", ",", "\\", "-LRB-", "-LSB-", "0.0007", ",", "0.001", ",", "0.005", ",", "0.01", ",", "0.05", "-RSB-", "\\", "-RRB-", "."]], "ner": [[[29, 29, "a"]], [[55, 55, "v"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [63, 63, "v"]]], "relations": [[], []], "predicted_ner": [[[7, 7, "a"], [8, 12, "a"], [17, 17, "v"], [23, 23, "v"], [24, 24, "p"], [26, 26, "p"], [27, 27, "v"], [29, 29, "a"]], [[48, 49, "p"], [55, 55, "v"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"], [63, 63, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2109.07953-dd41c431-8677-4ae7-aa59-98921eceb2c8", "sentences": [["Our", "model", "is", "implemented", "in", "Python", "3", ",", "and", "mainly", "uses", "the", "following", "dependencies", ":", "torch", "as", "the", "machine", "learning", "library", ",", "nltk", "for", "text", "preprocessing", ",", "transformers", "for", "their", "BERT", "implementation", ",", "and", "numpy", "for", "high-level", "mathematical", "operations", "in", "CPU", "."], ["During", "our", "experiments", ",", "we", "used", "machines", "with", "a", "single", "GeForce", "GTX", "1080Ti", "GPU", ",", "4", "CPUs", "and", "16GB", "of", "RAMs", "."], ["The", "training", "times", "for", "all", "datasets", "are", "less", "than", "a", "day", "."], ["The", "total", "number", "of", "parameters", "depends", "on", "the", "number", "of", "attributes", ",", "each", "of", "which", "has", "their", "own", "attribute-specific", "adapters", "."], ["In", "our", "experiments", ",", "excluding", "the", "embedding", "matrices", "and", "classifiers", "that", "vary", "a", "lot", "across", "datasets", "and", "tasks", ",", "BERT-base", "with", "Injectors", "can", "have", "a", "total", "of", "105M", "parameters", "with", "19M", "-LRB-", "18", "%", "-RRB-", "trained", "for", "tasks", "with", "two", "attributes", ",", "or", "a", "total", "of", "121M", "parameters", "with", "36M", "-LRB-", "29", "%", "-RRB-", "trained", "for", "tasks", "with", "four", "attributes", "."], ["Using", "the", "accuracy", "of", "the", "model", "on", "the", "development", "set", ",", "we", "tuned", "the", "learning", "rate", "-LRB-", "from", "\\", "-LRB-", "1e-6\\", "-RRB-", ",", "\\", "-LRB-", "3e-5\\", "-RRB-", ",", "\\", "-LRB-", "1e-5\\", "-RRB-", ",", "and", "\\", "-LRB-", "3e-4\\", "-RRB-", "-RRB-", ",", "the", "adapter", "size", "-LRB-", "from", "32", ",", "48", ",", "64", ",", "and", "128", "-RRB-", ",", "and", "the", "hypercomplex", "dimensions", "-LRB-", "from", "2", ",", "4", ",", "6", ",", "and", "8", "-RRB-", "."]], "ner": [[[15, 15, "a"], [22, 22, "a"], [27, 27, "a"], [34, 34, "a"], [30, 30, "a"]], [[57, 57, "v"]], [], [], [[116, 116, "a"]], [[172, 173, "p"], [219, 219, "v"], [194, 194, "v"], [221, 221, "v"], [178, 178, "v"], [223, 223, "v"], [226, 226, "v"], [199, 200, "p"], [215, 216, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [15, 15, "a"], [22, 22, "a"], [30, 30, "a"]], [[57, 57, "v"], [60, 60, "v"]], [], [], [[116, 116, "a"], [124, 124, "v"], [127, 127, "v"], [129, 130, "v"], [136, 136, "v"], [143, 143, "v"], [146, 146, "v"], [148, 149, "v"], [155, 155, "v"]], [[172, 173, "p"], [178, 178, "v"], [183, 183, "v"], [188, 188, "v"], [194, 194, "v"], [203, 203, "v"], [205, 205, "v"], [207, 207, "v"], [210, 210, "v"], [219, 219, "v"], [221, 221, "v"], [223, 223, "v"], [226, 226, "v"]]], "predicted_relations": [[], [], [], [], [], [[219, 219, 215, 216, "USED-FOR"], [221, 221, 215, 216, "USED-FOR"], [178, 178, 172, 173, "USED-FOR"], [223, 223, 215, 216, "USED-FOR"], [226, 226, 215, 216, "USED-FOR"]]]}
{"doc_key": "2102.07266-c4081307-0069-42d3-8c57-e6c07243e66b", "sentences": [["Sparse", "Dynamic", "."], ["The", "only", "difference", "with", "the", "original", "dynamic", "model", "is", "the", "additional", "application", "of", "the", "confusion-contribution", "loss", "\\", "-LRB-", "-LRB-", "L_", "-LCB-", "CC", "-RCB-", "-RRB-", "\\", "-RRB-", "during", "the", "training", "process", "."], ["A", "hyperparameter", "selection", "of", "\\", "-LRB-", "\\lbrace", "k_1=0.1", ",", "k_2=1\\rbrace", "\\", "-RRB-", "was", "seen", "to", "give", "competitive", "results", "for", "most", "ProcGen", "environments", "."]], "ner": [[[0, 1, "a"]], [[17, 18, "a"]], [[41, 41, "p"], [41, 41, "v"], [43, 43, "p"], [41, 41, "v"], [43, 43, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[17, 18, "a"], [22, 26, "a"]], []], "predicted_relations": [[], [], [[41, 41, 41, 41, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 43, 43, "USED-FOR"], [41, 41, 41, 41, "USED-FOR"], [41, 41, 43, 43, "USED-FOR"], [43, 43, 41, 41, "USED-FOR"], [43, 43, 43, 43, "USED-FOR"]]]}
{"doc_key": "2102.07266-90173c48-3802-4abe-96bb-9b21944a51ac", "sentences": [["All", "the", "three", "configurations", "are", "trained", "using", "the", "Proximal", "policy", "optimization", "-LRB-", "PPO", "-RRB-", "-LSB-", "30", "-RSB-", "algorithm", ",", "which", "is", "ran", "with", "4", "parallel", "workers", "for", "gradient", "computations", "as", "this", "is", "seen", "to", "enhance", "performance", "."], ["Each", "worker", "is", "trained", "for", "50M", "steps", ",", "thus", "equating", "to", "a", "total", "of", "200M", "steps", "across", "all", "the", "4", "workers", "."], ["All", "results", "are", "reported", "as", "the", "average", "across", "4", "runs", "using", "500", "levels", "for", "training", "."]], "ner": [[[24, 25, "p"], [23, 23, "v"], [23, 23, "v"]], [[56, 56, "v"], [43, 43, "p"], [52, 52, "p"], [42, 42, "v"], [56, 56, "v"]], [[67, 67, "v"], [68, 68, "p"], [67, 67, "v"], [71, 71, "p"], [70, 70, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "v"], [8, 13, "a"], [23, 23, "v"]], [[42, 42, "v"], [51, 51, "v"], [56, 56, "v"]], [[67, 67, "v"], [70, 70, "v"]]], "predicted_relations": [[], [[56, 56, 52, 52, "USED-FOR"], [42, 42, 43, 43, "USED-FOR"], [42, 42, 52, 52, "USED-FOR"], [56, 56, 52, 52, "USED-FOR"]], [[67, 67, 68, 68, "USED-FOR"], [67, 67, 71, 71, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [67, 67, 71, 71, "USED-FOR"], [70, 70, 68, 68, "USED-FOR"], [70, 70, 71, 71, "USED-FOR"]]]}
{"doc_key": "2102.07358-5f0c3e02-b83a-4ac4-9d66-36cfdd3c8897", "sentences": [["Generally", ",", "the", "scaling", "factor", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "in", "our", "algorithm", "is", "set", "to", "\\", "-LRB-", "1e-4\\", "-RRB-", "."], ["The", "learning", "rate", "is", "selected", "from", "-LSB-", "1e-1", ",", "1e-2", ",", "1e-3", ",", "1e-4", ",", "1e-5", "-RSB-", ",", "for", "the", "value", "with", "the", "best", "performance", "in", "experiments", "."], ["The", "training", "epochs", "are", "empirically", "set", "as", "multiples", "of", "10", "and", "are", "selected", "for", "each", "experiment", "."], ["We", "pre-run", "each", "experiment", "to", "determine", "the", "epoch", "value", "and", "stop", "training", "when", "the", "performance", "does", "not", "increase", "in", "the", "next", "20", "epochs", "to", "prevent", "over-fitting", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "p"], [7, 7, "p"], [12, 12, "a"], [18, 18, "v"]], [[22, 23, "p"]], [[50, 51, "p"], [58, 58, "v"]], [[87, 87, "v"], [88, 88, "p"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2102.07358-958b689d-f1f0-4d16-9478-8c9687f911ee", "sentences": [["In", "the", "VisDA-C", "experiments", ",", "the", "training", "epochs", "in", "each", "training", "step", "is", "chosen", "as", ":", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_1", "=", "90\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_2", "=", "90\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_3", "=", "40\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_4", "=", "180\\", "-RRB-", "."], ["The", "learning", "rate", "for", "experiment", "is", "set", "to", "\\", "-LRB-", "1e-5\\", "-RRB-", "."], ["Training", "batch", "size", "is", "set", "to", "128", "."], ["For", "the", "baseline", "\\", "-LRB-", "B_t\\", "-RRB-", ",", "it", "is", "trained", "for", "90", "epochs", ",", "and", "learning", "rate", "is", "\\", "-LRB-", "1e-5\\", "-RRB-", "."], ["For", "\\", "-LRB-", "B_", "-LCB-", "f_1", "-RCB-", "\\", "-RRB-", ",", "it", "is", "trained", "on", "the", "source", "data", "with", "weak", "labels", "for", "90", "epochs", "and", "on", "the", "target", "data", "for", "90", "epochs", ",", "and", "the", "learning", "rate", "is", "\\", "-LRB-", "1e-5\\", "-RRB-", "."], ["For", "\\", "-LRB-", "B_", "-LCB-", "f_2", "-RCB-", "\\", "-RRB-", ",", "it", "is", "trained", "on", "the", "source", "data", "with", "weak", "labels", "for", "90", "epochs", "and", "on", "the", "target", "data", "for", "90", "epochs", ",", "and", "the", "learning", "rate", "is", "\\", "-LRB-", "1e-5\\", "-RRB-", "."], ["The", "image", "augmentation", "techniques", "are", "also", "applied", "for", "baselines", "\\", "-LRB-", "B_", "-LCB-", "t", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "B_", "-LCB-", "f_1", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "B_", "-LCB-", "t_2", "-RCB-", "\\", "-RRB-", ",", "and", "our", "approach", "."], ["Other", "baselines", "use", "their", "original", "augmentation", "setting", "."], ["We", "similarly", "use", "the", "function", "in", "the", "Pytorch", "vision", "package", "for", "the", "implementation", ",", "and", "the", "images", "may", "be", "rotated", "from", "\\", "-LRB-", "-3\\", "-RRB-", "to", "3", "degree", ",", "or", "changed", "to", "gray-scale", "with", "a", "probability", "of", "0.1", ",", "or", "horizontally", "flipped", "with", "a", "probability", "of", "0.5", "."]], "ner": [[[2, 3, "a"], [6, 7, "p"], [23, 23, "v"], [33, 33, "v"], [23, 23, "v"], [33, 33, "v"], [43, 43, "v"], [53, 53, "v"]], [[57, 58, "p"], [66, 66, "v"]], [[75, 75, "v"]], [[89, 89, "v"], [89, 89, "v"], [93, 94, "p"], [98, 98, "v"]], [[122, 122, "v"], [130, 130, "v"], [122, 122, "v"], [130, 130, "v"], [135, 136, "p"], [140, 140, "v"]], [[164, 164, "v"], [172, 172, "v"], [164, 164, "v"], [172, 172, "v"], [177, 178, "p"], [182, 182, "v"]], [[186, 188, "a"]], [], [[265, 265, "p"], [270, 270, "v"], [273, 274, "p"], [279, 279, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 7, "p"], [23, 23, "v"], [33, 33, "v"], [43, 43, "v"], [53, 53, "v"]], [[57, 58, "p"], [66, 66, "v"]], [[69, 71, "p"], [75, 75, "v"]], [[89, 89, "v"], [90, 90, "p"], [93, 94, "p"], [98, 98, "v"]], [[122, 122, "v"], [130, 130, "v"], [131, 131, "p"], [135, 136, "p"], [140, 140, "v"]], [[164, 164, "v"], [165, 165, "p"], [172, 172, "v"], [177, 178, "p"], [182, 182, "v"]], [], [], [[256, 256, "v"], [259, 259, "v"], [270, 270, "v"], [279, 279, "v"]]], "predicted_relations": [[[6, 7, 2, 3, "USED-FOR"]], [[66, 66, 57, 58, "USED-FOR"]], [], [[98, 98, 93, 94, "USED-FOR"]], [[140, 140, 135, 136, "USED-FOR"]], [[182, 182, 177, 178, "USED-FOR"]], [], [], [[270, 270, 265, 265, "USED-FOR"]]]}
{"doc_key": "2102.07358-0a37c01b-9f88-44a9-aca9-74b1a3e2b55c", "sentences": [["In", "the", "CIFAR-10", "experiments", ",", "the", "training", "epochs", "in", "each", "training", "step", "is", "chosen", "as", ":", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_1", "=", "40\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_2", "=", "30\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_3", "=", "70\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "ep", "-RCB-", "_4", "=", "70\\", "-RRB-", "."], ["The", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "1e-3\\", "-RRB-", "."], ["Training", "batch", "size", "is", "set", "to", "128", "."], ["For", "the", "baseline", "\\", "-LRB-", "B_t\\", "-RRB-", ",", "it", "is", "trained", "for", "70", "epochs", ",", "and", "the", "learning", "rate", "is", "\\", "-LRB-", "1e-3\\", "-RRB-", "."], ["For", "\\", "-LRB-", "B_", "-LCB-", "f_1", "-RCB-", "\\", "-RRB-", ",", "it", "is", "trained", "on", "the", "source", "data", "with", "weak", "labels", "for", "30", "epochs", "and", "on", "the", "target", "data", "for", "40", "epochs", ",", "and", "the", "learning", "rate", "is", "\\", "-LRB-", "1e-3\\", "-RRB-", "."], ["For", "\\", "-LRB-", "B_", "-LCB-", "f_2", "-RCB-", "\\", "-RRB-", ",", "it", "is", "trained", "on", "the", "source", "data", "with", "weak", "labels", "for", "30", "epochs", "and", "on", "the", "target", "data", "for", "40", "epochs", ",", "and", "the", "learning", "rate", "is", "\\", "-LRB-", "1e-3\\", "-RRB-", "."], ["The", "image", "augmentation", "techniques", "are", "still", "applied", "to", "baselines", "\\", "-LRB-", "B_", "-LCB-", "t", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "B_", "-LCB-", "f_1", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "B_", "-LCB-", "t_2", "-RCB-", "\\", "-RRB-", ",", "and", "our", "approach", "."], ["We", "use", "the", "function", "in", "the", "Pytorch", "vision", "package", "for", "the", "implementation", ",", "and", "the", "images", "are", "horizontally", "flipped", "with", "a", "probability", "of", "0.5", "."]], "ner": [[[2, 2, "a"], [6, 7, "a"], [23, 23, "v"], [33, 33, "v"], [43, 43, "v"], [53, 53, "v"], [43, 43, "v"], [53, 53, "v"], [7, 7, "p"], [43, 43, "v"], [53, 53, "v"], [7, 7, "p"], [33, 33, "v"], [23, 23, "v"], [7, 7, "p"], [33, 33, "v"], [23, 23, "v"]], [[57, 58, "a"], [57, 58, "p"], [64, 64, "v"], [57, 58, "p"], [64, 64, "v"], [57, 58, "p"], [64, 64, "v"], [57, 58, "p"], [64, 64, "v"]], [[73, 73, "v"]], [[87, 87, "v"], [87, 87, "v"], [92, 93, "a"], [92, 93, "p"], [97, 97, "v"], [88, 88, "p"], [87, 87, "v"], [92, 93, "p"], [97, 97, "v"], [88, 88, "p"], [92, 93, "p"], [97, 97, "v"], [88, 88, "p"], [92, 93, "p"], [97, 97, "v"]], [[129, 129, "v"], [121, 121, "v"], [134, 135, "a"], [134, 135, "p"], [139, 139, "v"], [122, 122, "p"], [130, 130, "p"], [134, 135, "p"], [139, 139, "v"], [122, 122, "p"], [130, 130, "p"], [121, 121, "v"], [115, 119, "c"], [129, 129, "v"], [126, 127, "c"], [134, 135, "p"], [139, 139, "v"], [122, 122, "p"], [130, 130, "p"], [121, 121, "v"], [115, 119, "c"], [129, 129, "v"], [126, 127, "c"], [134, 135, "p"], [139, 139, "v"]], [[171, 171, "v"], [163, 163, "v"], [176, 177, "a"], [176, 177, "p"], [181, 181, "v"], [164, 164, "p"], [172, 172, "p"], [176, 177, "p"], [181, 181, "v"], [164, 164, "p"], [172, 172, "p"], [163, 163, "v"], [157, 161, "c"], [171, 171, "v"], [168, 169, "c"], [176, 177, "p"], [181, 181, "v"], [164, 164, "p"], [172, 172, "p"], [163, 163, "v"], [157, 161, "c"], [171, 171, "v"], [168, 169, "c"], [176, 177, "p"], [181, 181, "v"]], [[185, 186, "a"]], [[241, 242, "p"], [247, 247, "v"], [245, 245, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 7, "p"], [33, 33, "v"], [43, 43, "v"], [53, 53, "v"]], [[57, 58, "p"], [64, 64, "v"]], [[67, 69, "p"], [73, 73, "v"]], [[87, 87, "v"], [88, 88, "p"], [92, 93, "p"], [97, 97, "v"]], [[121, 121, "v"], [122, 122, "p"], [129, 129, "v"], [130, 130, "p"], [134, 135, "p"], [139, 139, "v"]], [[163, 163, "v"], [171, 171, "v"], [172, 172, "p"], [176, 177, "p"], [181, 181, "v"]], [], [[247, 247, "v"]]], "predicted_relations": [[[7, 7, 2, 2, "USED-FOR"], [7, 7, 6, 7, "USED-FOR"], [7, 7, 2, 2, "USED-FOR"], [7, 7, 6, 7, "USED-FOR"], [7, 7, 2, 2, "USED-FOR"], [7, 7, 6, 7, "USED-FOR"]], [[64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"], [64, 64, 57, 58, "USED-FOR"]], [], [[87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [88, 88, 92, 93, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [87, 87, 88, 88, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [88, 88, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [88, 88, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"], [97, 97, 92, 93, "USED-FOR"]], [[129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [130, 130, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [130, 130, 134, 135, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [130, 130, 134, 135, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [121, 121, 122, 122, "USED-FOR"], [121, 121, 130, 130, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [115, 119, 121, 121, "USED-FOR"], [115, 119, 129, 129, "USED-FOR"], [115, 119, 139, 139, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [129, 129, 122, 122, "USED-FOR"], [129, 129, 130, 130, "USED-FOR"], [129, 129, 134, 135, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [126, 127, 121, 121, "USED-FOR"], [126, 127, 129, 129, "USED-FOR"], [126, 127, 139, 139, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"], [139, 139, 134, 135, "USED-FOR"]], [[171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [172, 172, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [172, 172, 176, 177, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [172, 172, 176, 177, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [163, 163, 164, 164, "USED-FOR"], [163, 163, 172, 172, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [157, 161, 163, 163, "USED-FOR"], [157, 161, 171, 171, "USED-FOR"], [157, 161, 181, 181, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [171, 171, 164, 164, "USED-FOR"], [171, 171, 172, 172, "USED-FOR"], [171, 171, 176, 177, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [168, 169, 163, 163, "USED-FOR"], [168, 169, 171, 171, "USED-FOR"], [168, 169, 181, 181, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"]], [], []]}
{"doc_key": "2103.04290-763c28c1-7643-4c6e-852f-50e32f24d211", "sentences": [["MTLHealth", "makes", "use", "of", "a", "technique", "called", "dropout", ",", "where", "a", "percentage", "of", "the", "output", "is", "randomly", "set", "to", "zero", ",", "which", "helps", "to", "prevent", "over-fitting", "by", "removing", "noise", "in", "the", "representations", "-LSB-", "20", "-RSB-", "."], ["Dropout", "probability", "is", "set", "at", "\\", "-LRB-", "p", "=", "0.5\\", "-RRB-", "."]], "ner": [[], [[36, 36, "a"], [36, 37, "p"], [45, 45, "v"]]], "relations": [[], []], "predicted_ner": [[[0, 0, "a"], [7, 7, "a"], [19, 19, "v"]], [[36, 36, "a"], [45, 45, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2108.04135-7a0742a6-9d32-4921-9592-2f6565a86748", "sentences": [["We", "trained", "the", "networks", "using", "an", "Adam", "optimizer", "-LSB-", "31", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "beta1", ",", "beta2", "values", "of", "0.5", "and", "0.999", "."], ["Hyper-parameters", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\mathrm", "-LCB-", "prior", "-RCB-", "_", "-LCB-", "X", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\mathrm", "-LCB-", "prior", "-RCB-", "_", "-LCB-", "Y", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\mathrm", "-LCB-", "cyc", "-RCB-", "_", "-LCB-", "X", "-RCB-", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\mathrm", "-LCB-", "cyc", "-RCB-", "_", "-LCB-", "Y", "-RCB-", "-RCB-", "\\", "-RRB-", "were", "experimentally", "set", "to", "10", ",", "0.5", ",", "5", "and", "0.25", "."], ["Furthermore", ",", "we", "used", "a", "reduce", "on", "plateau", "learning", "rate", "scheduler", "with", "a", "patience", "of", "10", "epochs", "and", "a", "factor", "of", "10", "."], ["Batches", "of", "8", "patches", "were", "used", "and", "the", "models", "were", "trained", "for", "35", "epochs", "-LRB-", "\\", "-LRB-", "\\sim", "220\\", "-RRB-", "k", "steps", "-RRB-", "on", "an", "NVIDIA", "TITAN", "XP", "GPU", "with", "12", "GB", "of", "VRAM", "."], ["All", "experiments", "were", "repeated", "three", "times", "with", "a", "different", "initialization", "seed", "."]], "ner": [[[6, 7, "a"], [13, 14, "p"], [25, 25, "p"], [30, 30, "v"], [27, 27, "p"], [32, 32, "v"], [18, 18, "v"], [30, 30, "v"], [30, 30, "v"], [18, 18, "v"]], [[108, 108, "v"], [34, 34, "a"], [106, 106, "v"], [108, 108, "v"], [108, 108, "v"], [110, 110, "v"], [112, 112, "v"], [106, 106, "v"]], [[122, 123, "p"], [129, 129, "v"], [135, 135, "v"], [119, 124, "a"], [127, 127, "p"], [129, 130, "v"], [133, 133, "p"], [129, 129, "v"], [135, 135, "v"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [13, 14, "p"], [18, 21, "v"], [30, 30, "v"], [32, 32, "v"]], [[106, 106, "v"], [108, 108, "v"], [110, 110, "v"], [112, 112, "v"]], [[129, 129, "v"], [130, 130, "p"], [135, 135, "v"]], [[139, 139, "v"], [149, 149, "v"], [150, 150, "p"], [157, 158, "p"], [167, 168, "v"]], [[176, 176, "v"]]], "predicted_relations": [[[25, 25, 6, 7, "USED-FOR"], [30, 30, 25, 25, "USED-FOR"], [30, 30, 27, 27, "USED-FOR"], [27, 27, 6, 7, "USED-FOR"], [32, 32, 27, 27, "USED-FOR"], [18, 18, 13, 14, "USED-FOR"], [30, 30, 25, 25, "USED-FOR"], [30, 30, 27, 27, "USED-FOR"], [30, 30, 25, 25, "USED-FOR"], [30, 30, 27, 27, "USED-FOR"], [18, 18, 13, 14, "USED-FOR"]], [], [[122, 123, 119, 124, "USED-FOR"], [129, 129, 127, 127, "USED-FOR"], [129, 129, 133, 133, "USED-FOR"], [135, 135, 127, 127, "USED-FOR"], [135, 135, 133, 133, "USED-FOR"], [127, 127, 119, 124, "USED-FOR"], [129, 130, 122, 123, "USED-FOR"], [129, 130, 127, 127, "USED-FOR"], [129, 130, 133, 133, "USED-FOR"], [133, 133, 119, 124, "USED-FOR"], [129, 129, 127, 127, "USED-FOR"], [129, 129, 133, 133, "USED-FOR"], [135, 135, 127, 127, "USED-FOR"], [135, 135, 133, 133, "USED-FOR"]], [], []]}
{"doc_key": "2109.10760-3807cb72-4839-4797-98b7-659e5acc082d", "sentences": [["Training", "images", "and", "masks", "are", "obtained", "from", "FFHQ", "dataset", "-LSB-", "9", "-RSB-", "by", "following", "the", "procedure", "as", "described", "in", "Section", "REF", "."], ["We", "choose", "FFHQ", "dataset", "as", "it", "contains", "considerable", "variation", "in", "terms", "of", "age", ",", "ethnicity", ",", "poses", "and", "illumination", "conditions", ",", "and", "it", "has", "good", "coverage", "of", "accessories", "such", "as", "eyeglasses", ",", "sunglasses", "and", "hats", "."], ["We", "obtain", "about", "35,000", "images", "and", "10,000", "masks", "for", "training", ",", "and", "4000", "images", "and", "1000", "masks", "for", "validation", "."], ["Our", "model", "can", "do", "inference", "on", "images", "from", "VoxCeleb", "-LSB-", "14", "-RSB-", ",", "CelebA-HQ", "-LSB-", "8", "-RSB-", ",", "unseen", "faces", "from", "FFHQ", "or", "any", "other", "unconstrained", "faces", "."], ["The", "network", "is", "trained", "using", "256", "\\", "-LRB-", "\\times", "\\", "-RRB-", "256", "images", "with", "a", "batch", "size", "of", "8", "."], ["The", "model", "is", "optimized", "using", "Adam", "optimizer", "-LSB-", "10", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=", "0.0", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=", "0.9", "."], ["All", "generators", "are", "trained", "with", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "discriminators", "are", "trained", "with", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[7, 8, "a"]], [[24, 25, "a"]], [], [], [], [[131, 132, "a"], [143, 143, "v"], [151, 151, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[7, 8, "a"]], [[24, 25, "a"]], [[61, 61, "v"], [64, 64, "v"], [70, 70, "v"], [73, 73, "v"]], [[79, 79, "a"], [86, 86, "a"], [91, 91, "a"], [99, 99, "a"]], [[111, 111, "v"], [117, 117, "v"], [121, 122, "p"], [124, 124, "v"]], [[131, 131, "a"], [143, 143, "v"], [151, 151, "v"]], [[158, 159, "p"], [162, 166, "v"], [174, 175, "p"], [179, 182, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2110.08176-688d1e4c-0954-481d-b601-cce2871f0d55", "sentences": [["Agents", "are", "trained", "using", "a", "distributed", "set", "of", "environments", "running", "in", "parallel", "."], ["Each", "agent", "is", "trained", "using", "one", "GPU", "on", "\\", "-LRB-", "N", "\\times", "200\\", "-RRB-", "environments", ",", "where", "\\", "-LRB-", "N\\", "-RRB-", "is", "the", "number", "of", "agents", "being", "trained", "in", "the", "population", "."], ["Agents", "are", "trained", "for", "\\", "-LRB-", "1", "\\times", "10^9\\", "-RRB-", "environment", "steps", "which", "takes", "between", "three", "and", "eight", "days", "depending", "on", "the", "size", "of", "the", "training", "population", "."], ["As", "the", "environment", "involves", "two", "players", ",", "each", "one", "samples", "with", "replacement", "from", "the", "training", "population", "of", "agents", "every", "episode", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[], [[18, 18, "v"], [23, 23, "p"], [25, 25, "v"]], [[51, 51, "v"], [53, 53, "v"], [60, 60, "v"], [62, 62, "v"]], [[77, 77, "v"], [81, 81, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.02866-3945a970-0331-4879-9575-a163305158b6", "sentences": [["For", "unsupervised", "pretraining", ",", "we", "select", "a", "multi-layer", "convolutional", "network", "as", "the", "encoder", "\\", "-LRB-", "\\phi", "_", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", ",", "and", "we", "select", "a", "two-layer", "transformer", "with", "hidden", "dimension", "256", "as", "the", "sequential", "model", "\\", "-LRB-", "\\psi", "_", "-LCB-", "\\rho", "-RCB-", "\\", "-RRB-", "."], ["Here", ",", "the", "positive", "pair", "is", "\\", "-LRB-", "-LRB-", "h_", "-LCB-", "t+k", "-RCB-", ",", "c_t", "-RRB-", "\\", "-RRB-", "where", "\\", "-LRB-", "k\\", "-RRB-", "is", "the", "number", "of", "time", "steps", "ahead", ",", "and", "the", "negative", "pairs", "are", "\\", "-LRB-", "-LRB-", "h_i", ",", "c_t", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "h_i\\", "-RRB-", "hidden", "representations", "of", "a", "batch", "of", "random", "hidden", "representations", "assumed", "to", "be", "unrelated", "to", "\\", "-LRB-", "c_t\\", "-RRB-", "."], ["The", "scoring", "function", "\\", "-LRB-", "f\\", "-RRB-", "based", "on", "Equation", "-LRB-", "1", "-RRB-", "in", "the", "main", "text", "at", "step", "\\", "-LRB-", "t\\", "-RRB-", "with", "\\", "-LRB-", "k\\", "-RRB-", "steps", "ahead", "is", "\\", "-LRB-", "f_k", "=", "f_k", "-LRB-", "h", ",", "c_t", "-RRB-", "=", "\\exp", "-LRB-", "-LRB-", "h", "-RRB-", "^\\top", "W_k", "c_t", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "W_k\\", "-RRB-", "is", "a", "learnable", "linear", "transformation", "defined", "separately", "for", "each", "\\", "-LRB-", "k\\in", "\\lbrace", "1", ",", "...", ",", "K\\rbrace", "\\", "-RRB-", "and", "\\", "-LRB-", "K\\", "-RRB-", "is", "predetermined", "as", "12", "time", "steps", "."], ["The", "loss", "will", "then", "be", "formulated", "as", ":", "\\", "-LRB-", "\\ell", "^", "-LCB-", "\\mathrm", "-LCB-", "InfoNCE", "-RCB-", "-RCB-", "_", "-LCB-", "t", "-RCB-", "=", "-", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "K", "-RCB-", "\\sum", "_", "-LCB-", "k=1", "-RCB-", "^K", "\\big", "-LSB-", "-LCB-", "\\rm", "log", "-RCB-", "\\frac", "-LCB-", "-LCB-", "\\rm", "exp", "-RCB-", "-LRB-", "f_k", "-LRB-", "h_", "-LCB-", "t+k", "-RCB-", ",", "c_t", "-RRB-", "-RRB-", "-RCB-", "-LCB-", "\\sum", "_", "-LCB-", "h_i\\in", "\\mathcal", "-LCB-", "N", "-RCB-", "-RCB-", "-LCB-", "\\rm", "exp", "-RCB-", "-LRB-", "f_k", "-LRB-", "h_i", ",", "c_t", "-RRB-", "-RRB-", "-RRB-", "-RCB-", "-RSB-", "\\", "-RRB-"]], "ner": [[[7, 9, "a"], [27, 28, "a"]], [[58, 58, "p"], [68, 68, "p"], [72, 76, "v"]], [[143, 143, "p"], [187, 187, "p"], [118, 119, "a"], [165, 165, "p"], [174, 174, "p"]], [[242, 242, "p"], [262, 262, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 9, "a"], [30, 31, "p"], [32, 32, "v"]], [], [[204, 204, "v"]], []], "predicted_relations": [[], [[72, 76, 58, 58, "USED-FOR"], [72, 76, 68, 68, "USED-FOR"]], [[143, 143, 118, 119, "USED-FOR"], [187, 187, 118, 119, "USED-FOR"], [165, 165, 118, 119, "USED-FOR"]], []]}
{"doc_key": "2106.02866-e6484066-6d3a-4b14-918a-06e007672805", "sentences": [["Classifier-based", "method", "use", "\\", "-LRB-", "\\int", "_", "-LCB-", "\\mathcal", "-LCB-", "Z", "-RCB-", "-RCB-", "D_", "-LCB-", "\\mathrm", "-LCB-", "KL", "-RCB-", "-RCB-", "-LRB-", "P_", "-LCB-", "X", ",", "Y", ",", "Z", "-RCB-", "\\Vert", "P_", "-LCB-", "X", ",", "Z", "-RCB-", "P_", "-LCB-", "Y|Z", "-RCB-", "-RRB-", "\\", ",", "-LCB-", "\\rm", "d", "-RCB-", "P_", "-LCB-", "Z", "-RCB-", "\\", "-RRB-", "to", "estimate", "conditional", "mutual", "information", "."], ["To", "be", "specific", ",", "given", "\\", "-LRB-", "n\\", "-RRB-", "i.i.d", "samples", "\\", "-LRB-", "\\left\\lbrace", "x_", "-LCB-", "i", "-RCB-", ",", "y_", "-LCB-", "i", "-RCB-", ",", "z_", "-LCB-", "i", "-RCB-", "\\right\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "n", "-RCB-", ",", "-LRB-", "x_", "-LCB-", "i", "-RCB-", ",", "y_i", ",", "z_i", "-RRB-", "\\sim", "P_", "-LCB-", "X", ",", "Y", ",", "Z", "-RCB-", "\\", "-RRB-", ",", "-LSB-", "28", "-RSB-", "use", "the", "generative", "model", "GAN", "-LSB-", "13", "-RSB-", "to", "model", "the", "conditional", "distribution", "\\", "-LRB-", "P", "-LRB-", "Y|Z", "-RRB-", "\\", "-RRB-", "."], ["For", "notation", "simplicity", ",", "we", "refer", "the", "GAN", "model", "as", "\\", "-LRB-", "\\hat", "-LCB-", "P", "-RCB-", "^", "-LCB-", "\\rm", "GAN", "-RCB-", "-LRB-", "Y|Z", "-RRB-", "\\", "-RRB-", "."], ["Given", "samples", "from", "the", "joint", "distribution", ",", "\\", "-LRB-", "P_", "-LCB-", "X", ",", "Y", ",", "Z", "-RCB-", "\\", "-RRB-", ",", "and", "samples", "from", "\\", "-LRB-", "P_", "-LCB-", "X", ",", "Z", "-RCB-", "\\hat", "-LCB-", "P", "-RCB-", "^", "-LCB-", "\\rm", "GAN", "-RCB-", "_", "-LCB-", "Y|Z", "-RCB-", "\\", "-RRB-", ",", "classifier-based", "method", "labels", "the", "points", "drawn", "from", "\\", "-LRB-", "P_", "-LCB-", "-LRB-", "X", ",", "Y", ",", "Z", "-RRB-", "-RCB-", "\\", "-RRB-", "as", "\\", "-LRB-", "label=1\\", "-RRB-", "and", "the", "points", "from", "\\", "-LRB-", "\\hat", "-LCB-", "P", "-RCB-", "_", "-LCB-", "X", ",", "Z", "-RCB-", "P^", "-LCB-", "\\rm", "GAN", "-RCB-", "_", "-LCB-", "Y|Z", "-RCB-", "\\", "-RRB-", "as", "\\", "-LRB-", "label=0\\", "-RRB-", "."], ["Then", ",", "it", "trains", "a", "binary", "classifier", "for", "predicting", "the", "assigned", "binary", "label", "."], ["Then", "the", "point-wise", "likelihood", "ratio", "\\", "-LRB-", "\\frac", "-LCB-", "p", "-LRB-", "x", ",", "y", ",", "z", "-RRB-", "-RCB-", "-LCB-", "p", "-LRB-", "x", ",", "z", "-RRB-", "p", "-LRB-", "y|z", "-RRB-", "-RCB-", "\\approx", "\\frac", "-LCB-", "p", "-LRB-", "x", ",", "y", ",", "z", "-RRB-", "-RCB-", "-LCB-", "p", "-LRB-", "x", ",", "z", "-RRB-", "p^", "-LCB-", "\\rm", "GAN", "-RCB-", "-LRB-", "y|z", "-RRB-", "-RCB-", "\\", "-RRB-", "of", "each", "data", "point", "\\", "-LRB-", "-LRB-", "x_i", ",", "y_i", ",", "z_i", "-RRB-", "\\", "-RRB-", "can", "be", "calculated", "by", "\\", "-LRB-", "\\frac", "-LCB-", "Pr", "-LRB-", "label=1|", "-LRB-", "x_i", ",", "y_i", ",", "z_i", "-RRB-", "-RRB-", "-RCB-", "-LCB-", "1", "-", "Pr", "-LRB-", "label=1|", "-LRB-", "x_i", ",", "y_i", ",", "z_i", "-RRB-", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "Pr", "-LRB-", "label=1|", "-LRB-", "x_i", ",", "y_i", ",", "z_i", "-RRB-", "\\", "-RRB-", "is", "the", "predicted", "probability", "of", "data", "point", "has", "\\", "-LRB-", "label=1\\", "-RRB-", "from", "the", "classifier", "."], ["Using", "the", "point-wise", "likelihood", ",", "we", "can", "obtain", "\\", "-LRB-", "\\int", "_", "-LCB-", "\\mathcal", "-LCB-", "Z", "-RCB-", "-RCB-", "D_", "-LCB-", "\\mathrm", "-LCB-", "KL", "-RCB-", "-RCB-", "-LRB-", "P_", "-LCB-", "X", ",", "Y", ",", "Z", "-RCB-", "\\Vert", "P_", "-LCB-", "X", ",", "Z", "-RCB-", "P_", "-LCB-", "Y|Z", "-RCB-", "-RRB-", "-LCB-", "\\rm", "d", "-RCB-", "P_Z\\", "-RRB-", "by", "plugging", "the", "point-wise", "likelihood", "into", "a", "lower", "bound", "of", "KL-divergence", "."], ["Further", "discussions", "of", "this", "classifier-based", "estimation", "method", "is", "out", "of", "the", "scope", "of", "our", "discussion", ",", "and", "readers", "could", "refer", "to", "-LSB-", "28", "-RSB-", "for", "more", "details", "."]], "ner": [[[0, 1, "a"]], [[126, 126, "a"]], [[151, 151, "a"], [163, 163, "a"]], [[209, 209, "a"], [263, 263, "a"]], [], [[343, 343, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[126, 126, "a"]], [[151, 152, "a"]], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2110.13705-095094c9-6b9f-408e-982a-6e643b318bc2", "sentences": [["IHDP", ":", "This", "data", "is", "constructed", "from", "the", "Infant", "Health", "and", "Development", "Program", "-LRB-", "IHDP", "-RRB-", "."], ["There", "are", "100", "files", "in", "which", "each", "file", "contains", "747", "subjectsThe", "IHDP", "data", "set", "is", "available", "at", "https", ":", "//github.com/Osier-Yi/SITE/tree/master/data", "."], ["Both", "factual", "and", "counterfactual", "are", "provided", "for", "each", "subject", ",", "which", "provides", "a", "ground", "truth", "for", "evaluating", "causal", "inference", "algorithms", "."]], "ner": [[[0, 0, "a"], [14, 14, "a"]], [[28, 28, "a"]], []], "relations": [[], [], []], "predicted_ner": [[], [[19, 19, "v"], [26, 26, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2110.13705-8a06af84-482c-4269-8bd2-b3dd6b05a10b", "sentences": [["Twins", ":", "This", "data", "is", "a", "benchmark", "task", "that", "utilizes", "data", "from", "twin", "births", "in", "the", "USA", "between", "1989-1991", "."], ["There", "are", "11399", "subjects", "in", "this", "dataThe", "Twins", "data", "set", "is", "available", "at", "https", ":", "//github.com/jsyoon0823/GANITE/tree/master/data", "or", "https", ":", "//github.com/AMLab-Amsterdam/CEVAE/tree/master/", "datasets/TWINS", ".."], ["The", "samples", "in", "the", "data", "set", "are", "all", "twins", ",", "\\", "-LRB-", "t", "=", "1\\", "-RRB-", "represents", "the", "heavier", "baby", ",", "and", "the", "outcome", "\\", "-LRB-", "Y\\", "-RRB-", "corresponds", "to", "the", "mortality", "of", "each", "of", "the", "twins", "in", "their", "first", "year", "of", "life", "."]], "ner": [[[0, 0, "a"]], [[27, 27, "a"]], []], "relations": [[], [], []], "predicted_ner": [[], [[22, 22, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2110.13705-9c40d441-36aa-4dde-a16f-74de2f303b34", "sentences": [["ACIC", ":", "This", "data", "is", "a", "collection", "of", "semi-synthetic", "datasets", "derived", "from", "the", "linked", "birth", "and", "infant", "death", "data", "-LRB-", "LBIDD", "-RRB-", "-LSB-", "18", "-RSB-", "."], ["It", "was", "developed", "for", "the", "2018", "Atlantic", "Causal", "Inference", "Conference", "competition", "-LRB-", "ACIC", "-RRB-", "We", "use", "the", "scaling", "folder", "in", "ACIC", "to", "evaluate", "our", "methods", "."], ["The", "ACIC", "data", "set", "is", "available", "at", "https", ":", "//github.com/IBM-HRL-MLHLS/IBM-Causal-Inference-Benchmarking-Framework/tree/master/data/LBIDD.", ",", "which", "include", "30", "different", "data", "generating", "process", "settings", "with", "subject", "sample", "sizes", "from", "1,000", "to", "50,000", "."]], "ner": [[[0, 0, "a"], [20, 20, "a"]], [[38, 38, "a"], [46, 46, "a"]], [[53, 53, "a"], [61, 61, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"]], [[46, 46, "a"]], [[53, 53, "a"], [65, 65, "v"], [76, 76, "v"], [78, 78, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2110.13705-6d5b7d4c-3799-480f-a315-ac5115f8f481", "sentences": [["To", "train", "CEVIB", ",", "we", "use", "the", "architecture", "in", "Figure", "REF", "."], ["For", "both", "IHDP", "and", "ACIC", "experiments", ",", "we", "randomly", "split", "each", "file", "data", "into", "test/validation/train", "with", "proportion", "63/27/10", "and", "report", "the", "In", "SampleIn", "Sample", "uses", "all", "observational", "data", "for", "both", "training", "and", "prediction", "."], ["and", "Out", "of", "SampleOut", "of", "Sample", "uses", "the", "training", "set", "to", "train", "and", "the", "test", "set", "for", "prediction", "."], ["errors", ",", "and", "repeat", "the", "procedure", "for", "25", "times", "."], ["For", "Twins", "experiments", ",", "we", "randomly", "split", "the", "data", "into", "test/validation/train", "with", "proportion", "56/24/20", "and", "report", "the", "In", "Sample", "and", "Out", "of", "Sample", "errors", ",", "and", "repeat", "the", "procedure", "for", "50", "times", "."]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[16, 16, "a"]], [], [[72, 72, "v"]], [[105, 105, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2110.13864-f9ab9750-83e9-43a7-8bd6-9d20748badc3", "sentences": [["where", "\\", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "W", "-RCB-", "-RCB-", "_", "-LCB-", "t", ",", "I", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-LRB-", "\\alpha", "=1", "-RRB-", "\\", "-RRB-", "indicates", "that", "\\", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "W", "-RCB-", "-RCB-", "_", "-LCB-", "t", ",", "I", "-RCB-", "^", "-LCB-", "k", "-RCB-", "\\", "-RRB-", "is", "trained", "using", "Equation", "REF", "with", "setting", "\\", "-LRB-", "\\alpha", "=1\\", "-RRB-", "-LRB-", "i.e.", ",", "the", "\\", "-LRB-", "k\\", "-RRB-", "-th", "device", "is", "benign", "-RRB-", "."], ["A", "special", "case", "is", "\\", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "W", "-RCB-", "-RCB-", "_t", "-LRB-", "-LCB-", "\\mathbb", "-LCB-", "S", "-RCB-", "-RCB-", "\\setminus", "-LCB-", "\\mathbb", "-LCB-", "M", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "which", "means", "the", "global", "model", "is", "optimized", "when", "all", "the", "malicious", "devices", "do", "not", "conduct", "attacks", "before", "the", "\\", "-LRB-", "t\\", "-RRB-", "-th", "round", "."], ["To", "quantify", "the", "attack", "effect", "on", "the", "global", "model", ",", "we", "define", "the", "Attack", "Effect", "on", "Parameter", "-LRB-", "AEP", "-RRB-", "as", "follows", ":"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "2110.04866-84169b63-7b56-4332-abd3-f7544b443b75", "sentences": [["For", "all", "experiments", ",", "we", "train", "CoRGi", "with", "Adam", "-LSB-", "17", "-RSB-", "and", "a", "learning", "rate", "of", "0.001", "."], ["We", "employ", "early", "stopping", "on", "validation", "loss", ",", "with", "train", ",", "test", ",", "and", "validation", "sets", "split", "in", "8:1:1", "ratio", "."], ["We", "use", "binary", "cross", "entropy", "loss", "-LRB-", "BCE", "-RRB-", "for", "binary", "values", "and", "mean", "squared", "error", "-LRB-", "MSE", "-RRB-", "for", "ordinal", "values", "."], ["We", "apply", "dropout", "-LSB-", "41", "-RSB-", "on", "the", "message", "passing", "layers", ",", "the", "prediction", "MLPs", ",", "as", "well", "as", "on", "edges", ",", "with", "rates", "chosen", "from", "\\", "-LRB-", "\\lbrace", "\\", "-RRB-", "0.1", ",", "0.3", ",", "0.5", ",", "0.7\\", "-LRB-", "\\rbrace", "\\", "-RRB-", "with", "respect", "to", "the", "validation", "set", "performance", "."], ["For", "the", "baselines", ",", "the", "parameter", "settings", "are", "done", "in", "the", "following", "manner", ":", "1", "-RRB-", "When", "the", "settings", "of", "the", "comparison", "models", "overlap", "with", "CoRGi", "'s", ",", "e.g.", ",", "the", "number", "of", "message", "passing", "layers", "or", "the", "learning", "rate", ",", "we", "used", "the", "same", "configurations", "as", "CoRGi", "."], ["2", "-RRB-", "For", "the", "parameter", "settings", "that", "are", "unique", "to", "the", "comparison", "model", ",", "we", "followed", "the", "setting", "that", "is", "disclosed", "in", "the", "original", "paper", "."], ["3", "-RRB-", "When", "the", "setting", "disclosed", "in", "the", "original", "paper", "is", "not", "applicable", "to", "the", "datasets", "used", "or", "our", "training", "environment", ",", "we", "select", "those", "that", "yield", "the", "best", "validation", "performance", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[8, 8, "a"], [14, 15, "p"], [17, 17, "v"], [15, 15, "p"]], [[21, 22, "a"]], [[42, 45, "a"], [53, 55, "a"]], [[65, 65, "a"], [94, 94, "v"], [96, 96, "v"], [98, 98, "v"], [100, 100, "v"]], [[151, 152, "p"], [152, 152, "p"]], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "a"], [14, 15, "p"], [17, 17, "v"]], [[21, 22, "a"], [24, 25, "a"]], [[42, 48, "a"]], [[65, 65, "a"], [94, 94, "v"]], [[138, 138, "a"], [151, 152, "p"], [160, 160, "a"]], [], [], []], "predicted_relations": [[[14, 15, 8, 8, "USED-FOR"], [15, 15, 8, 8, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2103.15396-df0ed6d3-0085-407a-a747-0ac63ee3183d", "sentences": [["After", "solving", "the", "challenge", "of", "data", ",", "we", "train", "a", "model", "based", "on", "PCN", "-LSB-", "43", "-RSB-", "."], ["Concretely", ",", "we", "use", "Adam", "-LSB-", "13", "-RSB-", "optimizer", "with", "a", "starting", "learning", "rate", "at", "0.0001", ",", "which", "decays", "by", "0.7", "in", "every", "50,000", "iterations", "."], ["We", "train", "the", "model", "on", "one", "NVIDIA", "TITAN", "XP", "GPU", "with", "batch", "size", "32", "for", "300,000", "iterations", "."], ["Furthermore", ",", "due", "to", "the", "limitation", "of", "GPU", "memory", ",", "we", "remove", "the", "detailed", "output", "branch", "after", "the", "model", "is", "trained", "."], ["Finally", ",", "we", "initialize", "our", "spatial", "shape", "prediction", "network", "with", "the", "saved", "weights", "."]], "ner": [[[13, 13, "a"]], [[22, 22, "a"], [30, 31, "p"], [33, 33, "v"]], [[50, 53, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[10, 10, "a"], [13, 13, "a"]], [[22, 22, "a"], [30, 31, "p"], [33, 33, "v"], [38, 38, "v"], [41, 41, "v"]], [[49, 49, "v"], [55, 56, "p"], [57, 57, "v"], [59, 59, "v"]], [], [[89, 92, "a"]]], "predicted_relations": [[], [[30, 31, 22, 22, "USED-FOR"], [33, 33, 30, 31, "USED-FOR"]], [], [], []]}
{"doc_key": "2101.04109-bfe22b7f-9fe4-47bb-895b-b60b05448688", "sentences": [["All", "experiments", "are", "conducted", "on", "an", "Nvidia", "32GB", "V100", "using", "the", "PyTorch", "and", "Tensorflow", "framework", "."], ["We", "consider", "\\", "-LRB-", "\\textsc", "-LCB-", "Bert", "-RCB-", "_\\textrm", "-LCB-", "Base", "-RCB-", "-LCB-", "-RCB-", "\\", "-RRB-", "as", "the", "shared", "encoder", "model", "with", "\\", "-LRB-", "\\textrm", "-LCB-", "MAX\\_SEQ\\_LEN", "-RCB-", "=512\\", "-RRB-", "and", "the", "warm-up", "proportion", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["Both", "the", "explanation", "generation", "and", "task", "prediction", "models", "are", "trained", "using", "Adam", "optimizer", "-LSB-", "14", "-RSB-", "with", "a", "batch", "size", "of", "16", ",", "and", "\\", "-LRB-", "\\textrm", "-LCB-", "learning\\_rate", "-RCB-", "=1e-5\\", "-RRB-", "."], ["Models", "are", "trained", "for", "10", "epochs", "with", "early-stopping", "criteria", "on", "the", "validation", "set", "and", "\\", "-LRB-", "\\textrm", "-LCB-", "patience", "-RCB-", "=3\\", "-RRB-", "."], ["The", "MLP", "for", "the", "task", "classification", "consists", "of", "a", "dropout", "layer", "with", "a", "10", "%", "chance", "of", "masking", ",", "followed", "by", "a", "256", "dimensional", "hidden", "dense", "layer", ",", "again", "followed", "by", "a", "Sigmoid", "output", "layer", "."], ["The", "explanation", "decoder", "consists", "of", "a", "128-dimensional", "GRU", "with", "a", "uniform", "random", "kernel", "analyzer", "."], ["Note", "that", "the", "final", "outputs", "of", "the", "explanation", "generator", "correspond", "to", "the", "sub-token", "representations", "of", "Bert", "."], ["Adjacent", "sub-tokens", "are", "merged", "to", "their", "corresponding", "original", "words", "through", "max-pooling", "."], ["The", "best", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "chosen", "over", "a", "validation", "set", "that", "provides", "the", "best", "trade-off", "between", "task", "performance", "and", "token-F1", "."], ["The", "best", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "values", "for", "Movie", "Reviews", ",", "MultiRC", ",", "FEVER", "are", "\\", "-LRB-", "5.0", ",", "20.0", ",", "2.0\\", "-RRB-", "respectively", "."], ["After", "training", "the", "explanation", "generation", "network", "in", "ExPred", ",", "we", "remove", "instances", "that", "the", "auxiliary", "output", "predicts", "wrongly", ",", "and", "use", "the", "rest", "to", "train", "the", "prediction", "model", "."], ["This", "is", "to", "avoid", "distraction", "from", "the", "wrong", "predictions", "from", "the", "explanation", "prediction", "phase", "."], ["Note", "that", "this", "is", "only", "done", "during", "training", ",", "while", "the", "predictions", "on", "the", "validation", "and", "test", "sets", "are", "regardless", "of", "the", "task", "prediction", "from", "the", "explanation", "phase", "."]], "ner": [[], [[44, 44, "v"], [48, 49, "p"], [52, 52, "v"]], [[66, 67, "a"], [73, 74, "p"], [76, 76, "v"], [85, 85, "v"]], [[106, 106, "p"], [108, 108, "v"]], [[112, 112, "a"], [120, 121, "p"], [126, 128, "c"]], [[154, 154, "p"], [153, 153, "v"]], [], [[189, 189, "a"]], [[195, 195, "a"]], [[219, 219, "a"], [224, 225, "p"], [233, 233, "v"], [227, 227, "p"], [235, 235, "v"], [229, 229, "p"], [237, 237, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"]], [[44, 44, "v"], [52, 52, "v"]], [[66, 66, "a"], [73, 74, "p"], [76, 76, "v"]], [[92, 92, "v"], [93, 93, "p"]], [[112, 112, "a"], [124, 125, "v"], [133, 134, "v"], [143, 143, "a"]], [[153, 153, "v"], [154, 154, "a"]], [[177, 177, "a"]], [[189, 189, "a"]], [], [[219, 220, "p"], [227, 227, "a"], [233, 233, "v"], [235, 235, "v"], [237, 237, "v"]], [], [], []], "predicted_relations": [[], [[44, 44, 48, 49, "USED-FOR"], [52, 52, 48, 49, "USED-FOR"]], [[73, 74, 66, 67, "USED-FOR"]], [[108, 108, 106, 106, "USED-FOR"]], [[120, 121, 112, 112, "USED-FOR"]], [[153, 153, 154, 154, "USED-FOR"]], [], [], [], [[224, 225, 219, 219, "USED-FOR"], [233, 233, 229, 229, "USED-FOR"], [227, 227, 219, 219, "USED-FOR"], [235, 235, 229, 229, "USED-FOR"], [229, 229, 219, 219, "USED-FOR"]], [], [], []]}
{"doc_key": "2101.04279-fa7f2b29-7ec2-46be-b39d-bc119043b831", "sentences": [["During", "training", ",", "we", "random", "crop", "patches", "of", "size", "-LSB-", "224", ",", "224", "-RSB-", "from", "the", "images", "and", "the", "batchsize", "is", "set", "to", "16", "."], ["The", "parameters", "of", "the", "IFNet", "are", "initialized", "by", "Xavier", "-LSB-", "9", "-RSB-", "."], ["Adam", "-LSB-", "12", "-RSB-", "optimizer", "with", "the", "learning", "rate", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "is", "used", "to", "train", "our", "model", "and", "the", "learning", "rate", "is", "halved", "every", "1000", "epochs", "."], ["We", "random", "flip", "images", "horizontally", "and", "scale", "brightness", "and", "saturation", "for", "data", "augmentation", "."], ["When", "inference", ",", "image", "will", "be", "fed", "into", "our", "model", "directly", "."]], "ner": [[], [[29, 29, "a"], [33, 33, "a"]], [[45, 46, "p"], [65, 66, "p"], [38, 38, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[19, 19, "p"], [23, 23, "v"]], [[29, 29, "a"], [33, 33, "a"]], [[38, 38, "a"], [45, 46, "p"], [51, 53, "v"], [62, 62, "a"], [65, 66, "p"], [70, 70, "v"], [71, 71, "p"]], [], []], "predicted_relations": [[], [], [[45, 46, 38, 38, "USED-FOR"]], [], []]}
{"doc_key": "2112.03615-a97d1cea-fb05-492f-805d-ed7f78cb3e62", "sentences": [["We", "run", "our", "training", "algorithm", "for", "50", "epochs", "on", "MNIST", "and", "F-MNIST", "and", "200", "epochs", "on", "CIFAR-10", ",", "using", "the", "Adam", "optimizer", "-LSB-", "19", "-RSB-", ",", "a", "learning", "rate", "of", "0.001", ",", "weight", "decay", "of", "0.0001", ",", "and", "batch-sizes", "of", "128", "."], ["We", "use", "no", "data", "augmentation", "on", "MNIST", "and", "F-MNIST", "and", "use", "normalization", ",", "random", "cropping", ",", "and", "flipping", "on", "CIFAR-10", "."], ["In", "all", "of", "our", "experiments", ",", "we", "use", "86", "%", "of", "the", "data", "for", "training", "and", "14", "%", "for", "testing.In", "the", "implemented", "regularizers", "from", "prior", "work", ",", "we", "used", "the", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "that", "was", "suggested", "by", "the", "respective", "authors", "."], ["While", "we", "found", "out", "that", "the", "strength", "of", "the", "SMD", "regularizer", "-LRB-", "also", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "-RRB-", "in", "the", "range", "\\", "-LRB-", "-LSB-", "0.5", ",", "2", "-RSB-", "\\", "-RRB-", "gives", "good", "results", "."], ["Thus", "in", "all", "of", "our", "experiments", ",", "we", "take", "\\", "-LRB-", "\\lambda", "=1\\", "-RRB-", "."], ["We", "report", "all", "the", "results", "as", "an", "average", "over", "5", "independent", "trials", "-LRB-", "we", "include", "the", "standard", "deviations", "in", "the", "Appendix", "A", "-RRB-", "."], ["We", "report", "results", "for", "the", "ensembles", "of", "3", "members", "in", "the", "main", "paper", ",", "and", "for", "5", "and", "8", "in", "the", "Appendix", "C", "."]], "ner": [[[20, 21, "a"], [27, 28, "p"], [30, 30, "v"], [32, 33, "p"], [35, 35, "v"], [38, 38, "a"]], [[45, 46, "a"], [53, 53, "a"], [55, 56, "a"], [59, 59, "a"]], [[95, 95, "p"]], [[115, 116, "a"], [121, 121, "p"]], [[152, 152, "p"], [153, 153, "v"], [142, 146, "c"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [7, 7, "p"], [9, 9, "a"], [11, 11, "a"], [13, 13, "v"], [14, 14, "p"], [16, 16, "a"], [20, 20, "a"], [27, 28, "p"], [30, 30, "v"], [32, 33, "p"], [35, 35, "v"], [38, 38, "p"], [40, 40, "v"]], [[48, 48, "a"], [50, 50, "a"], [61, 61, "a"]], [[71, 72, "v"], [79, 80, "v"], [95, 95, "p"]], [[121, 121, "p"], [131, 131, "v"], [133, 133, "v"]], [[152, 152, "p"], [153, 153, "v"]], [[165, 165, "v"]], [[187, 187, "v"], [196, 196, "v"], [198, 198, "v"]]], "predicted_relations": [[[27, 28, 20, 21, "USED-FOR"], [30, 30, 32, 33, "USED-FOR"], [32, 33, 20, 21, "USED-FOR"], [35, 35, 32, 33, "USED-FOR"]], [], [], [[121, 121, 115, 116, "USED-FOR"]], [[153, 153, 152, 152, "USED-FOR"], [142, 146, 153, 153, "USED-FOR"]], [], []]}
{"doc_key": "2112.03615-109e1fcf-c2b0-4db3-a33d-7f2b7b5af195", "sentences": [["In", "the", "setting", "of", "adversarial", "training", ",", "we", "follow", "the", "EAT", "approach", "-LSB-", "41", "-RSB-", "by", "creating", "adversarial", "examples", "on", "3", "holdout", "pre-trained", "ensembles", "with", "the", "same", "size", "and", "architecture", "as", "the", "baseline", "ensemble", "."], ["The", "examples", "are", "created", "via", "PGD-\\", "-LRB-", "L_\\infty", "\\", "-RRB-", "attack", "with", "10", "steps", "and", "\\", "-LRB-", "\\epsilon", "=0.1\\", "-RRB-", "."]], "ner": [[[10, 11, "a"]], [[48, 48, "p"], [47, 47, "v"], [53, 53, "v"]]], "relations": [[], []], "predicted_ner": [[[10, 11, "a"], [20, 20, "v"]], [[47, 47, "v"]]], "predicted_relations": [[], [[47, 47, 48, 48, "USED-FOR"]]]}
{"doc_key": "2112.03555-f193a1e8-16f8-4e9a-8b44-2c20ce986eb0", "sentences": [["The", "CGL", "part", "in", "each", "local", "model", "is", "parameterized", "by", "a", "\\", "-LRB-", "d\\times", "d\\", "-RRB-", "matrix", "named", "\\", "-LRB-", "\\mathbf", "-LCB-", "U", "-RCB-", "\\", "-RRB-", "and", "the", "Gumbel-Sigmoid", "approach", "is", "leveraged", "for", "approximating", "the", "binary", "form", "."], ["Each", "entry", "in", "\\", "-LRB-", "\\mathbf", "-LCB-", "U", "-RCB-", "\\", "-RRB-", "is", "initialized", "as", "0", "."], ["The", "temperature", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "0.2\\", "-RRB-", "for", "all", "settings", "."], ["Then", ",", "for", "the", "causal", "mechanism", "approximation", "part", ",", "we", "use", "4", "dense", "layers", "with", "16", "variables", "in", "each", "hidden", "layer", "."], ["All", "weights", "in", "the", "Network", "are", "initialized", "using", "the", "Xavier", "uniform", "initialization", "."]], "ner": [[[1, 2, "a"], [28, 29, "a"]], [[52, 52, "v"]], [[66, 66, "v"], [55, 55, "p"], [66, 66, "v"]], [[76, 79, "a"]], [[103, 105, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[28, 29, "a"]], [[52, 52, "v"]], [[66, 66, "v"]], [[83, 83, "v"], [87, 87, "v"]], [[103, 103, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2103.05930-f5045a82-c68a-4547-bbd0-94528449df84", "sentences": [["We", "train", "the", "network", "using", "standard", "SGD", "-LSB-", "13", "-RSB-", "."], ["The", "mini-batch", "size", "is", "set", "to", "16", "and", "32", "for", "Cityscapes", "and", "ADE20K", "respectively", "."], ["And", "we", "use", "the", "momentum", "of", "0.9", "and", "a", "weight", "decay", "of", "\\", "-LRB-", "5e^", "-LCB-", "-LRB-", "-4", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["Similar", "to", "other", "works", "-LSB-", "1", "-RSB-", ",", "-LSB-", "31", "-RSB-", ",", "we", "apply", "the", "`", "poly", "'", "learning", "rate", "policy", "in", "which", "the", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "1e^", "-LCB-", "-LRB-", "-2", "-RRB-", "-RCB-", "\\", "-RRB-", "and", "decayed", "by", "\\", "-LRB-", "-LRB-", "1-\\frac", "-LCB-", "iter", "-RCB-", "-LCB-", "max_iter", "-RCB-", "-RRB-", "^", "-LCB-", "power", "-RCB-", "\\", "-RRB-", "with", "power=0.9", "."], ["The", "training", "images", "are", "augmented", "by", "employing", "random", "color", "jittering", ",", "random", "horizontal", "flipping", ",", "random", "cropping", ",", "and", "random", "scaling", "with", "5", "scales", "-LCB-", "0.75", ",", "1.0", ",", "1.5", ",", "1.75", ",", "2.0", "-RCB-", "."], ["For", "Cityscapes", ",", "images", "are", "cropped", "into", "size", "of", "\\", "-LRB-", "1024\\times", "1024\\", "-RRB-", ",", "and", "the", "network", "is", "trained", "with", "200k", "iterations", "."], ["For", "ADE20K", ",", "crop", "size", "of", "\\", "-LRB-", "512\\times", "512\\", "-RRB-", "and", "250K", "training", "iterations", "are", "used", "for", "training", "."]], "ner": [[[6, 6, "a"]], [[12, 13, "p"], [17, 17, "v"], [21, 21, "c"], [19, 19, "v"], [23, 23, "c"], [21, 21, "c"], [23, 23, "c"], [21, 21, "c"], [23, 23, "c"]], [[30, 30, "p"], [32, 32, "v"], [35, 36, "p"], [36, 36, "p"]], [[110, 110, "v"], [67, 68, "p"], [74, 75, "p"], [110, 110, "v"], [65, 65, "a"]], [[119, 121, "v"], [123, 125, "v"], [127, 128, "v"]], [[149, 149, "c"], [149, 149, "c"], [169, 169, "v"], [149, 149, "c"]], [[173, 173, "c"], [175, 176, "p"], [173, 173, "c"], [185, 186, "p"], [173, 173, "c"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [6, 6, "a"]], [[12, 13, "p"], [17, 17, "v"], [19, 19, "v"], [23, 23, "a"]], [[30, 30, "p"], [32, 32, "v"], [35, 36, "p"]], [[74, 75, "p"], [81, 84, "v"]], [[134, 134, "v"], [137, 137, "v"], [139, 139, "v"], [141, 141, "v"], [143, 143, "v"], [145, 145, "v"]], [[160, 160, "v"], [169, 169, "v"]], [[173, 173, "a"], [181, 181, "v"], [184, 184, "v"]]], "predicted_relations": [[], [], [], [[67, 68, 65, 65, "USED-FOR"], [74, 75, 65, 65, "USED-FOR"]], [], [[149, 149, 169, 169, "USED-FOR"], [149, 149, 169, 169, "USED-FOR"], [149, 149, 169, 169, "USED-FOR"]], []]}
{"doc_key": "2111.03184-f742b50f-ceb7-462c-94b5-f0b29773255f", "sentences": [["During", "each", "SDMM", "step", ",", "the", "dense", "input", "is", "stored", "in", "on-chip", "LUT", "RAM", ",", "where", "multiple", "rows", "would", "be", "stored", "on", "the", "same", "slice", "of", "memory", "in", "order", "to", "fully", "utilize", "it", "."], ["The", "limitation", "where", "only", "a", "single", "row", "can", "be", "read", "from", "each", "LUT", "RAM", "slice", "at", "a", "time", "induces", "data", "collision", "when", "multiple", "reads", "are", "needed", "for", "a", "same", "RAM", "slice", "and", "at", "a", "same", "time", "."], ["As", "explained", "in", "Section", "REF", ",", "both", "data", "replication", "and", "row", "grouping", "can", "effectively", "reduce", "data", "collision", "."], ["The", "less", "data", "collision", "will", "in", "return", "results", "in", "smaller", "latency", "of", "computing", "SDMM", "."], ["On", "the", "other", "hand", ",", "due", "to", "the", "irregular", "nature", "of", "graph", "adjacency", "matrices", ",", "individual", "rows", "have", "very", "different", "sparsity", "which", "results", "in", "PE", "imbalance", ",", "we", "statistically", "minimize", "this", "effect", "by", "utilizing", "larger", "tiles", "."], ["As", "GCN", "has", "the", "hidden", "size", "of", "16", ",", "we", "set", "each", "PE", "to", "have", "16", "multiply-accumulators", "and", "have", "the", "fixed", "relationship", "between", "tile", "size", "\\", "-LRB-", "T\\", "-RRB-", "and", "row", "grouping", "\\", "-LRB-", "g\\", "-RRB-", "that", "\\", "-LRB-", "T=16g\\", "-RRB-", "."], ["Therefore", ",", "we", "evaluate", "the", "impact", "of", "latency", "from", "dense", "data", "replication", "\\", "-LRB-", "r\\", "-RRB-", "and", "tile", "size", "\\", "-LRB-", "T\\", "-RRB-", ",", "as", "shown", "in", "Fig", "."], ["REF", "."], ["We", "can", "see", "that", "the", "latency", "of", "computing", "is", "decreased", "by", "more", "dense", "data", "replications", "as", "well", "as", "larger", "tile", "sizes", "."], ["At", "8", "replicas", ",", "LW-GCN", "'s", "SDMM", "latency", "is", "reduced", "by", "up", "to", "44.23", "%", "-LRB-", "on", "PubMed", "-RRB-", "compared", "to", "1", "replica", "under", "the", "same", "512-row", "tile", "setup", "."], ["At", "4096-row", "tiles", ",", "SDMM", "latency", "is", "reduced", "by", "up", "to", "61.83", "%", "-LRB-", "on", "PubMed", "-RRB-", "with", "the", "same", "replication", "setup", "."], ["The", "ideal", "cases", "in", "Fig", "."], ["REF", "is", "estimated", "by", "summing", "up", "the", "total", "amount", "of", "workload", ",", "and", "assuming", "every", "PE", "is", "fully", "utilized", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [[102, 102, "a"]], [], [[142, 142, "a"], [148, 148, "v"], [156, 156, "v"], [168, 168, "p"]], [[204, 204, "p"]], [], [], [[237, 237, "v"], [240, 240, "a"], [249, 250, "v"], [257, 257, "v"], [262, 262, "v"]], [[277, 278, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2106.06130-2f014343-0eaf-4d42-9cad-68c870981ea4", "sentences": [["Datasets", "."], ["We", "use", "20", "million", "unlabelled", "molecules", "sampled", "from", "Zinc15", "-LSB-", "45", "-RSB-", ",", "a", "public", "access", "database", "that", "contains", "purchasable", "\u201c", "drug-like", "\u201d", "compounds", ",", "to", "pre-train", "GeoGNN", "."], ["We", "randomly", "sample", "90", "%", "of", "the", "molecules", "for", "training", "and", "the", "remaining", "for", "evaluation", "."]], "ner": [[], [[10, 10, "a"]], []], "relations": [[], [], []], "predicted_ner": [[], [[4, 5, "v"], [10, 10, "a"], [29, 29, "a"]], [[34, 35, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2103.07098-59379640-6217-4ce6-a6c7-729782a81922", "sentences": [["As", "the", "dataset", "in", "not", "balanced", ",", "F1-Macro", "is", "used", "to", "compare", "the", "models", "as", "in", "many", "prior", "stance", "studies", "-LSB-", "19", "-RSB-", ",", "-LSB-", "15", "-RSB-", "."], ["For", "co-training", ",", "we", "have", "five", "hyper", "parameters", "namely", ":", "1", "-RRB-", "\\", "-LRB-", "\\theta", "_u\\", "-RRB-", ",", "2", "-RRB-", "\\", "-LRB-", "\\theta", "^T\\", "-RRB-", ",", "3", "-RRB-", "K", "-LRB-", "mixing", "parameter", "-RRB-", ",", "4", "-RRB-", "k", "-LRB-", "most", "used", "hashtags", "-RRB-", ",", "and", ",", "5", "-RRB-", "p", "-LRB-", "popular", "retweets", "count", "-RRB-", "."], ["The", "values", "of", "these", "parameters", "are", "determined", "by", "trials", "on", "one", "of", "the", "datasets", "-LRB-", "Student", "Marches", "-RRB-", "."], ["By", "a", "uniform", "grid", "search", "on", "SM", "dataset", "using", "F1-macro", "as", "criterion", ",", "we", "find", "the", "following", "values", "that", "work", "well", ":", "\\", "-LRB-", "k=250\\", "-RRB-", ",", "\\", "-LRB-", "p=1000\\", "-RRB-", ",", "\\", "-LRB-", "\\theta", "_u", "=", "0.7", ",", "\\theta", "^T", "=", "0.7", ",", "K", "=", "0.2\\", "-RRB-", "."], ["For", "\\", "-LRB-", "k\\", "-RRB-", "and", "\\", "-LRB-", "p\\", "-RRB-", ",", "the", "parameter", "search", "range", "was", "100", "to", "10,000", "."], ["For", "\\", "-LRB-", "\\theta", "_u\\", "-RRB-", ",", "\\", "-LRB-", "\\theta", "^T\\", "-RRB-", "and", "\\", "-LRB-", "K\\", "-RRB-", ",", "the", "search", "range", "was", "0", "to", "1", "."], ["Five", "iterations", "of", "co-training", "was", "used", "as", "the", "classifiers", "appear", "to", "converge", "after", "four", "iterations", "."]], "ner": [[[7, 7, "a"]], [[29, 29, "a"], [56, 56, "p"], [64, 64, "p"], [75, 75, "p"]], [], [[138, 138, "v"], [143, 143, "v"], [107, 108, "c"], [138, 138, "v"], [143, 143, "v"], [107, 108, "c"], [145, 145, "p"], [147, 147, "v"], [107, 108, "c"], [125, 125, "p"], [125, 125, "v"], [107, 108, "c"], [130, 130, "p"], [130, 130, "v"], [107, 108, "c"]], [[153, 153, "p"], [158, 158, "p"]], [[185, 185, "p"]], [[199, 199, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"]], [[33, 33, "v"], [56, 56, "p"], [58, 59, "p"], [64, 64, "p"], [75, 75, "p"]], [[92, 92, "v"]], [[107, 108, "a"], [125, 125, "v"], [130, 130, "v"], [138, 138, "v"], [143, 143, "v"], [145, 145, "p"], [147, 147, "v"]], [[153, 153, "p"], [158, 158, "p"], [166, 166, "v"], [168, 168, "v"]], [[185, 185, "p"], [192, 192, "v"], [194, 194, "v"]], [[196, 196, "v"], [209, 209, "v"]]], "predicted_relations": [[], [[56, 56, 29, 29, "USED-FOR"], [64, 64, 29, 29, "USED-FOR"], [75, 75, 29, 29, "USED-FOR"]], [], [[138, 138, 145, 145, "USED-FOR"], [138, 138, 125, 125, "USED-FOR"], [138, 138, 130, 130, "USED-FOR"], [143, 143, 145, 145, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 147, 147, "USED-FOR"], [107, 108, 125, 125, "USED-FOR"], [107, 108, 130, 130, "USED-FOR"], [138, 138, 145, 145, "USED-FOR"], [138, 138, 125, 125, "USED-FOR"], [138, 138, 130, 130, "USED-FOR"], [143, 143, 145, 145, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 147, 147, "USED-FOR"], [107, 108, 125, 125, "USED-FOR"], [107, 108, 130, 130, "USED-FOR"], [147, 147, 145, 145, "USED-FOR"], [147, 147, 130, 130, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 147, 147, "USED-FOR"], [107, 108, 125, 125, "USED-FOR"], [107, 108, 130, 130, "USED-FOR"], [125, 125, 125, 125, "USED-FOR"], [125, 125, 125, 125, "USED-FOR"], [125, 125, 130, 130, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 147, 147, "USED-FOR"], [107, 108, 125, 125, "USED-FOR"], [107, 108, 130, 130, "USED-FOR"], [130, 130, 130, 130, "USED-FOR"], [130, 130, 125, 125, "USED-FOR"], [130, 130, 130, 130, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 138, 138, "USED-FOR"], [107, 108, 143, 143, "USED-FOR"], [107, 108, 147, 147, "USED-FOR"], [107, 108, 125, 125, "USED-FOR"], [107, 108, 130, 130, "USED-FOR"]], [], [], []]}
{"doc_key": "2103.07098-506a0d5c-37ac-4dd6-8d9d-48abea7bd183", "sentences": [["For", "training", "classifier", "with", "weak", "labels", ",", "a", "standard", "desktop", "was", "used", "for", "SVM", ",", "but", "for", "the", "neural-network", "based", "models", ",", "a", "machine", "with", "Nvidia", "GT-1080Ti", "GPU", "was", "used", "."], ["Only", "weak", "labeled", "examples", "-LRB-", "excluding", "any", "test", "data", "-RRB-", "were", "used", "for", "training", "."], ["The", "training", "of", "neural-networks", "took", "between", "half-an-hour", "to", "two", "hours", "but", "training", "SVM", "took", "less", "than", "half-an-hour", "."], ["BERT", ",", "which", "has", "110", "million", "parameters", ",", "is", "much", "larger", "than", "LSTM", "which", "is", "in", "order", "of", "200,000", "parameters", "."], ["However", ",", "for", "BERT", "we", "only", "tune", "the", "model", "whereas", "for", "LSTM", "we", "fully", "train", "the", "model", "-LRB-", "except", "the", "embeddings", "-RRB-", "."]], "ner": [[[13, 13, "a"]], [], [[58, 58, "a"]], [[64, 64, "a"], [70, 70, "p"], [83, 83, "p"], [82, 82, "v"], [76, 76, "a"]], [[88, 88, "a"], [96, 96, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[13, 13, "a"], [18, 18, "a"]], [], [[49, 49, "a"], [54, 54, "v"]], [[64, 64, "a"], [68, 68, "v"], [76, 76, "a"], [82, 82, "v"]], [[88, 88, "a"], [96, 96, "a"]]], "predicted_relations": [[], [], [], [[70, 70, 64, 64, "USED-FOR"], [70, 70, 76, 76, "USED-FOR"], [83, 83, 76, 76, "USED-FOR"], [82, 82, 83, 83, "USED-FOR"]], []]}
{"doc_key": "2107.00152-adaa6105-1861-4bab-ab2b-25f44c1396ee", "sentences": [["We", "use", "Adam", "-LSB-", "16", "-RSB-", "for", "the", "training", "of", "all", "our", "models", "."], ["Our", "question", "type", "classifiers", "and", "template", "exemplar", "classifiers", "are", "trained", "with", "a", "maximum", "learning", "rate", "of", "\\", "-LRB-", "1", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "a", "batch", "size", "of", "32", "."], ["For", "training", "generation", "models", ",", "the", "maximum", "learning", "rate", "is", "\\", "-LRB-", "3", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "each", "batch", "contains", "at", "most", "\\", "-LRB-", "32", "-LCB-", ",", "-RCB-", "768\\", "-RRB-", "tokens", "."], ["Mixed-precision", "training", "is", "adopted", "for", "all", "models", "except", "for", "models", "with", "GATs", "."]], "ner": [[[2, 2, "a"]], [[26, 28, "p"], [42, 43, "p"], [45, 45, "v"]], [[53, 55, "p"], [75, 75, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[27, 28, "p"], [32, 32, "v"], [34, 37, "v"], [42, 43, "p"], [45, 45, "v"]], [[59, 59, "v"], [75, 75, "v"]], [[94, 94, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2103.08317-50407da8-8685-4833-afec-8623bad9936c", "sentences": [["In", "our", "GBDT", "and", "XGBT", "regression", "models", ",", "we", "considered", "max_depth", ",", "learning_rate", ",", "n_estimators", ",", "subsample", "as", "the", "main", "parameters", "to", "be", "hyper-tuned", ",", "where", ":", "max_depth", "represents", "the", "maximum", "depth", "of", "the", "individual", "regression", "estimators", "-LRB-", "each", "estimator", "is", "a", "decision", "tree", "-LRB-", "DT", "-RRB-", "-RRB-", ",", "learning_rate", "is", "the", "contribution", "of", "each", "tree", "to", "the", "overall", "outcome", ",", "n_estimators", "is", "the", "number", "of", "boosting", "stages", "to", "perform", ",", "and", "subsample", "is", "the", "fraction", "of", "samples", "to", "be", "used", "for", "fitting", "the", "individual", "base", "learners", "-LRB-", "if", "smaller", "than", "1.0", "this", "results", "in", "Stochastic", "Gradient", "Boosting", "-RRB-", "."], ["subsample", "parameter", "interacts", "with", "the", "n_estimators", "parameter", "."], ["Choosing", "\\", "-LRB-", "\\textit", "-LCB-", "subsample", "-RCB-", "<", "1.0\\", "-RRB-", "leads", "to", "a", "reduction", "of", "variance", "and", "an", "increase", "in", "bias", "."]], "ner": [[[2, 2, "a"], [10, 10, "p"], [27, 27, "p"], [12, 12, "p"], [49, 49, "p"], [14, 14, "p"], [61, 61, "p"], [16, 16, "p"], [72, 72, "p"], [95, 97, "c"], [4, 4, "a"], [10, 10, "p"], [27, 27, "p"], [12, 12, "p"], [49, 49, "p"], [14, 14, "p"], [61, 61, "p"], [16, 16, "p"], [72, 72, "p"], [95, 97, "c"]], [[105, 105, "p"], [100, 100, "p"], [105, 105, "p"], [100, 100, "p"]], [[113, 113, "p"], [113, 113, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [10, 10, "a"], [12, 12, "p"], [27, 27, "a"], [49, 49, "p"], [91, 91, "v"], [95, 97, "a"]], [], [[116, 116, "v"]]], "predicted_relations": [[[10, 10, 2, 2, "USED-FOR"], [10, 10, 4, 4, "USED-FOR"], [27, 27, 2, 2, "USED-FOR"], [27, 27, 4, 4, "USED-FOR"], [12, 12, 2, 2, "USED-FOR"], [12, 12, 4, 4, "USED-FOR"], [49, 49, 2, 2, "USED-FOR"], [49, 49, 4, 4, "USED-FOR"], [14, 14, 2, 2, "USED-FOR"], [14, 14, 4, 4, "USED-FOR"], [61, 61, 2, 2, "USED-FOR"], [16, 16, 2, 2, "USED-FOR"], [16, 16, 4, 4, "USED-FOR"], [72, 72, 2, 2, "USED-FOR"], [10, 10, 2, 2, "USED-FOR"], [10, 10, 4, 4, "USED-FOR"], [27, 27, 2, 2, "USED-FOR"], [27, 27, 4, 4, "USED-FOR"], [12, 12, 2, 2, "USED-FOR"], [12, 12, 4, 4, "USED-FOR"], [49, 49, 2, 2, "USED-FOR"], [49, 49, 4, 4, "USED-FOR"], [14, 14, 2, 2, "USED-FOR"], [14, 14, 4, 4, "USED-FOR"], [61, 61, 2, 2, "USED-FOR"], [16, 16, 2, 2, "USED-FOR"], [16, 16, 4, 4, "USED-FOR"], [72, 72, 2, 2, "USED-FOR"]], [], []]}
{"doc_key": "2106.11582-c906cf14-195e-472f-ad8b-d32100428429", "sentences": [["This", "experiment", "uses", "the", "Adam", "optimizer", "with", "a", "0.0002", "learning", "rate", "and", "sets", "the", "batch", "size", "to", "32", "in", "our", "training", "process", "."], ["In", "Fig", "."], ["REF", "and", "Fig", "."], ["REF", "show", "the", "accuracy", "and", "loss", "curves", "of", "different", "deep", "learning", "models", "in", "this", "experiment", "."], ["We", "find", "that", "the", "loss", "and", "accuracy", "curves", "of", "the", "training", "set", "are", "converging", "after", "training", "for", "40", "layers", "."], ["Therefore", ",", "considering", "the", "computational", "performance", "of", "the", "workstation", ",", "we", "finally", "set", "50", "epochs", "for", "training", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[[4, 5, "a"], [9, 10, "p"], [8, 8, "v"], [14, 15, "p"], [17, 17, "v"], [20, 20, "a"]], [], [], [[39, 41, "a"]], [[56, 56, "a"], [61, 61, "a"]], [[82, 82, "a"], [80, 80, "p"], [79, 79, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "v"], [9, 10, "p"], [14, 15, "p"], [17, 17, "v"]], [], [], [], [[63, 63, "v"], [64, 64, "p"]], [[79, 79, "v"], [80, 80, "p"]], []], "predicted_relations": [[[9, 10, 4, 5, "USED-FOR"], [8, 8, 9, 10, "USED-FOR"], [14, 15, 4, 5, "USED-FOR"]], [], [], [], [], [[80, 80, 82, 82, "USED-FOR"], [79, 79, 80, 80, "USED-FOR"]], []]}
{"doc_key": "2108.07058-c8600ff0-b085-428f-9b1e-553ec0dd402e", "sentences": [["For", "all", "experiments", "shown", "in", "the", "main", "paper", ",", "we", "use", "SGD", "optimizer", "with", "0.9", "momentum", "and", "0.0001", "weight", "decay", "."], ["The", "standard", "data", "augmentation", "of", "horizontal", "flipping", "and", "scaling", "are", "also", "applied", "."], ["In", "addition", ",", "the", "weights", "of", "the", "batch", "normalization", "-LSB-", "16", "-RSB-", "layers", "derived", "from", "the", "ImageNet", "pre-trained", "models", "are", "kept", "frozen", "."], ["To", "be", "consistent", "with", "prior", "works", ",", "we", "have", "not", "incorporated", "any", "testing", "time", "augmentation", "tricks", "."], ["For", "semantic", "segmentation", ",", "the", "model", "is", "trained", "for", "65K", "iterations", "starting", "with", "a", "learning", "rate", "of", "0.01", "that", "is", "reduced", "by", "a", "factor", "of", "10", "at", "40K", "and", "55K", "."], ["For", "the", "other", "three", "dense", "prediction", "tasks", ",", "the", "model", "is", "trained", "for", "90K", "or", "270K", "iterations", "with", "the", "initial", "learning", "rate", "of", "0.02", "that", "is", "reduced", "to", "0.002", "at", "60K/210K", "and", "0.0002", "at", "80K/250K", "."], ["Our", "implementation", "is", "based", "on", "the", "Detectron2", "-LSB-", "45", "-RSB-", "with", "the", "default", "configurations", ",", "to", "maintain", "a", "fair", "comparison", "with", "prior", "works", ",", "neither", "have", "we", "tuned", "any", "training", "hyperparameters", "nor", "used", "advanced", "data", "augmentations", "."]], "ner": [[[11, 12, "a"], [15, 15, "p"], [14, 14, "v"], [18, 19, "p"], [17, 17, "v"]], [[23, 24, "a"]], [[41, 42, "a"]], [], [], [], [[147, 147, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"], [14, 14, "v"], [15, 15, "p"], [17, 17, "v"], [18, 19, "p"]], [], [[41, 42, "a"], [50, 50, "a"]], [], [[83, 83, "v"], [88, 89, "p"], [91, 91, "v"], [99, 99, "v"], [101, 101, "v"], [103, 103, "v"]], [[108, 108, "v"], [118, 118, "v"], [120, 120, "v"], [125, 126, "p"], [128, 128, "v"], [133, 133, "v"], [135, 135, "v"], [137, 137, "v"], [139, 139, "v"]], [[147, 147, "a"]]], "predicted_relations": [[[15, 15, 11, 12, "USED-FOR"], [18, 19, 11, 12, "USED-FOR"], [17, 17, 15, 15, "USED-FOR"], [17, 17, 18, 19, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2108.00882-df88a8be-cd2c-4e05-862b-c65539091d45", "sentences": [["To", "evaluate", "the", "performance", "of", "the", "proposed", "SANet", ",", "five", "polyp", "segmentation", "datasets", "are", "adopted", ",", "including", "Kvasir", "-LSB-", "9", "-RSB-", ",", "CVC-ClinicDB", "-LSB-", "1", "-RSB-", ",", "CVC-ColonDB", "-LSB-", "2", "-RSB-", ",", "EndoScene", "-LSB-", "17", "-RSB-", "and", "ETIS", "-LSB-", "15", "-RSB-", "."], ["To", "keep", "the", "fairness", "of", "the", "experiments", ",", "we", "follow", "-LSB-", "4", "-RSB-", "advice", "and", "take", "exactly", "the", "same", "training", "and", "testing", "dataset", "division", "."], ["Besides", ",", "six", "state-of-the-art", "methods", "are", "used", "for", "comparison", ",", "namely", "U-Net", "-LSB-", "14", "-RSB-", ",", "U-Net++", "-LSB-", "24", "-RSB-", ",", "ResUNet", "-LSB-", "22", "-RSB-", ",", "ResUNet++", "-LSB-", "10", "-RSB-", ",", "SFA", "-LSB-", "5", "-RSB-", "and", "PraNet", "-LSB-", "4", "-RSB-", "."], ["We", "use", "Pytorch", "to", "implement", "our", "model", "."], ["All", "input", "images", "are", "uniformly", "resized", "to", "352\u00d7352", "."], ["For", "data", "augmentation", ",", "we", "adopt", "the", "random", "flip", ",", "random", "rotation", "and", "multi-scale", "training", "."], ["The", "whole", "network", "is", "trained", "in", "an", "end-to-end", "way", ",", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "."], ["Initial", "learning", "rate", "and", "batch", "size", "are", "set", "to", "0.04", "and", "64", ",", "respectively", "."], ["We", "train", "the", "entire", "model", "for", "128", "epoches", "."]], "ner": [[[17, 17, "a"], [22, 22, "a"], [27, 27, "a"], [32, 32, "a"], [37, 37, "a"]], [], [[78, 78, "a"], [83, 83, "a"], [88, 88, "a"], [93, 93, "a"], [98, 98, "a"], [103, 103, "a"]], [], [], [], [], [[159, 161, "p"], [168, 168, "v"], [170, 170, "v"]], [[180, 180, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [9, 9, "v"], [17, 17, "a"], [22, 22, "a"], [27, 27, "a"], [32, 32, "a"], [37, 37, "a"]], [], [[69, 69, "v"], [78, 78, "a"], [83, 83, "a"], [88, 88, "a"], [93, 93, "a"], [98, 98, "a"], [103, 103, "a"]], [[110, 110, "a"], [114, 114, "a"]], [[123, 123, "v"]], [], [[152, 157, "a"]], [[160, 161, "p"], [163, 164, "p"], [168, 168, "v"], [170, 170, "v"]], [[178, 178, "a"], [180, 180, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2109.02631-c5d72e47-0782-4b80-b487-a376057d0c0d", "sentences": [["Training", "is", "performed", "on", "a", "single", "DGX", "machine", "with", "8", "Tesla", "V100", "GPUs", "."], ["7", "GPUs", "are", "filled", "with", "actor", "instances", "-LRB-", "2", "or", "3", "per", "GPU", "depending", "on", "design", "size", "-RRB-", "running", "our", "DREAMPlace", "based", "RL", "environment", "."], ["The", "final", "GPU", "is", "used", "for", "running", "the", "training", "algorithm", "for", "the", "policy", "and", "value", "networks", "."], ["Training", "is", "performed", "for", "1.5e6", "training", "steps", "-LRB-", "between", "10,000", "and", "25,000", "placement", "episodes", "depending", "on", "placement", "episode", "length", "-RRB-", "and", "the", "best", "solution", "found", "during", "training", "is", "reported", "."], ["This", "training", "process", "takes", "between", "24", "and", "48", "hours", "depending", "on", "the", "size", "of", "the", "partition", "."]], "ner": [[], [[34, 37, "a"]], [[47, 48, "a"]], [[61, 62, "p"], [60, 60, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 9, "v"]], [[14, 14, "v"], [22, 22, "v"], [24, 24, "v"]], [[53, 54, "a"]], [[60, 60, "v"], [65, 65, "v"], [67, 67, "v"]], [[91, 91, "v"], [93, 93, "v"]]], "predicted_relations": [[], [], [], [[60, 60, 61, 62, "USED-FOR"]], []]}
{"doc_key": "2107.03852-277d2f3f-7091-4ad5-aa8a-ffebd042a84b", "sentences": [["Runtime", "Environment", ":", "Nvidia", "GP107CL", "Quadro", "P620", "Architecture", ":", "Autoencoder", "Encoder", ":", "Contains", "4", "VGG", "Blocks", "VGG", "Block", "has", "2", "Convolution", "Layers", "followed", "by", "a", "maxpooling", "layer", "Batch", "normalization", "layer", "was", "used", "at", "the", "end", "of", "each", "layer", "before", "the", "activation", "function", "Activation", "Function", ":", "ReLU", "Decoder", ":", "Decoder", "part", "of", "the", "model", "consists", "of", "convolution", "transpose", "layers", "with", "batch", "normalization", "layer", "at", "the", "end", "of", "each", "layer", "before", "the", "activation", "function", "Activation", "Function", ":", "ReLU", ",", "Sigmoid", "-LRB-", "Output", "Layer", "-RRB-", "Batch", "Size", ":", "16", "Learning", "Rate", ":", "0.001", "Number", "of", "Epochs", ":", "500", "-LRB-", "CAE", "-RRB-", ",", "2000", "-LRB-", "DEC", "and", "IDEC", "-RRB-", "Optimizer", ":", "Adam"]], "ner": [[[9, 9, "a"], [82, 83, "p"], [85, 85, "v"], [86, 87, "p"], [89, 89, "v"], [90, 92, "p"], [105, 105, "p"], [107, 107, "v"], [16, 17, "a"], [45, 45, "a"], [75, 75, "a"], [77, 77, "a"]]], "relations": [[]], "predicted_ner": [[[5, 6, "a"], [9, 9, "a"], [13, 13, "v"], [14, 15, "a"], [16, 17, "a"], [19, 19, "v"], [45, 45, "a"], [75, 75, "a"], [77, 77, "a"], [82, 83, "p"], [85, 85, "v"], [86, 87, "p"], [89, 89, "v"], [94, 94, "v"], [99, 99, "v"], [107, 107, "a"]]], "predicted_relations": [[[82, 83, 45, 45, "USED-FOR"], [82, 83, 75, 75, "USED-FOR"], [86, 87, 16, 17, "USED-FOR"], [86, 87, 45, 45, "USED-FOR"], [86, 87, 75, 75, "USED-FOR"], [86, 87, 77, 77, "USED-FOR"], [89, 89, 86, 87, "USED-FOR"], [89, 89, 90, 92, "USED-FOR"], [90, 92, 45, 45, "USED-FOR"], [90, 92, 75, 75, "USED-FOR"], [90, 92, 77, 77, "USED-FOR"], [105, 105, 45, 45, "USED-FOR"], [105, 105, 75, 75, "USED-FOR"], [105, 105, 77, 77, "USED-FOR"], [107, 107, 90, 92, "USED-FOR"]]]}
{"doc_key": "2110.14295-8a57187b-96d9-4b3e-acba-78db51cb3f4c", "sentences": [["For", "both", "experiments", ",", "we", "set", "the", "total", "training", "episodes", "\\", "-LRB-", "L", "=", "5000\\", "-RRB-", ",", "trajectory", "generation", "size", "\\", "-LRB-", "B", "=", "5\\", "-RRB-", ",", "exploratory", "policy", "parameter", "\\", "-LRB-", "\\lambda", "=", "1.5\\", "-RRB-", ",", "and", "resample", "constant", "\\", "-LRB-", "\\kappa", "=", "1\\", "-RRB-", "."], ["We", "note", "that", "such", "setup", "of", "\\", "-LRB-", "B\\", "-RRB-", "and", "\\", "-LRB-", "\\kappa", "\\", "-RRB-", "then", "implies", "a", "mini-batch", "size", "\\", "-LRB-", "|\\tilde", "-LCB-", "\\mathcal", "-LCB-", "D", "-RCB-", "-RCB-", "_", "-LCB-", "\\cdot", ",", "\\cdot", "-RCB-", "|", "=", "1000\\", "-RRB-", "after", "appending", "past", "experiences", "and", "including", "samples", "from", "all", "time", "periods", "\\", "-LRB-", "t", "<", "T-1\\", "-RRB-", "as", "specified", "in", "Section", "REF", "."], ["We", "initialize", "our", "critic", "parameters", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "\\text", "-LCB-", "\\textbf", "-LCB-", "w", "-RCB-", "-RCB-", "-RCB-", "\\", "-RRB-", "near", "the", "true", "analytical", "parameters", "and", "actor", "parameters", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "to", "0", "."], ["We", "fix", "the", "learning", "rate", "for", "actor", "parameter", "update", "\\", "-LRB-", "\\alpha", "_", "-LCB-", "\\theta", "-RCB-", "=", "2\\", "-RRB-", "and", "use", "EMA", "learning", "rate", "\\", "-LRB-", "\\alpha", "^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "w", "-RCB-", "-RCB-", "=", "2/", "-LRB-", "l", "+", "1", "-RRB-", "\\", "-RRB-", "for", "our", "critic", "parameter", "update", "."]], "ner": [[[7, 9, "a"], [17, 19, "a"], [27, 29, "a"], [38, 39, "a"]], [[66, 67, "a"]], [[113, 114, "a"], [135, 136, "a"]], [[148, 153, "a"], [166, 168, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[12, 12, "p"], [12, 14, "v"], [22, 24, "v"], [27, 29, "p"], [32, 32, "p"], [34, 34, "v"], [38, 39, "p"], [42, 42, "p"], [44, 44, "v"]], [[60, 60, "p"], [66, 67, "p"], [85, 85, "v"], [100, 100, "p"], [100, 102, "v"]], [[139, 139, "p"], [143, 143, "v"]], [[148, 149, "p"], [150, 153, "c"], [156, 160, "p"], [162, 162, "v"], [166, 168, "a"], [188, 188, "p"], [196, 198, "c"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2104.05353-2e544fee-db76-4214-91b0-1f3c756e95a6", "sentences": [["Our", "defense", ":", "We", "evaluate", "our", "defense", "on", "the", "CIFAR-10", "dataset", "-LRB-", "\\", "-LRB-", "N=32\\", "-RRB-", "-RRB-", ",", "for", "which", "there", "are", "well-established", "benchmarks", "in", "adversarial", "ML", "."], ["In", "our", "defense", ",", "we", "use", "\\", "-LRB-", "4", "\\times", "4\\", "-RRB-", "patches", "-LRB-", "\\", "-LRB-", "n=4\\", "-RRB-", "-RRB-", "and", "an", "overcomplete", "dictionary", "with", "\\", "-LRB-", "L=500\\", "-RRB-", "atoms", "."], ["The", "stride", "\\", "-LRB-", "S=2\\", "-RRB-", ",", "so", "the", "encoder", "output", "is", "a", "\\", "-LRB-", "15", "\\times", "15", "\\times", "500\\", "-RRB-", "tensor", "-LRB-", "\\", "-LRB-", "m=15\\", "-RRB-", ",", "\\", "-LRB-", "L=500\\", "-RRB-", "-RRB-", "."], ["The", "regularization", "parameter", "in", "equation", "REF", "is", "set", "to", "\\", "-LRB-", "\\lambda", "=", "1\\", "-RRB-", ",", "in", "the", "upper", "range", "of", "values", "resulting", "in", "convergence", "."], ["The", "number", "of", "iterations", "in", "dictionary", "learning", "is", "chosen", "as", "1000", "to", "ensure", "convergence", "."], ["The", "number", "of", "dictionary", "atoms", "\\", "-LRB-", "L\\", "-RRB-", "is", "chosen", "to", "be", "10", "times", "the", "ambient", "dimension", "of", "patches", "."]], "ner": [[[9, 10, "a"]], [[49, 50, "a"]], [[59, 59, "a"]], [[103, 103, "p"], [105, 105, "v"], [93, 94, "a"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 10, "a"], [14, 14, "v"]], [[36, 36, "v"], [38, 38, "v"], [44, 44, "v"], [54, 54, "v"]], [[62, 62, "v"], [77, 77, "v"], [83, 83, "v"], [88, 88, "v"]], [[93, 94, "p"], [103, 105, "p"]], [[128, 128, "v"]], [[140, 140, "p"], [146, 146, "v"]]], "predicted_relations": [[], [], [], [[103, 103, 93, 94, "USED-FOR"], [105, 105, 103, 103, "USED-FOR"]], [], []]}
{"doc_key": "2104.05353-56a52bc5-7231-4664-8fb2-183a5578156a", "sentences": [["We", "test", "our", "defense", "for", "\\", "-LRB-", "T=1,2,5,10,15", ",", "\\", "-RRB-", "and", "20", "with", "hyperparameter", "\\", "-LRB-", "\\beta", "=", "3\\", "-RRB-", "for", "the", "threshold", "in", "equation", "REF", "."], ["We", "train", "the", "CNN-based", "decoder", "in", "supervised", "fashion", "in", "tandem", "with", "the", "classifier", ",", "using", "the", "standard", "cross-entropy", "loss", "."], ["We", "use", "a", "cyclic", "learning", "rate", "scheduler", "-LSB-", "16", "-RSB-", "with", "a", "maximum", "learning", "rate", "of", "\\", "-LRB-", "\\eta", "_", "-LCB-", "max", "-RCB-", "=0.05\\", "-RRB-", "for", "\\", "-LRB-", "T=1,2\\", "-RRB-", "and", "\\", "-LRB-", "\\eta", "_", "-LCB-", "max", "-RCB-", "=0.02\\", "-RRB-", "for", "\\", "-LRB-", "T=5,10,15,20\\", "-RRB-", "."], ["In", "order", "to", "provide", "a", "consistent", "evaluation", ",", "we", "employ", "the", "ResNet-32", "classifier", "used", "in", "-LSB-", "13", "-RSB-", "and", "train", "it", "for", "70", "epochs", "."]], "ner": [[], [[31, 32, "a"], [45, 46, "a"]], [[60, 62, "p"], [71, 71, "v"], [86, 86, "v"]], [[105, 106, "a"], [117, 117, "p"], [116, 116, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[12, 12, "v"], [19, 19, "v"]], [[45, 46, "a"]], [[60, 62, "p"], [71, 71, "v"], [76, 76, "v"], [86, 86, "v"]], [[105, 105, "a"], [116, 116, "v"], [117, 117, "p"]]], "predicted_relations": [[], [], [], [[117, 117, 105, 106, "USED-FOR"], [116, 116, 117, 117, "USED-FOR"]]]}
{"doc_key": "2104.05353-f2a5df4b-b29b-46a6-939f-5e49c9bd6fce", "sentences": [["Benchmarks", ":", "For", "a", "fair", "comparison", ",", "we", "use", "the", "same", "ResNet-32", "classifier", "architecture", "for", "the", "benchmarks", "."], ["We", "train", "the", "PGD", "adversarially", "trained", "model", "from", "-LSB-", "13", "-RSB-", "with", "the", "same", "cyclic", "learning", "rate", "with", "\\", "-LRB-", "\\eta", "_", "-LCB-", "max", "-RCB-", "=0.05\\", "-RRB-", "for", "100", "epochs", "."], ["We", "train", "the", "model", "for", "TRADES", "defense", "with", "learning", "rate", "\\", "-LRB-", "\\eta", "=0.01\\", "-RRB-", "for", "the", "first", "50", "epochs", "and", "then", "with", "\\", "-LRB-", "\\eta", "=10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "next", "50", "epochs", "."], ["For", "both", "PGD", "adversarially", "trained", "model", "and", "TRADES", ",", "training", "hyperparameters", "are", "\\", "-LRB-", "\\epsilon", "=8/255\\", "-RRB-", ",", "\\", "-LRB-", "\\delta", "=1/255\\", "-RRB-", ",", "\\", "-LRB-", "N_S=10\\", "-RRB-", ",", "\\", "-LRB-", "N_R=1\\", "-RRB-", "."], ["Additionally", "for", "TRADES", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\text", "-LCB-", "TRADES", "-RCB-", "-RCB-", "=1/6\\", "-RRB-", "."], ["We", "also", "report", "on", "naturally", "trained", "network", "-LRB-", "i.e.", ",", "no", "defense", "-RRB-", "."], ["This", "network", "is", "also", "trained", "for", "70", "epochs", "with", "the", "same", "cyclic", "learning", "rate", "with", "\\", "-LRB-", "\\eta", "_", "-LCB-", "max", "-RCB-", "=0.05\\", "-RRB-", "."]], "ner": [[[11, 13, "a"]], [[21, 24, "a"], [32, 34, "p"], [43, 43, "v"]], [[54, 55, "a"]], [[89, 92, "a"], [101, 101, "p"], [107, 107, "p"], [113, 113, "p"], [118, 118, "p"]], [], [[141, 143, "a"]], [[162, 164, "p"], [173, 173, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"]], [[21, 21, "a"], [32, 34, "p"], [43, 43, "v"], [46, 46, "v"], [47, 47, "p"]], [[57, 58, "p"], [67, 67, "v"], [68, 68, "p"], [84, 84, "v"], [85, 85, "p"]], [[89, 89, "a"], [107, 107, "p"], [113, 113, "v"]], [[126, 133, "p"], [134, 134, "v"]], [], [[157, 157, "v"], [158, 158, "p"], [162, 164, "p"], [173, 173, "v"]]], "predicted_relations": [[], [[32, 34, 21, 24, "USED-FOR"]], [], [[101, 101, 89, 92, "USED-FOR"], [107, 107, 89, 92, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.04604-0ee48207-78ef-472e-9727-23c87d1cd32f", "sentences": [["We", "tuned", "the", "only", "hyper", "parameter", "for", "data", "augmentation", ",", "the", "percentage", "of", "augmented", "data", "points", ",", "\\", "-LRB-", "p\\", "-RRB-", ",", "for", "MNLI", "."], ["On", "this", "task", "we", "augmented", "5", ",", "10", ",", "and", "15", "%", "of", "sentence", "pairs", "from", "training", "data", ",", "and", "found", "5", "and", "10", "%", "of", "training", "data", "as", "the", "best", "thresholds", "for", "ACCESS", "and", "NTS", "respectively", "."], ["For", "TACRED", ",", "we", "did", "not", "use", "this", "hyper", "parameter", "."], ["Instead", ",", "we", "used", "all", "simplifications", "that", "preserve", "critical", "information", "for", "data", "augmentation", "."], ["That", "is", ",", "we", "added", "all", "simplified", "sentences", "that", "preserve", "the", "subject", "and", "object", "entities", "necessary", "for", "the", "underlying", "relation", "."], ["We", "found", "that", "66", "%", "of", "training", "data", "sentences", "could", "be", "simplified", "while", "preserving", "this", "information", "by", "ACCESS", ",", "and", "72", "%", "by", "NTS", "."]], "ner": [[[11, 15, "p"], [23, 23, "c"], [23, 23, "c"], [23, 23, "c"]], [], [[64, 64, "c"], [64, 64, "c"]], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[23, 23, "a"]], [[30, 30, "v"], [32, 32, "v"], [35, 36, "v"], [46, 46, "v"], [48, 49, "v"]], [[64, 64, "a"]], [], [], [[112, 113, "v"], [129, 130, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2106.08254-20e8eb60-b0cf-4461-a44c-87271a84002e", "sentences": [["The", "network", "architecture", "of", "BEiT", "follows", "that", "of", "ViT-Base", "-LSB-", "17", "-RSB-", "for", "a", "fair", "comparison", "."], ["We", "use", "a", "12-layer", "Transformer", "with", "768", "hidden", "size", ",", "and", "12", "attention", "heads", "."], ["The", "intermediate", "size", "of", "feed-forward", "networks", "is", "3072", "."], ["We", "employ", "the", "default", "\\", "-LRB-", "16", "\\times", "16\\", "-RRB-", "input", "patch", "size", "."], ["We", "directly", "borrow", "the", "image", "tokenizer", "trained", "by", "-LSB-", "37", "-RSB-", "."], ["The", "vocabulary", "size", "of", "visual", "tokens", "is", "8192", "."]], "ner": [[[4, 4, "a"], [8, 8, "a"]], [[24, 25, "p"], [23, 23, "v"], [29, 30, "p"], [20, 20, "v"], [28, 28, "v"], [21, 21, "a"]], [[33, 37, "p"], [39, 39, "v"]], [[51, 53, "p"]], [], [[68, 72, "p"], [74, 74, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "a"]], [[20, 20, "v"], [23, 23, "v"], [28, 28, "v"]], [[36, 37, "a"], [39, 39, "v"]], [[47, 47, "v"], [49, 49, "v"]], [], [[74, 74, "v"]]], "predicted_relations": [[], [[28, 28, 29, 30, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2106.08254-489ceab0-7d45-463b-8438-cacd9418a601", "sentences": [["We", "pretrain", "BEiT", "on", "the", "training", "set", "of", "ImageNet-1K", "-LSB-", "39", "-RSB-", ",", "which", "contains", "about", "\\", "-LRB-", "1.2\\", "-RRB-", "M", "images", "."], ["Our", "augmentation", "policy", "includes", "random", "resized", "cropping", ",", "horizontal", "flipping", ",", "color", "jittering", "-LSB-", "45", "-RSB-", "."], ["Notice", "that", "we", "do", "not", "use", "the", "labels", "for", "self-supervised", "learning", "."], ["We", "use", "the", "\\", "-LRB-", "224", "\\times", "224\\", "-RRB-", "resolution", "in", "our", "experiments", "."], ["So", "the", "input", "is", "split", "to", "\\", "-LRB-", "14", "\\times", "14\\", "-RRB-", "image", "patches", ",", "and", "the", "same", "amount", "of", "visual", "tokens", "."], ["We", "randomly", "mask", "at", "most", "75", "patches", "-LRB-", "i.e.", ",", "roughly", "\\", "-LRB-", "40\\", "%", "\\", "-RRB-", "of", "total", "image", "patches", "-RRB-", "."]], "ner": [[[2, 2, "a"], [8, 8, "a"]], [[27, 29, "a"], [31, 32, "a"], [34, 35, "a"]], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [8, 8, "a"], [18, 18, "v"], [20, 20, "v"]], [], [], [[57, 57, "v"], [59, 59, "v"]], [[74, 74, "v"], [76, 76, "v"]], [[94, 94, "v"], [102, 103, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2106.08254-0bcec749-13e3-4c29-a879-6b523c679c64", "sentences": [["The", "pre-training", "runs", "for", "about", "500k", "steps", "-LRB-", "i.e.", ",", "800", "epochs", "-RRB-", "with", "2k", "batch", "size", "."], ["Adam", "-LSB-", "25", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2=0.999\\", "-RRB-", "is", "employed", "for", "optimization", "."], ["The", "learning", "rate", "is", "set", "to", "1.5e-3", ",", "with", "a", "warmup", "of", "10", "epochs", ",", "and", "cosine", "learning", "rate", "decay", "."], ["The", "weight", "decay", "is", "\\", "-LRB-", "0.05\\", "-RRB-", "."], ["We", "employ", "stochastic", "depth", "-LSB-", "22", "-RSB-", "with", "a", "\\", "-LRB-", "0.1\\", "-RRB-", "rate", ",", "and", "disable", "dropout", "."], ["The", "500k", "training", "steps", "take", "about", "five", "days", "using", "16", "Nvidia", "Telsa", "V100", "32GB", "GPU", "cards", "."]], "ner": [[], [[18, 18, "a"], [26, 26, "v"], [29, 29, "v"]], [[38, 38, "p"], [54, 54, "p"]], [], [[79, 79, "p"], [77, 77, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [10, 10, "v"], [11, 11, "p"], [14, 14, "v"], [15, 16, "p"]], [[18, 18, "a"]], [[37, 38, "p"], [42, 42, "v"], [48, 48, "v"], [49, 49, "p"]], [[58, 59, "p"], [63, 63, "v"]], [[68, 69, "a"], [77, 77, "v"], [83, 83, "a"]], [[86, 86, "v"], [91, 91, "v"], [94, 94, "v"], [98, 98, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2107.09437-026031c4-605d-49eb-ae40-a367ef8a9dc0", "sentences": [["With", "the", "analytical", "framework", "that", "can", "map", "the", "weight", "distribution", "of", "the", "hidden", "layer", "to", "the", "order-chaos", "phase", "diagram", ",", "we", "can", "then", "study", "the", "back-propagation", "process", "during", "the", "model", "training", "process", "in", "the", "phase", "diagram", "."], ["In", "our", "experiment", ",", "we", "use", "the", "standard", "Fashion-MNIST", "image", "dataset", "-LSB-", "32", "-RSB-", "for", "training", "and", "testing", "."], ["This", "dataset", "contains", "70,000", "greyscale", "images", "of", "10", "types", "of", "clothing", "and", "accessories", ",", "of", "which", "60,000", "images", "are", "used", "for", "training", "and", "10,000", "images", "are", "for", "testing", "."], ["Since", "the", "network", "architecture", "of", "our", "model", "requires", "a", "vector", "as", "input", ",", "we", "flatten", "the", "2D", "images", "into", "a", "1D", "vector", "."], ["As", "each", "sample", "image", "in", "the", "Fashion-MNIST", "dataset", "has", "\\", "-LRB-", "28", "\\times", "28\\", "-RRB-", "=", "784", "pixels", ",", "we", "design", "the", "hidden", "layer", "with", "784", "neurons", ",", "such", "that", "there", "are", "\\", "-LRB-", "784\\times", "784\\", "-RRB-", "weights", "in", "the", "hidden", "layer", "."], ["The", "activation", "function", "of", "the", "hidden", "layer", "is", "\\", "-LRB-", "\\tanh", "\\", "-RRB-", "in", "line", "with", "the", "theoretical", "framework", "."], ["We", "use", "the", "basic", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "momentum", "as", "the", "optimization", "algorithm", "."], ["After", "every", "epoch", "during", "the", "training", "process", ",", "we", "calculate", "the", "mean", "and", "variance", "of", "the", "weights", "in", "the", "hidden", "layer", "to", "identify", "the", "ordered/chaotic", "phase", "of", "the", "hidden", "layer", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [[45, 47, "a"]], [], [], [], [], [[175, 182, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[45, 47, "a"]], [[59, 59, "v"], [63, 63, "v"], [72, 72, "v"], [79, 79, "v"]], [[101, 101, "v"], [105, 105, "v"]], [[114, 115, "a"], [119, 119, "v"], [121, 121, "v"], [124, 124, "v"], [133, 133, "v"], [143, 143, "v"]], [], [[174, 180, "a"]], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2107.09437-ee89c068-39db-4497-af7f-73fa67cd3e7f", "sentences": [["In", "the", "training", "process", "of", "a", "neural", "network", "with", "back-propagation", ",", "the", "training", "data", "are", "repeated", "fed", "into", "the", "model", "to", "optimize", "the", "weights", "iteratively", "."], ["Each", "time", "the", "whole", "set", "of", "training", "sample", "is", "used", "for", "one", "round", "of", "back-propagation", ",", "the", "training", "time", "is", "defined", "as", "incremented", "by", "one", "epoch", "."], ["Hence", ",", "at", "the", "beginning", "of", "each", "epoch", ",", "we", "calculate", "\\", "-LRB-", "J_0\\", "-RRB-", "and", "\\", "-LRB-", "J\\", "-RRB-", "from", "the", "mean", "and", "variance", "of", "the", "hidden", "layer", "'s", "weights", ",", "and", "map", "its", "coordinates", "to", "the", "order-chaos", "phase", "diagram", "for", "the", "first", "500", "epochs", "."], ["The", "trajectory", "in", "Fig", "."], ["REF", "-LRB-", "a", "-RRB-", "represents", "the", "model", "'s", "evolution", "path", "during", "training", "."], ["We", "initialize", "the", "hidden", "layer", "weight", "matrix", "\\", "-LRB-", "W\\", "-RRB-", "with", "\\", "-LRB-", "J_0=0\\", "-RRB-", "and", "\\", "-LRB-", "J=0.5\\", "-RRB-", ",", "such", "that", "the", "hidden", "layer", "starts", "from", "the", "ordered", "phase", ",", "i.e.", ",", "the", "white", "region", "in", "the", "figure", "."], ["As", "the", "training", "proceeds", ",", "the", "model", "evolves", "from", "the", "ordered", "phase", "towards", "the", "chaotic", "phase", "."], ["When", "the", "model", "is", "around", "the", "edge", "of", "chaos", "\\", "-LRB-", "-LRB-", "J=1", "-RRB-", "\\", "-RRB-", ",", "the", "test", "loss", "is", "the", "lowest", "as", "Fig", "."], ["REF", "-LRB-", "a", "-RRB-", "-", "-LRB-", "b", "-RRB-", "shows", ",", "indicating", "optimal", "model", "performance", "around", "this", "point", "."], ["This", "demonstrates", "that", "the", "model", "optimality", "near", "the", "edge", "of", "chaos", "also", "holds", "for", "single", "hidden", "layer", "neural", "networks", ",", "even", "though", "this", "network", "is", "a", "feedforward", "process", "rather", "than", "an", "iterative", "recurrent", "computation", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], [], [[132, 132, "v"], [137, 137, "v"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"]], [[37, 37, "v"], [40, 40, "a"], [50, 50, "v"]], [[97, 97, "v"]], [], [], [], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2102.02335-a39dd6ee-717a-42d7-981f-8fd48fa6fe14", "sentences": [["We", "train", "our", "Multihead", "Attention", "model", "for", "Claim", "Identification", ",", "MA-CIN", ",", "on", "datasets", "mentioned", "in", "Section", "."], ["The", "CDC", "dataset", "contains", "total", "of", "522", "articles", "."], ["Amongst", "these", ",", "there", "are", "47", "articles", "with", "8", "or", "more", "annotated", "claim", "sentences", "which", "are", "considered", "as", "evaluation", "set", "-LRB-", "CDC_Eval", "-RRB-", "for", "this", "dataset", "."], ["Next", ",", "for", "DNF-300", "and", "DNF-700", ",", "we", "asked", "two", "annotators", "to", "manually", "tag", "at", "least", "5", "sentences", "as", "\u201c", "claim-worthy", "\u201d", "in", "each", "of", "the", "50", "articles", "."], ["Sentences", "which", "were", "consented", "by", "both", "the", "annotators", "as", "\u201c", "claim-worthy", "\u201d", "were", "finalized", "as", "ground", "truth", "claims", "for", "these", "50", "articles", ",", "and", "used", "as", "testing", "set", "for", "evaluating", "the", "model", "performance", "on", "DNF", "datasets", "."], ["The", "remaining", "475", "articles", "from", "CDC", ",", "250", "articles", "from", "DNF-300", ",", "and", "650", "articles", "from", "DNF-700", "were", "split", "into", "5", "folds", "to", "train", "the", "model", "using", "a", "5-Fold", "cross", "validation", "-LSB-", "14", "-RSB-", ",", "where", "we", "use", "4", "folds", "for", "training", "and", "1", "fold", "for", "validation", "."], ["Each", "of", "the", "three", "settings", ",", "described", "in", "Section-", ":", "MA-CIN", "-LRB-", "HV", "-RRB-", ",", "MA-CIN", "-LRB-", "OHWV", "-RRB-", "and", "MA-CIN", "-LRB-", "Combined", "-RRB-", ",", "was", "trained", "with", "each", "of", "the", "three", "datasets", ",", "and", "evaluated", "on", "DNF_Eval", "and", "CDC_Eval", "."], ["Total", "number", "of", "parameters", "for", "these", "three", "settings", "are", "15,012,916", "-LRB-", "10,240", "non-trainable", "-RRB-", ",", "40,975,656", "-LRB-", "10,240", "non-trainable", "-RRB-", "and", "41,812,564", "-LRB-", "12,288", "non-trainable", "-RRB-", "respectively", "."], ["All", "other", "network", "parameters", "are", "displayed", "in", "supplemental", "material", "."]], "ner": [[[3, 5, "a"]], [[19, 20, "a"]], [[48, 48, "a"]], [[57, 57, "a"], [59, 59, "a"]], [], [[130, 130, "a"], [136, 136, "a"], [148, 150, "a"]], [[207, 207, "a"], [205, 205, "a"]], [[218, 218, "v"], [224, 224, "v"], [230, 230, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 5, "a"], [10, 10, "a"]], [[19, 20, "a"], [24, 24, "v"]], [[32, 32, "v"], [35, 35, "v"], [52, 52, "a"]], [[57, 57, "a"], [59, 59, "a"], [63, 63, "v"], [70, 70, "v"], [80, 80, "v"]], [[103, 103, "v"]], [[122, 122, "v"], [127, 127, "v"], [130, 130, "a"], [133, 133, "v"], [136, 136, "a"], [140, 140, "v"], [148, 148, "v"], [149, 150, "a"], [158, 158, "v"], [163, 163, "v"]], [[171, 171, "v"], [183, 183, "a"], [188, 188, "a"], [199, 199, "v"], [205, 205, "a"], [207, 207, "a"]], [[215, 215, "v"], [218, 218, "v"], [220, 220, "v"], [224, 224, "v"], [226, 226, "v"], [230, 230, "v"], [232, 232, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2102.02335-6229e0bb-67ce-486c-9057-b079c503f3cf", "sentences": [["In", "each", "setting", ",", "we", "use", "batch", "normalization", ",", "ReLU", "non-linearity", "as", "an", "activation", "function", ",", "and", "a", "dropout", "of", "0.5", "for", "every", "convolution", "operation", "."], ["We", "trained", "all", "the", "models", "for", "2000", "epochs", ",", "where", ",", "for", "every", "training", "we", "used", "Adam", "optimizer", "with", "a", "learning", "rate", "\\", "-LRB-", "lr=0.0001\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "=0.99\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_", "-LCB-", "2", "-RCB-", "=0.0\\", "-RRB-", "."], ["There", "was", "no", "weight", "decay", "set", "as", "the", "model", "was", "trained", "in", "a", "self-supervised", "setting", "with", "finite", "epochs", "and", "an", "already", "small", "learning", "rate", "."], ["Glove", "300D", "word", "embedding", "was", "used", "for", "all", "our", "experiments", "and", "the", "number", "of", "input", "sentences", "was", "set", "to", "500", "."], ["The", "models", "were", "trained", "on", "three", "11GiB", "Nvidia", "1080Ti", "GPUs", "in", "parallel", "."]], "ner": [[[6, 7, "a"], [9, 10, "a"], [18, 18, "a"], [20, 20, "v"]], [[42, 43, "a"], [46, 47, "p"], [50, 50, "v"], [60, 60, "v"], [70, 70, "v"]], [[95, 96, "p"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 7, "a"], [9, 9, "a"], [18, 18, "p"], [20, 20, "v"]], [[32, 32, "v"], [33, 33, "p"], [42, 42, "a"], [46, 47, "p"], [50, 50, "v"], [60, 60, "v"]], [[76, 77, "a"], [89, 89, "v"], [90, 90, "p"], [95, 96, "p"]], [[98, 98, "a"], [117, 117, "v"]], [[124, 124, "v"], [125, 125, "v"]]], "predicted_relations": [[], [[50, 50, 46, 47, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.13122-96944685-0676-4922-b93f-e8cbacedae27", "sentences": [["Our", "code", "is", "a", "re-implementation", "of", "the", "conjugate-gradient", "Newton", "procedure", "of", "recent", "versions", "of", "Liblinear", "."], ["The", "hyperparameters", "related", "to", "stopping", "condition", "for", "conjugate-gradient", "iterations", "-LRB-", "\\", "-LRB-", "\\epsilon", "=0.5\\", "-RRB-", "-RRB-", "preconditioner", "-LRB-", "\\", "-LRB-", "\\alpha", "=0.01\\", "-RRB-", "-RRB-", ",", "back-tracking", "line", "search", "-LRB-", "\\", "-LRB-", "\\alpha", "=0.5\\", "-RRB-", ",", "\\", "-LRB-", "\\eta", "=0.01\\", "-RRB-", ",", "\\", "-LRB-", "\\text", "-LCB-", "max\\_steps", "-RCB-", "=20\\", "-RRB-", "-RRB-", ",", "and", "stopping", "condition", "for", "the", "optimization", "-LRB-", "\\", "-LRB-", "\\epsilon", "=0.01\\", "-RRB-", "-RRB-", "have", "been", "taken", "from", "their", "code", "."], ["To", "reduce", "model", "size", ",", "all", "weights", "below", "a", "threshold", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "have", "been", "clipped", "to", "zero", "."]], "ner": [[[14, 14, "a"]], [[20, 24, "p"], [29, 29, "v"], [48, 48, "v"], [32, 32, "p"], [37, 37, "v"], [54, 54, "v"], [77, 77, "v"], [41, 43, "p"], [29, 29, "v"], [48, 48, "v"], [37, 37, "v"], [54, 54, "v"], [77, 77, "v"], [63, 63, "v"], [37, 37, "v"], [54, 54, "v"], [77, 77, "v"], [37, 37, "v"], [54, 54, "v"], [77, 77, "v"]], [[100, 100, "v"], [100, 100, "v"], [100, 100, "v"], [96, 96, "p"], [100, 100, "v"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [7, 9, "a"], [14, 14, "a"]], [[23, 24, "a"], [29, 29, "v"], [37, 37, "v"], [41, 43, "a"], [48, 48, "v"], [63, 63, "v"]], [[100, 100, "v"], [106, 106, "v"]]], "predicted_relations": [[], [[29, 29, 20, 24, "USED-FOR"], [29, 29, 32, 32, "USED-FOR"], [29, 29, 41, 43, "USED-FOR"], [48, 48, 41, 43, "USED-FOR"], [37, 37, 20, 24, "USED-FOR"], [37, 37, 41, 43, "USED-FOR"], [54, 54, 41, 43, "USED-FOR"], [29, 29, 20, 24, "USED-FOR"], [29, 29, 32, 32, "USED-FOR"], [29, 29, 41, 43, "USED-FOR"], [48, 48, 41, 43, "USED-FOR"], [37, 37, 20, 24, "USED-FOR"], [37, 37, 41, 43, "USED-FOR"], [54, 54, 41, 43, "USED-FOR"], [63, 63, 41, 43, "USED-FOR"], [37, 37, 20, 24, "USED-FOR"], [37, 37, 41, 43, "USED-FOR"], [54, 54, 41, 43, "USED-FOR"], [37, 37, 20, 24, "USED-FOR"], [37, 37, 41, 43, "USED-FOR"], [54, 54, 41, 43, "USED-FOR"]], []]}
{"doc_key": "2106.07229-937c9abd-7a18-4c23-81ba-4c02a8e37c74", "sentences": [["We", "simulate", "the", "proposed", "model", "by", "the", "SEAL", "library", "released", "by", "Microsoft", "."], ["Our", "simulation", "environment", "is", "a", "dual", "Intel", "Xeon", "Platinum", "8280", "CPU", "-LRB-", "112", "cores", "-RRB-", "with", "512GB", "memory", "."], ["We", "allocate", "one", "thread", "per", "one", "channel", "of", "each", "layer", "by", "using", "the", "OpenMP", "library", "to", "improve", "the", "execution", "speed", "of", "the", "ResNet-20", "."]], "ner": [[[7, 8, "a"]], [], [[45, 46, "a"], [54, 54, "a"]]], "relations": [[], [], []], "predicted_ner": [[[4, 4, "a"]], [[25, 25, "v"], [29, 29, "v"]], [[34, 34, "v"], [37, 37, "v"], [54, 54, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2106.07229-f4cf5255-9177-42ec-831e-f42e4258158f", "sentences": [["The", "model", "parameters", "are", "prepared", "by", "the", "following", "training", "method", "."], ["We", "use", "32", "x", "32", "color", "images", ",", "subtract", "the", "mean", "of", "the", "pixels", "in", "the", "training", "dataset", ",", "and", "adopt", "a", "data", "argumentation", "method", "such", "as", "shifting", "and", "mirroring", "horizontally", "for", "training", "."], ["We", "adopt", "the", "He", "initialization", "as", "the", "weight", "initialization", "and", "no", "dropout", "."], ["We", "train", "the", "model", "with", "32", "\\", "-LRB-", "\\times", "\\", "-RRB-", "32", "mini-batches", "and", "cross-entropy", "loss", "function", "."], ["The", "learning", "rate", "starts", "with", "a", "0.001", "learning", "rate", "divided", "by", "10", "after", "80", "epochs", "and", "100", "after", "120", "epochs", "during", "training", "."], ["The", "classification", "accuracy", "with", "the", "trained", "model", "parameters", "is", "91.89", "%", ",", "which", "is", "tested", "with", "10,000", "images", "."]], "ner": [[], [], [[48, 49, "a"]], [], [[88, 90, "c"], [92, 92, "v"], [93, 95, "c"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[13, 13, "v"], [15, 15, "v"]], [], [[63, 63, "v"], [69, 69, "v"], [72, 72, "a"]], [[77, 78, "p"], [82, 82, "v"], [83, 84, "p"], [87, 87, "v"], [89, 89, "v"], [90, 90, "p"], [92, 92, "v"], [94, 94, "v"], [95, 95, "p"]], [[108, 109, "v"], [115, 115, "v"]]], "predicted_relations": [[], [], [], [], [[88, 90, 92, 92, "USED-FOR"], [93, 95, 92, 92, "USED-FOR"]], []]}
{"doc_key": "2103.00488-83ce61d0-9320-4667-a381-0f90f258a5db", "sentences": [["The", "batch", "size", "used", "in", "our", "experiments", "is", "32", "."], ["We", "train", "each", "model", "for", "15", "epochs", "."], ["The", "initial", "learning", "rate", "for", "the", "text", "encoder", "is", "\\", "-LRB-", "1.0", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "for", "other", "parameters", ",", "the", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "5.0", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "evaluate", "our", "model", "on", "the", "validation", "set", "at", "each", "epoch", "."], ["If", "the", "macro", "F1", "score", "does", "n't", "increase", ",", "we", "then", "decay", "the", "learning", "rate", "by", "a", "factor", "of", "0.1", "."], ["The", "minimum", "learning", "rate", "is", "\\", "-LRB-", "5.0", "\\times", "10^", "-LCB-", "-7", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "Adam", "optimizer", "-LSB-", "11", "-RSB-", "in", "all", "our", "experiments", "."]], "ner": [[], [], [[19, 21, "a"], [44, 46, "a"], [24, 25, "p"], [40, 41, "p"]], [], [], [[95, 97, "c"]], [[112, 113, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "p"], [8, 8, "v"]], [[15, 15, "v"], [16, 16, "p"]], [[20, 21, "p"], [29, 29, "v"], [45, 46, "p"], [52, 52, "v"]], [[64, 64, "a"]], [[86, 87, "p"], [92, 92, "v"]], [[96, 97, "p"], [101, 101, "v"]], [[112, 112, "a"]]], "predicted_relations": [[], [], [[24, 25, 19, 21, "USED-FOR"], [40, 41, 19, 21, "USED-FOR"], [40, 41, 44, 46, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2110.13675-4919f217-0334-43c3-83d7-cf9f5e2401bc", "sentences": [["We", "conduct", "all", "experiments", "on", "two", "popular", "benchmarks", ",", "i.e.", ",", "PASCAL", "VOC", "-LSB-", "8", "-RSB-", "and", "MS", "COCO", "-LSB-", "21", "-RSB-", "."], ["On", "the", "PASCAL", "VOC", "benchmark", ",", "we", "train", "all", "models", "on", "the", "trainval", "set", "2007+2012", "-LRB-", "containing", "\\", "-LRB-", "16,551\\", "-RRB-", "images", "from", "20", "categories", "-RRB-", "and", "evaluate", "them", "on", "the", "test", "set", "2007", "-LRB-", "containing", "\\", "-LRB-", "4,952\\", "-RRB-", "images", "-RRB-", "-LSB-", "8", "-RSB-", "."], ["On", "the", "MS", "COCO", "benchmark", ",", "we", "train", "all", "models", "on", "the", "training", "set", "2017", "-LRB-", "containing", "118K", "images", "from", "80", "categories", "-RRB-", "and", "evaluate", "them", "on", "the", "val", "set", "2017", "-LRB-", "containing", "5K", "images", "-RRB-", "-LSB-", "21", "-RSB-", "."], ["We", "train", "all", "state-of-the-art", "models", "with", "the", "original", "implementation", "released", "by", "the", "authors", "."], ["Specifically", ",", "we", "follow", "the", "original", "implementation", "'s", "training", "protocol", "with", "default", "parameters", "and", "the", "number", "of", "training", "epochs", "with", "different", "losses", "-LSB-", "30", "-RSB-", ",", "-LSB-", "31", "-RSB-", ",", "-LSB-", "42", "-RSB-", ",", "-LSB-", "3", "-RSB-", "."], ["Implementation", "details", "of", "all", "models", "are", "given", "in", "Appendix", "REF", "."], ["All", "experiments", "are", "run", "with", "NVIDIA", "V100", "GPUs", "."], ["Code", "is", "available", "at", "https", ":", "//github.com/Jacobi93/Alpha-IoU", "."]], "ner": [[[11, 12, "a"], [17, 18, "a"]], [[25, 26, "a"]], [[71, 72, "a"]], [[116, 117, "a"]], [[128, 129, "a"], [131, 132, "p"], [134, 135, "v"], [138, 141, "v"], [142, 144, "c"]], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [11, 12, "a"], [17, 18, "a"]], [[25, 26, "a"], [42, 42, "v"], [46, 46, "v"], [61, 61, "v"]], [[86, 86, "v"], [89, 89, "v"], [102, 102, "v"]], [], [], [], [], []], "predicted_relations": [[], [], [], [], [[131, 132, 128, 129, "USED-FOR"], [134, 135, 131, 132, "USED-FOR"], [138, 141, 131, 132, "USED-FOR"], [142, 144, 138, 141, "USED-FOR"]], [], [], []]}
{"doc_key": "2110.13675-9eb43b4c-a0d3-4f10-9a19-e93005c33209", "sentences": [["YOLOv5", "."], ["We", "train", "YOLOv5s", "and", "YOLOv5x", "with", "different", "losses", "following", "the", "original", "code", "'s", "training", "protocol", "at", "https", ":", "//github.com/ultralytics/yolov5", "with", "the", "released", "version", "being", "v4.0", "."], ["We", "train", "both", "models", "from", "scratch", "using", "the", "same", "hyperparaemter", "in", "the", "file", "named", "``", "hyp.scratch.yaml", "''", "."], ["The", "configuration", "is", "set", "following", "the", "file", "``", "yolov5s.yaml", "''", "for", "YOLOv5s", "and", "``", "yolov5x.yaml", "''", "for", "YOLOv5x", ",", "respectively", "."], ["The", "batch", "size", "is", "64", ",", "the", "initial", "learning", "rate", "is", "\\", "-LRB-", "0.01\\", "-RRB-", ",", "and", "the", "number", "of", "training", "epochs", "is", "300", "in", "all", "experiments", "."], ["The", "file", "``", "voc.yaml", "''", "is", "set", "for", "models", "trained", "on", "PASCAL", "VOC", "while", "the", "file", "``", "coco.yaml", "''", "is", "set", "for", "those", "trained", "on", "MS", "COCO", "."]], "ner": [[[0, 0, "a"]], [], [[43, 43, "a"]], [[54, 54, "a"], [60, 60, "a"]], [[68, 69, "p"], [71, 71, "v"], [74, 76, "p"], [80, 80, "v"], [85, 88, "p"], [90, 90, "v"]], [[98, 98, "a"], [112, 112, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[4, 4, "a"], [6, 6, "a"], [26, 26, "a"]], [], [[57, 57, "a"], [63, 63, "a"]], [[68, 69, "p"], [71, 71, "v"], [75, 76, "p"], [80, 80, "v"], [90, 90, "v"], [91, 93, "c"]], [[98, 98, "a"]]], "predicted_relations": [[], [], [], [], [[90, 90, 85, 88, "USED-FOR"]], []]}
{"doc_key": "2110.13675-01deec56-0a02-4a29-b87d-f70a3eaa4f23", "sentences": [["Faster", "R-CNN", "."], ["We", "train", "Faster", "R-CNN", "with", "different", "losses", "following", "the", "original", "code", "'s", "training", "protocol", "at", "https", ":", "//github.com/open-mmlab/mmdetection/tree/master/configs/faster_rcnn", "."], ["The", "configuration", "is", "set", "following", "the", "file", "``", "faster_rcnn_r50_fpn.py", "''", "for", "Faster", "R-CNN", "with", "the", "backbone", "being", "ResNet-50-FPN", "."], ["The", "file", "``", "schedule_1x.py", "''", "is", "set", "for", "models", "trained", "with", "1x", "schedule", "and", "single", "scale", "."], ["The", "checkpoint", "and", "logging", "configuration", "is", "set", "in", "``", "default_runtime.py", "''", "."], ["The", "batch", "size", "is", "16", ",", "the", "initial", "learning", "rate", "is", "\\", "-LRB-", "0.02\\", "-RRB-", ",", "and", "the", "number", "of", "training", "epochs", "is", "12", "in", "all", "experiments", "."], ["The", "file", "``", "coco_detection.py", "''", "is", "set", "for", "models", "trained", "on", "MS", "COCO", "."], ["We", "do", "not", "train", "Faster", "R-CNN", "on", "PASCAL", "VOC", "."]], "ner": [[[0, 1, "a"]], [[5, 6, "a"]], [[33, 34, "a"], [39, 39, "a"]], [], [], [[71, 72, "p"], [74, 74, "v"], [77, 79, "p"], [83, 83, "v"], [88, 91, "p"], [93, 93, "v"]], [[109, 110, "a"]], [[116, 117, "a"], [119, 120, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[6, 6, "a"]], [[34, 34, "a"], [39, 39, "a"]], [[52, 52, "v"]], [], [[71, 72, "p"], [74, 74, "v"], [78, 79, "p"], [83, 83, "v"], [93, 93, "v"], [94, 96, "c"]], [], [[117, 117, "a"]]], "predicted_relations": [[], [], [], [], [], [[93, 93, 88, 91, "USED-FOR"]], [], []]}
{"doc_key": "2110.13675-8759d8a0-a6f3-4c70-83e4-a789502290c7", "sentences": [["DETR", "."], ["We", "train", "DETR", "with", "different", "losses", "following", "the", "original", "code", "'s", "training", "protocol", "at", "https", ":", "//github.com/open-mmlab/mmdetection/tree/master/configs/detr", "."], ["The", "configuration", "is", "set", "following", "the", "file", "``", "detr_r50_8x2_150e_coco.py", "''", "for", "DETR", "with", "the", "backbone", "being", "ResNet-50", "."], ["``", "8x2", "''", "stands", "for", "using", "8", "GPUs", "-LRB-", "we", "use", "NVIDIA", "V100", "GPUs", "-RRB-", "in", "parallel", "with", "2", "images", "trained", "on", "every", "GPU", "-LRB-", "i.e.", ",", "batch", "size", "is", "16", "-RRB-", "."], ["The", "number", "of", "training", "epochs", "is", "150", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "the", "first", "100", "epochs", "and", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "the", "rest", "50", "epochs", "."], ["The", "checkpoint", "and", "logging", "configuration", "is", "set", "in", "``", "default_runtime.py", "''", "."], ["The", "file", "``", "coco_detection.py", "''", "is", "set", "for", "models", "trained", "on", "MS", "COCO", "."], ["We", "also", "modify", "it", "for", "models", "trained", "on", "PASCAL", "VOC", "."]], "ner": [[[0, 0, "a"]], [[4, 4, "a"]], [[31, 31, "a"], [34, 34, "p"], [36, 36, "v"]], [[65, 66, "p"], [68, 68, "v"]], [], [[80, 82, "p"], [95, 99, "c"], [112, 116, "c"]], [], [[141, 142, "a"]], [[152, 153, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [[4, 4, "a"]], [[31, 31, "a"], [36, 36, "a"]], [[39, 39, "v"], [44, 44, "v"], [56, 56, "v"], [65, 66, "p"], [68, 68, "v"]], [[74, 75, "p"], [77, 77, "v"]], [[81, 82, "p"], [98, 98, "v"], [99, 99, "p"], [115, 115, "v"], [116, 116, "p"]], [], [], []], "predicted_relations": [[], [], [[36, 36, 34, 34, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2104.14090-f9413fbc-3b89-42f2-a067-81b35c33c999", "sentences": [["For", "the", "ellipse", "dataset", ",", "we", "train", "the", "unrolled", "network", "using", "a", "batch", "size", "of", "15", "for", "60", "epochs", "."], ["The", "F-FPN", "network", "training", "used", "a", "batch-size", "of", "15", "for", "50", "epochs", "."], ["The", "unrolled", "network", "architecture", "contains", "20", "total", "layers", "-LRB-", "i.e", "."], ["update", "steps", "-RRB-", "\u2013", "the", "number", "of", "layers", "was", "chosen", "on", "the", "memory", "capacity", "of", "the", "GPU", "."]], "ner": [[[8, 9, "a"], [12, 13, "p"], [15, 15, "v"], [0, 3, "c"], [15, 15, "v"], [18, 18, "p"], [17, 17, "v"], [0, 3, "c"], [12, 13, "p"], [15, 15, "v"], [18, 18, "p"]], [[28, 28, "v"], [28, 28, "v"], [20, 23, "c"], [31, 31, "p"], [30, 30, "v"], [20, 23, "c"], [21, 22, "a"], [28, 28, "v"], [20, 23, "c"], [31, 31, "p"], [30, 30, "v"], [20, 23, "c"]], [[34, 35, "a"], [38, 38, "v"]], [[49, 51, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 9, "a"], [12, 13, "p"], [15, 15, "v"], [17, 17, "v"], [18, 18, "p"]], [[21, 22, "a"], [26, 26, "p"], [28, 28, "v"], [30, 30, "v"], [31, 31, "p"]], [[38, 38, "v"]], []], "predicted_relations": [[[12, 13, 8, 9, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [0, 3, 17, 17, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [18, 18, 8, 9, "USED-FOR"], [17, 17, 18, 18, "USED-FOR"], [17, 17, 18, 18, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [0, 3, 17, 17, "USED-FOR"], [0, 3, 15, 15, "USED-FOR"], [12, 13, 8, 9, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 18, 18, "USED-FOR"], [18, 18, 8, 9, "USED-FOR"]], [[28, 28, 31, 31, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [31, 31, 21, 22, "USED-FOR"], [30, 30, 31, 31, "USED-FOR"], [30, 30, 31, 31, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [28, 28, 31, 31, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [31, 31, 21, 22, "USED-FOR"], [30, 30, 31, 31, "USED-FOR"], [30, 30, 31, 31, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"], [20, 23, 28, 28, "USED-FOR"], [20, 23, 30, 30, "USED-FOR"]], [], []]}
{"doc_key": "2104.14090-846866f0-8093-46a2-bac9-8e5e87bd6055", "sentences": [["For", "the", "LoDoPab", "dataset", ",", "we", "train", "the", "unrolled", "and", "F-FPN", "networks", "using", "a", "batch-size", "of", "50", "for", "50", "epochs", "total", "."], ["The", "unrolled", "network", "architecture", "contains", "14", "total", "layers", "-LRB-", "i.e", "."], ["update", "steps", "-RRB-", "\u2013", "the", "number", "of", "layers", "was", "chosen", "on", "the", "memory", "capacity", "of", "the", "GPU", "."]], "ner": [[[2, 3, "a"], [8, 11, "a"], [14, 14, "p"], [19, 20, "p"]], [[27, 27, "v"]], [[38, 40, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 3, "a"], [10, 11, "a"], [14, 14, "p"], [16, 16, "v"], [18, 18, "v"], [19, 19, "p"]], [[27, 27, "v"]], []], "predicted_relations": [[[14, 14, 2, 3, "USED-FOR"], [14, 14, 8, 11, "USED-FOR"], [19, 20, 8, 11, "USED-FOR"]], [], []]}
{"doc_key": "2101.02697-b13285b1-575c-41b3-9d9d-54bd742d07c2", "sentences": [["Our", "capture", "setup", "consists", "of", "53", "cameras", "positioned", "around", "the", "subject", "."], ["For", "each", "subject", ",", "we", "record", "a", "set", "of", "30", "expressions", "with", "a", "hair-cap", "."], ["And", "a", "neutral", "expression", "with", "no", "hair-cap", "."], ["Each", "frame", "is", "fit", "with", "a", "3D", "face", "model", "including", "rigid", "head", "pose", "which", "we", "use", "to", "center", "the", "volume", "between", "different", "identities", "and", "expressions", "."], ["We", "do", "not", "use", "any", "of", "the", "mesh", "information", "during", "training", "."], ["We", "train", "our", "network", "on", "50", "subjects", "using", "40", "viewpoints", "and", "test", "on", "held", "out", "viewpoints", "."], ["Additionally", ",", "for", "the", "expression-based", "model", "we", "train", "our", "network", "on", "25", "expressions", "and", "test", "on", "the", "remaining", "expressions", "."], ["During", "training", ",", "we", "divide", "each", "target", "image", "into", "a", "\\", "-LRB-", "16", "\\times", "16\\", "-RRB-", "grid", ",", "and", "randomly", "sample", "a", "ray", "from", "each", "grid", "location", "for", "a", "total", "of", "256", "rays", "per", "training", "image", "."], ["Further", ",", "we", "sample", "\\", "-LRB-", "n_s=128\\", "-RRB-", "points", "along", "the", "ray", "while", "clamping", "the", "sample", "points", "to", "lie", "in", "a", "unit", "volume", "cube", "."], ["We", "train", "our", "model", "with", "a", "batch-size", "of", "4", "."], ["Our", "model", "takes", "around", "24", "hours", "to", "converge", "on", "4", "Nvidia", "Tesla", "V100s", "."]], "ner": [[], [], [], [[41, 43, "a"]], [], [], [], [], [], [[180, 180, "v"]], [[191, 191, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"]], [[21, 21, "v"]], [], [], [], [[76, 76, "a"], [78, 78, "v"], [81, 81, "v"]], [[99, 99, "a"], [101, 101, "v"]], [[122, 122, "v"], [124, 124, "v"], [141, 141, "v"]], [], [[175, 175, "a"], [178, 178, "p"], [180, 180, "v"]], [[183, 183, "a"], [186, 186, "v"], [191, 191, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2109.02903-5d1638a8-9ccf-4409-a12c-d5dd5c561918", "sentences": [["For", "fine-tuning", ",", "we", "use", "a", "single", "GPU", "for", "bilingual", "models", "and", "8", "GPUs", "for", "multilingual", "models", "."], ["We", "use", "dropouts", "of", "0.1", ",", "label", "smoothing", "of", "0.1", ",", "warmup", "of", "16,000", "steps", ",", "2048", "tokens", "per", "batch", "per", "GPU", ",", "learning", "rate", "of", "0.001", "and", "weight", "decay", "of", "0.00001", "with", "the", "ADAM", "optimizer", "for", "training", "."], ["For", "mBART50", ",", "we", "use", "dropouts", "of", "0.3", ",", "warmup", "of", "16,000", "steps", ",", "512", "tokens", "per", "batch", "per", "GPU", ",", "and", "learning", "rate", "of", "0.00003.A", "small", "learning", "rate", "is", "needed", "since", "we", "can", "train", "on", "very", "small", "batches", "given", "the", "large", "model", "size", "."], ["For", "unidirectional", "and", "multilingual", "models", "trained", "from", "scratch", "on", "PMI", "and", "PIB", "data", ",", "we", "use", "smaller", "hidden", "and", "filter", "sizes", "of", "512", "and", "2048", ",", "respectively", ",", "keeping", "all", "other", "hyperparameters", "the", "same", "as", "for", "IndicBART", "."], ["This", "is", "because", "the", "corpora", "sizes", "are", "rather", "small", "and", "a", "small", "model", "should", "be", "sufficient", "."], ["For", "consistency", "of", "training", "we", "use", "the", "same", "IndicBART", "vocabularyNaturally", ",", "we", "use", "unified", "script", "vocabularies", "when", "we", "use", "the", "unified", "script", "IndicBART", "model", "."], ["across", "all", "experimentsExperiments", "on", "mBart50", "will", "use", "the", "vocabularies", "specific", "to", "these", "models", ".."]], "ner": [[], [[52, 53, "a"], [41, 42, "p"], [44, 44, "v"], [46, 47, "p"], [49, 49, "v"], [20, 20, "a"], [22, 22, "v"], [27, 27, "v"], [24, 25, "a"], [22, 22, "v"], [27, 27, "v"], [29, 29, "a"], [32, 32, "p"], [31, 31, "v"], [35, 39, "a"], [34, 34, "v"], [34, 34, "v"]], [[79, 80, "p"], [84, 85, "p"], [82, 82, "v"], [58, 58, "c"], [62, 62, "a"], [64, 64, "v"], [58, 58, "c"], [66, 66, "a"], [69, 69, "p"], [68, 68, "v"], [72, 76, "a"], [71, 71, "v"], [58, 58, "c"], [71, 71, "v"]], [[126, 126, "v"], [124, 124, "v"], [119, 122, "a"], [124, 124, "v"], [103, 114, "c"], [126, 126, "v"], [103, 114, "c"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [12, 12, "v"]], [[20, 20, "p"], [22, 22, "v"], [24, 25, "p"], [27, 27, "v"], [29, 29, "p"], [31, 31, "v"], [34, 34, "v"], [41, 42, "p"], [44, 44, "v"], [46, 47, "p"], [49, 49, "v"], [52, 52, "a"]], [[58, 58, "a"], [62, 62, "p"], [64, 64, "v"], [66, 66, "p"], [68, 68, "v"], [71, 71, "v"], [79, 80, "p"], [84, 85, "p"]], [[124, 124, "v"], [126, 126, "v"], [138, 138, "a"]], [], [[165, 165, "a"], [179, 180, "a"]], [[186, 186, "a"]]], "predicted_relations": [[], [[41, 42, 20, 20, "USED-FOR"], [41, 42, 29, 29, "USED-FOR"], [41, 42, 35, 39, "USED-FOR"], [44, 44, 46, 47, "USED-FOR"], [46, 47, 20, 20, "USED-FOR"], [46, 47, 24, 25, "USED-FOR"], [46, 47, 29, 29, "USED-FOR"], [49, 49, 46, 47, "USED-FOR"], [22, 22, 32, 32, "USED-FOR"], [27, 27, 32, 32, "USED-FOR"], [22, 22, 32, 32, "USED-FOR"], [27, 27, 32, 32, "USED-FOR"], [32, 32, 20, 20, "USED-FOR"], [32, 32, 24, 25, "USED-FOR"], [32, 32, 29, 29, "USED-FOR"], [31, 31, 32, 32, "USED-FOR"], [34, 34, 32, 32, "USED-FOR"], [34, 34, 32, 32, "USED-FOR"]], [[79, 80, 62, 62, "USED-FOR"], [79, 80, 66, 66, "USED-FOR"], [79, 80, 72, 76, "USED-FOR"], [84, 85, 66, 66, "USED-FOR"], [84, 85, 72, 76, "USED-FOR"], [64, 64, 69, 69, "USED-FOR"], [69, 69, 62, 62, "USED-FOR"], [69, 69, 66, 66, "USED-FOR"], [68, 68, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"]], [[103, 114, 126, 126, "USED-FOR"], [103, 114, 124, 124, "USED-FOR"], [103, 114, 124, 124, "USED-FOR"], [103, 114, 126, 126, "USED-FOR"], [103, 114, 126, 126, "USED-FOR"], [103, 114, 124, 124, "USED-FOR"], [103, 114, 124, 124, "USED-FOR"], [103, 114, 126, 126, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.02903-efc67a8c-3558-4daf-b5e0-b8a1892ef44c", "sentences": [["We", "train", "our", "models", "till", "convergence", "on", "the", "development", "set", "BLEU", "scores", "-LSB-", "33", "-RSB-", "which", "are", "computed", "via", "greedy", "decoding", "every", "1,000", "batches", "."], ["For", "multilingual", "models", "we", "use", "the", "global", "development", "set", "BLEU", "score", ",", "an", "average", "of", "BLEU", "scores", "for", "each", "language", "pair", "."], ["Different", "from", "most", "previous", "works", ",", "instead", "of", "decoding", "a", "single", "final", "model", ",", "we", "choose", "a", "particular", "model", "checkpoint", "for", "a", "language", "pair", "with", "the", "highest", "development", "set", "BLEU", "score", "for", "that", "pair", "."], ["Therefore", ",", "we", "treat", "multilingualism", "as", "a", "way", "to", "get", "a", "-LRB-", "potentially", "-RRB-", "different", "model", "per", "language", "pair", "leading", "to", "the", "best", "BLEU", "scores", "for", "that", "pair", "and", "not", "as", "a", "way", "to", "get", "a", "single", "model", "that", "gives", "the", "best", "performance", "for", "each", "language", "pair", "."], ["During", "decoding", "the", "test", "sets", ",", "we", "use", "beam", "search", "with", "a", "beam", "of", "size", "4", "and", "a", "length", "penalty", "of", "0.8", "."], ["We", "report", "the", "BLEU", "scores", "on", "the", "decoded", "results", "computed", "using", "sacreBLEUBLEU+case.mixed+numrefs.1+smooth.exp+tok.13a", "+version.1.5.1", "-LSB-", "35", "-RSB-", "."]], "ner": [[[10, 11, "a"]], [[40, 41, "a"], [31, 35, "a"]], [], [[105, 106, "a"]], [[138, 139, "a"], [145, 145, "v"], [148, 149, "p"], [151, 151, "v"]], [[156, 157, "a"], [164, 165, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[22, 22, "v"]], [], [], [], [[138, 139, "a"], [145, 145, "v"], [151, 151, "v"]], []], "predicted_relations": [[], [], [], [], [[145, 145, 148, 149, "USED-FOR"], [148, 149, 138, 139, "USED-FOR"], [151, 151, 148, 149, "USED-FOR"]], []]}
{"doc_key": "2110.15709-c6e99d8b-c8c5-464e-b9d4-3b4ec21d9523", "sentences": [["The", "datasets", "used", "for", "training", "the", "model", "are", "Data", "2", ",", "3", ",", "4", "presented", "in", "Section", "."], ["Moreover", ",", "the", "text", "preprocessing", "phase", ",", "carried", "out", "before", "the", "training", "of", "the", "models", ",", "was", "composed", "of", "a", "specific", "text", "cleaning", "for", "BERtikal", ",", "performed", "using", "the", "clean_bert", "function", "presented", "in", "Section", "REF", "."], ["That", "function", "makes", "few", "changes", "to", "the", "texts", "and", "keeps", "the", "uppercased", "letters", "."]], "ner": [[[8, 13, "a"]], [[47, 48, "a"], [39, 40, "p"]], [[65, 66, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[42, 42, "a"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2110.15709-3e9b3589-012a-44d8-a07c-82fb02386f7b", "sentences": [["Our", "model", "was", "trained", "from", "the", "checkpoint", "made", "available", "in", "Neuralmind", "'s", "Github", "repositoryhttps", ":", "//github.com/neuralmind-ai/portuguese-bert", "-", "Accessed", "on", "07/30/2021", "."], ["by", "the", "authors", "of", "a", "recent", "research", "-LSB-", "12", "-RSB-", "."], ["In", "the", "training", "phase", ",", "we", "-LRB-", "i", "-RRB-", "kept", "the", "configuration", "of", "the", "model", "and", "vocabulary", "used", "by", "the", "authors", ",", "-LRB-", "ii", "-RRB-", "used", "the", "Masked", "Language", "Model", "-LRB-", "MLM", "-RRB-", "objective", "with", "masking", "probability", "0.15", ",", "-LRB-", "iii", "-RRB-", "used", "one", "epoch", ",", "-LRB-", "iv", "-RRB-", "batch", "size", "equals", "to", "4", "texts", ",", "and", "-LRB-", "v", "-RRB-", "made", "use", "of", "a", "Tesla", "T4", "GPU", "."], ["The", "optimizer", "settings", "have", "been", "set", "as", "the", "default", "for", "the", "Transformers", "package", "from", "the", "company", "Hugging", "FaceSee", "https", ":", "//github.com/huggingface/transformers/blob/master/src/transformers/training_args.py", "-", "Accessed", "on", "10/22/2020", "."], ["and", "the", "full", "training", "took", "approximately", "one", "week", "to", "be", "completed", "."]], "ner": [[], [], [[67, 68, "p"], [69, 69, "v"], [96, 98, "a"]], [[111, 112, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [10, 10, "a"]], [], [[69, 69, "v"], [75, 75, "v"], [76, 76, "p"], [85, 85, "v"]], [[116, 117, "a"]], [[132, 132, "v"]]], "predicted_relations": [[], [], [[69, 69, 67, 68, "USED-FOR"]], [], []]}
{"doc_key": "2103.06627-e97bfda9-57a8-4b87-aaca-1f605157facf", "sentences": [["We", "adopt", "ResNet50", "as", "the", "backbone", "network", "."], ["Models", "are", "trained", "on", "MS1Mv2", "-LSB-", "13", "-RSB-", ",", "-LSB-", "8", "-RSB-", "for", "20", "epochs", "with", "batch", "size", "512", "and", "initial", "learning", "rate", "0.1", ",", "dropped", "by", "0.1", "every", "5", "epochs", "."], ["512", "samples", "of", "the", "last", "iteration", "are", "used", "for", "visualization", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[2, 2, "a"]], [[12, 12, "a"], [22, 22, "a"], [38, 38, "a"], [24, 25, "p"], [26, 26, "v"], [31, 31, "v"], [35, 35, "v"], [28, 30, "c"], [33, 38, "a"]], [[40, 40, "v"], [40, 45, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[12, 12, "a"], [21, 21, "v"], [22, 22, "p"], [24, 25, "p"], [26, 26, "v"], [29, 30, "p"], [31, 31, "v"], [35, 35, "v"], [37, 37, "v"], [38, 38, "p"]], [[40, 40, "v"]], []], "predicted_relations": [[], [[24, 25, 12, 12, "USED-FOR"], [28, 30, 31, 31, "USED-FOR"], [28, 30, 35, 35, "USED-FOR"]], [], []]}
{"doc_key": "2111.03930-eb5d3cf8-e36f-419f-b101-71cab96698a3", "sentences": [["As", "mentioned", "in", "the", "previous", "section", ",", "our", "Tip-Adapter", "has", "two", "versions", "."], ["The", "first", "version", "is", "training-free", ",", "which", "directly", "sets", "the", "adapter", "'s", "MLP", "weights", "following", "Eq", "."], ["-LRB-", "REF", "-RRB-", "."], ["The", "second", "version", "allows", "further", "fine-tuning", "of", "the", "adapter", "initialized", "by", "the", "properly", "set", "weights", "."], ["The", "two", "version", "are", "denoted", "as", "Tip-Adapter", "and", "Tip-Adapter-F", "in", "this", "section", ",", "respectively", "."], ["Each", "model", "is", "trained", "with", "1", ",", "2", ",", "4", ",", "8", ",", "and", "16", "few-shot", "training", "sets", ",", "and", "tested", "on", "the", "full", "test", "sets", "."], ["For", "the", "CLIP", "backbone", ",", "we", "utilize", "ResNet-50", "-LSB-", "23", "-RSB-", "as", "the", "visual", "encoder", "and", "a", "transformer", "-LSB-", "13", "-RSB-", "as", "the", "textual", "encoder", "."], ["In", "terms", "of", "prompt", "design", ",", "we", "adopt", "prompt", "ensembling", "in", "-LSB-", "50", "-RSB-", ",", "which", "inputs", "7", "templates", "into", "the", "CLIP", "textual", "encoder", "and", "then", "averages", "them", "as", "the", "final", "prompt", "."], ["The", "7", "templates", "are", ":", "\u201c", "itap", "of", "a", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", ",", "\u201c", "a", "bad", "photo", "of", "the", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", ",", "\u201c", "a", "origami", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", ",", "\u201c", "a", "photo", "of", "the", "large", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", ",", "\u201c", "a", "-LSB-", "CLASS", "-RSB-", "in", "a", "video", "game.", "\u201d", ",", "\u201c", "art", "of", "the", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", "and", "\u201c", "a", "photo", "of", "the", "small", "-LSB-", "CLASS", "-RSB-", ".", "\u201d", "."], ["To", "fine-tune", "Tip-Adapter-F", ",", "we", "train", "it", "with", "a", "batch", "size", "of", "256", ",", "and", "use", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "-LSB-", "33", "-RSB-", ",", "-LSB-", "41", "-RSB-", "with", "a", "learning", "rate", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "a", "cosine", "scheduler", "."], ["In", "contrast", "to", "the", "200-epoch", "training", "in", "CoOp", "and", "CLIP-Adapter", ",", "Tip-Adapter-F", "only", "requires", "20", "epochs", "for", "fine-tuning", "and", "has", "super-fast", "convergence", "speed", ",", "saving", "much", "computational", "cost", "for", "training", "."]], "ner": [[], [], [], [], [], [], [[99, 99, "a"], [109, 109, "a"]], [], [], [[263, 264, "p"], [267, 267, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [10, 10, "v"]], [], [], [], [[51, 51, "v"], [56, 56, "a"], [58, 58, "a"]], [[70, 70, "v"], [72, 72, "v"], [79, 79, "v"]], [[99, 99, "a"]], [[126, 127, "a"], [135, 135, "v"]], [[152, 152, "v"]], [[234, 234, "a"], [241, 242, "p"], [244, 244, "v"], [248, 253, "a"], [263, 264, "p"], [267, 267, "v"]], [[278, 278, "v"], [281, 281, "a"], [283, 283, "a"], [285, 285, "a"], [288, 288, "v"], [289, 289, "p"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2110.00842-9dbb1709-29af-4b4a-a367-6d249bbd6d61", "sentences": [["The", "task", "description", "is", "tokenized", "into", "words", "."], ["We", "do", "not", "remove", "stop", "words", "or", "lemmatize", "words", "."], ["Embeddings", "for", "words", "are", "obtained", "by", "using", "pretrained", "word2vec", "-LSB-", "17", "-RSB-", "vectors", "-LRB-", "300", "dimensional", "-RRB-", "."], ["Next", ",", "these", "embeddings", "are", "passed", "into", "an", "encoder", "RNN", "made", "of", "LSTM", "cells", "."], ["The", "LSTM", "network", "is", "unidirectional", "with", "hidden", "dimension", "of", "100", "."], ["The", "decoder", "RNN", "is", "also", "unidirectional", "with", "hidden", "dimension", "as", "100", "."], ["The", "last", "hidden", "state", "of", "the", "encoder", "RNN", "is", "used", "to", "initialise", "the", "hidden", "state", "of", "the", "decoder", "."], ["We", "train", "each", "model", "for", "400", "epochs", "using", "the", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "."], ["We", "choose", "the", "hyperparameters", "and", "best", "epoch", "for", "each", "model", "by", "obtaining", "results", "on", "the", "validation", "set", "using", "beam", "size", "of", "3", "and", "not", "enforcing", "executability", "."], ["Since", "we", "adapt", "the", "model", "from", "puig2018virtualhome", "the", "size", "of", "network", "is", "still", "same", "with", "around", "3M", "parameters", "."]], "ner": [[], [], [[26, 26, "a"]], [[48, 48, "a"]], [[52, 52, "a"]], [], [], [[102, 103, "a"]], [[126, 127, "p"], [129, 129, "v"], [126, 127, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[26, 26, "a"], [32, 32, "v"], [33, 33, "p"]], [[45, 45, "a"], [48, 49, "a"]], [[52, 53, "a"], [60, 60, "v"]], [[64, 64, "a"], [72, 72, "v"]], [[81, 81, "a"]], [[98, 98, "v"], [99, 99, "p"], [102, 102, "a"]], [[129, 129, "v"]], [[151, 151, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [[126, 127, 126, 127, "USED-FOR"]], []]}
{"doc_key": "2108.10600-027cbe12-30d1-41ad-b6de-8e3bf94945b4", "sentences": [["Dropout", "."], ["Commonly", "used", "as", "regularizer", "in", "convolutional", "neural", "networks", ",", "it", "prevents", "overfitting", "and", "co-adaptation", "of", "the", "feature", "maps", "-LSB-", "30", "-RSB-", "."], ["During", "the", "training", "procedure", "a", "certain", "number", "of", "neurons", "are", "randomly", "removed", ",", "dropping", "units", "with", "a", "probability", "\\", "-LRB-", "p\\", "-RRB-", "."], ["We", "fix", "the", "probability", "of", "dropping", "a", "connection", "equal", "to", "\\", "-LRB-", "50\\", "%", "\\", "-RRB-", ",", "i.e", "."], ["\\", "-LRB-", "\\textit", "-LCB-", "p", "-RCB-", "=", "0.5\\", "-RRB-", "."]], "ner": [[[0, 0, "a"]], [], [[44, 44, "p"]], [], [[70, 70, "p"], [73, 73, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 0, "a"]], [], [], [[59, 60, "v"]], [[73, 73, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.10600-86fe64b8-8809-4965-835f-e21cf4be3de8", "sentences": [["All", "the", "training", "parameters", "are", "fixed", "as", "in", "-LSB-", "17", "-RSB-", "."], ["The", "Adam", "optimizer", "'s", "parameters", "\\", "-LRB-", "beta1\\", "-RRB-", "and", "\\", "-LRB-", "beta2\\", "-RRB-", "have", "been", "set", "to", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "0.999\\", "-RRB-", "respectively", "."], ["The", "mini-batch", "size", "has", "been", "set", "to", "100", "."], ["During", "the", "batch", "normalization", "procedure", ",", "the", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "value", "of", "\\", "-LRB-", "10\\textsuperscript", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "has", "been", "added", "to", "the", "mini-batch", "variance", "."], ["In", "order", "to", "compute", "the", "mean", "and", "variance", "of", "the", "training", "samples", ",", "the", "moving", "average", "has", "been", "implemented", "using", "a", "fixed", "decay", "rate", "value", "of", "\\", "-LRB-", "0.999\\", "-RRB-", "."], ["The", "learning", "rates", "parameter", "\\", "-LRB-", "lr\\", "-RRB-", "has", "been", "fixed", "to", "\\", "-LRB-", "10\\textsuperscript", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "maximum", "number", "of", "iterations", "has", "been", "set", "to", "100", ",", "with", "the", "early", "stopping", "patience", "parameter", "equal", "to", "50", "."]], "ner": [[], [[13, 14, "a"], [19, 19, "p"], [32, 32, "v"], [24, 24, "p"], [37, 37, "v"], [37, 37, "v"]], [[42, 43, "p"], [48, 48, "v"], [48, 48, "v"]], [], [[108, 108, "v"], [102, 103, "p"], [108, 108, "v"]], [[117, 117, "p"]], [[141, 141, "v"], [133, 136, "p"], [141, 141, "v"], [145, 148, "p"], [151, 151, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[13, 13, "a"], [32, 32, "v"], [37, 37, "v"]], [[42, 43, "p"], [48, 48, "v"]], [], [[94, 95, "a"], [102, 103, "p"], [108, 108, "v"]], [], [[141, 141, "v"], [151, 151, "v"]]], "predicted_relations": [[], [[19, 19, 13, 14, "USED-FOR"], [24, 24, 13, 14, "USED-FOR"]], [], [], [], [], [[151, 151, 145, 148, "USED-FOR"]]]}
{"doc_key": "2104.02947-22ea99ad-bc53-46c5-9435-ba93facde41e", "sentences": [["We", "use", "the", "bert-base-uncasedhttps", ":", "//huggingface.co/bert-base-uncased", "as", "the", "base", "transformer", "for", "our", "English", "models", "-LRB-", "for", "CA", "and", "IN", "locale", "-RRB-", ",", "camembert-base", "-LSB-", "17", "-RSB-", "https", ":", "//huggingface.co/camembert-base", "as", "the", "base", "transformer", "for", "FR", "locale", ",", "and", "bert-base-multilingual-uncased", "https", ":", "//huggingface.co/bert-base-multilingual-uncased", "as", "the", "base", "transformer", "for", "DE", "locale", "."], ["We", "train", "our", "models", "upto", "10", "epochs", ",", "with", "a", "batch", "size", "of", "16", ",", "Adam", "optimizer", "with", "learning", "rate", "of", "\\", "-LRB-", "2e-5\\", "-RRB-", "with", "a", "schedule", "of", "linear", "warmup", "of", "first", "10000", "steps", "and", "then", "linear", "decay", "."], ["We", "set", "\\", "-LRB-", "\\epsilon", "=1\\", "-RRB-", "in", "the", "loss", "equation", "REF", ",", "and", "\\", "-LRB-", "\\alpha", "=0.4\\", "-RRB-", "in", "the", "inference", "equation", "REF", "."], ["For", "the", "joint", "training", "-LRB-", "CQA", "triplets", "and", "user", "query", "triplets", "-RRB-", ",", "we", "have", "two", "training", "runs", "-LRB-", "data", "mixing", "and", "multi-task", "as", "described", "in", "section", "REF", "-RRB-", "per", "locale", "and", "picked", "the", "best", "models", "-LRB-", "data", "mixing", "for", "CA", ",", "FR", "and", "multi-task", "for", "DE", ",", "IN", "-RRB-", "."], ["We", "use", "the", "Pytorchhttps", ":", "//pytorch.org", ",", "Huggingface", "-LSB-", "29", "-RSB-", "and", "Sentence-Transformers", "-LSB-", "22", "-RSB-", "libraries", "to", "develop", "our", "models", "on", "an", "Nvidia", "V100", "GPU", "and", "hence", "our", "training", "time", "per", "batch", "and", "inference", "time", "per", "sample", "are", "same", "as", "that", "of", "Sentence-Transformers", "with", "BERT", "-LRB-", "base-model", ",", "110M", "parameters", "-RRB-", "."]], "ner": [[[5, 5, "a"], [22, 22, "a"], [28, 28, "a"], [38, 38, "a"], [41, 41, "a"]], [], [[106, 106, "p"], [107, 107, "v"], [99, 100, "a"], [111, 112, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[22, 22, "a"], [38, 38, "a"]], [[53, 53, "a"], [55, 55, "v"], [56, 56, "p"], [60, 61, "p"], [63, 63, "v"], [65, 65, "a"], [68, 69, "p"], [73, 73, "v"], [79, 80, "a"], [83, 83, "v"], [84, 84, "p"], [87, 88, "a"]], [[106, 106, "p"], [107, 107, "v"]], [[130, 130, "v"]], [[173, 173, "a"], [211, 211, "a"], [215, 215, "v"]]], "predicted_relations": [[], [], [[106, 106, 99, 100, "USED-FOR"], [107, 107, 106, 106, "USED-FOR"]], [], []]}
{"doc_key": "2103.01287-b1fab499-1e63-4e44-9054-57e368d67b3c", "sentences": [["Dialogue", "agent", "training", "In", "this", "work", ",", "we", "use", "DQN", "-LSB-", "22", "-RSB-", ",", "which", "is", "an", "off-policy", "RL", "algorithm", ",", "to", "train", "the", "dialogue", "agent", "in", "both", "Step", "1", "and", "Step", "4", "."], ["We", "implemented", "the", "DQN", "algorithm", "by", "utilizing", "the", "RL", "training", "modules", "in", "ConvLab", "."]], "ner": [[[9, 9, "a"]], [[37, 37, "a"]]], "relations": [[], []], "predicted_ner": [[[9, 9, "a"], [29, 29, "v"], [32, 32, "v"]], [[37, 38, "a"], [46, 46, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2103.01287-2e7424c6-beb8-4b1f-98cb-81feb5ed7fa7", "sentences": [["User", "1", "We", "assume", "that", "\\", "-LRB-", "\\textit", "-LCB-", "User", "-RCB-", "_1\\", "-RRB-", "has", "no", "specific", "requirements", "about", "the", "interactions", ",", "and", "he", "only", "cares", "if", "his", "task", "can", "be", "accomplished", "successfully", "with", "fewer", "turns", "."], ["According", "to", "this", "user", "profile", ",", "we", "handcraft", "the", "corresponding", "user", "reward", "function", "\\", "-LRB-", "f_1", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "."], ["Assuming", "the", "interaction", "between", "the", "agent", "and", "\\", "-LRB-", "\\textit", "-LCB-", "User", "-RCB-", "_1\\", "-RRB-", "terminates", "at", "time", "step", "\\", "-LRB-", "m\\", "-RRB-", ",", "and", "the", "task", "status", "is", "Successful", ",", "a", "large", "positive", "value", "will", "be", "returned", "to", "the", "dialogue", "agent", "as", "the", "intermediate", "reward", "for", "the", "final", "system", "action", ":", "\\", "-LRB-", "f_1", "-LRB-", "s_m", ",", "a_m", "-RRB-", "=\\left|r\\right|.\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "2103.01287-44786264-1d3a-4544-a862-478df7769b7a", "sentences": [["User", "3", "We", "design", "a", "new", "user", ",", "\\", "-LRB-", "\\textit", "-LCB-", "User", "-RCB-", "_3\\", "-RRB-", ",", "who", "is", "forward-looking", "as", "described", "in", "Section", "REF", "."], ["After", "each", "interaction", "turn", ",", "\\", "-LRB-", "\\textit", "-LCB-", "User", "-RCB-", "_3\\", "-RRB-", "will", "estimate", "the", "potential", "cost", "to", "finish", "remaining", "tasks", "."], ["This", "feature", "is", "incorporated", "to", "the", "rule-based", "user", "simulator", "."], ["We", "use", "\\", "-LRB-", "goal\\", "-RRB-", "and", "\\", "-LRB-", "goal^", "-LCB-", "\\prime", "-RCB-", "\\", "-RRB-", "to", "denote", "the", "initial", "tasks", "and", "the", "remaining", "tasks", "in", "the", "same", "dialogue", "respectively", "."], ["We", "define", "\\", "-LRB-", "goal-goal^", "-LCB-", "\\prime", "-RCB-", "\\", "-RRB-", "as", "tasks", "that", "have", "been", "completed", "already", "."], ["The", "function", "\\", "-LRB-", "h^", "-LCB-", "\\prime", "-RCB-", "-LRB-", "goal^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "\\", "-RRB-", "is", "defined", "as", ":", "\\", "-LRB-", "h^", "-LCB-", "\\prime", "-RCB-", "-LRB-", "goal^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "=", "\\frac", "-LCB-", "\\textit", "-LCB-", "cost", "-RCB-", "_\\textit", "-LCB-", "-LCB-", "spent", "-RCB-", "-RCB-", "-RCB-", "-LCB-", "h", "-LRB-", "goal-goal^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "-RCB-", "*", "h", "-LRB-", "goal^", "-LCB-", "\\prime", "-RCB-", "-RRB-", "*", "\\gamma", ",", "\\", "-RRB-"]], "ner": [[], [[43, 43, "a"]], [[55, 57, "a"]], [], [], [[144, 144, "a"], [111, 111, "a"], [129, 129, "a"], [154, 154, "a"], [163, 163, "a"], [171, 171, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], [[171, 171, 144, 144, "USED-FOR"], [171, 171, 129, 129, "USED-FOR"], [171, 171, 154, 154, "USED-FOR"], [171, 171, 163, 163, "USED-FOR"]]]}
{"doc_key": "2107.13117-1b5c2606-3a78-49f3-b643-0400feb65713", "sentences": [["We", "initialized", "the", "weights", "of", "the", "conv", "layers", "using", "He", "'s", "initialization", "-LSB-", "161", "-RSB-", "."], ["The", "training", "process", "is", "performed", "for", "165,000", "iterations", "using", "the", "Adam", "optimizer", "-LSB-", "206", "-RSB-", ",", "with", "a", "decay", "rate", "of", "gradient", "moving", "average", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", "and", "a", "decay", "rate", "of", "squared", "gradient", "moving", "average", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", "."], ["We", "used", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "reduced", "it", "by", "0.5", "every", "25", "epochs", "."], ["The", "mini-batch", "size", "was", "32", "training", "patches", "per", "iteration", "."]], "ner": [[[9, 11, "a"]], [[26, 27, "a"], [34, 39, "p"], [43, 43, "v"], [47, 53, "p"], [57, 57, "v"]], [[63, 64, "p"], [78, 78, "v"], [81, 81, "p"], [80, 80, "v"]], [[84, 85, "p"], [87, 87, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"], [9, 9, "a"]], [[22, 22, "v"], [26, 26, "a"], [34, 35, "p"], [37, 39, "a"], [47, 48, "p"], [50, 53, "a"]], [[63, 64, "p"], [68, 71, "v"], [78, 78, "v"], [80, 80, "v"], [81, 81, "p"]], [[84, 85, "p"], [87, 87, "v"]]], "predicted_relations": [[], [[34, 39, 26, 27, "USED-FOR"], [43, 43, 34, 39, "USED-FOR"], [57, 57, 47, 53, "USED-FOR"]], [[78, 78, 81, 81, "USED-FOR"], [80, 80, 81, 81, "USED-FOR"]], []]}
{"doc_key": "2112.02379-6a581d4f-1fdf-4007-8083-6beb32f72d30", "sentences": [["Synthesized", "Testing", "Benchmark", "."], ["For", "the", "reference-based", "evaluation", ",", "we", "synthesize", "turbulence-clean", "image", "pairs", "using", "TurbulenceSim_P2S", "-LSB-", "26", "-RSB-", "which", "is", "the", "current", "state-of-the-art", "turbulence", "simulation", "works", "."], ["The", "synthesis", "is", "conducted", "on", "the", "selected", "first", "100", "images", "of", "CelebAHQ", "-LSB-", "16", "-RSB-", ",", "named", "CelebAHQ100", ",", "and", "the", "parameters", "of", "TurbulenceSim_P2S", "are", "carefully", "selected", "to", "match", "the", "real-world", "turbulence", "images", "."], ["Specifically", ",", "we", "set", "D", ",", "r0", ",", "and", "corr", "as", "\\", "-LRB-", "\\lbrace", "5", ",", "1.25", ",", "-0.01\\rbrace", "\\", "-RRB-", "for", "the", "CelebAHQ100", "simulation", "."], ["The", "synthesized", "image", "pairs", "are", "provided", "in", "the", "supplementary", "document", "in", "8-bit", "sRGB", "format", "with", "a", "resolution", "of", "\\", "-LRB-", "512\\times", "512\\", "-RRB-", "."]], "ner": [[], [[15, 15, "a"]], [[51, 51, "a"], [45, 45, "a"]], [[66, 66, "p"], [76, 76, "v"], [68, 68, "p"], [78, 78, "v"], [71, 71, "p"], [85, 85, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[15, 15, "a"]], [[36, 36, "v"], [39, 39, "a"], [45, 45, "a"], [51, 51, "a"]], [[66, 66, "p"], [68, 68, "p"], [78, 78, "v"], [85, 85, "a"]], [[99, 99, "v"], [100, 100, "a"], [109, 109, "v"]]], "predicted_relations": [[], [], [], [[76, 76, 68, 68, "USED-FOR"], [76, 76, 71, 71, "USED-FOR"]], []]}
{"doc_key": "2112.02379-850adfd7-8562-4a77-b2b5-cec4978b9cec", "sentences": [["Real-world", "Testing", "Benchmark", "."], ["For", "evaluating", "the", "performance", "of", "different", "methods", "on", "real-world", "turbulence", "degraded", "images", "without", "pixel-wise", "corresponding", "ground", "truths", ",", "we", "use", "face", "recognition", "accuracy", "based", "on", "indoor", "reference", "clear", "images", "."], ["The", "authors", "of", "-LSB-", "47", "-RSB-", "provided", "us", "high-quality", "raw", "real-world", "turbulence", "degraded", "faces", "which", "are", "taken", "at", "300", "meters", "from", "the", "camera", "in", "a", "hot", "day", "."], ["In", "addition", "to", "those", "images", ",", "we", "received", "the", "corresponding", "indoor", "face", "images", "without", "turbulence", "for", "reference", "."], ["We", "crop", "and", "wrap", "faces", "with", "the", "pre-trained", "RetinaFace", "-LSB-", "11", "-RSB-", "network", "."], ["The", "final", "dataset", "contains", "images", "from", "89", "separate", "individuals", "each", "having", "3", "turbulence", "degraded", "images", "in", "different", "poses", "."], ["We", "call", "this", "data", "TubFace89", "and", "show", "its", "sampled", "images", "in", "Figure", "REF", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], [[88, 88, "a"]], [], [[117, 117, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[52, 52, "v"]], [], [[88, 88, "a"]], [[100, 100, "v"], [105, 105, "v"]], [[117, 117, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2112.02373-627f541c-de0a-475f-b160-89c1fe320d27", "sentences": [["Our", "model", "implementation", "is", "based", "on", "the", "Pytorch", "framework", "and", "Faiss", "library", "-LSB-", "4", "-RSB-", "."], ["And", "using", "8", "NVIDIA", "Tesla", "V100", "for", "training", "the", "Transformer", "model", "."], ["For", "training", "settings", "."], ["We", "use", "Adamw", "-LSB-", "8", "-RSB-", "as", "the", "optimizer", ",", "the", "initial", "learning", "rate", "of", "model", "finetune", "is", "set", "to", "0.0001", ",", "and", "cosine", "scheduler", "-LSB-", "7", "-RSB-", "is", "used", "to", "adjust", "the", "learning", "rate", "."], ["For", "most", "models", ",", "we", "train", "50", "epochs", "on", "the", "training", "dataset", ",", "and", "train", "200", "epochs", "on", "the", "small", "number", "of", "labeled", "data", "in", "Phase", "1", "."], ["See", "our", "code", "for", "some", "details", "and", "differences", "."], ["Besides", ",", "our", "local", "retrieval", "is", "accelerated", "by", "GPU", "and", "need", "a", "certain", "amount", "of", "memory", "to", "build", "the", "index", "database", "."]], "ner": [[[7, 8, "a"], [10, 11, "a"]], [], [], [[34, 34, "a"], [43, 45, "p"], [52, 52, "v"], [55, 56, "a"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[7, 8, "a"]], [[18, 18, "v"], [25, 26, "a"]], [], [[34, 34, "a"], [44, 45, "p"], [52, 52, "v"], [55, 56, "a"], [65, 66, "p"]], [[74, 74, "v"], [75, 75, "p"], [83, 83, "v"], [84, 84, "p"]], [], []], "predicted_relations": [[], [], [], [[43, 45, 34, 34, "USED-FOR"]], [], [], []]}
{"doc_key": "2104.07149-27c83bfc-eb4a-421d-aeaf-19789e4a2bc7", "sentences": [["We", "fine-tune", "BERT", "for", "up", "to", "40", "epochs", "with", "a", "batch", "size", "of", "32", "."], ["To", "prevent", "over", "fitting", ",", "we", "use", "early", "stopping", "on", "the", "validation", "loss", "."], ["We", "optimize", "BERT", "parameters", "using", "gluonnlp", "'s", "bertadam", "optimizer", "with", "a", "learning", "rate", "of", "5e-5", "and", "no", "weight", "decay", "."], ["These", "are", "the", "default", "hyper-parameters", "provided", "in", "the", "gluon", "tutorial", "for", "intent", "classification", "and", "slot", "labeling", "-LRB-", "https", ":", "//nlp.gluon.ai/model_zoo/intent_cls_slot_labeling/index.html", "-RRB-", "."]], "ner": [[[2, 2, "a"]], [[22, 23, "a"]], [[31, 31, "a"], [34, 37, "a"], [40, 41, "p"], [43, 43, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "v"], [7, 7, "p"], [10, 11, "p"], [13, 13, "v"]], [[22, 23, "a"], [26, 27, "a"]], [[31, 31, "a"], [34, 34, "a"], [36, 36, "a"], [40, 41, "p"], [43, 43, "v"], [46, 47, "p"]], []], "predicted_relations": [[], [], [[40, 41, 31, 31, "USED-FOR"], [40, 41, 34, 37, "USED-FOR"], [43, 43, 40, 41, "USED-FOR"]], []]}
{"doc_key": "2105.04241-d26228ab-e8e8-414d-a157-b065a1e1136c", "sentences": [["All", "ReadTwice", "models", "are", "initialized", "with", "the", "public", "RoBERTa", "-LRB-", "base", "-RRB-", "checkpointhttps", ":", "//dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz", "adapted", "to", "Tensorflow", "by", "-LSB-", "15", "-RSB-", "."], ["Further", ",", "models", "are", "pre-trained", "for", "1M", "steps", "on", "64", "TPU", "cores", "using", "the", "LAMB", "optimizer", "-LSB-", "23", "-RSB-", "."]], "ner": [[], [[37, 38, "a"]]], "relations": [[], []], "predicted_ner": [[[8, 8, "a"]], [[29, 29, "v"], [32, 32, "v"], [37, 37, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2102.09812-2d44f44d-4dde-43cb-9604-a0de2057ea08", "sentences": [["Most", "of", "the", "training", "parameters", "correspond", "to", "the", "implementation", "of", "-LSB-", "37", "-RSB-", ",", "a", "state-of-the-art", "model-based", "RL", "algorithm", "for", "learning", "to", "plan", "in", "latent-space", "from", "image", "observations", "."], ["DLC", "trains", "every", "1000", "environment", "steps", "for", "200", "iterations", "with", "the", "Adam", "optimizer", "-LSB-", "46", "-RSB-", "."], ["The", "batch", "size", "is", "set", "to", "50", "."], ["The", "representation", ",", "value", "and", "actor", "model", "are", "respectively", "trained", "with", "learning", "rates", "6e-4", ",", "6e-4", ",", "and", "8e-5", "."], ["Gradients", "over", "the", "magnitude", "of", "100", "are", "clipped", "for", "all", "models", "."], ["The", "prior", "\\", "-LRB-", "\\sigma", "_", "-LCB-", "\\tau", ",", "s", "-RCB-", "^", "-LCB-", "prior", "-RCB-", "\\", "-RRB-", "and", "posterior", "\\", "-LRB-", "\\sigma", "_", "-LCB-", "\\tau", ",", "s", "-RCB-", "^", "-LCB-", "post", "-RCB-", "\\", "-RRB-", "variance", "in", "the", "transition", "model", "are", "bounded", "from", "below", "to", "a", "minimum", "value", "of", "0.1", "."], ["The", "model", "loss", "on", "true", "observations", "\\", "-LRB-", "J_", "-LCB-", "M", ",", "s_t^1", ",", "s_t^2", "-RCB-", "\\", "-RRB-", "is", "weighted", "twice", "as", "much", "as", "the", "model", "losses", "on", "predicted", "opponent", "observations", "\\", "-LRB-", "J_", "-LCB-", "M", ",", "s_t^1", ",", "\\tilde", "-LCB-", "s", "-RCB-", "_t^2", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "J_", "-LCB-", "M", ",", "\\tilde", "-LCB-", "s", "-RCB-", "_t^1", ",", "s_t^2", "-RCB-", "\\", "-RRB-", "."], ["Throughout", ",", "we", "use", "\\", "-LRB-", "\\gamma", "=0.99\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "=0.95\\", "-RRB-", "."], ["The", "model", "learning", "horizon", "is", "\\", "-LRB-", "L=50\\", "-RRB-", "whereas", "the", "imagination", "horizon", "is", "\\", "-LRB-", "H=15\\", "-RRB-", "."], ["Value", "and", "action", "models", "are", "trained", "on", "the", "same", "trajectory", "rollouts", "."]], "ner": [[[16, 18, "a"]], [[40, 41, "a"]], [[52, 52, "v"]], [[67, 67, "v"], [69, 69, "v"], [72, 72, "v"], [57, 57, "p"], [57, 57, "p"], [57, 57, "p"], [57, 57, "p"]], [[77, 77, "p"], [79, 79, "v"]], [[131, 132, "p"], [134, 134, "v"], [132, 132, "p"], [132, 132, "p"], [132, 132, "p"], [132, 132, "p"]], [[137, 138, "a"], [156, 158, "v"]], [[208, 208, "v"], [214, 214, "v"]], [[218, 220, "a"], [224, 224, "v"], [228, 229, "a"], [233, 233, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[17, 18, "a"]], [[29, 29, "a"], [32, 32, "v"], [36, 36, "v"], [40, 40, "a"]], [[47, 48, "p"], [52, 52, "v"]], [[65, 66, "p"], [69, 69, "v"], [72, 72, "v"]], [[79, 79, "v"]], [[134, 134, "v"]], [], [[207, 207, "p"], [208, 208, "v"], [213, 214, "p"], [214, 214, "v"]], [[224, 224, "v"], [233, 233, "v"]], []], "predicted_relations": [[], [], [], [[67, 67, 57, 57, "USED-FOR"], [67, 67, 57, 57, "USED-FOR"], [67, 67, 57, 57, "USED-FOR"], [67, 67, 57, 57, "USED-FOR"], [69, 69, 57, 57, "USED-FOR"], [69, 69, 57, 57, "USED-FOR"], [69, 69, 57, 57, "USED-FOR"], [69, 69, 57, 57, "USED-FOR"]], [[79, 79, 77, 77, "USED-FOR"]], [[134, 134, 131, 132, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2101.10460-8f3be452-3474-4e9e-a627-d3bbc9818c8c", "sentences": [["Next", ",", "for", "fixed", "batch", "size", "\\", "-LRB-", "b", "=", "2L\\", "-RRB-", ",", "we", "vary", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "=", "1e-6", ",", "1e-5", ",", "1e-4", ",", "1e-3", ",", "5e-3", ",", "5e-2", ",", "5e-1", ",", "and", "5", "and", "train", "the", "model", "with", "500", "epochs", "."], ["Figure", "REF", "plots", "the", "prediction", "accuracy", "with", "respect", "to", "different", "choices", "of", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "."], ["As", "the", "regularization", "on", "the", "latent", "space", "is", "ignored", "by", "assigning", "very", "small", "parameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", ",", "the", "overall", "prediction", "performance", "is", "poor", "."], ["The", "performance", "is", "quickly", "improved", "when", "higher", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "selected", "-", "the", "latent", "constraint", "starts", "to", "dominate", "the", "reconstruction", "term", "with", "larger", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "."], ["The", "best", "range", "of", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "between", "-LSB-", "1e-4", ",", "1e-2", "-RSB-", "."]], "ner": [[[40, 40, "a"], [17, 17, "p"], [21, 21, "v"], [23, 23, "v"], [25, 25, "v"], [27, 27, "v"], [29, 29, "v"], [31, 31, "v"], [33, 33, "v"], [23, 23, "v"], [36, 36, "v"]], [[59, 59, "p"]], [[79, 79, "p"]], [[99, 99, "p"], [118, 118, "p"]], [[128, 128, "p"], [134, 134, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 5, "p"], [8, 8, "p"], [8, 10, "v"], [17, 17, "p"], [36, 36, "v"], [42, 42, "v"], [43, 43, "p"]], [[59, 59, "p"]], [[79, 79, "p"]], [[96, 96, "v"], [99, 99, "p"], [118, 118, "p"]], [[128, 128, "p"], [134, 136, "v"]]], "predicted_relations": [[[21, 21, 17, 17, "USED-FOR"], [23, 23, 17, 17, "USED-FOR"], [23, 23, 17, 17, "USED-FOR"]], [], [], [], [[134, 134, 128, 128, "USED-FOR"]]]}
{"doc_key": "2104.11228-287b288c-9aaf-4591-adbb-6aa925d7d323", "sentences": [["We", "train", "both", "the", "attribute", "prediction", "and", "the", "latent", "manipulation", "networks", "using", "Adam", "optimizer", "for", "60", "epochs", "with", "the", "batch", "size", "of", "128", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.01\\", "-RRB-", "and", "decayed", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "every", "10", "epochs", "."], ["For", "the", "latent", "manipulation", "network", ",", "the", "weights", "of", "each", "loss", "term", "are", "set", "as", "\\", "-LRB-", "\\lambda", "_r=1\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_l=0.001\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\lambda", "_c=0.01\\", "-RRB-", "for", "all", "our", "experiments", ",", "respectively", "."], ["To", "train", "the", "domain-specific", "StyleGAN2", "generator", "\\", "-LRB-", "\\text", "-LCB-", "G", "-RCB-", "^", "*", "\\", "-RRB-", "for", "each", "out-of-domain", "domain", ",", "we", "finetune", "the", "pretrained", "StyleGAN2", "for", "\\", "-LRB-", "32,000\\", "-RRB-", "iterations", "with", "the", "batch", "size", "of", "16", "on", "each", "dataset", "using", "the", "same", "learning", "rate", "scheduler", "but", "a", "smaller", "learning", "rate", "of", "\\", "-LRB-", "0.002\\", "-RRB-", "."], ["Besides", ",", "Pytorch3D", "is", "used", "as", "the", "differential", "renderer", "."]], "ner": [[[12, 13, "a"]], [[25, 27, "p"], [33, 33, "v"], [40, 40, "v"], [26, 27, "p"]], [[77, 77, "v"]], [[90, 90, "a"], [111, 111, "a"], [130, 131, "p"], [136, 137, "p"], [141, 141, "v"]], [[146, 146, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 10, "a"], [12, 12, "a"], [15, 15, "v"], [16, 16, "p"], [19, 20, "p"], [22, 22, "v"]], [[26, 27, "p"], [33, 33, "v"], [40, 40, "v"], [43, 43, "v"], [44, 44, "p"]], [[48, 50, "a"]], [[90, 90, "a"], [111, 111, "a"], [115, 115, "v"], [120, 121, "p"], [123, 123, "v"], [124, 126, "c"], [130, 131, "p"], [136, 137, "p"], [141, 141, "v"]], [[146, 146, "a"]]], "predicted_relations": [[], [], [], [[130, 131, 111, 111, "USED-FOR"], [136, 137, 111, 111, "USED-FOR"]], []]}
{"doc_key": "2101.09688-3112567e-09d6-4aee-9878-13e40e377b5c", "sentences": [["For", "fine-tuning", "BERT", "on", "the", "OntoNotes", "data", ",", "the", "following", "settings", "were", "used", "."], ["Standard", "hyperparameter", "choices", "of", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2=0.999", ",", "\\epsilon", "=10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", ",", "and", "a", "dropout", "probability", "of", "0.1", "were", "chosen", "."], ["Model", "training", "and", "validating", "with", "a", "80/20", "train/test", "split", "of", "the", "training", "data", ",", "across", "training", "epochs", "\\", "-LRB-", "\\in", "\\lbrace", "1", ",", "\\dots", ",", "10\\rbrace", "\\", "-RRB-", "."], ["The", "selected", "-LRB-", "epoch", "-RRB-", "model", "was", "that", "with", "the", "highest", "pronoun", "prediction", "accuracy", "on", "the", "validation", "set", "."]], "ner": [[[2, 2, "a"], [5, 6, "a"]], [[36, 37, "p"], [39, 39, "v"], [21, 21, "v"], [24, 24, "v"]], [[50, 51, "a"], [49, 49, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[5, 6, "a"]], [[36, 37, "p"], [39, 39, "v"]], [[49, 49, "v"], [63, 68, "v"]], []], "predicted_relations": [[], [[39, 39, 36, 37, "USED-FOR"]], [], []]}
{"doc_key": "2107.04357-23cb0808-4f44-40c1-b10b-d345b528d27e", "sentences": [["Once", "the", "document", "has", "been", "processed", "and", "visibility", "graph", "has", "been", "generated", ",", "we", "feed", "them", "to", "our", "Graph", "Recurrent", "Neural", "Network", "-LRB-", "GRNN", "-RRB-", "model", "framework", "with", "the", "7-dimensional", "node", "input", "space", "to", "get", "projected", "to", "a", "higher", "order", "space", "encoding", "with", "individual", "node", "features", "preserving", "the", "structural", "content", "information", "of", "the", "document", "."], ["The", "graph-level", "RNN", "used", "in", "our", "work", "uses", "4", "layered", "GRU", "with", "128", "dimensional", "hidden", "state", "."], ["To", "output", "the", "adjacency", "vector", "prediction", ",", "the", "edge-level", "RNN", "uses", "4", "layered", "GRU", "cells", "with", "16", "hidden", "dimensional", "state", "."], ["To", "get", "the", "predicted", "adjacency", "vector", "in", "the", "output", ",", "the", "edge-level", "RNN", "maps", "the", "16", "dimensional", "hidden", "state", "to", "a", "8", "dimensional", "vector", "through", "a", "MLP", "and", "ReLU", "activation", ",", "then", "another", "MLP", "maps", "the", "vector", "to", "a", "scalar", "with", "sigmoid", "activation", "."], ["We", "initialize", "the", "the", "edge-level", "RNN", "by", "the", "output", "of", "the", "graph-level", "RNN", "when", "generating", "the", "start", "of", "sequences", "\\", "-LRB-", "S_", "-LCB-", "i-1", "-RCB-", "^", "-LCB-", "\\pi", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "the", "highest", "layer", "hidden", "state", "of", "the", "graph-level", "RNN", "to", "initialize", "with", "a", "linear", "layer", "to", "match", "the", "dimensionality", "."], ["During", "the", "training", "time", ",", "ground", "truth", "has", "been", "used", "rather", "than", "the", "model", "'s", "own", "predictions", "."], ["During", "the", "inference", "time", ",", "the", "model", "is", "allowed", "to", "use", "its", "own", "predicted", "graph", "samples", "at", "each", "time", "step", "to", "generate", "a", "graph", "."], ["The", "Adam", "Optimizer", "has", "been", "used", "for", "minibatch", "size", "of", "32", "."], ["We", "set", "the", "learning", "rate", "to", "be", "0.001", "which", "is", "decayed", "by", "0.2", "at", "every", "100th", "epoch", "in", "all", "experiments", "."]], "ner": [[[18, 26, "a"], [30, 32, "p"], [29, 29, "v"]], [[56, 57, "p"], [63, 65, "v"], [67, 70, "v"]], [[83, 85, "v"], [80, 81, "p"], [83, 86, "v"], [88, 91, "v"]], [[104, 105, "p"], [119, 122, "v"], [126, 135, "v"]], [[148, 149, "p"], [141, 142, "p"]], [[178, 179, "p"]], [], [], [[235, 236, "p"], [241, 244, "v"], [235, 236, "a"]], [[256, 262, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[18, 25, "a"], [29, 29, "v"]], [[57, 57, "a"], [63, 63, "v"], [65, 65, "a"], [67, 68, "v"]], [[81, 81, "a"], [83, 83, "v"], [85, 86, "a"], [88, 88, "v"]], [[105, 105, "a"], [108, 108, "v"], [114, 114, "v"], [119, 119, "a"], [121, 121, "a"]], [[142, 142, "a"], [149, 149, "a"]], [[179, 179, "a"]], [], [], [[235, 235, "a"], [244, 244, "v"]], [[249, 250, "p"], [253, 253, "v"], [258, 258, "v"], [261, 261, "v"]]], "predicted_relations": [[[30, 32, 18, 26, "USED-FOR"]], [], [[83, 85, 80, 81, "USED-FOR"], [83, 86, 80, 81, "USED-FOR"], [88, 91, 80, 81, "USED-FOR"]], [[119, 122, 104, 105, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2109.05074-34264033-f2fa-4e6c-95be-bfa424f6916b", "sentences": [["We", "trained", "the", "resulting", "fBERT", "for", "25", "epochs", "using", "the", "MLM", "objective", "with", "\\", "-LRB-", "0.15\\", "-RRB-", "probability", "to", "randomly", "mask", "tokens", "in", "the", "input", "."], ["The", "language", "model", "is", "trained", "with", "a", "batch", "size", "of", "32", "and", "a", "512", "maximum", "token", "length", "using", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "5e-5\\", "-RRB-", "."], ["The", "training", "time", "took", "5", "days", "on", "a", "single", "Nvidia", "V100", "GPU", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[4, 4, "a"], [7, 7, "p"], [6, 6, "v"], [10, 11, "p"], [15, 15, "v"], [17, 24, "c"]], [[33, 34, "p"], [36, 36, "v"], [40, 42, "p"], [39, 39, "v"], [45, 46, "p"], [54, 54, "v"], [49, 50, "c"]], [[66, 68, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "a"], [6, 6, "v"], [7, 7, "p"], [10, 10, "a"], [15, 15, "v"]], [[33, 34, "p"], [36, 36, "v"], [39, 39, "v"], [45, 45, "a"], [49, 50, "p"], [54, 54, "v"]], [[61, 61, "v"]], []], "predicted_relations": [[[6, 6, 7, 7, "USED-FOR"], [6, 6, 10, 11, "USED-FOR"], [10, 11, 4, 4, "USED-FOR"], [17, 24, 15, 15, "USED-FOR"]], [[49, 50, 54, 54, "USED-FOR"]], [], []]}
{"doc_key": "2104.12642-41500653-b275-4ff0-b0ef-14d7c180facf", "sentences": [["We", "train", "the", "full-sized", "CompOFA", "network", "-LRB-", "\\", "-LRB-", "D=", "-LSB-", "4", "-RSB-", ",", "W=", "-LSB-", "6", "-RSB-", "\\", "-RRB-", "-RRB-", "on", "ImageNet", "-LSB-", "5", "-RSB-", "using", "the", "same", "base", "architecture", "of", "MobileNetV3", "as", "OFA", "."], ["We", "use", "a", "batch", "size", "of", "1536", "and", "a", "learning", "rate", "of", "1.95", "to", "train", "on", "6", "NVIDIA", "V100", "GPUs", "."], ["All", "other", "training", "hyperparameters", "are", "kept", "the", "same", "as", "OFA", "for", "accurate", "comparison", "."]], "ner": [[[4, 5, "a"], [9, 9, "p"], [11, 11, "v"], [14, 14, "p"], [16, 16, "v"], [22, 22, "a"], [32, 32, "a"]], [[52, 52, "v"], [39, 40, "a"], [39, 40, "p"], [42, 42, "v"], [45, 46, "a"], [45, 46, "p"], [48, 48, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[4, 5, "a"], [22, 22, "a"], [32, 32, "a"]], [[39, 40, "p"], [42, 42, "v"], [45, 46, "p"], [48, 48, "v"], [52, 52, "v"]], [[66, 66, "a"]]], "predicted_relations": [[[9, 9, 4, 5, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 14, 14, "USED-FOR"], [14, 14, 4, 5, "USED-FOR"], [14, 14, 22, 22, "USED-FOR"], [16, 16, 9, 9, "USED-FOR"], [16, 16, 14, 14, "USED-FOR"]], [[42, 42, 39, 40, "USED-FOR"], [45, 46, 39, 40, "USED-FOR"], [48, 48, 45, 46, "USED-FOR"]], []]}
{"doc_key": "2106.06916-65ff15c5-85e7-4e8c-908c-7635650f4e15", "sentences": [["Training", "parameters", "."], ["For", "the", "optimization", "of", "NTL", ",", "we", "utilize", "Adam", "as", "the", "optimizer", ",", "with", "learning", "\\", "-LRB-", "\\gamma", "=0.0001\\", "-RRB-", "and", "batch", "size", "of", "32", "."], ["For", "all", "datasets", ",", "we", "randomly", "select", "8,000", "samples", "from", "their", "own", "training", "sets", "as", "the", "source", "data", ",", "and", "1,000", "samples", "from", "their", "own", "testing", "sets", "as", "the", "test", "data", "-LRB-", "if", "a", "dataset", "does", "not", "have", "test", "set", ",", "we", "select", "its", "test", "data", "from", "the", "training", "set", "without", "overlapping", "with", "the", "chosen", "8,000", "source", "samples", "-RRB-", "."], ["And", "the", "sample", "quantities", "of", "the", "source", "and", "auxiliary", "domain", "are", "always", "the", "same", "."], ["In", "the", "training", "of", "adversarial", "augmentation", ",", "the", "optimizer", "is", "also", "Adam", ",", "and", "we", "set", "the", "learning", "rate", "to", "\\", "-LRB-", "\\gamma", "=0.0002\\", "-RRB-", "with", "two", "decay", "momentums", "\\", "-LRB-", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "0.999\\", "-RRB-", "."], ["The", "batch", "size", "is", "64", ",", "and", "the", "dimension", "of", "the", "latent", "space", "fed", "to", "the", "generator", "is", "256", "."]], "ner": [[], [[11, 11, "a"], [21, 21, "v"], [24, 25, "p"], [27, 27, "v"]], [], [], [[115, 115, "a"], [121, 122, "p"], [127, 127, "v"], [131, 132, "p"], [135, 135, "v"], [140, 140, "v"]], [[144, 145, "p"], [147, 147, "v"], [151, 155, "p"], [161, 161, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[7, 7, "a"], [11, 11, "a"], [20, 20, "p"], [21, 21, "v"], [24, 25, "p"], [27, 27, "v"]], [[36, 36, "v"], [49, 49, "v"], [84, 84, "v"]], [], [[115, 115, "a"], [121, 122, "p"], [126, 126, "p"], [127, 127, "v"], [130, 130, "v"], [131, 132, "p"], [135, 135, "v"], [140, 140, "v"]], [[144, 145, "p"], [147, 147, "v"], [161, 161, "v"]]], "predicted_relations": [[], [[24, 25, 11, 11, "USED-FOR"]], [], [], [[121, 122, 115, 115, "USED-FOR"], [127, 127, 121, 122, "USED-FOR"], [127, 127, 131, 132, "USED-FOR"], [131, 132, 115, 115, "USED-FOR"], [135, 135, 131, 132, "USED-FOR"], [140, 140, 131, 132, "USED-FOR"]], [[161, 161, 151, 155, "USED-FOR"]]]}
{"doc_key": "2106.06911-d37b259f-ac7f-4ad8-957d-11d5177afd13", "sentences": [["Stride", "Level", "."], ["The", "level", "of", "stride", "is", "how", "many", "rows", "or", "columns", "that", "get", "skipped", "over", "."], ["This", "tuning", "parameter", "allows", "the", "algorithm", "to", "move", "faster", "but", "it", "makes", "sacrifice", "by", "skipping", "some", "variables", "."], ["For", "example", ",", "we", "investigate", "stride", "level", "of", "1", "starting", "from", "row", "\\", "-LRB-", "i\\", "-RRB-", "and", "column", "\\", "-LRB-", "j\\", "-RRB-", "."], ["Assume", "we", "use", "a", "\\", "-LRB-", "2", "\\times", "2\\", "-RRB-", "window", "and", "let", "us", "start", "from", "\\", "-LRB-", "-LRB-", "i", ",", "j", "-RRB-", "\\", "-RRB-", "."], ["We", "can", "visualize", "this", "action", "by", "using", "the", "following", "diagram", "\\", "-LRB-", "\\begin", "-LCB-", "array", "-RCB-", "-LCB-", "lll", "-RCB-", "\\text", "-LCB-", "Original", "matrix", ":", "-RCB-", "&", "\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i", ",", "j", "-RRB-", "&", "-LRB-", "i", ",", "j+1", "-RRB-", "\\\\", "-LRB-", "i+1", ",", "j", "-RRB-", "&", "-LRB-", "i+1", ",", "j+1", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\\\\\\\\\stackrel", "-LCB-", "\\text", "-LCB-", "stride", "-RCB-", "=1", "-RCB-", "-LCB-", "\\longrightarrow", "-RCB-", "&", "\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i", ",", "j+1", "-RRB-", "&", "-LRB-", "i", ",", "j+2", "-RRB-", "\\\\", "-LRB-", "i+1", ",", "j+1", "-RRB-", "&", "-LRB-", "i+1", ",", "j+2", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\\\\\end", "-LCB-", "array", "-RCB-", "\\", "-RRB-"]], "ner": [[], [], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [], [[44, 44, "v"]], [[65, 65, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2106.06911-f1138318-2ce6-4009-a806-67646bb60605", "sentences": [["If", "we", "are", "at", "the", "end", "of", "the", "column", "for", "a", "row", ",", "we", "move", "down", "by", "moving", "to", "the", "first", "column", "of", "the", "next", "row", "."], ["For", "example", ",", "in", "a", "grid", "structure", "of", "size", "\\", "-LRB-", "6", "\\times", "6\\", "-RRB-", ",", "assume", "we", "are", "in", "the", "last", "position", "in", "a", "certain", "row", "\\", "-LRB-", "i\\", "-RRB-", "."], ["The", "action", "of", "stride", "level", "1", "can", "be", "taken", "using", "the", "following", "diagram", "\\", "-LRB-", "\\begin", "-LCB-", "array", "-RCB-", "-LCB-", "lll", "-RCB-", "\\text", "-LCB-", "Original", "matrix", "-RCB-", "\\\\\\text", "-LCB-", "in", "the", "end", "of", "a", "row", ":", "-RCB-", "\\\\\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i", ",", "5", "-RRB-", "&", "-LRB-", "i", ",", "6", "-RRB-", "\\\\", "-LRB-", "i+1", ",", "5", "-RRB-", "&", "-LRB-", "i+1", ",", "6", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\stackrel", "-LCB-", "\\text", "-LCB-", "stride", "-RCB-", "=1", "-RCB-", "-LCB-", "\\longrightarrow", "-RCB-", "\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i+1", ",", "1", "-RRB-", "&", "-LRB-", "i+1", ",", "2", "-RRB-", "\\\\", "-LRB-", "i+2", ",", "1", "-RRB-", "&", "-LRB-", "i+2", ",", "2", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\\\\\end", "-LCB-", "array", "-RCB-", "\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], [[64, 64, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2106.06911-324e6b98-291b-4c47-a4c4-24c25d3acebf", "sentences": [["Again", "assume", "we", "are", "at", "row", "\\", "-LRB-", "i\\", "-RRB-", "and", "column", "\\", "-LRB-", "j\\", "-RRB-", "."], ["Suppose", "we", "set", "stride", "level", "to", "be", "2", "and", "we", "want", "to", "move", "down", "."], ["This", "means", "we", "increase", "increment", "of", "2", "on", "the", "number", "of", "rows", "and", "the", "action", "is", "the", "following", "\\", "-LRB-", "\\begin", "-LCB-", "array", "-RCB-", "-LCB-", "lll", "-RCB-", "\\text", "-LCB-", "Original", "matrix", ":", "-RCB-", "\\\\\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i", ",", "j", "-RRB-", "&", "-LRB-", "i", ",", "j+1", "-RRB-", "\\\\", "-LRB-", "i+1", ",", "j", "-RRB-", "&", "-LRB-", "i+1", ",", "j+1", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "&", "\\stackrel", "-LCB-", "\\text", "-LCB-", "stride", "-RCB-", "=2", "-RCB-", "-LCB-", "\\longrightarrow", "-RCB-", "&", "\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i+2", ",", "j", "-RRB-", "&", "-LRB-", "i+2", ",", "j", "-RRB-", "\\\\", "-LRB-", "i+3", ",", "j", "-RRB-", "&", "-LRB-", "i+3", ",", "j", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\\\\\end", "-LCB-", "array", "-RCB-", "\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [[24, 24, "v"]], [[38, 38, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2106.06911-f433308c-6941-4719-9070-bd815a575ca6", "sentences": [["If", "this", "window", "happens", "to", "be", "in", "the", "final", "position", "of", "a", "row", ",", "then", "we", "move", "down", "by", "skipping", "one", "row", "and", "we", "start", "with", "the", "first", "column", "."], ["If", "we", "have", "a", "grid", "structure", "of", "size", "\\", "-LRB-", "6", "\\times", "6\\", "-RRB-", ",", "this", "action", "is", "shown", "in", "the", "following", "diagram", "\\", "-LRB-", "\\begin", "-LCB-", "array", "-RCB-", "-LCB-", "lll", "-RCB-", "\\text", "-LCB-", "Original", "matrix", "-RCB-", "\\\\\\text", "-LCB-", "in", "the", "end", "of", "a", "row", ":", "-RCB-", "\\\\\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i", ",", "5", "-RRB-", "&", "-LRB-", "i", ",", "6", "-RRB-", "\\\\", "-LRB-", "i+1", ",", "5", "-RRB-", "&", "-LRB-", "i+1", ",", "6", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\stackrel", "-LCB-", "\\text", "-LCB-", "stride", "-RCB-", "=2", "-RCB-", "-LCB-", "\\longrightarrow", "-RCB-", "\\begin", "-LCB-", "bmatrix", "-RCB-", "-LRB-", "i+2", ",", "1", "-RRB-", "&", "-LRB-", "i+2", ",", "2", "-RRB-", "\\\\", "-LRB-", "i+3", ",", "1", "-RRB-", "&", "-LRB-", "i+3", ",", "2", "-RRB-", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "\\\\\\end", "-LCB-", "array", "-RCB-", "\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[20, 20, "v"]], [[40, 40, "v"], [42, 42, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.06911-9dbcf6a4-69c2-40df-aa9d-158dd2fed171", "sentences": [["Alternatively", ",", "we", "can", "initiate", "the", "starting", "point", "to", "be", "at", "a", "higher", "level", "such", "as", "two", "or", "three", "."], ["This", "allows", "algorithms", "to", "run", "more", "efficiently", "in", "large-scale", "data", "sets", "."], ["For", "a", "simple", "example", ",", "in", "a", "matrix", "that", "is", "sized", "\\", "-LRB-", "6", "\\times", "6\\", "-RRB-", "-LRB-", "see", "\u00a72.3", "for", "the", "first", "artificial", "example", "-RRB-", ",", "we", "have", "the", "first", "row", "of", "variables", "to", "be", "\\", "-LRB-", "\\lbrace", "X_1", ",", "X_2", ",", "...", ",", "X_6\\rbrace", "\\", "-RRB-", "and", "the", "second", "row", "of", "variables", "to", "be", "\\", "-LRB-", "\\lbrace", "X_7", ",", "X_8", ",", "...", "X_", "-LCB-", "12", "-RCB-", "\\rbrace", "\\", "-RRB-", "."], ["At", "a", "starting", "point", "of", "2", ",", "we", "start", "with", "\\", "-LRB-", "X_8\\", "-RRB-", "to", "pass", "over", "the", "rolling", "window", ",", "because", "this", "variable", "sits", "at", "the", "position", "with", "the", "second", "row", "and", "the", "second", "column", "."], ["This", "can", "be", "illustrated", "in", "the", "following", "matrix", "\\", "-LRB-", "\\text", "-LCB-", "Starting", "point", "-RCB-", "=", "2", ":", "\\begin", "-LCB-", "bmatrix", "-RCB-", "X_1", "&", "X_2", "&", "\\dots", "\\\\X_7", "&", "\\color", "-LCB-", "red", "-RCB-", "-LCB-", "X_8", "-RCB-", "&", "\\dots", "\\\\X_", "-LCB-", "13", "-RCB-", "&", "\\vdots", "&", "\\ddots", "\\\\\\end", "-LCB-", "bmatrix", "-RCB-", "_", "-LCB-", "6", "\\times", "6", "-RCB-", "\\\\\\", "-RRB-"]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[16, 16, "v"], [18, 18, "v"]], [], [[45, 45, "v"]], [[109, 109, "v"]], [[157, 157, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.05635-a49207ff-9332-4050-9676-dde40af116d3", "sentences": [["Following", "-LSB-", "31", "-RSB-", ",", "a", "poly", "learning", "rate", "policy", "is", "adopted", "."], ["The", "initial", "learning", "rate", "is", "set", "as", "0.01", "and", "the", "learning", "rate", "at", "each", "iteration", "is", "the", "initial", "learning", "rate", "multiplied", "by", "\\", "-LRB-", "-LRB-", "-LCB-", "1-\\frac", "-LCB-", "iter", "-RCB-", "-LCB-", "total\\_iter", "-RCB-", "-RCB-", "-RRB-", "^", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-", "."], ["The", "momentum", "and", "weight", "decay", "rates", "are", "set", "to", "0.9", "and", "0.0001", ",", "respectively", "."], ["The", "networks", "are", "trained", "with", "8", "mini-batch", "sizes", "per", "GPU", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "."], ["We", "set", "150", "epochs", "for", "training", "."], ["As", "in", "existing", "methods", ",", "parameters", "in", "the", "encoder", "are", "initialized", "from", "the", "weights", "pretrained", "from", "the", "ImageNet", "-LSB-", "48", "-RSB-", "while", "those", "in", "the", "decoder", "and", "the", "memory", "module", "are", "randomly", "initialized", "."], ["To", "avoid", "overfitting", ",", "data", "augmentation", "is", "exploited", "during", "training", "including", "horizontal", "flipping", ",", "scaling", "-LRB-", "from", "0.5", "to", "2.0", "-RRB-", ",", "and", "rotation", "-LRB-", "from", "-10\\", "-LRB-", "^", "-LCB-", "\\circ", "-RCB-", "\\", "-RRB-", "to", "10\\", "-LRB-", "^", "-LCB-", "\\circ", "-RCB-", "\\", "-RRB-", "-RRB-", "."]], "ner": [[[6, 9, "a"]], [[14, 16, "p"], [30, 32, "p"], [20, 20, "v"], [50, 50, "v"]], [[64, 64, "v"], [66, 66, "v"]], [[75, 75, "v"]], [[91, 91, "p"], [90, 90, "v"]], [[112, 112, "a"]], [[133, 134, "a"], [140, 141, "p"], [143, 143, "p"], [146, 146, "v"], [148, 148, "v"], [152, 152, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[15, 16, "p"], [20, 20, "v"], [23, 24, "p"], [31, 32, "p"], [50, 50, "v"]], [[58, 60, "p"], [64, 64, "v"], [66, 66, "v"]], [[75, 75, "v"], [76, 77, "p"], [81, 86, "a"]], [[90, 90, "v"], [91, 91, "p"]], [[112, 112, "a"]], [[146, 146, "v"], [148, 148, "v"]]], "predicted_relations": [[], [], [], [], [[90, 90, 91, 91, "USED-FOR"]], [], [[140, 141, 133, 134, "USED-FOR"], [143, 143, 133, 134, "USED-FOR"], [146, 146, 152, 152, "USED-FOR"], [148, 148, 152, 152, "USED-FOR"], [152, 152, 133, 134, "USED-FOR"]]]}
{"doc_key": "2109.09519-e1a583dd-df0b-40f1-8590-0783494858e7", "sentences": [["For", "the", "pre-training", "corpora", ",", "the", "English", "conversation", "samples", "are", "extracted", "from", "Reddit", "comments", ",", "which", "are", "collected", "by", "a", "third", "party", "and", "made", "publicly", "available", "at", "pushshift.io", "-LSB-", "5", "-RSB-", "."], ["To", "guarantee", "the", "data", "quality", ",", "we", "follow", "the", "elaborate", "cleaning", "process", "as", "PLATO-2", "-LSB-", "4", "-RSB-", "."], ["After", "filtering", ",", "the", "data", "is", "split", "into", "training", "and", "validation", "sets", "in", "chronological", "order", "."], ["The", "training", "set", "contains", "811M", "-LRB-", "context", ",", "response", "-RRB-", "samples", ",", "ranging", "from", "December", "2005", "to", "December", "2019", "."], ["For", "the", "validation", "set", ",", "0.2M", "samples", "are", "selected", "from", "the", "rest", "data", "after", "December", "2019", "."], ["The", "English", "vocabulary", "contains", "8K", "BPE", "tokens", "-LSB-", "30", "-RSB-", ",", "constructed", "with", "the", "SentencePiece", "library", "."], ["The", "Chinese", "pre-training", "data", "is", "collected", "from", "public", "domain", "social", "medias", "."], ["After", "filtering", ",", "there", "are", "1.2B", "-LRB-", "context", ",", "response", "-RRB-", "samples", "in", "the", "training", "set", "."], ["As", "for", "the", "Chinese", "vocabulary", ",", "it", "contains", "30K", "BPE", "tokens", "."]], "ner": [[], [[45, 45, "a"]], [], [], [], [[117, 118, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[27, 27, "a"]], [[45, 45, "a"]], [], [[70, 70, "v"]], [[91, 91, "v"]], [[107, 107, "v"]], [], [[137, 137, "v"]], [[157, 157, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2112.05328-8b3193a7-2c9d-4b3a-b6b2-b668ffa4c7e8", "sentences": [["We", "use", "a", "pretrained", "unimodal", "model", "using", "the", "huggingface", "library", "https", ":", "//huggingface.co/", "."], ["The", "optimizer", "used", "for", "training", "is", "AdamW", "and", "the", "learning", "rate", "scheduler", "is", "\\", "-LRB-", "get\\_linear\\_schedule\\_with\\_warmup\\", "-RRB-", "."], ["We", "use", "training", "epochs", "from", "5", "to", "10", "depending", "on", "the", "subtask", "."], ["Also", ",", "the", "learning", "rate", "is", "1e-5", "in", "subtask", "#", "1", "and", "1e-6", "in", "other", "subtasks", "."], ["We", "use", "multi-GPU", "training", "for", "two", "-LRB-", "or", "four", "-RRB-", "A100", "-LRB-", "or", "V100", "-RRB-", "GPUs", "through", "apex", "https", ":", "//github.com/NVIDIA/apex", "."]], "ner": [[], [[20, 20, "a"], [23, 24, "a"], [23, 24, "p"]], [], [[48, 49, "a"], [48, 49, "p"], [51, 51, "v"], [53, 55, "c"], [57, 57, "v"], [59, 60, "c"]], [[64, 65, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 5, "a"]], [[20, 20, "a"], [23, 24, "p"]], [[34, 35, "p"], [37, 37, "v"], [39, 39, "v"]], [[48, 49, "p"], [51, 51, "v"], [57, 57, "v"]], [[67, 67, "v"], [70, 70, "v"], [75, 75, "v"], [79, 79, "a"]]], "predicted_relations": [[], [[23, 24, 20, 20, "USED-FOR"]], [], [[51, 51, 48, 49, "USED-FOR"], [59, 60, 57, 57, "USED-FOR"]], []]}
{"doc_key": "2103.02405-55466b9e-7810-44c9-8673-53892860995f", "sentences": [["We", "use", "hidden", "size", "\\", "-LRB-", "task_H=8\\", "-RRB-", ",", "layers", "\\", "-LRB-", "task_L=2\\", "-RRB-", ",", "heads", "\\", "-LRB-", "K=2\\", "-RRB-", ",", "structure", "learner", "'s", "hidden", "size", "\\", "-LRB-", "func_H=8\\", "-RRB-", "and", "\\", "-LRB-", "d_", "-LCB-", "pos", "-RCB-", "=4\\", "-RRB-", "."], ["We", "compare", "to", "an", "MLP", "with", "2", "hidden", "layers", "and", "hidden", "size", "16", "."], ["We", "use", "\\", "-LRB-", "\\ell", "_", "-LCB-", "sparse", "-RCB-", "=0.0\\", "-RRB-", "and", "\\", "-LRB-", "\\ell", "_", "-LCB-", "struct", "-RCB-", "=10.0\\", "-RRB-", "."], ["We", "train", "the", "models", "for", "250", "epochs", "."], ["To", "optimize", "the", "model", ",", "we", "use", "Adam", "optimizer", "with", "learning", "rate", "\\", "-LRB-", "0.001\\", "-RRB-", "."], ["We", "report", "the", "average", "performance", "for", "3", "random", "seeds", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[12, 12, "v"], [18, 18, "v"], [2, 3, "p"], [24, 25, "p"]], [[44, 44, "a"], [47, 48, "p"], [46, 46, "v"], [50, 51, "p"], [52, 52, "v"]], [[61, 61, "p"], [63, 63, "v"], [71, 71, "p"], [73, 73, "v"]], [], [[91, 92, "a"], [94, 95, "p"], [98, 98, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 3, "p"], [18, 18, "v"], [37, 37, "v"]], [[44, 44, "a"], [46, 46, "v"], [47, 48, "p"], [50, 51, "p"], [52, 52, "v"]], [[58, 62, "a"], [63, 63, "v"], [68, 72, "a"], [73, 73, "v"]], [[81, 81, "v"], [82, 82, "p"]], [[91, 91, "a"], [94, 95, "p"], [98, 98, "v"]], [[107, 107, "v"]], []], "predicted_relations": [[[18, 18, 2, 3, "USED-FOR"], [18, 18, 24, 25, "USED-FOR"]], [[47, 48, 44, 44, "USED-FOR"], [46, 46, 47, 48, "USED-FOR"], [46, 46, 50, 51, "USED-FOR"], [50, 51, 44, 44, "USED-FOR"], [52, 52, 50, 51, "USED-FOR"]], [[63, 63, 61, 61, "USED-FOR"], [63, 63, 71, 71, "USED-FOR"], [73, 73, 71, 71, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2102.01223-442eb332-6d42-4032-a046-01213c8a8592", "sentences": [["We", "use", "a", "standard", "Transformer", "architecture", "-LSB-", "46", "-RSB-", "with", "model", "dimension", "256", "."], ["The", "encoder", "consists", "of", "2", "layers", "with", "4", "self-attention", "heads", "and", "the", "decoder", "consists", "of", "1", "layer", "with", "1", "self-attention", "head", "and", "1", "attention", "head", "over", "the", "slots", "."], ["We", "use", "the", "same", "positional", "encodings", "as", "in", "-LSB-", "46", "-RSB-", "."], ["We", "feed", "in", "the", "sentences", "with", "less", "than", "128", "characters", "to", "our", "model", "and", "consider", "the", "number", "of", "slots", "as", "64", "-LRB-", "half", "of", "the", "maximum", "input", "length", "-RRB-", "."], ["In", "addition", ",", "we", "take", "the", "dimension", "of", "slots", "as", "128", ",", "and", "run", "the", "algorithm", "for", "\\", "-LRB-", "T", "-LCB-", "=", "-RCB-", "1\\", "-RRB-", "iterations.We", "choose", "\\", "-LRB-", "T", "-LCB-", "=", "-RCB-", "1\\", "-RRB-", "iterations", "for", "simplicity", "and", "efficiency", ",", "and", "because", "preliminary", "experiments", "showed", "no", "improvements", "with", "more", "iterations", "."], ["We", "leave", "the", "investigation", "of", "how", "to", "get", "improvements", "from", "more", "iterations", "to", "future", "work", "."], ["We", "initialized", "the", "slots", "according", "to", "equation", "-LRB-", "REF", "-RRB-", "in", "Sections", "REF", "and", "REF", "."]], "ner": [[[4, 5, "a"], [10, 11, "p"], [12, 12, "v"]], [[18, 18, "v"], [22, 23, "p"], [21, 21, "v"], [29, 29, "v"], [32, 32, "v"], [36, 36, "v"], [22, 23, "p"], [29, 29, "v"], [32, 32, "v"], [36, 36, "v"], [29, 29, "v"], [32, 32, "v"], [36, 36, "v"], [41, 41, "p"], [41, 41, "p"], [29, 29, "v"], [32, 32, "v"], [36, 36, "v"]], [[47, 48, "a"]], [[80, 82, "a"], [64, 64, "p"], [63, 63, "v"], [71, 73, "a"], [73, 73, "p"], [75, 75, "v"], [73, 73, "p"], [63, 63, "v"]], [[108, 108, "v"], [118, 118, "v"], [108, 108, "v"], [118, 118, "v"], [108, 108, "v"], [118, 118, "v"], [95, 95, "v"], [93, 93, "p"], [91, 93, "a"], [93, 93, "p"], [95, 95, "v"], [100, 100, "a"], [110, 110, "p"], [120, 120, "p"], [135, 135, "p"], [108, 108, "v"], [118, 118, "v"]], [[148, 148, "p"]], [[156, 156, "p"], [156, 156, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [12, 12, "v"]], [[18, 18, "v"], [21, 21, "v"], [29, 29, "v"], [32, 32, "v"], [36, 36, "v"]], [], [[63, 63, "v"], [75, 75, "v"]], [[95, 95, "v"]], [], []], "predicted_relations": [[[10, 11, 4, 5, "USED-FOR"]], [[21, 21, 22, 23, "USED-FOR"], [21, 21, 22, 23, "USED-FOR"]], [], [[64, 64, 80, 82, "USED-FOR"], [63, 63, 64, 64, "USED-FOR"], [73, 73, 71, 73, "USED-FOR"], [73, 73, 71, 73, "USED-FOR"], [63, 63, 64, 64, "USED-FOR"]], [[108, 108, 110, 110, "USED-FOR"], [118, 118, 110, 110, "USED-FOR"], [118, 118, 120, 120, "USED-FOR"], [108, 108, 110, 110, "USED-FOR"], [118, 118, 110, 110, "USED-FOR"], [118, 118, 120, 120, "USED-FOR"], [108, 108, 110, 110, "USED-FOR"], [118, 118, 110, 110, "USED-FOR"], [118, 118, 120, 120, "USED-FOR"], [93, 93, 91, 93, "USED-FOR"], [93, 93, 91, 93, "USED-FOR"], [108, 108, 110, 110, "USED-FOR"], [118, 118, 110, 110, "USED-FOR"], [118, 118, 120, 120, "USED-FOR"]], [], []]}
{"doc_key": "2102.01223-64fa330f-7858-49e1-b6f3-a381d6197ce4", "sentences": [["We", "scheduled", "the", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "parameter", "in", "the", "training", "loss", "to", "start", "with", "a", "low", "value", "of", "\\", "-LRB-", "2", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "exponentially", "increase", "it", "every", "10", "epochs", "until", "it", "reaches", "a", "certain", "limit", "."], ["We", "control", "this", "parameter", "in", "a", "way", "that", "the", "final", "number", "of", "open", "gates", "roughly", "equals", "the", "average", "number", "of", "BPE", "tokens", "in", "a", "sequence", "."], ["We", "used", "Adam", "optimizer", "-LSB-", "26", "-RSB-", "for", "training", "our", "models", "with", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "train", "our", "models", "for", "200", "epochs", "."], ["More", "details", "of", "the", "settings", "are", "available", "in", "the", "Appendix", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[11, 12, "a"]], [], [[72, 73, "a"], [82, 83, "p"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "p"], [11, 12, "a"], [22, 22, "v"], [24, 27, "v"], [35, 35, "v"], [36, 36, "p"]], [], [[72, 72, "a"], [80, 80, "a"], [82, 83, "p"], [86, 89, "v"], [95, 95, "a"], [97, 97, "v"], [98, 98, "p"]], [], []], "predicted_relations": [[], [], [[82, 83, 72, 73, "USED-FOR"]], [], []]}
{"doc_key": "2102.01208-d936a830-2f95-44ed-871b-8058bdfb0785", "sentences": [["We", "directly", "use", "the", "code", "provided", "for", "IBP", "-LSB-", "12", "-RSB-", "and", "use", "the", "same", "CNN", "architectures", "-LRB-", "small", ",", "medium", ",", "large", "and", "wide", "-RRB-", "on", "MNIST", "and", "CIFAR-10", "datasets", "."], ["We", "use", "adaptive", "hyperparameter", "selection", "for", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "or", "a", "piecewise", "linear", "schedule", "for", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "for", "all", "robust", "training", "methods", "."], ["The", "MNIST", "networks", "are", "trained", "for", "100", "epochs", "each", "with", "a", "batch", "size", "of", "100", "while", "the", "CIFAR", "networks", "are", "trained", "for", "350", "epochs", "each", "with", "a", "batch", "size", "of", "50", "."], ["We", "use", "the", "standard", "values", "of", "\\", "-LRB-", "\\epsilon", "=", "0.3\\", "-RRB-", "for", "MNIST", "and", "\\", "-LRB-", "\\epsilon", "=", "8/255\\", "-RRB-", "as", "the", "training", "target", "perturbation", "size", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "train", "-RCB-", "\\", "-RRB-", "."], ["Following", "-LSB-", "12", "-RSB-", ",", "the", "schedule", "of", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "starts", "at", "0", "for", "a", "warmup", "period", "-LRB-", "2000", "training", "steps", "on", "MNIST", ",", "5000", "training", "steps", "on", "CIFAR", "-RRB-", ",", "followed", "by", "a", "linear", "increase", "to", "the", "desired", "target", "perturbation", "size", "-LRB-", "10000", "training", "steps", "on", "MNIST", ",", "50000", "training", "steps", "on", "CIFAR", "-RRB-", ",", "after", "which", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "is", "fixed", "at", "the", "target", "level", "."], ["Additional", "details", "are", "reported", "in", "Appendix", "."]], "ner": [[[7, 7, "a"], [15, 16, "a"], [27, 27, "a"], [29, 29, "a"], [27, 27, "c"], [29, 29, "c"]], [[34, 36, "a"], [40, 40, "p"], [51, 51, "p"], [45, 47, "a"], [40, 40, "p"], [51, 51, "p"]], [[61, 61, "a"], [61, 61, "c"], [77, 77, "c"]], [[105, 105, "a"], [100, 100, "a"], [109, 109, "a"], [121, 121, "a"], [100, 100, "p"], [109, 109, "p"], [121, 121, "p"], [102, 102, "v"], [105, 105, "c"], [111, 111, "v"]], [[154, 154, "a"], [179, 179, "a"], [139, 139, "a"], [192, 192, "a"], [139, 139, "p"], [192, 192, "p"], [154, 154, "c"], [179, 179, "c"], [160, 160, "c"], [185, 185, "c"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [15, 15, "a"], [27, 27, "a"], [29, 29, "a"]], [[40, 40, "p"], [51, 51, "p"]], [[61, 62, "a"], [66, 66, "v"], [67, 67, "p"], [71, 72, "p"], [74, 74, "v"], [77, 78, "a"], [82, 82, "v"], [83, 83, "p"], [87, 88, "p"], [90, 90, "v"]], [[102, 102, "v"], [105, 105, "a"], [111, 111, "v"]], [[144, 144, "v"], [150, 150, "v"], [154, 154, "a"], [156, 156, "v"], [160, 160, "a"], [175, 175, "v"], [179, 179, "a"], [181, 181, "v"], [185, 185, "a"]], []], "predicted_relations": [[], [[40, 40, 34, 36, "USED-FOR"], [51, 51, 34, 36, "USED-FOR"], [40, 40, 34, 36, "USED-FOR"], [51, 51, 34, 36, "USED-FOR"]], [], [[100, 100, 105, 105, "USED-FOR"], [109, 109, 105, 105, "USED-FOR"], [109, 109, 100, 100, "USED-FOR"], [121, 121, 105, 105, "USED-FOR"], [121, 121, 100, 100, "USED-FOR"], [121, 121, 109, 109, "USED-FOR"], [102, 102, 100, 100, "USED-FOR"], [102, 102, 109, 109, "USED-FOR"], [105, 105, 102, 102, "USED-FOR"], [111, 111, 100, 100, "USED-FOR"], [111, 111, 109, 109, "USED-FOR"], [111, 111, 121, 121, "USED-FOR"]], [[192, 192, 179, 179, "USED-FOR"]], []]}
{"doc_key": "2104.08116-69c46541-8da1-4d96-8374-3cea48f8514d", "sentences": [["For", "both", "MLM", "and", "PSP", ",", "we", "used", "cross-entropy", "loss", "."], ["As", "an", "optimiser", ",", "we", "used", "AdamW", "-LSB-", "24", "-RSB-", "with", "a", "5e-5", "learning", "rate", "and", "a", "0.01", "weight", "decay", "."], ["For", "regularisation", ",", "we", "set", "a", "10", "%", "dropout", "probability", "."], ["Maximum", "input", "sequence", "length", "is", "128", "tokens", "."], ["For", "adapting", "to", "unlabelled", "data", ",", "we", "trained", "for", "one", "epoch", ",", "i.e", "."], ["one", "pass", "over", "all", "additional", "data", ",", "which", "matches", "-LSB-", "11", "-RSB-", "."], ["Training", "batch", "size", "was", "128", "."], ["For", "finetuning", "on", "labelled", "data", ",", "we", "trained", "for", "three", "epochs", "with", "a", "batch", "size", "of", "32", ",", "which", "corresponds", "to", "default", "settings", "recommended", "by", "-LSB-", "9", "-RSB-", "."]], "ner": [[[8, 9, "a"]], [[17, 17, "a"], [24, 25, "p"], [23, 23, "v"], [29, 30, "p"], [28, 28, "v"]], [[40, 40, "a"], [41, 41, "p"]], [], [], [], [[79, 80, "p"]], [[85, 88, "a"], [94, 94, "p"], [97, 98, "p"], [100, 100, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [8, 9, "a"]], [[17, 17, "a"], [23, 23, "v"], [24, 25, "p"], [28, 28, "v"], [29, 30, "p"]], [[38, 39, "v"], [40, 41, "p"]], [[48, 48, "v"]], [[60, 60, "v"], [61, 61, "p"]], [[65, 65, "v"]], [[78, 80, "p"], [82, 82, "v"]], [[93, 93, "v"], [94, 94, "p"], [97, 98, "p"], [100, 100, "v"]]], "predicted_relations": [[], [[24, 25, 17, 17, "USED-FOR"], [23, 23, 24, 25, "USED-FOR"], [29, 30, 17, 17, "USED-FOR"], [28, 28, 29, 30, "USED-FOR"]], [], [], [], [], [], [[94, 94, 85, 88, "USED-FOR"], [100, 100, 94, 94, "USED-FOR"]]]}
{"doc_key": "2104.08006-913100e5-17c3-44c5-8464-b0dbf903349a", "sentences": [["We", "carry", "out", "pre-training", "with", "12-layer", "encoder", ",", "12-layer", "decoder", "ProphetNet", "models", "."], ["The", "hidden", "size", "is", "1,024", ",", "feed", "forward", "size", "is", "4,096", ",", "future", "tokens", "'", "prediction", "length", "is", "2", "."], ["Both", "the", "max", "sequence", "lengths", "of", "the", "input", "and", "output", "are", "set", "to", "512", "."]], "ner": [[[10, 10, "a"]], [[14, 15, "p"], [19, 21, "p"], [25, 29, "p"], [31, 31, "v"]], [[46, 46, "v"], [46, 46, "v"]]], "relations": [[], [], []], "predicted_ner": [[[10, 10, "a"]], [[17, 17, "v"], [23, 23, "v"], [31, 31, "v"]], [[46, 46, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2104.08006-44c62a04-594a-41b1-9b09-f6be480d847e", "sentences": [["For", "ProphetNet-En", ",", "ProphetNet-Zh", ",", "ProphetNet-Multi", ",", "ProphetNet-Dialog-En", ",", "and", "ProphetNet-Code", ",", "we", "carry", "out", "un-supervised", "pre-training", "with", "masked", "span", "prediction", "task", "."], ["Spans", "of", "continuous", "tokens", "are", "masked", "out", "from", "the", "encoder", "input", "sentences", "and", "predicted", "from", "the", "decoder", "side", "."], ["We", "masked", "continuous", "9", "tokens", "in", "every", "64", "tokens", "from", "the", "encoder", "side", ",", "and", "predict", "the", "9", "tokens", "on", "the", "decoder", "side", "."], ["In", "other", "words", ",", "for", "maximum", "512", "encoder", "sequence", "length", ",", "totally", "\\", "-LRB-", "8", "-LRB-", "spans", "-RRB-", "\\times", "9", "-LRB-", "tokens\\", "per\\", "span", "-RRB-", "=", "72\\", "-RRB-", "tokens", "are", "masked", "and", "predicted", "."], ["If", "the", "last", "part", "does", "not", "reach", "a", "maximum", "length", "of", "64", ",", "15", "%", "continuous", "tokens", "are", "masked", "."], ["ProphetNet-Dialog-En", "has", "special", "tokens", "-LSB-", "X_SEP", "-RSB-", "to", "separate", "turns", "in", "a", "session", "and", "-LSB-", "SEP", "-RSB-", "to", "separate", "different", "sessions", "."], ["For", "ProphetNet-Dialog-Zh", ",", "we", "conduct", "supervised", "pre-training", "."], ["Previous", "turns", "of", "dialogs", "are", "fed", "into", "the", "encoder", ",", "and", "the", "response", "is", "predicted", "from", "the", "decoder", "."], ["It", "means", "that", "for", "a", "multi-turn", "session", "with", "\\", "-LRB-", "n\\", "-RRB-", "sentences", ",", "\\", "-LRB-", "n-1\\", "-RRB-", "samples", "are", "created", "for", "pre-training", "."], ["The", "pre-trained", "ProphetNet-Dialog-Zh", "can", "be", "used", "to", "directly", "generate", "dialogs", "without", "finetuning", "."]], "ner": [[[18, 21, "a"], [18, 18, "c"], [15, 16, "a"]], [[28, 34, "c"], [28, 28, "c"]], [[45, 46, "v"], [59, 60, "v"], [43, 43, "c"]], [[71, 75, "p"], [96, 96, "c"]], [[102, 103, "p"], [113, 116, "v"], [118, 118, "c"]], [], [[147, 148, "a"]], [], [[174, 175, "p"], [189, 191, "c"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [3, 3, "a"], [5, 5, "a"], [7, 7, "a"], [10, 10, "a"]], [], [[45, 45, "v"], [49, 49, "v"], [59, 59, "v"]], [[72, 72, "v"], [80, 80, "v"], [85, 85, "v"], [92, 92, "v"]], [[111, 111, "v"], [113, 114, "v"]], [[120, 120, "a"]], [[143, 143, "a"]], [], [[179, 179, "p"], [185, 185, "p"]], [[195, 195, "a"]]], "predicted_relations": [[], [], [[43, 43, 45, 46, "USED-FOR"], [43, 43, 59, 60, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2106.09637-bf1768fd-4f18-42db-a6fd-965bdf841d30", "sentences": [["The", "AttDLNet", "was", "implemented", "on", "PyTorch", "-LSB-", "24", "-RSB-", "and", "run", "on", "a", "hardware", "setup", "with", "an", "NVIDIA", "GFORCE", "GTx1070Ti", "GPU", "and", "an", "AMD", "Ryzen", "5", "CPU", "with", "32", "GB", "of", "RAM", "."], ["The", "hyperparameters", "are", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "25", "-RSB-", "with", "a", "learning", "rate", "of", "0.001", "and", "the", "cosine", "embedding", "loss", "function", "from", "the", "PyTorch", "framework", "."]], "ner": [[], [[39, 40, "a"], [46, 47, "p"], [49, 49, "v"], [52, 55, "a"]]], "relations": [[], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "a"], [28, 29, "v"]], [[39, 39, "a"], [46, 47, "p"], [49, 49, "v"], [52, 53, "a"]]], "predicted_relations": [[], [[46, 47, 39, 40, "USED-FOR"]]]}
{"doc_key": "2106.09637-191772f3-e5ce-4ec6-9600-cc6e4752ce38", "sentences": [["Since", "place", "matching", "is", "computed", "in", "the", "cosine", "space", ",", "AttDLNet", "is", "trained", "in", "the", "same", "similarity", "space", ",", "using", "the", "cosine", "loss", "function", ",", "with", "a", "margin", "parameter", "that", "has", "to", "be", "set", "."], ["To", "assess", "the", "best", "margin", "value", ",", "a", "margin", "study", "was", "conducted", ",", "for", "which", "AttDLNet", "was", "trained", "and", "evaluated", "several", "times", ",", "using", "each", "time", "a", "different", "margin", "value", "."], ["The", "discrete", "margin", "values", "used", "in", "the", "study", "are", ":", "0.0", ",", "0.3", ",", "0.5", ",", "0.7", ",", "0.8", ",", "0.85", ",", "0.9", ",", "0.95", "."], ["Training", "and", "evaluation", "were", "performed", "using", "the", "conditions", "described", "in", "previous", "sections", "."]], "ner": [[[21, 23, "a"], [27, 28, "p"]], [], [[76, 76, "v"], [78, 78, "v"], [80, 80, "v"], [82, 82, "v"], [84, 84, "v"], [86, 86, "v"], [88, 88, "v"], [90, 90, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "a"]], [[50, 50, "a"]], [[76, 76, "v"], [90, 90, "v"]], []], "predicted_relations": [[[27, 28, 21, 23, "USED-FOR"]], [], [], []]}
{"doc_key": "2102.09582-0ce368c9-9670-4df4-b1a5-1565ad0a717c", "sentences": [["The", "tumor", "types", "or", "organ", "labels", "were", "evenly", "separated", "in", "the", "three", "training", ",", "validation", ",", "and", "testing", "groups", "and", "the", "data", "were", "sampled", "with", "a", "batch", "size", "of", "8", "."], ["The", "FiLMed", "U-Nets", "of", "depth", "4", "for", "the", "spinal", "cord", "tumor", "and", "5", "for", "the", "chest", "CT", "were", "trained", "with", "a", "Dice", "loss", "function", "until", "the", "validation", "loss", "plateaued", "for", "50", "epochs", "-LRB-", "early", "stopping", "with", "\\", "-LRB-", "\\epsilon", "=", "0.001\\", "-RRB-", "-RRB-", "."], ["The", "depth", "was", "chosen", "according", "to", "the", "size", "of", "the", "input", "images", "."], ["The", "initial", "learning", "rate", "was", "0.001", "and", "was", "modulated", "according", "to", "a", "cosine", "annealing", "learning", "rate", "."]], "ner": [[], [[32, 33, "a"], [35, 35, "p"], [36, 36, "v"], [39, 41, "c"], [43, 43, "v"], [46, 47, "c"], [52, 54, "a"], [64, 65, "a"], [69, 69, "p"], [71, 71, "v"], [71, 71, "v"]], [[76, 76, "p"]], [[93, 93, "v"], [89, 91, "a"], [93, 93, "v"], [100, 103, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[11, 11, "v"], [26, 27, "p"], [29, 29, "v"]], [[33, 33, "a"], [36, 36, "v"], [43, 43, "v"], [61, 61, "v"], [62, 62, "p"], [71, 71, "v"]], [], [[90, 91, "p"], [93, 93, "v"], [100, 103, "a"]]], "predicted_relations": [[], [[35, 35, 32, 33, "USED-FOR"], [36, 36, 35, 35, "USED-FOR"], [39, 41, 36, 36, "USED-FOR"], [39, 41, 43, 43, "USED-FOR"], [39, 41, 71, 71, "USED-FOR"], [39, 41, 71, 71, "USED-FOR"], [43, 43, 35, 35, "USED-FOR"], [46, 47, 36, 36, "USED-FOR"], [46, 47, 43, 43, "USED-FOR"], [69, 69, 52, 54, "USED-FOR"], [69, 69, 64, 65, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"]], [], []]}
{"doc_key": "2102.11582-91ead2e8-68f2-4912-8025-454455c04ef3", "sentences": [["We", "train", "the", "softmax", "baselines", "on", "CIFAR-10/100", "for", "350", "epochs", "using", "SGD", "as", "the", "optimiser", "with", "a", "momentum", "of", "0.9", ",", "and", "an", "initial", "learning", "rate", "of", "0.1", "."], ["The", "learning", "rate", "drops", "by", "a", "factor", "of", "10", "at", "epochs", "150", "and", "250", "."], ["We", "train", "the", "5-Ensemble", "baseline", "using", "this", "same", "training", "setup", "."], ["The", "SNGP", "and", "DUQ", "models", "were", "trained", "using", "the", "setup", "of", "SNGP", "and", "hyper-parameters", "mentioned", "in", "their", "respective", "papers", "-LSB-", "41", "-RSB-", ",", "-LSB-", "57", "-RSB-", "."], ["For", "models", "trained", "on", "ImageNet", ",", "we", "train", "for", "90", "epochs", "with", "SGD", "optimizer", ",", "an", "initial", "learning", "rate", "of", "0.1", "and", "a", "weight", "decay", "of", "1e-4", "."], ["We", "use", "a", "learning", "rate", "warmup", "decay", "of", "0.01", "along", "with", "a", "step", "scheduler", "with", "step", "size", "of", "30", "and", "a", "step", "factor", "of", "0.1", "."]], "ner": [[[6, 6, "a"], [11, 11, "a"], [17, 17, "p"], [19, 19, "v"], [23, 25, "p"], [27, 27, "v"], [11, 11, "a"], [23, 25, "p"], [27, 27, "v"], [27, 27, "v"]], [], [[47, 48, "a"]], [[56, 56, "a"], [66, 66, "a"], [58, 58, "a"]], [[94, 94, "a"], [98, 100, "p"], [102, 102, "v"], [86, 86, "a"], [94, 94, "a"], [98, 100, "p"], [102, 102, "v"], [105, 106, "p"], [108, 108, "v"], [102, 102, "v"]], [[134, 134, "v"], [134, 134, "v"], [113, 116, "p"], [118, 118, "v"], [125, 126, "p"], [128, 128, "v"], [131, 132, "p"], [134, 134, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [8, 8, "v"], [9, 9, "p"], [11, 11, "a"], [17, 17, "p"], [19, 19, "v"], [24, 25, "p"], [27, 27, "v"]], [[30, 31, "p"], [37, 37, "v"], [40, 40, "v"], [42, 42, "v"]], [[47, 47, "v"]], [[56, 56, "a"], [58, 58, "a"], [66, 66, "a"]], [[86, 86, "a"], [91, 91, "v"], [92, 92, "p"], [94, 94, "a"], [99, 100, "p"], [102, 102, "v"], [105, 106, "p"], [108, 108, "v"]], [[113, 114, "p"], [115, 116, "a"], [118, 118, "v"], [125, 126, "p"], [128, 128, "v"], [131, 132, "p"], [134, 134, "v"]]], "predicted_relations": [[[17, 17, 6, 6, "USED-FOR"], [17, 17, 11, 11, "USED-FOR"], [17, 17, 11, 11, "USED-FOR"], [19, 19, 23, 25, "USED-FOR"], [19, 19, 23, 25, "USED-FOR"], [23, 25, 6, 6, "USED-FOR"], [23, 25, 11, 11, "USED-FOR"], [23, 25, 11, 11, "USED-FOR"], [23, 25, 6, 6, "USED-FOR"], [23, 25, 11, 11, "USED-FOR"], [23, 25, 11, 11, "USED-FOR"]], [], [], [], [[98, 100, 94, 94, "USED-FOR"], [98, 100, 86, 86, "USED-FOR"], [98, 100, 94, 94, "USED-FOR"], [98, 100, 94, 94, "USED-FOR"], [98, 100, 86, 86, "USED-FOR"], [98, 100, 94, 94, "USED-FOR"], [105, 106, 94, 94, "USED-FOR"], [105, 106, 86, 86, "USED-FOR"], [105, 106, 94, 94, "USED-FOR"], [108, 108, 98, 100, "USED-FOR"], [108, 108, 98, 100, "USED-FOR"], [108, 108, 105, 106, "USED-FOR"]], [[128, 128, 125, 126, "USED-FOR"]]]}
{"doc_key": "2102.11603-ceb918d8-7455-4578-a99e-377f45f04331", "sentences": [["We", "used", "a", "margin", "value", "of", "\\", "-LRB-", "\\alpha", "=0.3\\", "-RRB-", "for", "computing", "the", "loss", "which", "was", "then", "minimized", "using", "SGD", "optimizer", ",", "with", "weight", "decay", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["The", "initial", "learning", "rate", "was", "set", "to", "\\", "-LRB-", "0.0001\\", "-RRB-", "which", "was", "reduced", "by", "a", "factor", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "every", "50", "epochs", "."], ["For", "the", "Oxford", "Robotcar", "dataset", ",", "we", "ran", "training", "for", "only", "60", "epochs", "and", "for", "other", "larger", "datasets", ",", "Brisbane", "City", "Loop", ",", "Nordland", "and", "MSLS", ",", "training", "was", "done", "for", "200", "epochs", "-LRB-", "this", "is", "due", "to", "the", "increased", "number", "of", "negatives", "in", "proportion", "to", "the", "size", "of", "the", "database", "as", "we", "only", "consider", "10", "negatives", "for", "each", "query", "-LSB-", "0", "-RSB-", "-RRB-", "."], ["For", "generating", "positives/negatives", "for", "the", "triplet", "loss", ",", "we", "used", "a", "maximum/minimum", "distance", "of", "\\", "-LRB-", "5/20\\", "-RRB-", "meters", "for", "the", "city", "datasets", "and", "\\", "-LRB-", "10/40\\", "-RRB-", "frames", "for", "the", "Nordland", "dataset", "."], ["For", "city", "datasets", ",", "we", "used", "\\", "-LRB-", "L_d\\", "-RRB-", "as", "5", "and", "\\", "-LRB-", "w\\", "-RRB-", "as", "3", "for", "training", "."], ["For", "the", "Nordland", "dataset", ",", "these", "values", "were", "set", "to", "10", "and", "5", "respectively", "."], ["During", "testing", ",", "we", "used", "a", "sequence", "length", "of", "5", "for", "all", "datasets", "and", "all", "methods", "."]], "ner": [[[20, 21, "a"], [24, 26, "p"], [30, 30, "v"], [33, 33, "p"], [36, 36, "v"], [9, 9, "v"]], [[40, 42, "p"], [48, 48, "v"], [59, 59, "v"], [59, 59, "v"], [59, 59, "v"], [59, 59, "v"]], [[120, 120, "v"], [120, 120, "v"]], [[135, 136, "a"], [146, 146, "v"], [151, 152, "c"], [156, 156, "v"], [161, 162, "c"], [141, 142, "p"], [146, 146, "v"], [151, 152, "c"], [156, 156, "v"], [161, 162, "c"], [146, 146, "v"], [151, 152, "c"], [156, 156, "v"], [161, 162, "c"], [151, 152, "c"], [146, 146, "v"], [161, 162, "c"]], [[175, 175, "v"], [165, 166, "c"], [165, 166, "c"], [172, 172, "p"], [175, 175, "v"], [165, 166, "c"], [179, 179, "p"], [182, 182, "v"], [165, 166, "c"], [175, 175, "v"]], [[198, 198, "v"], [196, 196, "v"], [188, 189, "c"], [188, 189, "c"], [198, 198, "v"], [196, 196, "v"], [188, 189, "c"], [198, 198, "v"], [188, 189, "c"]], [[210, 210, "v"], [210, 210, "v"], [210, 210, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 4, "p"], [8, 8, "p"], [9, 9, "v"], [20, 20, "a"], [24, 26, "p"], [30, 30, "v"], [33, 33, "p"], [36, 36, "v"]], [[41, 42, "p"], [48, 48, "v"], [59, 59, "v"], [62, 62, "v"], [63, 63, "p"]], [[67, 69, "a"], [76, 76, "v"], [77, 77, "p"], [88, 88, "a"], [90, 90, "a"], [96, 96, "v"], [97, 97, "p"], [120, 120, "v"]], [[135, 136, "a"], [146, 146, "v"], [156, 156, "v"], [161, 162, "a"]], [[175, 175, "v"], [182, 182, "v"]], [[188, 189, "a"], [196, 196, "v"], [198, 198, "v"]], [[210, 210, "v"]]], "predicted_relations": [[[30, 30, 24, 26, "USED-FOR"], [30, 30, 33, 33, "USED-FOR"], [33, 33, 20, 21, "USED-FOR"], [36, 36, 24, 26, "USED-FOR"], [36, 36, 33, 33, "USED-FOR"], [9, 9, 24, 26, "USED-FOR"]], [[48, 48, 40, 42, "USED-FOR"]], [], [[146, 146, 141, 142, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [156, 156, 141, 142, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [141, 142, 135, 136, "USED-FOR"], [146, 146, 141, 142, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [156, 156, 141, 142, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [146, 146, 141, 142, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [156, 156, 141, 142, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [151, 152, 156, 156, "USED-FOR"], [151, 152, 146, 146, "USED-FOR"], [146, 146, 141, 142, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"], [161, 162, 156, 156, "USED-FOR"], [161, 162, 146, 146, "USED-FOR"]], [[182, 182, 179, 179, "USED-FOR"]], [[188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"], [188, 189, 196, 196, "USED-FOR"], [188, 189, 198, 198, "USED-FOR"]], []]}
{"doc_key": "2104.15104-b34c8dce-71b0-4e80-aa36-5c697a13819e", "sentences": [["For", "both", "the", "models", ",", "we", "select", "100", "as", "the", "dimension", "of", "the", "word", "embeddings", ",", "and", "50", "as", "the", "dimension", "of", "all", "the", "other", "embeddings", ",", "i.e.", ",", "POS-tag", "embedding", ",", "entity-type", "embedding", ",", "and", "positional", "embedding", "."], ["Following", "prior", "work", ",", "we", "restrict", "the", "length", "of", "each", "sentence", "to", "be", "50", "-LRB-", "truncating", "long", "sentences", "if", "necessary", "-RRB-", "."], ["We", "select", "the", "hidden", "units", "of", "the", "BiLSTM", "network", "as", "100", "."], ["We", "choose", "a", "batch", "size", "of", "10", ",", "and", "Adam", "with", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.0002\\", "-RRB-", "."], ["We", "select", "the", "dimension", "of", "the", "graph", "representation", "to", "be", "150", "."], ["When", "using", "GTNs", ",", "the", "number", "of", "edge-types", "-LRB-", "\\", "-LRB-", "L\\", "-RRB-", "-RRB-", "is", "35", ",", "which", "is", "determined", "by", "the", "number", "of", "unique", "types", "of", "dependency", "relations", ",", "e.g.", ",", "nsubj", ",", "case", ",", "etc.", ",", "as", "obtained", "from", "the", "dependency", "parser", "."]], "ner": [[[7, 7, "v"], [13, 14, "a"], [24, 25, "a"]], [], [[68, 69, "a"], [64, 65, "p"], [71, 71, "v"]], [[82, 82, "a"], [84, 86, "p"], [90, 90, "v"], [76, 77, "a"]], [[99, 100, "a"]], [[107, 107, "a"], [110, 112, "p"], [120, 120, "v"], [127, 133, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"], [17, 17, "v"]], [[52, 52, "v"]], [[68, 69, "a"], [71, 71, "v"]], [[76, 77, "p"], [79, 79, "v"], [82, 82, "a"], [85, 86, "p"], [90, 90, "v"]], [[103, 103, "v"]], [[107, 107, "a"], [120, 120, "v"], [137, 137, "a"]]], "predicted_relations": [[], [], [[64, 65, 68, 69, "USED-FOR"]], [[84, 86, 82, 82, "USED-FOR"], [84, 86, 76, 77, "USED-FOR"], [90, 90, 84, 86, "USED-FOR"]], [], [[110, 112, 107, 107, "USED-FOR"]]]}
{"doc_key": "2104.15135-1059212d-1d1e-4faf-9349-7548b5f861de", "sentences": [["When", "the", "model", "is", "transparent", "and", "the", "explanation", "displays", "the", "model", "parameters", "in", "an", "intelligible", "way", ",", "humans", "can", "directly", "adjust", "the", "parameters", "based", "on", "their", "judgements", "."], ["This", "idea", "was", "adopted", "by", "-LSB-", "53", "-RSB-", ",", "-LSB-", "51", "-RSB-", "where", "humans", "can", "adjust", "a", "bar", "chart", "showing", "word", "importance", "scores", ",", "corresponding", "to", "the", "parameters", "of", "the", "underlying", "Naive", "Bayes", "model", "."], ["In", "this", "special", "case", ",", "steps", "2", "and", "3", "in", "Figure", "REF", "are", "combined", "into", "a", "single", "step", "."], ["Besides", ",", "human", "feedback", "can", "be", "used", "to", "modify", "the", "model", "parameters", "indirectly", "."], ["For", "example", ",", "-LSB-", "91", "-RSB-", "increased", "a", "word", "weight", "in", "the", "Naive", "Bayes", "model", "by", "20", "%", "for", "the", "class", "that", "the", "word", "supported", ",", "according", "to", "human", "feedback", ",", "and", "reduced", "the", "weight", "by", "20", "%", "for", "the", "opposite", "class", "-LRB-", "binary", "classification", "-RRB-", "."], ["This", "choice", "gives", "good", "results", ",", "however", ",", "it", "is", "not", "clear", "why", "and", "whether", "20", "%", "is", "the", "best", "choice", "here", "."]], "ner": [[], [[59, 61, "a"], [48, 50, "p"]], [], [], [[108, 110, "a"], [104, 105, "p"], [102, 102, "c"], [128, 128, "c"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[59, 61, "a"]], [[69, 69, "v"], [71, 71, "v"]], [], [[108, 110, "a"], [112, 113, "v"], [132, 133, "v"]], [[158, 159, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2104.08710-222fd364-8c39-435b-bd7f-bb213f31bdcf", "sentences": [["When", "finetuning", "for", "QA", ",", "REALM", "performs", "an", "approximate", "MIPS", "search", "for", "retrieving", "relevant", "documents", "."], ["Additionally", ",", "the", "system", "is", "trained", "on", "a", "single", "machine", "with", "a", "12GB", "GPU", "with", "\\", "-LRB-", "k=5\\", "-RRB-", "and", "batch", "size", "1", "."], ["While", "this", "is", "modest", "use", "of", "resources", ",", "we", "show", "that", "this", "results", "in", "suboptimal", "training", "of", "the", "system", "."], ["We", "begin", "by", "scaling", "the", "realm", "system", "during", "training", "."], ["We", "perform", "exact", "MIPS", "search", "by", "leveraging", "the", "efficiency", "of", "large", "matrix", "multiplications", "of", "TPUs", "-LSB-", "25", "-RSB-", "to", "compute", "the", "retrieval", "score", ",", "\\", "-LRB-", "S_", "-LCB-", "retr", "-RCB-", "\\", "-RRB-", ",", "for", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "13M", "passages", "of", "corpus", "and", "extract", "\\", "-LRB-", "c\\", "-RRB-", "passages", "having", "the", "highest", "scores", "."], ["We", "further", "increase", "the", "training", "batch", "size", "from", "1", "to", "16", "by", "leveraging", "8", "TPUv3", "cores", "on", "Google", "Cloud", "for", "distributed", "training", "."], ["Finally", ",", "we", "increase", "the", "number", "of", "documents", "passed", "to", "the", "reader", "to", "\\", "-LRB-", "k=10\\", "-RRB-", "during", "training", "."]], "ner": [[[5, 5, "a"], [9, 10, "a"]], [[36, 37, "p"], [38, 38, "v"], [36, 37, "a"]], [], [], [[73, 74, "a"]], [[130, 131, "p"], [133, 133, "v"], [135, 135, "v"], [130, 131, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [9, 10, "a"]], [[19, 19, "a"], [28, 28, "v"], [33, 33, "v"], [36, 37, "p"], [38, 38, "v"]], [], [[65, 66, "a"]], [[84, 84, "a"], [109, 109, "v"]], [[133, 133, "v"], [135, 135, "v"], [138, 138, "v"], [139, 139, "a"]], [[163, 163, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2112.05827-13ada15a-d86b-4ba6-8a8d-b0f1ca70472b", "sentences": [["To", "provide", "real-world", "scenarios", "for", "our", "training", "setup", ",", "we", "augment", "the", "described", "datasets", "with", "corruptions", "that", "reduce", "image", "quality", "."], ["The", "face", "images", "are", "corrupted", "using", "motion", "blur", ",", "JPEG", "compression", ",", "additive", "Gaussian", "noise", ",", "scaling", "-LRB-", "width", "to", "height", "ratio", "\\", "-LRB-", "\\sim", "\\", "!"], ["0.9\\", "!", "-\\", "!", "1.1\\", "-RRB-", "-RRB-", ",", "down-sampling", "and", "smoothing", "."], ["To", "corrupt", "the", "iris", "images", ",", "blurring", "matrix", ",", "\\", "-LRB-", "B\\", "-RRB-", ",", "warping", ",", "\\", "-LRB-", "W\\", "-RRB-", ",", "downsampling", ",", "\\", "-LRB-", "D\\", "-RRB-", ",", "and", "additive", "noise", "\\", "-LRB-", "\\bar", "-LCB-", "n", "-RCB-", "\\", "-RRB-", "are", "considered", ":", "\\", "-LRB-", "\\bar", "-LCB-", "X", "-RCB-", "=DBWX+\\bar", "-LCB-", "n", "-RCB-", "\\", "-RRB-", "as", "described", "in", "-LSB-", "75", "-RSB-", "."]], "ner": [[], [[30, 31, "a"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[], [], [[52, 52, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2112.05827-fe430ba0-78fc-4bf0-8844-bb5cb385a2fd", "sentences": [["Similarly", ",", "as", "presented", "in", "Fig", "."], ["REF", ",", "the", "fingerprint", "images", "are", "degraded", "using", "two", "corruptions", "-LSB-", "57", "-RSB-", ",", "-LSB-", "56", "-RSB-", "."], ["The", "first", "corruption", "consists", "of", "warping", "the", "clean", "fingerprints", "-LSB-", "56", "-RSB-", "by", "randomly", "sampling", "the", "first", "two", "principal", "warp", "components", "extracted", "from", "the", "Tsinghua", "Distorted", "Fingerprint", "Database", "-LSB-", "76", "-RSB-", ",", "-LSB-", "56", "-RSB-", "."], ["The", "other", "corruption", "considers", "fading", "the", "fingerprint", "ridges", "at", "random", "points", "-LSB-", "57", "-RSB-", "."], ["Data", "augmentation", "is", "also", "performed", "on", "the", "fingerprint", "images", ",", "where", "20", "samples", "are", "generated", "for", "each", "fingerprint", "image", "by", "translating", "the", "core", "point", "both", "vertically", "and", "horizontally", "using", "distances", "coming", "from", "Gaussian", "distributions", "-LSB-", "38", "-RSB-", "."], ["Here", ",", "ten", "translated", "images", "are", "generated", "using", "a", "Gaussian", "distribution", "with", "parameters", "\\", "-LRB-", "\\mu", "=0\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "=2.5\\", "-RRB-", "."], ["The", "remaining", "ten", "augmented", "images", "are", "generated", "with", "\\", "-LRB-", "\\mu", "=0\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "=5\\", "-RRB-", "."]], "ner": [[], [], [[49, 52, "a"]], [], [[76, 77, "a"]], [[123, 124, "p"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[15, 15, "v"]], [[42, 42, "v"], [49, 52, "a"]], [], [[87, 87, "v"]], [[116, 116, "v"], [135, 136, "p"], [136, 136, "v"]], [[141, 141, "v"], [155, 156, "p"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2112.05827-7b06aa35-4470-4468-8673-886129d532e7", "sentences": [["Training", ":", "We", "initially", "train", "each", "\\", "-LRB-", "\\mathrm", "-LCB-", "qNet", "-RCB-", "_k^", "-LCB-", "\\mathrm", "-LCB-", "a", "-RCB-", "-RCB-", "\\", "-RRB-", "for", "the", "classification", "setup", "with", "a", "varying", "number", "of", "modality", "samples", "per", "multimodal", "sample", "set", ",", "where", "a", "feature", "vector", "of", "size", "512", "is", "trained", "using", "uniform", "angular", "loss", "and", "network", "compactness", "loss", "as", "defined", "in", "Equations", "REF", "and", "REF", ",", "respectively", "."], ["Iris", "and", "fingerprint", "unimodal", "networks", "are", "trained", "on", "their", "respective", "BioCOP", "modalities", ",", "while", "the", "face", "network", "is", "trained", "on", "the", "combination", "of", "BioCOP", "and", "VGGFace2", "datasets", "."], ["The", "estimated", "normalized", "quality", "scores", "for", "degraded", "samples", "in", "the", "BioCOP", "dataset", "can", "be", "found", "in", "Fig", "."], ["REF", "."], ["Each", "row", "in", "this", "figure", "presents", "eight", "samples", "of", "the", "same", "subject", "to", "construct", "the", "unimodal", "multi-sample", "set", "."], ["The", "number", "of", "samples", "from", "a", "modality", "in", "a", "multimodal", "sample", "set", "is", "chosen", "to", "represent", "the", "test", "datasets", "."], ["Therefore", ",", "up", "to", "30", "samples", "are", "considered", "for", "the", "face", "modality", ",", "while", "for", "the", "other", "two", "modalities", "up", "to", "five", "samples", "are", "considered", "."]], "ner": [[[47, 49, "a"], [51, 53, "a"]], [[74, 75, "a"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[43, 43, "v"]], [[74, 74, "a"], [87, 87, "a"], [89, 89, "a"]], [[102, 103, "a"]], [], [[118, 118, "v"]], [], [[155, 155, "v"], [168, 168, "v"], [172, 172, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2112.05827-99ab0ba5-083d-43bc-ac19-0dfb9ed29748", "sentences": [["The", "main", "branch", "of", "\\", "-LRB-", "\\mathrm", "-LCB-", "qNet", "-RCB-", "_k^", "-LCB-", "\\mathrm", "-LCB-", "a", "-RCB-", "-RCB-", "\\", "-RRB-", "networks", "are", "initialized", "with", "weights", "pre-trained", "on", "Imagenet", "-LSB-", "79", "-RSB-", "."], ["The", "other", "parameters", "are", "initialized", "using", "Kaiming", "initialization", "-LSB-", "80", "-RSB-", "."], ["The", "preprocessing", "algorithm", "consists", "of", "the", "channel-wise", "mean", "subtraction", "."], ["The", "five-fold", "cross-validation", "method", "is", "considered", "to", "estimate", "the", "best", "hyperparameters", "during", "the", "training", "phase", "."], ["The", "training", "algorithm", "is", "deployed", "using", "mini-batch", "stochastic", "gradient", "descent", "with", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["The", "training", "is", "regularized", "by", "weight", "decay", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "50\\", "%", "\\", "-RRB-", "dropout", "for", "the", "fully-connected", "layers", ",", "except", "for", "the", "last", "layer", "of", "each", "network", "where", "the", "representations", "are", "considered", "for", "recognition", "."], ["The", "moving", "average", "decay", "is", "set", "to", "\\", "-LRB-", "0.99\\", "-RRB-", "for", "all", "the", "networks", "except", "the", "iris", "modality", ",", "for", "which", "it", "is", "set", "to", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["Batch", "size", "is", "set", "to", "32", "and", "16", "for", "unimodal", "and", "multimodal", "frameworks", ",", "respectively", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "learning", "rate", "decreases", "exponentially", "by", "a", "factor", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "after", "\\", "-LRB-", "10^5\\", "-RRB-", "iterations", ",", "and", "then", "every", "\\", "-LRB-", "5\\times", "10^4\\", "-RRB-", "iterations", ",", "with", "the", "final", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[8, 8, "a"], [26, 26, "a"]], [[37, 38, "a"]], [], [[54, 55, "a"]], [[75, 78, "a"]], [[92, 93, "a"], [111, 111, "a"]], [[134, 136, "a"]], [], [[181, 183, "a"]], [[199, 199, "p"], [210, 210, "p"], [220, 220, "p"], [224, 226, "p"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[26, 26, "a"]], [], [], [[54, 54, "v"], [55, 56, "a"]], [[75, 78, "a"], [80, 80, "p"], [84, 84, "v"]], [[92, 93, "p"], [98, 101, "v"], [107, 108, "v"], [111, 111, "p"]], [[134, 136, "a"], [142, 142, "v"], [144, 147, "c"], [161, 161, "v"]], [[164, 165, "p"], [169, 169, "v"], [171, 171, "v"]], [[182, 183, "p"], [189, 189, "v"]], [[193, 194, "p"], [203, 203, "v"], [208, 208, "v"], [218, 218, "v"], [225, 226, "p"], [230, 233, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2106.05596-b1521fb4-076c-43ba-9c20-4609ae663f04", "sentences": [["As", "we", "use", "a", "Siamese", "network", "based", "approach", "for", "training", "our", "feature", "extractor", ",", "we", "create", "pairs", "of", "images", "for", "training", "."], ["Each", "pair", "corresponds", "to", "an", "unmasked", "reference", "and", "a", "masked", "probe", "image", "."], ["The", "network", "outputs", "a", "similarity", "in", "-LSB-", "0,1", "-RSB-", "with", "0", "indicating", "imposter", "and", "1", "indicating", "authentic", "match", "."], ["Since", "absolute", "difference", "is", "taken", "between", "embeddings", "from", "a", "shared", "weight", "siamese", "network", ",", "the", "ordering", "of", "masked/unmasked", "images", "as", "reference", "and", "probe", "has", "no", "effect", "on", "the", "final", "similarity", "scores", "."], ["Figure", "REF", "contains", "a", "high", "level", "overview", "of", "the", "architecture", "."]], "ner": [[[4, 5, "a"]], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 5, "a"]], [], [[45, 45, "v"], [49, 49, "v"]], [[65, 66, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2105.04642-28a2ee71-2d12-4a25-aae8-d3b31ea888d4", "sentences": [["In", "the", "experiment", ",", "the", "videos", "are", "re-sampled", "at", "1", "fps", "and", "input", "to", "the", "model", "."], ["The", "number", "of", "the", "MoN", "samples", "is", "set", "to", "10", "."], ["During", "model", "training", ",", "the", "generator", "encoder", "is", "pre-trained", "with", "the", "surgical", "phase", "recognition", "task", "for", "20", "epochs", "."], ["The", "pre-training", "is", "accomplished", "with", "the", "same", "dataset", ";", "therefore", ",", "no", "additional", "data", "are", "used", "."], ["During", "GAN", "training", ",", "we", "use", "small", "epochs", "to", "train", "the", "generator", "and", "the", "discriminator", "in", "an", "iterative", "fashion", ",", "where", "the", "epoch", "size", "is", "64", "and", "the", "number", "of", "epoch", "is", "2000", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[15, 15, "a"]], [[21, 22, "a"], [26, 26, "v"]], [[39, 42, "a"], [29, 29, "a"]], [], [[86, 87, "p"], [89, 89, "v"], [92, 94, "p"], [96, 96, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "v"]], [[26, 26, "v"]], [[44, 44, "v"]], [], [[70, 70, "v"], [89, 89, "v"], [96, 96, "v"]], []], "predicted_relations": [[], [], [], [], [[89, 89, 86, 87, "USED-FOR"], [96, 96, 86, 87, "USED-FOR"], [96, 96, 92, 94, "USED-FOR"]], []]}
{"doc_key": "2112.13593-b705080e-96f9-4acf-873f-fd39d7fc0fff", "sentences": [["We", "restrict", "14", "days", "for", "a", "textual", "sample", "and", "set", "the", "duration", "of", "the", "historical", "trending", "description", "as", "64-day", "."], ["The", "prediction", "interval", "is", "five", "days", ",", "and", "there", "are", "64", "shuffled", "samples", "in", "a", "batch", "."], ["The", "maximal", "length", "of", "the", "text", "is", "64", "in", "words", "."], ["And", "the", "maximal", "length", "of", "a", "textual", "sequence", "\\", "-LRB-", "s\\", "-RRB-", "is", "restricted", "to", "96", ",", "with", "excess", "clipped", "."], ["To", "improve", "the", "expression", "of", "word", "vectors", ",", "we", "set", "the", "latent", "dimension", "as", "512", "."], ["All", "weight", "matrices", "in", "the", "model", "are", "initialized", "with", "the", "fan-in", "trick", ",", "while", "we", "set", "biases", "as", "zero", "in", "the", "beginning", "."], ["We", "train", "the", "model", "as", "an", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "follow", "a", "linear", "decay", "strategy", "."], ["We", "use", "the", "input", "dropout", "rate", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "and", "the", "weight", "decay", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "to", "regularize", "."]], "ner": [[], [], [], [], [], [], [[114, 115, "a"], [118, 120, "p"], [124, 124, "v"], [130, 131, "p"], [129, 129, "v"], [124, 124, "v"]], [[152, 152, "v"], [136, 138, "a"], [136, 138, "p"], [142, 142, "v"], [146, 148, "a"], [146, 148, "p"], [152, 152, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [18, 18, "v"]], [[24, 24, "v"], [30, 30, "v"]], [[44, 44, "v"]], [[63, 63, "v"]], [[80, 81, "p"], [83, 83, "v"]], [[103, 103, "v"]], [[114, 114, "a"], [119, 120, "p"], [124, 124, "v"]], [[137, 138, "p"], [142, 142, "v"], [146, 148, "p"], [152, 152, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[118, 120, 114, 115, "USED-FOR"]], [[152, 152, 146, 148, "USED-FOR"], [136, 138, 136, 138, "USED-FOR"], [152, 152, 146, 148, "USED-FOR"]]]}
{"doc_key": "2102.12877-62a734b0-d1a5-4af7-9128-08f69e2f492a", "sentences": [["Most", "specifications", "related", "to", "the", "training", "of", "TELESTO", "are", "listed", "in", "tbl", ":", "evalspecs", "."], ["We", "employ", "leave", "one", "group", "out", "-LRB-", "LOGO", "-RRB-", "cross-validation", "for", "data", "splitting", ",", "i.e", "."], ["the", "five", "injections", "of", "each", "anomaly", "and", "each", "service", "component", "are", "split", "as", "3/1/1", "as", "a", "training/validation/test", "split", "."], ["For", "TELESTO", "itself", ",", "we", "choose", "a", "graph", "node", "feature", "dimensionality", "of", "64", "and", "set", "the", "number", "of", "graph", "transformation", "levels", "to", "5", "."], ["For", "the", "TAGCN", "layers", ",", "we", "choose", "\\", "-LRB-", "k=3\\", "-RRB-", "fixed-size", "learnable", "filters", "as", "recommended", "in", "-LSB-", "4", "-RSB-", "."], ["For", "the", "GAT", "layers", ",", "we", "choose", "\\", "-LRB-", "K=8\\", "-RRB-", "parallel", "attention", "mechanisms", "to", "produce", "rich", "node", "features", "with", "multi-head", "attention", "."], ["Lastly", ",", "the", "JK", "LSTM-aggregator", "is", "equipped", "with", "seven", "layers", "in", "order", "to", "learn", "a", "reasonable", "node", "weighting", "based", "on", "node", "features", "."], ["We", "choose", "ELU", "-LSB-", "2", "-RSB-", "as", "activation", "function", "for", "the", "FFF", "block", "."], ["The", "final", "softmax", "calculates", "a", "distribution", "over", "anomaly", "classes", ",", "whereof", "the", "highest", "is", "used", "as", "the", "prediction", "target", "."]], "ner": [[], [[17, 24, "a"]], [[44, 44, "v"]], [[57, 60, "a"], [57, 60, "p"], [62, 62, "v"], [66, 70, "a"], [66, 70, "p"], [72, 72, "v"]], [[76, 77, "a"], [83, 83, "p"], [83, 83, "v"]], [[97, 98, "a"], [104, 104, "p"], [104, 104, "v"]], [[121, 122, "a"]], [[143, 143, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [13, 13, "a"]], [[18, 18, "v"], [24, 24, "a"]], [[32, 32, "v"]], [[51, 51, "a"], [62, 62, "v"], [72, 72, "v"]], [[76, 76, "a"], [83, 83, "v"]], [[97, 97, "a"], [104, 104, "v"]], [[121, 122, "a"], [126, 126, "v"]], [[143, 143, "a"], [152, 152, "a"]], [[157, 157, "a"]]], "predicted_relations": [[], [], [], [[57, 60, 57, 60, "USED-FOR"], [66, 70, 57, 60, "USED-FOR"], [66, 70, 66, 70, "USED-FOR"]], [[83, 83, 76, 77, "USED-FOR"], [83, 83, 83, 83, "USED-FOR"], [83, 83, 83, 83, "USED-FOR"]], [[104, 104, 97, 98, "USED-FOR"], [104, 104, 104, 104, "USED-FOR"], [104, 104, 104, 104, "USED-FOR"]], [], [], []]}
{"doc_key": "2109.05729-cff3a5b3-eb1f-4d55-a2e1-21450b5a3ea6", "sentences": [["We", "train", "our", "models", "on", "the", "open", "source", "large-scale", "raw", "text", ",", "Chinese", "Wikipedia", "and", "a", "part", "of", "WuDaoCorpus", "."], ["The", "training", "data", "contains", "200GB", "cleaned", "text", "ranges", "from", "different", "domains", "."], ["We", "use", "Jieba", "to", "segment", "Chinese", "words", "for", "Whole", "Word", "Masking", "and", "use", "WordPiece", "tokenizer", "inherited", "from", "BERT", "to", "split", "input", "text", "into", "tokens", "."], ["We", "use", "Adam", "to", "train", "the", "models", "for", "500k", "steps", ",", "with", "the", "batch", "size", "of", "2048", ",", "the", "learning", "rate", "of", "1e-4", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.9", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.98\\", "-RRB-", ",", "weight", "decay", "of", "0.01", "."], ["We", "warmup", "the", "learning", "rate", "for", "first", "10,000", "steps", "then", "do", "linear", "decay", "."], ["In", "addition", ",", "a", "Chinese", "BART", "is", "pre-trained", "with", "the", "same", "corpora", ",", "tokenization", "and", "hyper-parameters", "as", "a", "baseline", "."]], "ner": [[[12, 13, "a"], [18, 18, "a"]], [], [[34, 34, "a"], [45, 46, "a"]], [[59, 59, "a"], [70, 71, "p"], [73, 73, "v"], [76, 77, "p"], [79, 79, "v"], [86, 86, "v"], [95, 95, "v"], [98, 99, "p"], [101, 101, "v"]], [[106, 107, "p"]], [[121, 122, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[24, 24, "v"]], [[34, 34, "a"], [49, 49, "a"]], [[59, 59, "a"], [65, 65, "v"], [70, 71, "p"], [73, 73, "v"], [76, 77, "p"], [79, 79, "v"], [86, 87, "v"], [95, 95, "v"], [98, 99, "p"], [101, 101, "v"]], [[106, 107, "p"], [110, 110, "v"], [111, 111, "p"], [114, 115, "a"]], [[122, 122, "a"]]], "predicted_relations": [[], [], [], [[70, 71, 59, 59, "USED-FOR"], [73, 73, 70, 71, "USED-FOR"], [76, 77, 59, 59, "USED-FOR"], [79, 79, 76, 77, "USED-FOR"], [95, 95, 98, 99, "USED-FOR"], [101, 101, 98, 99, "USED-FOR"]], [], []]}
{"doc_key": "2104.09903-bfcf15e3-359f-47e0-9e0b-38d3e58759d0", "sentences": [["Adam", "optimizer", "and", "MSE", "loss", "are", "used", "in", "both", "models", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "in", "the", "3D", "ResNet", "case", ",", "and", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "in", "the", "CNN-GRU", "."], ["Another", "difference", "between", "both", "models", "is", "in", "the", "batch", "size", ",", "and", "in", "the", "number", "of", "epochs", ",", "being", "5", "and", "100", "in", "the", "3D", "model", ",", "and", "3", "and", "150", "in", "the", "RNN", ",", "respectively", "."], ["Also", ",", "in", "the", "3D-CNN", "model", ",", "early", "stopping", "is", "used", ",", "with", "a", "patience", "of", "7", ",", "so", "the", "training", "end", "in", "epoch", "25/100", "."], ["To", "perform", "some", "regularization", ",", "the", "output", "targets", "are", "normalized", "between", "-1", "-LRB-", "\\", "-LRB-", "30", "km/h\\", "-RRB-", "-RRB-", "and", "1", "-LRB-", "\\", "-LRB-", "100", "km/h\\", "-RRB-", "-RRB-", "."]], "ner": [[[0, 1, "a"], [13, 14, "p"], [3, 4, "a"], [18, 18, "v"]], [[52, 53, "a"], [58, 60, "p"], [63, 63, "v"], [68, 69, "c"], [65, 65, "v"], [68, 69, "c"], [72, 72, "v"], [77, 77, "c"], [74, 74, "v"], [77, 77, "c"]], [[105, 105, "v"], [88, 89, "a"], [95, 95, "p"], [97, 97, "v"]], [[131, 131, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[0, 0, "a"], [3, 4, "a"], [13, 14, "p"], [19, 22, "v"], [28, 28, "a"], [34, 37, "v"], [42, 42, "a"]], [[52, 53, "p"], [63, 63, "v"], [65, 65, "v"], [68, 68, "v"], [72, 72, "v"], [74, 74, "v"], [77, 77, "a"]], [[85, 85, "a"], [88, 89, "a"], [95, 95, "p"], [97, 97, "v"], [105, 105, "v"]], [[118, 118, "v"], [122, 122, "v"], [127, 127, "v"], [131, 131, "v"]]], "predicted_relations": [[[13, 14, 0, 1, "USED-FOR"], [13, 14, 3, 4, "USED-FOR"]], [[63, 63, 58, 60, "USED-FOR"], [68, 69, 63, 63, "USED-FOR"], [68, 69, 65, 65, "USED-FOR"], [68, 69, 72, 72, "USED-FOR"], [68, 69, 74, 74, "USED-FOR"], [68, 69, 63, 63, "USED-FOR"], [68, 69, 65, 65, "USED-FOR"], [68, 69, 72, 72, "USED-FOR"], [68, 69, 74, 74, "USED-FOR"]], [[105, 105, 95, 95, "USED-FOR"], [95, 95, 88, 89, "USED-FOR"], [97, 97, 95, 95, "USED-FOR"]], []]}
{"doc_key": "2106.09997-41b5e243-caa6-43ef-9e8a-59f0aaaae5d1", "sentences": [["In", "the", "pre-training", "step", ",", "we", "denote", "the", "number", "of", "Transformer", "encoder", "layers", "as", "L", ",", "the", "size", "of", "hidden", "vectors", "as", "H", ",", "and", "the", "number", "of", "self-attention", "heads", "as", "A", "."], ["We", "followed", "the", "setting", "of", "BERTBASE", "-LRB-", "L=12", ",", "H=768", ",", "A=12", ",", "total", "parameters=110M", "-RRB-", "and", "continued", "to", "train", "200K", "steps", "from", "cased", "BERTBASE", "checkpoint", "."], ["The", "maximum", "sequence", "length", "was", "fixed", "to", "512", ",", "and", "the", "batch", "size", "was", "set", "to", "128", "."], ["We", "used", "Adam", "with", "a", "learning", "rate", "of", "2e-5", "and", "epsilon", "of", "1e-8", "and", "employed", "cased", "BERTBASE", "vocabulary", "with", "30K", "tokens", "."]], "ner": [[[10, 11, "a"], [17, 20, "p"], [26, 29, "p"]], [[40, 40, "v"], [44, 44, "v"], [42, 42, "v"], [40, 40, "v"], [44, 44, "v"]], [], [[80, 80, "a"], [83, 84, "p"], [86, 86, "v"], [88, 88, "p"], [90, 90, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[14, 14, "p"], [22, 22, "p"], [31, 31, "v"]], [[38, 38, "a"], [40, 40, "v"], [42, 42, "v"], [44, 44, "v"], [53, 53, "v"], [56, 57, "a"]], [[67, 67, "v"], [71, 72, "p"], [76, 76, "v"]], [[80, 80, "a"], [83, 84, "p"], [86, 86, "v"], [90, 90, "v"], [93, 94, "a"], [97, 97, "v"]]], "predicted_relations": [[[17, 20, 10, 11, "USED-FOR"]], [], [], [[83, 84, 80, 80, "USED-FOR"], [86, 86, 83, 84, "USED-FOR"], [88, 88, 80, 80, "USED-FOR"], [90, 90, 83, 84, "USED-FOR"], [90, 90, 88, 88, "USED-FOR"]]]}
{"doc_key": "2111.10513-4072964d-1b3c-4c58-b583-e7096f00a827", "sentences": [["Our", "models", "are", "trained", "using", "the", "Adam", "-LSB-", "5", "-RSB-", "optimizer", "."], ["Following", "-LSB-", "15", "-RSB-", ",", "we", "also", "use", "the", "\u201c", "Noam", "\u201c", "learning", "rate", "scheduler", ",", "linearly", "increasing", "the", "learning", "rate", "from", "0", "for", "the", "first", "8000", "steps", ",", "then", "decaying", "afterward", "."], ["We", "also", "set", "Adam", "'s", "\\", "-LRB-", "\\beta", "_2", "=", "0.998\\", "-RRB-", "and", "use", "a", "label", "smoothing", "factor", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "."]], "ner": [[[6, 6, "a"]], [[22, 22, "a"], [24, 25, "p"], [31, 32, "p"], [34, 34, "v"], [35, 39, "c"], [42, 42, "v"], [43, 43, "c"]], [[48, 48, "a"], [55, 55, "v"], [55, 55, "v"], [66, 66, "v"], [60, 62, "a"], [66, 66, "v"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"]], [[31, 32, "p"], [34, 34, "v"], [38, 38, "v"]], [[48, 48, "a"], [55, 55, "v"], [60, 62, "p"], [66, 66, "v"]]], "predicted_relations": [[], [[24, 25, 22, 22, "USED-FOR"], [31, 32, 22, 22, "USED-FOR"], [35, 39, 34, 34, "USED-FOR"], [35, 39, 42, 42, "USED-FOR"]], []]}
{"doc_key": "2111.10513-453d8538-d274-4ff2-b09f-1d6ceadfd845", "sentences": [["For", "batching", ",", "we", "accumulate", "tokens", "until", "we", "reach", "a", "maximum", "size", "of", "approximately", "32,000", "tokens", "per", "batch", ",", "an", "increase", "over", "the", "25,000", "tokens", "used", "in", "-LSB-", "15", "-RSB-", "."], ["We", "then", "train", "the", "base", "model", "and", "the", "large", "model", "for", "100,000", "steps", "and", "300,000", "steps", ",", "respectively", "."], ["All", "our", "models", "are", "trained", "on", "8", "NVIDIA", "Tesla", "P100", "GPUs", "in", "parallel", "using", "the", "OpenNMT-py", "-LSB-", "6", "-RSB-", "toolkit", "."]], "ner": [[[1, 1, "a"], [10, 11, "p"], [14, 15, "v"]], [], [[65, 65, "a"], [58, 60, "a"]]], "relations": [[], [], []], "predicted_ner": [[[14, 14, "v"], [23, 23, "v"]], [[42, 42, "v"], [45, 45, "v"]], [[56, 56, "v"], [65, 65, "a"]]], "predicted_relations": [[[10, 11, 1, 1, "USED-FOR"]], [], []]}
{"doc_key": "2106.03631-4ab9e7e3-b903-4dea-9b88-e9a26ed0520c", "sentences": [["We", "adopt", "the", "VAE", "architecture", "from", "-LSB-", "6", "-RSB-", ",", "using", "a", "LSTM", "encoder-decoder", "."], ["Unless", "stated", "otherwise", ",", "-LRB-", "word", "embedding", ",", "LSTM", ",", "representation", "embedding", "-RRB-", "dimensionalities", "for", "YNOC", "and", "POS", "datasets", "are", "-LRB-", "4D", ",", "32D", ",", "4D", "-RRB-", "and", "-LRB-", "4D", ",", "64D", ",", "8D", "-RRB-", ",", "respectively", ",", "and", "we", "use", "the", "latent", "code", "to", "initialize", "the", "hidden", "state", "of", "the", "LSTM", "decoder", "."], ["We", "use", "greedy", "decoding", "."], ["All", "models", "are", "trained", "from", "multiple", "random", "starts", "using", "Adam", "-LSB-", "24", "-RSB-", "with", "learning", "rate", "0.001", "for", "10", "epochs", "."], ["We", "set", "batch", "size", "to", "256", "and", "512", "for", "YNOC", "and", "POS", ",", "respectively", "."]], "ner": [[[3, 4, "a"], [12, 13, "a"]], [], [], [[83, 83, "a"], [88, 89, "p"], [90, 90, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [12, 12, "a"]], [[23, 23, "a"], [30, 30, "a"], [36, 36, "v"], [38, 38, "v"], [40, 40, "v"], [44, 44, "v"], [46, 46, "v"], [48, 48, "v"], [66, 66, "a"]], [[71, 72, "a"]], [[83, 83, "a"], [88, 89, "p"], [90, 90, "v"], [92, 92, "v"], [93, 93, "p"]], [[97, 98, "p"], [100, 100, "v"], [102, 102, "v"], [104, 104, "a"]]], "predicted_relations": [[], [], [], [[88, 89, 83, 83, "USED-FOR"]], []]}
{"doc_key": "2108.12988-cd3a0b88-6c92-4ae6-b041-d10b9ec85654", "sentences": [["We", "adopt", "the", "same", "set", "of", "hyperparameter", "for", "experiments", "."], ["12", "rollouts", "are", "executed", "in", "parallel", "when", "training", "."], ["The", "maximum", "length", "of", "the", "replay", "buffer", "is", "\\", "-LRB-", "1e6\\", "-RRB-", "."], ["Episode", "length", "is", "set", "to", "20", "."], ["The", "dimension", "of", "the", "latent", "code", "\\", "-LRB-", "z\\", "-RRB-", "is", "6", "."], ["The", "critic", "also", "adopts", "a", "self-attention", "network", "in", "a", "similar", "way", "with", "MAAC", "-LSB-", "9", "-RSB-", "."], ["And", "the", "number", "of", "gradient", "steps", "of", "policy", "and", "critic", "parameters", "in", "each", "update", ",", "i.e.", ",", "\\", "-LRB-", "K\\", "-RRB-", ",", "is", "set", "as", "10", "."], ["And", "\\", "-LRB-", "\\alpha", "=1\\", "-RRB-", "works", "well", "in", "experiments", "."], ["Batch", "size", "is", "set", "to", "1024", "and", "Adam", "is", "used", "as", "the", "optimizer", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "0.0003\\", "-RRB-", "."], ["In", "all", "experiments", ",", "we", "use", "one", "NVIDIA", "Tesla", "P40", "GPU", "."]], "ner": [[], [], [], [], [], [[64, 64, "a"]], [], [], [[114, 114, "a"]], [[123, 124, "p"], [130, 130, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[10, 10, "v"]], [[29, 29, "v"]], [[37, 37, "v"]], [[47, 47, "p"], [50, 50, "v"]], [[57, 58, "a"], [64, 64, "a"]], [[88, 88, "p"], [94, 94, "v"]], [], [[107, 108, "p"], [112, 112, "v"], [114, 114, "a"]], [[123, 124, "p"], [130, 130, "v"]], [[139, 139, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2103.07829-42d4ba08-0876-46d4-b4c0-26e5ed70a53a", "sentences": [["Pre-training", "Data", "We", "use", "the", "same", "in-domain", "data", "as", "in", "LXMERT", "for", "pre-training", "."], ["It", "consists", "of", "the", "image", "caption", "data", "from", "MS", "COCO", ",", "Visual", "Genome", ",", "and", "image", "question", "answering", "data", "from", "VQA", "v2.0", ",", "GQA", "balanced", "version", "and", "VG-QA", "."], ["The", "total", "amount", "of", "the", "dataset", "is", "9.18M", "image-and-sentence", "pairs", "on", "180K", "distinct", "images", "."], ["Besides", ",", "we", "also", "use", "additional", "out-of-domain", "data", "from", "Conceptual", "Captions", "and", "SBU", "Captions", "for", "model", "pre-training", ",", "which", "consists", "of", "about", "4M", "image-text", "pairs", "on", "4M", "images", "."]], "ner": [[[10, 10, "a"]], [[22, 23, "a"], [25, 26, "a"], [34, 35, "a"], [37, 39, "a"], [41, 41, "a"]], [], [[67, 68, "a"], [70, 71, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "a"]], [[34, 35, "a"], [37, 37, "a"], [41, 41, "a"]], [[50, 50, "v"], [54, 54, "v"]], [[80, 80, "v"], [84, 84, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2109.03334-cb727a0e-fea4-4449-a9b0-671fadca5bff", "sentences": [["All", "experiments", "were", "performed", "with", "the", "3-billion", "parameter", "version", "of", "T5-UQA", "."], ["We", "made", "use", "of", "DeepSpeed", "ZeRo", "optimizations", "-LSB-", "31", "-RSB-", "to", "fit", "the", "3B", "model", "into", "the", "largest", "GPUs", "available", "to", "us", "-LRB-", "A100-40GB", "-RRB-", "."], ["Models", "were", "trained", "to", "30", "epochs", ",", "where", "generation", "performance", "-LRB-", "ROUGE-1", "-RRB-", "plateaued", "."], ["We", "use", "the", "default", "hyperparameters", "for", "training", "provided", "in", "the", "Huggingface", "Transformers", "library", "-LSB-", "36", "-RSB-", "."], ["To", "improve", "inference", "quality", ",", "at", "inference", "time", "we", "use", "a", "batch", "size", "of", "1", ",", "a", "beam", "search", "over", "64", "beams", ",", "and", "-LRB-", "given", "the", "diversity", "of", "generations", ",", "and", "the", "preference", "for", "shorter", "generations", "even", "after", "considerable", "training", "-RRB-", "combine", "all", "facts", "generated", "in", "the", "top", "10", "beams", "-LRB-", "after", "splicing", "on", "the", "fact", "delimiter", "-RRB-", "into", "a", "candidate", "list", "of", "generated", "facts", "."]], "ner": [[[10, 10, "a"], [6, 8, "p"]], [[25, 25, "v"], [16, 18, "a"]], [[42, 43, "a"]], [[56, 57, "a"]], [[81, 84, "a"], [87, 88, "a"], [90, 90, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[10, 10, "a"]], [[25, 25, "v"], [35, 35, "v"]], [[42, 42, "v"], [43, 43, "p"], [49, 49, "a"]], [], [[81, 82, "p"], [84, 84, "v"], [87, 88, "a"], [90, 90, "v"], [119, 119, "v"]]], "predicted_relations": [[[6, 8, 10, 10, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2105.10146-e317d669-830b-4d88-82a5-a669f19e52a1", "sentences": [["As", "mentioned", "previously", ",", "we", "use", "the", "sentence-transformers", "-LSB-", "26", "-RSB-", "library", "to", "conduct", "our", "experiments", "."], ["For", "every", "run", "of", "training", ",", "including", "pre-training", "and", "fine-tuning", "steps", "wherever", "applicable", ",", "we", "train", "for", "2", "epochs", "and", "checkpoint", "at", "intervals", "of", "10000", "steps", "."], ["We", "override", "the", "previous", "checkpoint", "only", "if", "results", "improve", "on", "our", "dev", "set", "."]], "ner": [[[7, 7, "a"]], [[21, 21, "a"], [24, 24, "a"], [35, 35, "p"], [34, 34, "v"], [37, 37, "p"], [41, 41, "v"]], [[48, 48, "p"], [55, 56, "v"], [45, 54, "c"]]], "relations": [[], [], []], "predicted_ner": [[], [[34, 34, "v"], [35, 35, "p"], [41, 41, "v"]], []], "predicted_relations": [[], [[35, 35, 21, 21, "USED-FOR"], [35, 35, 24, 24, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 37, 37, "USED-FOR"], [37, 37, 21, 21, "USED-FOR"], [37, 37, 24, 24, "USED-FOR"], [41, 41, 37, 37, "USED-FOR"]], [[45, 54, 55, 56, "USED-FOR"]]]}
{"doc_key": "2105.10146-f12766ae-5de6-4c19-b298-75a89a952104", "sentences": [["A", "constant", "batch", "size", "of", "32", "is", "maintained", "across", "all", "our", "experiments", "."], ["The", "AdamW", "-LSB-", "15", "-RSB-", "optimizer", "is", "used", "with", "a", "default", "learning", "rate", "of", "\\", "-LRB-", "2e^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["A", "linear", "warmup", "scheduler", "is", "applied", "to", "slowly", "increase", "the", "learning", "rate", "to", "a", "constant", "after", "10", "%", "of", "training", "iterations", "-LRB-", "warm-up", "ratio", "=", "0.1", "-RRB-", "to", "reduce", "volatility", "in", "the", "early", "iterations", "of", "training", "."], ["A", "single", "Tesla", "V100", "GPU", "-LRB-", "32", "GB", "-RRB-", "is", "used", "for", "all", "training", "iterations", "."]], "ner": [[], [[14, 14, "a"], [24, 25, "p"]], [[46, 47, "p"], [38, 39, "a"], [61, 61, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 3, "p"], [5, 5, "v"]], [[14, 14, "a"], [24, 25, "p"], [29, 31, "v"]], [[46, 47, "p"], [52, 53, "v"], [58, 59, "p"], [61, 61, "v"]], [[79, 80, "v"]]], "predicted_relations": [[], [[24, 25, 14, 14, "USED-FOR"]], [[46, 47, 38, 39, "USED-FOR"]], []]}
{"doc_key": "2110.07206-0987a28d-c500-4775-95ee-f95657afe8f9", "sentences": [["The", "used", "datasets", "are", "resized", "to", "1024", "\\", "-LRB-", "\\times", "\\", "-RRB-", "512", "including", "both", "training", "and", "testing", "."], ["All", "the", "networks", "are", "trained", "from", "scratch", "using", "Adam", "optimizer", "for", "100", "epochs", "with", "a", "total", "batch", "size", "of", "8", "."], ["The", "learning", "rate", "is", "first", "initialized", "to", "0.0001", "and", "divided", "by", "5", "following", "milestones", "at", "the", "30th", ",", "50th", ",", "and", "80th", "epochs", "."], ["The", "output", "channel", "width", "\\", "-LRB-", "k\\", "-RRB-", "is", "-LSB-", "14,16,20,20,40", "-RSB-", "for", "the", "71-layer", "and", "-LSB-", "14,16,40", "-RSB-", "for", "the", "33-layer", "."], ["Additionally", ",", "by", "empirical", "finding", ",", "the", "coefficient", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "for", "high-level", "tasks", "is", "set", "to", "0.01", ",", "0.05", ",", "and", "0.002", "for", "lane", "detection", ",", "depth", "estimation", ",", "and", "object", "detection", ",", "respectively", "."], ["All", "the", "experiments", "are", "performed", "by", "using", "one", "NVIDIA", "TITAN", "X", "GPU", "and", "one", "Intel", "Core", "i7-6700K", "CPU", "based", "on", "the", "PyTorch", "framework", "."]], "ner": [[], [[27, 28, "a"], [34, 36, "p"], [38, 38, "v"]], [[41, 42, "p"], [47, 47, "v"], [49, 62, "c"]], [[65, 67, "a"], [70, 70, "p"], [76, 78, "c"], [83, 85, "c"]], [[94, 94, "a"], [97, 97, "p"], [106, 106, "v"], [100, 102, "c"], [108, 108, "v"], [112, 114, "c"], [111, 111, "v"]], [[146, 147, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [9, 9, "p"], [12, 12, "v"]], [[27, 27, "a"], [30, 30, "v"], [31, 31, "p"], [35, 36, "p"], [38, 38, "v"]], [[41, 42, "p"], [47, 47, "v"], [51, 51, "v"], [56, 56, "v"], [58, 58, "v"], [61, 61, "v"]], [[65, 67, "p"], [70, 70, "p"]], [[97, 97, "p"], [106, 106, "v"], [108, 108, "v"], [111, 111, "v"]], [[132, 132, "v"], [138, 138, "v"]]], "predicted_relations": [[], [[34, 36, 27, 28, "USED-FOR"], [38, 38, 34, 36, "USED-FOR"]], [[49, 62, 47, 47, "USED-FOR"]], [[70, 70, 65, 67, "USED-FOR"]], [[97, 97, 94, 94, "USED-FOR"], [100, 102, 106, 106, "USED-FOR"], [100, 102, 108, 108, "USED-FOR"], [100, 102, 111, 111, "USED-FOR"], [112, 114, 106, 106, "USED-FOR"], [112, 114, 108, 108, "USED-FOR"], [112, 114, 111, 111, "USED-FOR"]], []]}
{"doc_key": "2105.05641-05758d91-eb28-4667-85a2-a672b7fecb7d", "sentences": [["We", "pre-train", "5", "BERT", "base", "and", "large", "uncased", "English", "models", ",", "each", "with", "the", "same", "configurations", "as", "in", "-LSB-", "10", "-RSB-", "using", "Tensorflowhttps", ":", "//github.com/tensorflow/models/tree/master/official/nlp/bert", "."], ["However", ",", "each", "model", "differs", "in", "its", "random", "seed", ",", "resulting", "in", "different", "parameter", "initializations", "and", "training", "data", "permutations", "."], ["Hence", ",", "it", "is", "expected", "that", "the", "checkpoints", "will", "each", "end", "up", "at", "a", "different", "local", "minima", "."], ["It", "should", "be", "noted", "that", "BERT", "uses", "static", "masking", "instead", "of", "dynamic", "masking", ",", "so", "the", "set", "of", "pre-training", "examples", "remains", "the", "same", "."]], "ner": [[[3, 9, "a"]], [], [], [[71, 72, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "v"], [3, 4, "a"]], [], [], [[69, 69, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2104.05752-a8f5584b-d8e3-4d66-bb75-5657ca3c7acd", "sentences": [["ASR-Text-Speech-2", "Model", "Similar", "to", "the", "ASR-Text-Speech-1", "model", ",", "ASR-Text-Speech-2", "also", "improves", "upon", "Text-Speech", "by", "taking", "ASR", "transcripts", "as", "its", "input", "."], ["However", ",", "ASR-Text-Speech-2", "uses", "ASR", "transcripts", "in", "addition", "to", "ground", "truth", "transcripts", "to", "domain-adapt", "the", "BERT", "branch", "before", "joint", "training", "it", "with", "the", "acoustic", "branch", "."], ["In", "this", "domain", "adaptation", "phase", ",", "we", "build", "a", "separate", "BERT", "model", "that", "has", "a", "structure", "identical", "to", "the", "text", "encoder", "in", "Text-Speech", "."], ["We", "domain-adapt", "this", "BERT", "model", "on", "the", "ground", "truth", "and", "ASR", "transcripts", "from", "our", "target", "datasets", "with", "a", "learning", "rate", "of", "2e-5", "."], ["We", "then", "use", "this", "domain-adapted", "BERT", "model", "as", "our", "text", "branch", "without", "any", "further", "fine-tuning", "."], ["By", "freezing", "the", "BERT", "text", "branch", "in", "the", "final", "training", "round", ",", "we", "let", "the", "domain-adapted", "text", "embeddings", "guide", "our", "audio", "embeddings", "."], ["This", "is", "why", ",", "in", "this", "stage", ",", "we", "only", "use", "pairs", "of", "audio", "and", "ground", "truth", "transcripts", ",", "which", "provides", "better-quality", "text", "embeddings", "compared", "to", "ASR", "transcripts", "."]], "ner": [[[0, 1, "a"]], [], [], [[89, 90, "p"], [92, 92, "v"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 1, "a"], [5, 6, "a"]], [[36, 37, "a"]], [[57, 58, "a"]], [[74, 75, "a"], [89, 90, "p"], [92, 92, "v"]], [[99, 100, "a"]], [[113, 113, "a"]], []], "predicted_relations": [[], [], [], [[92, 92, 89, 90, "USED-FOR"]], [], [], []]}
{"doc_key": "2108.13073-92880475-8205-4a3a-b237-3f11c14539a0", "sentences": [["Pre-training", "was", "only", "done", "with", "GRU", "encoders", ",", "as", "discussed", "in", "Section", "REF", "."], ["Due", "to", "the", "large", "number", "of", "entities", "in", "the", "pre-training", "set", ",", "1-N", "sampling", "is", "only", "performed", "with", "negative", "examples", "from", "the", "same", "batch", ",", "and", "batches", "of", "size", "4096", "were", "used", ",", "following", "-LSB-", "3", "-RSB-", "."], ["The", "learning", "rate", "was", "selected", "from", "-LCB-", "\\", "-LRB-", "1\\cdot", "10^", "-LCB-", "-4", "-RCB-", ",", "3\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "-RCB-", ",", "while", "the", "dropout", "rate", "was", "selected", "from", "-LCB-", "\\", "-LRB-", "0.2", ",", "0.3\\", "-RRB-", "-RCB-", "for", "ConvE", "and", "-LCB-", "\\", "-LRB-", "0.3", ",", "0.4\\", "-RRB-", "-RCB-", "for", "TuckER", "."], ["For", "5\\", "-LRB-", "^\\star", "\\", "-RRB-", "E", ",", "the", "dropout", "rate", "was", "not", "used", ",", "but", "N3", "regularization", "was", "-LSB-", "13", "-RSB-", ",", "its", "weight", "selected", "from", "-LCB-", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "\\", "-LRB-", "0.03\\", "-RRB-", "-RCB-", "."], ["For", "TuckER", ",", "models", "with", "embedding", "dimensions", "100", ",", "200", ",", "and", "300", "were", "trained", "."], ["We", "saved", "the", "best", "model", "of", "each", "dimension", "for", "fine-tuning", "."], ["For", "ConvE", ",", "models", "with", "embedding", "dimensions", "300", "and", "500", "were", "trained", ",", "and", "the", "best", "model", "for", "each", "dimension", "was", "saved", "for", "fine-tuning", "."], ["Following", "-LSB-", "10", "-RSB-", ",", "we", "use", "a", "single", "2d", "convolution", "layer", "with", "32", "channels", "and", "\\", "-LRB-", "3\\times", "3\\", "-RRB-", "kernel", "size", "."], ["When", "the", "dimension", "of", "entities", "and", "relations", "is", "300", ",", "they", "were", "reshaped", "into", "\\", "-LRB-", "15\\times", "20\\", "-RRB-", "inputs", ",", "while", "the", "\\", "-LRB-", "20\\times", "25\\", "-RRB-", "input", "shapes", "were", "used", "for", "the", "500-dimensional", "embeddings", "."], ["For", "5\\", "-LRB-", "^\\star", "\\", "-RRB-", "E", ",", "models", "with", "embedding", "dimensions", "200", "and", "500", "were", "trained", ",", "and", "the", "best", "model", "for", "each", "dimension", "was", "saved", "for", "fine-tuning", "."], ["Following", "-LSB-", "3", "-RSB-", ",", "we", "trained", "each", "model", "for", "100", "epochs", "."], ["Testing", "on", "the", "validation", "set", "is", "performed", "each", "20", "epochs", ",", "and", "the", "model", "with", "the", "best", "overall", "mean", "reciprocal", "rank", "-LRB-", "MRR", "-RRB-", "is", "selected", "."]], "ner": [[[5, 6, "a"]], [[26, 27, "a"], [43, 43, "v"]], [[53, 54, "a"], [78, 79, "a"], [92, 92, "p"], [86, 86, "v"], [88, 88, "v"], [97, 97, "v"], [103, 103, "p"], [88, 88, "v"], [97, 97, "v"], [99, 99, "v"]], [[114, 115, "a"], [121, 122, "a"], [129, 129, "p"], [135, 135, "v"], [140, 140, "v"]], [[145, 145, "p"]], [], [[172, 172, "p"]], [[205, 207, "a"], [210, 210, "p"], [209, 209, "v"], [217, 218, "p"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[26, 26, "v"], [43, 43, "v"]], [[53, 54, "p"], [78, 79, "p"], [86, 86, "v"], [88, 88, "v"], [92, 92, "a"], [97, 97, "v"], [99, 99, "v"], [103, 103, "a"]], [[114, 115, "p"], [121, 122, "a"], [135, 135, "v"], [140, 140, "v"]], [[145, 145, "a"], [151, 151, "v"], [153, 153, "v"], [156, 156, "v"]], [], [[172, 172, "a"], [178, 178, "v"], [180, 180, "v"]], [[209, 209, "v"], [214, 215, "v"]], [[228, 228, "v"], [236, 237, "v"], [245, 246, "v"], [254, 254, "v"]], [[269, 269, "v"], [271, 271, "v"]], [[297, 297, "v"], [298, 298, "p"]], [[308, 308, "v"], [309, 309, "p"]]], "predicted_relations": [[], [], [[92, 92, 78, 79, "USED-FOR"], [86, 86, 92, 92, "USED-FOR"], [88, 88, 92, 92, "USED-FOR"], [103, 103, 78, 79, "USED-FOR"], [88, 88, 92, 92, "USED-FOR"]], [[129, 129, 114, 115, "USED-FOR"], [129, 129, 121, 122, "USED-FOR"]], [], [], [], [[210, 210, 205, 207, "USED-FOR"], [209, 209, 210, 210, "USED-FOR"], [217, 218, 205, 207, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2108.13051-df4966e4-55f9-47f3-bd69-331e25cbba50", "sentences": [["The", "embedding", "model", "requires", "hp", "tuning", "to", "be", "trained", "effectively", "on", "a", "specific", "dataset", "."], ["The", "two", "most", "important", "hp", "in", "a", "kge", ",", "according", "to", "-LSB-", "13", "-RSB-", ",", "are", "the", "embedding", "dimension", "and", "the", "optimizer", "-LRB-", "with", "its", "learning", "rate", "-RRB-", "."], ["Other", "parameters", ",", "like", "the", "negative", "sampling", ",", "can", "affect", "the", "time", "to", "train", "a", "model", ",", "but", "they", "are", "less", "significant", "for", "the", "final", "accuracy", "."], ["In", "particular", ",", "in", "fig", ":", "negative", ",", "negative", "sampling", "is", "difficult", "to", "manage", "since", "it", "is", "hard", "to", "have", "a", "negative", "set", "-LRB-", "a", "set", "of", "false", "triples", "-RRB-", "available", "."], ["Perturbing", "the", "triples", "randomly", "is", "challenging", "as", "there", "is", "no", "certainty", "that", "this", "is", "not", "a", "possible", "repurposed", "drug", ",", "and", "inserting", "it", "in", "the", "negative", "set", "would", "indicate", "to", "the", "model", "to", "penalize", "an", "actually", "correct", "representation", "of", "the", "triple", "."], ["For", "this", "reason", ",", "we", "choose", "a", "low", "value", "for", "the", "negative", "sampling", "that", "reduces", "the", "probability", "of", "this", "event", "and", "saves", "computational", "resources", "."], ["The", "result", "shows", "that", "a", "low", "embedding", "dimension", "yields", "the", "worst", "accuracy", "."], ["Instead", ",", "an", "exaggerated", "embedding", "dimension", "does", "not", "bring", "benefits", "but", "only", "faster", "overfitting", "and", "a", "higher", "computational", "cost", "."], ["For", "the", "kg", "proposed", "in", "this", "work", ",", "the", "best", "embedding", "size", "is", "128", "-LRB-", "fig", ":", "embDim", "-RRB-", "since", "it", "is", "the", "best", "compromise", "between", "accuracy", "and", "model", "complexity", "."], ["The", "best", "optimizer", "proved", "to", "be", "ADAM", "with", "learning", "rate", "\\", "-LRB-", "\\lambda", "=", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "coherently", "to", "-LSB-", "16", "-RSB-", "-LRB-", "fig", ":", "optimizer", ",", "fig", ":", "lr", "-RRB-", "."]], "ner": [[[1, 2, "a"]], [[32, 33, "p"], [36, 36, "p"], [40, 41, "p"]], [[49, 50, "p"]], [[79, 80, "p"], [75, 77, "c"]], [], [[156, 157, "p"], [152, 152, "v"]], [[176, 177, "p"], [175, 175, "v"]], [[187, 188, "p"]], [[216, 216, "v"], [218, 220, "c"]], [[236, 236, "p"], [263, 263, "p"], [240, 240, "v"], [261, 263, "c"], [242, 243, "p"], [265, 267, "c"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[16, 16, "v"], [40, 41, "p"]], [], [], [], [], [], [], [[205, 205, "a"], [216, 216, "v"]], [[240, 240, "a"], [242, 243, "p"], [248, 250, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[175, 175, 176, 177, "USED-FOR"]], [], [[218, 220, 216, 216, "USED-FOR"]], []]}
{"doc_key": "2108.13032-00abea82-a7e7-489e-b4f6-daf2f0d6a1ca", "sentences": [["To", "save", "pretraining", "time", ",", "we", "tokenize", "the", "corpus", "in", "advance", "and", "cache", "the", "results", "to", "files", "."], ["The", "tokenization", "can", "be", "done", "with", "20", "parallel", "4-core", "CPU", "machines", "in", "2", "hours", "."], ["Following", "RoBERTa", "-LSB-", "22", "-RSB-", ",", "we", "use", "Masked", "Language", "Modeling", "-LRB-", "MLM", "-RRB-", "as", "the", "pretraining", "objective", ",", "without", "Next", "Sentence", "Prediction", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [[24, 24, "v"], [30, 30, "v"]], [[34, 34, "a"], [41, 46, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2108.13032-f8df9e36-cf46-4b16-82d5-ed81103bf5d4", "sentences": [["For", "optimization", "we", "use", "Adam", "with", "\\", "-LRB-", "0.01\\", "-RRB-", "weight", "decay", "-LSB-", "2", "-RSB-", "."], ["The", "learning", "rate", "is", "set", "to", "1e-4", ",", "with", "10k", "steps", "warmup", "then", "linear", "decay", "to", "0", "."]], "ner": [[[4, 4, "a"], [10, 11, "p"], [8, 8, "v"], [8, 8, "v"]], [[17, 18, "p"], [22, 22, "v"], [26, 27, "p"], [25, 25, "v"], [29, 30, "p"], [32, 32, "v"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "v"], [10, 11, "p"]], [[17, 18, "p"], [22, 22, "v"], [25, 25, "v"], [27, 27, "a"], [29, 30, "a"], [32, 32, "v"]]], "predicted_relations": [[[10, 11, 4, 4, "USED-FOR"], [8, 8, 10, 11, "USED-FOR"], [8, 8, 10, 11, "USED-FOR"]], [[22, 22, 17, 18, "USED-FOR"], [22, 22, 26, 27, "USED-FOR"], [25, 25, 26, 27, "USED-FOR"]]]}
{"doc_key": "2108.13865-71a601ef-3dcd-4bb5-baa8-4e041d0e5b12", "sentences": [["Our", "InSeGAN", "modules", "are", "implemented", "in", "PyTorch", "."], ["As", "alluded", "to", "above", ",", "we", "generate", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "depth", "images", "using", "our", "simulator", ";", "however", ",", "we", "use", "\\", "-LRB-", "64\\times", "64\\", "-RRB-", "images", "in", "our", "InSeGAN", "pipeline", "."], ["To", "this", "end", ",", "each", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "image", "is", "rescaled", "to", "\\", "-LRB-", "64\\times", "64\\", "-RRB-", "and", "normalized", "using", "mean", "subtraction", "and", "normalization", "by", "the", "variance", "."], ["For", "training", ",", "we", "use", "horizontal", "and", "vertical", "image", "flips", "for", "data", "augmentations", "."], ["We", "do", "not", "use", "any", "other", "augmentation", "scheme", "."]], "ner": [[[1, 2, "a"], [6, 6, "a"]], [[24, 24, "a"]], [[63, 64, "a"], [66, 69, "a"]], [[76, 80, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[18, 18, "v"], [33, 33, "v"], [38, 39, "a"]], [[49, 49, "v"], [58, 58, "v"]], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2104.06069-b3759df4-3668-4423-83ff-354ac2a3f373", "sentences": [["For", "BERT", "pre-training", ",", "we", "set", "the", "parameters", "in", "-LRB-", "REF", "-RRB-", "as", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", ",", "\\", "-LRB-", "c_", "-LCB-", "min", "-RCB-", "=", "0.01\\", "-RRB-", "and", "\\", "-LRB-", "c_", "-LCB-", "max", "-RCB-", "=", "0.3\\", "-RRB-", "for", "LAMB", "and", "1-bit", "LAMB", "."], ["For", "1-bit", "LAMB", ",", "we", "set", "\\", "-LRB-", "\\beta", "_3", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "r_", "-LCB-", "min", "-RCB-", "=", "0.5\\", "-RRB-", ",", "\\", "-LRB-", "r_", "-LCB-", "max", "-RCB-", "=", "4.0\\", "-RRB-", ",", "and", "\\", "-LRB-", "r_", "-LCB-", "threshold", "-RCB-", "=", "0.1\\", "-RRB-", "in", "Algorithm", "REF", "."], ["For", "convergence", "analysis", ",", "we", "set", "total", "batch", "size", "as", "64K", "for", "seqlen", "128", "and", "32K", "for", "seqlen", "512", "."], ["For", "performance", "analysis", ",", "we", "test", "different", "batch", "sizes", "from", "8K", "to", "64K", "."]], "ner": [[[49, 49, "a"], [52, 52, "a"], [18, 18, "v"], [26, 26, "v"], [36, 36, "v"], [46, 46, "v"], [51, 52, "a"], [18, 18, "v"], [1, 2, "a"]], [[56, 56, "a"], [65, 65, "v"], [55, 56, "a"], [65, 65, "v"], [75, 75, "v"], [85, 85, "v"], [96, 96, "v"]], [[103, 104, "a"], [108, 110, "p"], [112, 112, "v"], [114, 115, "c"], [117, 117, "v"], [119, 120, "c"], [109, 110, "p"], [112, 112, "v"]], [[134, 134, "v"], [123, 124, "a"], [132, 132, "v"], [134, 134, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[18, 18, "v"], [26, 26, "v"], [36, 36, "v"], [46, 46, "v"], [49, 49, "a"], [51, 51, "v"], [52, 52, "a"]], [[55, 55, "v"], [56, 56, "a"], [65, 65, "v"], [75, 75, "v"], [85, 85, "v"], [96, 96, "v"]], [[109, 110, "p"], [112, 112, "v"], [113, 115, "c"], [117, 117, "v"]], [[129, 130, "p"], [132, 132, "v"], [134, 134, "v"]]], "predicted_relations": [[], [], [[112, 112, 108, 110, "USED-FOR"], [114, 115, 112, 112, "USED-FOR"], [114, 115, 117, 117, "USED-FOR"], [114, 115, 112, 112, "USED-FOR"], [117, 117, 108, 110, "USED-FOR"], [119, 120, 112, 112, "USED-FOR"], [119, 120, 117, 117, "USED-FOR"], [119, 120, 112, 112, "USED-FOR"], [112, 112, 108, 110, "USED-FOR"]], []]}
{"doc_key": "2104.06069-a689b746-7b6f-45fc-b7bc-7e3b286411bf", "sentences": [["For", "BERT", "pre-training", "seqlen", "128", ",", "the", "learning", "rate", "starts", "from", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "exponentially", "increases", "to", "\\", "-LRB-", "12\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "as", "a", "warmup", "in", "the", "first", "450", "steps", ",", "then", "decays", "into", "0.9", "of", "the", "original", "after", "every", "250", "steps", "."], ["The", "total", "number", "of", "steps", "is", "5993", "."], ["For", "1-bit", "LAMB", "we", "use", "the", "first", "1000", "steps", "-LRB-", "16.7", "%", "-RRB-", "as", "the", "warmup", "stage", "."], ["For", "BERT", "pre-training", "seqlen", "512", ",", "the", "learning", "rate", "starts", "from", "0", ",", "exponentially", "increases", "to", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "as", "a", "warmup", "in", "the", "first", "150", "steps", ",", "then", "decays", "into", "0.9", "of", "the", "original", "after", "every", "150", "steps", "."], ["The", "total", "number", "of", "steps", "is", "555", "."], ["For", "1-bit", "LAMB", "we", "use", "the", "first", "107", "steps", "-LRB-", "19.3", "%", "-RRB-", "as", "the", "warmup", "stage", "."]], "ner": [[[1, 2, "a"], [3, 3, "p"], [4, 4, "v"], [7, 8, "p"], [35, 40, "c"], [35, 40, "c"], [1, 4, "c"]], [], [[63, 64, "a"], [77, 78, "p"]], [[81, 82, "a"], [83, 83, "p"], [84, 84, "v"], [87, 88, "p"], [107, 112, "c"], [81, 84, "c"]], [], [[135, 136, "a"], [149, 150, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [3, 4, "a"], [7, 8, "p"], [39, 39, "v"], [45, 45, "v"], [51, 51, "v"]], [[60, 60, "v"]], [[64, 64, "a"], [69, 69, "v"], [72, 73, "v"]], [[81, 81, "a"], [83, 84, "a"], [87, 88, "p"], [91, 91, "v"], [111, 111, "v"], [117, 117, "v"], [123, 123, "v"]], [[132, 132, "v"]], [[136, 136, "a"], [141, 141, "v"], [144, 145, "v"]]], "predicted_relations": [[[3, 3, 1, 2, "USED-FOR"], [4, 4, 3, 3, "USED-FOR"], [7, 8, 1, 2, "USED-FOR"], [35, 40, 4, 4, "USED-FOR"], [35, 40, 4, 4, "USED-FOR"], [1, 4, 4, 4, "USED-FOR"]], [], [[77, 78, 63, 64, "USED-FOR"]], [[83, 83, 81, 82, "USED-FOR"], [84, 84, 83, 83, "USED-FOR"], [87, 88, 81, 82, "USED-FOR"], [107, 112, 84, 84, "USED-FOR"], [81, 84, 84, 84, "USED-FOR"]], [], [[149, 150, 135, 136, "USED-FOR"]]]}
{"doc_key": "2104.06069-f76b4bd1-f59e-45a4-90d4-e53cbd77ffbe", "sentences": [["For", "GLUE", "benchmarks", "we", "use", "Adam", "optimizer", "and", "perform", "single-task", "training", "on", "the", "dev", "set", "."], ["Following", "the", "setup", "in", "the", "BERT", "paper", "-LSB-", "6", "-RSB-", ",", "we", "use", "a", "batch", "size", "of", "32", "and", "fine-tune", "for", "3", "epochs", "for", "all", "GLUE", "tasks", "."], ["For", "each", "task", ",", "we", "select", "the", "best", "learning", "rate", "among", "\\", "-LRB-", "\\lbrace", "2\\times", "10^", "-LCB-", "-5", "-RCB-", ",3\\times", "10^", "-LCB-", "-5", "-RCB-", ",4\\times", "10^", "-LCB-", "-5", "-RCB-", ",5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\rbrace", "\\", "-RRB-", "."], ["For", "SQuAD", "fine-tuning", "we", "use", "Adam", "optimizer", "and", "the", "same", "parameters", "as", "published", "by", "HuggingFace", "-LRB-", "batch", "size", "=", "24", ",", "learning", "rate", "=", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "dropout", "=", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "2", "epochs", "-RRB-", "."]], "ner": [[[5, 6, "a"]], [[30, 31, "p"], [33, 33, "v"], [38, 38, "p"], [37, 37, "v"]], [[52, 53, "p"], [63, 63, "v"], [58, 58, "v"]], [[87, 88, "a"], [98, 99, "p"], [101, 101, "v"], [103, 104, "p"], [116, 116, "p"], [120, 120, "v"], [124, 124, "p"], [108, 108, "v"], [123, 123, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"], [9, 10, "c"]], [[30, 31, "p"], [33, 33, "v"], [37, 37, "v"], [38, 38, "p"]], [[52, 53, "p"]], [[83, 83, "a"], [87, 87, "a"], [96, 96, "a"], [98, 99, "p"], [101, 101, "v"], [103, 104, "p"], [116, 116, "p"], [120, 120, "v"], [123, 123, "v"], [124, 124, "p"]]], "predicted_relations": [[], [[33, 33, 38, 38, "USED-FOR"], [37, 37, 38, 38, "USED-FOR"]], [[58, 58, 52, 53, "USED-FOR"]], [[98, 99, 87, 88, "USED-FOR"], [101, 101, 98, 99, "USED-FOR"], [103, 104, 87, 88, "USED-FOR"], [120, 120, 124, 124, "USED-FOR"], [123, 123, 116, 116, "USED-FOR"], [123, 123, 124, 124, "USED-FOR"]]]}
{"doc_key": "2104.06069-635f021b-11db-4fae-8c1f-85c3a7cc4792", "sentences": [["For", "experiments", "in", "Section", "REF", ",", "for", "both", "LAMB", "and", "1-bit", "Adam", "we", "use", "batch", "size", "=", "16K", ",", "28125/3125", "steps", "for", "seqlen", "128/512", ",", "weight", "decay", "=", "0.01", ",", "linear", "LR", "warmup", "and", "decay", "."], ["For", "LAMB", ",", "we", "use", "learning", "rate", "=", "\\", "-LRB-", "3.54\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "10", "%", "LR", "warmup", ",", "clipping", "configs", "-LRB-", "\\", "-LRB-", "c_", "-LCB-", "min", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "c_", "-LCB-", "max", "-RCB-", "\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "-RRB-", "as", "0.1", "and", "1", "."], ["For", "1-bit", "Adam", ",", "we", "use", "learning", "rates", "\\", "-LRB-", "\\in", "\\lbrace", "1\\times", "10^", "-LCB-", "-4", "-RCB-", ",2\\times", "10^", "-LCB-", "-4", "-RCB-", ",3\\times", "10^", "-LCB-", "-4", "-RCB-", "\\rbrace", "\\", "-RRB-", ",", "LR", "warmup", "\\", "-LRB-", "\\in", "\\lbrace", "5\\", "%", ",10\\", "%", ",20\\", "%", "\\rbrace", "\\", "-RRB-", "."], ["All", "of", "these", "training", "parameters", "-LRB-", "except", "LAMB", "clipping", "configs", "-RRB-", "are", "from", "the", "LAMB", "paper", "."], ["For", "1-bit", "Adam", ",", "following", "the", "original", "work", "'s", "strategy", "we", "set", "the", "number", "of", "warmup", "steps", "as", "4000", "-LRB-", "out", "of", "total", "28125", "steps", "-RRB-", "for", "seqlen", "128", "and", "475", "-LRB-", "out", "of", "3125", "-RRB-", "for", "seqlen", "512", "."]], "ner": [[[8, 8, "a"], [14, 15, "p"], [17, 17, "v"], [20, 20, "p"], [19, 19, "v"], [22, 23, "c"], [25, 26, "p"], [28, 28, "v"], [31, 32, "p"], [10, 11, "a"], [31, 32, "p"], [22, 23, "c"]], [[37, 37, "a"], [41, 42, "p"], [56, 57, "p"], [59, 60, "p"], [56, 57, "p"]], [[120, 121, "p"], [90, 91, "a"], [95, 96, "p"], [120, 121, "p"]], [[143, 143, "a"], [150, 150, "a"], [144, 145, "p"]], [[169, 169, "p"], [177, 177, "p"], [154, 155, "a"], [166, 169, "p"], [171, 171, "v"], [180, 181, "c"], [183, 183, "v"], [190, 191, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [11, 11, "a"], [14, 15, "p"], [17, 17, "v"], [19, 19, "v"], [25, 26, "p"], [28, 28, "v"], [31, 32, "a"], [34, 34, "p"]], [[37, 37, "a"], [41, 42, "p"], [54, 55, "v"], [56, 57, "a"], [85, 85, "v"], [87, 87, "v"]], [[91, 91, "a"], [95, 96, "p"], [120, 121, "a"], [125, 132, "v"]], [], [[155, 155, "a"], [168, 168, "a"], [171, 171, "v"], [176, 176, "v"], [183, 183, "v"], [187, 187, "v"]]], "predicted_relations": [[[14, 15, 8, 8, "USED-FOR"], [17, 17, 14, 15, "USED-FOR"], [17, 17, 20, 20, "USED-FOR"], [17, 17, 31, 32, "USED-FOR"], [17, 17, 31, 32, "USED-FOR"], [20, 20, 8, 8, "USED-FOR"], [20, 20, 10, 11, "USED-FOR"], [19, 19, 14, 15, "USED-FOR"], [19, 19, 20, 20, "USED-FOR"], [19, 19, 25, 26, "USED-FOR"], [19, 19, 31, 32, "USED-FOR"], [19, 19, 31, 32, "USED-FOR"], [22, 23, 17, 17, "USED-FOR"], [22, 23, 19, 19, "USED-FOR"], [22, 23, 28, 28, "USED-FOR"], [25, 26, 8, 8, "USED-FOR"], [25, 26, 10, 11, "USED-FOR"], [28, 28, 25, 26, "USED-FOR"], [28, 28, 31, 32, "USED-FOR"], [28, 28, 31, 32, "USED-FOR"], [31, 32, 8, 8, "USED-FOR"], [31, 32, 10, 11, "USED-FOR"], [31, 32, 8, 8, "USED-FOR"], [31, 32, 10, 11, "USED-FOR"], [22, 23, 17, 17, "USED-FOR"], [22, 23, 19, 19, "USED-FOR"], [22, 23, 28, 28, "USED-FOR"]], [[41, 42, 37, 37, "USED-FOR"], [56, 57, 37, 37, "USED-FOR"], [59, 60, 37, 37, "USED-FOR"], [56, 57, 37, 37, "USED-FOR"]], [[120, 121, 90, 91, "USED-FOR"], [95, 96, 90, 91, "USED-FOR"], [120, 121, 90, 91, "USED-FOR"]], [[144, 145, 143, 143, "USED-FOR"], [144, 145, 150, 150, "USED-FOR"]], [[169, 169, 154, 155, "USED-FOR"], [177, 177, 154, 155, "USED-FOR"], [166, 169, 154, 155, "USED-FOR"], [171, 171, 169, 169, "USED-FOR"], [171, 171, 177, 177, "USED-FOR"], [171, 171, 166, 169, "USED-FOR"], [180, 181, 171, 171, "USED-FOR"], [180, 181, 183, 183, "USED-FOR"], [183, 183, 169, 169, "USED-FOR"], [183, 183, 177, 177, "USED-FOR"], [183, 183, 166, 169, "USED-FOR"], [190, 191, 171, 171, "USED-FOR"], [190, 191, 183, 183, "USED-FOR"]]]}
{"doc_key": "2104.05942-c9d1e72f-322e-4e34-8c49-0cce7175bb8a", "sentences": [["and", "then", "compute", "the", "model", "parameters", "of", "robust", "RENs", "based", "on", "the", "matrix", "partition", "of", "\\", "-LRB-", "H\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "."], ["A", "special", "case", "with", "\\", "-LRB-", "Q=-\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "\\gamma", "-RCB-", "I", ",", "R=\\gamma", "I", ",", "S=0\\", "-RRB-", "and", "\\", "-LRB-", "D_", "-LCB-", "22", "-RCB-", "\\", "-RRB-", "was", "reported", "in", "-LSB-", "56", "-RSB-", "."]], "ner": [[], [[30, 30, "p"], [39, 39, "p"], [42, 42, "p"], [42, 42, "v"]]], "relations": [[], []], "predicted_ner": [[[8, 8, "a"]], []], "predicted_relations": [[], [[42, 42, 42, 42, "USED-FOR"], [42, 42, 30, 30, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"], [42, 42, 42, 42, "USED-FOR"]]]}
{"doc_key": "2110.04020-466ca434-0891-4871-b2e2-5a35682a3a8e", "sentences": [["Our", "models", "are", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "34", "-RSB-", "with", "the", "triangular", "learning", "rate", "schedule", "from", "-LSB-", "57", "-RSB-", "."], ["Our", "weight", "distribution", "experiments", "are", "conducted", "using", "900", "transformers", "trained", "by", "likelihood", "maximization", "with", "SGD", "as", "done", "in", "-LSB-", "20", "-RSB-", "."]], "ner": [[[6, 7, "a"], [13, 16, "a"]], [[33, 34, "a"], [36, 36, "a"]]], "relations": [[], []], "predicted_ner": [[[6, 6, "a"]], [[29, 29, "v"], [33, 34, "a"], [36, 36, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2110.04077-010bf8ef-5536-4d33-8b36-f41ed0ebbd11", "sentences": [["We", "train", "the", "model", "using", "Adam", "with", "\\", "-LRB-", "-LCB-", "\\beta", "-RCB-", "_1=0.5\\", "-RRB-", "and", "\\", "-LRB-", "-LCB-", "\\beta", "-RCB-", "_2", "=", "0.9\\", "-RRB-", "-LSB-", "15", "-RSB-", "with", "a", "mini-batch", "size", "of", "128", "."], ["For", "all", "the", "convolutions", "in", "the", "modules", ",", "we", "set", "the", "kernel", "size", "to", "-LSB-", "4", ",", "4", "-RSB-", ",", "stride", "to", "-LSB-", "2", ",", "2", "-RSB-", "and", "padding", "to", "-LSB-", "1", ",", "1", "-RSB-", "."], ["We", "set", "the", "numbers", "of", "output", "channels", "of", "the", "block", "to", "-LSB-", "64", ",", "128", ",", "256", ",", "64", "-RSB-", "for", "the", "convolution", "in", "the", "encoder", ",", "-LSB-", "256", ",", "256", ",", "128", ",", "64", "-RSB-", "for", "the", "transposed", "convolution", "in", "the", "generator", ",", "and", "-LSB-", "64", ",", "128", ",", "256", ",", "256", "-RSB-", "for", "the", "convolution", "in", "the", "discriminator", "."], ["Other", "hyper-parameters", "are", "tuned", "with", "the", "successive", "halving", "pruner", "in", "a", "hyper-parameter", "optimization", "framework", "Optuna", "-LSB-", "0", "-RSB-", "."], ["Such", "hyper-parameters", "include", "the", "learning", "rates", "of", "the", "encoder", "and", "generator", ",", "the", "learning", "rate", "of", "the", "discriminator", "using", "two", "time-scale", "update", "rule", "-LRB-", "TTUR", "-RRB-", "-LSB-", "10", "-RSB-", ",", "the", "gradient", "penalty", "coefficient", "in", "WGAN-GP", ",", "the", "dimensions", "of", "latent", "vectors", "from", "the", "encoder", ",", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "and", "the", "slope", "parameters", "of", "leaky", "ReLU", "activation", "functions", "in", "the", "modules", "."]], "ner": [[[5, 5, "a"], [12, 12, "v"], [22, 22, "v"], [29, 30, "a"]], [[45, 46, "a"], [54, 54, "a"], [62, 62, "a"]], [[75, 76, "a"]], [[145, 145, "a"]], [[154, 155, "a"], [181, 183, "a"], [188, 191, "a"], [185, 185, "a"]], [[209, 215, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [22, 22, "v"], [29, 30, "p"], [32, 32, "v"]], [], [], [[145, 145, "a"]], [[169, 169, "v"], [170, 175, "a"], [181, 183, "p"], [185, 185, "a"]], [[212, 213, "a"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2110.07038-23aea2b6-911f-4ed1-bcb9-3a1112493958", "sentences": [["Following", "BERT", "-LSB-", "8", "-RSB-", ",", "we", "train", "ElasticBERT", "in", "two", "different", "configurations", ":", "ElasticBERTBASE", "and", "ElasticBERTLARGE", ",", "which", "have", "the", "same", "model", "sizes", "with", "BERTBASE", "and", "BERTLARGE", ",", "respectively", "."], ["The", "parameters", "of", "ElasticBERT", "are", "initialized", "with", "BERT", ",", "and", "therefore", "it", "has", "the", "same", "vocabulary", "and", "tokenizer", "as", "BERT", "."], ["ElasticBERT", "is", "pre-trained", "on", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "160GB", "uncompressed", "English", "text", "corpora", ",", "which", "is", "comprised", "of", "English", "Wikipedia", "-LRB-", "12GB", "-RRB-", ",", "BookCorpus", "-LRB-", "4GB", "-RRB-", "-LSB-", "60", "-RSB-", ",", "OpenWebText", "-LRB-", "38GB", "-RRB-", "-LSB-", "12", "-RSB-", ",", "and", "part", "of", "the", "C4", "corpus", "-LRB-", "110GB", "-RRB-", "-LSB-", "32", "-RSB-", "."], ["We", "use", "Adam", "optimizer", "-LSB-", "18", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", "to", "pre-train", "ElasticBERTBASE", "and", "ElasticBERTLARGE", "for", "125K", "steps", "with", "the", "batch", "size", "of", "4096", "and", "learning", "rate", "of", "2e-4", "."], ["Our", "implementation", "is", "based", "on", "Huggingface", "'s", "Transformers", "-LSB-", "50", "-RSB-", "and", "the", "Megatron-LM", "toolkit", "-LSB-", "37", "-RSB-", "."], ["ElasticBERT", "is", "trained", "on", "64", "32G", "NVIDIA", "Tesla", "V100", "GPUs", "."]], "ner": [[[1, 1, "a"], [8, 8, "a"]], [[38, 38, "a"], [50, 50, "a"], [34, 34, "a"]], [[52, 52, "a"], [71, 72, "a"], [77, 77, "a"], [85, 85, "a"], [97, 98, "a"]], [[108, 109, "a"], [119, 119, "v"], [127, 127, "v"]], [[154, 156, "a"], [162, 163, "a"]], [[168, 168, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [8, 8, "a"], [10, 10, "v"], [14, 14, "a"], [16, 16, "a"], [25, 25, "a"], [27, 27, "a"]], [[34, 34, "a"], [38, 38, "a"], [50, 50, "a"]], [[52, 52, "a"], [61, 61, "v"], [74, 74, "v"], [79, 79, "v"], [87, 87, "v"], [97, 98, "a"], [100, 100, "v"]], [[108, 108, "a"], [119, 119, "v"], [124, 127, "p"], [127, 127, "v"], [131, 131, "a"], [133, 133, "a"], [135, 135, "v"], [139, 140, "p"], [142, 142, "v"], [144, 145, "p"], [147, 147, "v"]], [], [[168, 168, "a"], [172, 173, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2110.07816-edfdfa5c-22b5-45a8-bffa-ab1d484e382f", "sentences": [["All", "models", "are", "trained", "with", "Transformer", "architecture", "-LSB-", "32", "-RSB-", ",", "implemented", "in", "the", "Fairseq", "framework", "-LSB-", "20", "-RSB-", "."], ["The", "individual", "models", "are", "trained", "with", "the", "model", "hidden", "size", "of", "256", ",", "feed-forward", "hidden", "size", "of", "1024", ",", "and", "2", "layers", "."], ["All", "multilingual", "models", "either", "cluster-based", "or", "universal", "MNMT", "models", "with", "or", "without", "knowledge", "distillation", "were", "trained", "with", "the", "model", "hidden", "size", "of", "512", ",", "feed-forward", "hidden", "size", "of", "1024", ",", "and", "6", "layers", "."], ["We", "use", "the", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "and", "an", "inverse", "square", "root", "schedule", "with", "warmup", "-LRB-", "maximum", "LR", "0.0005", "-RRB-", "."], ["We", "apply", "dropout", "and", "label", "smoothing", "with", "a", "rate", "of", "0.3", "and", "0.1", "for", "bilingual", "and", "multilingual", "models", "respectively", "."]], "ner": [[[5, 6, "a"]], [[27, 29, "p"], [31, 31, "v"], [33, 35, "p"], [37, 37, "v"], [41, 41, "p"], [40, 40, "v"]], [[61, 63, "p"], [67, 69, "p"], [71, 71, "v"], [75, 75, "p"], [44, 45, "c"], [44, 45, "c"]], [[80, 81, "a"], [94, 95, "p"], [96, 96, "v"]], [[101, 101, "a"], [107, 107, "p"], [109, 109, "v"], [111, 111, "v"], [115, 116, "c"], [103, 104, "a"], [107, 107, "p"], [109, 109, "v"], [111, 111, "v"], [115, 116, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[14, 14, "a"]], [[31, 31, "v"], [37, 37, "v"], [40, 40, "v"], [41, 41, "p"]], [[65, 65, "v"], [71, 71, "v"], [74, 74, "v"], [75, 75, "p"]], [[80, 80, "a"], [92, 92, "a"], [96, 96, "v"]], [[101, 101, "a"], [103, 104, "a"], [109, 109, "v"], [111, 111, "v"]]], "predicted_relations": [[], [[37, 37, 33, 35, "USED-FOR"], [37, 37, 41, 41, "USED-FOR"], [40, 40, 33, 35, "USED-FOR"], [40, 40, 41, 41, "USED-FOR"]], [[71, 71, 67, 69, "USED-FOR"], [71, 71, 75, 75, "USED-FOR"]], [[94, 95, 80, 81, "USED-FOR"], [96, 96, 94, 95, "USED-FOR"]], [[107, 107, 101, 101, "USED-FOR"], [115, 116, 111, 111, "USED-FOR"], [115, 116, 111, 111, "USED-FOR"], [107, 107, 101, 101, "USED-FOR"], [115, 116, 111, 111, "USED-FOR"], [115, 116, 111, 111, "USED-FOR"]]]}
{"doc_key": "2109.05432-e4eb3b59-355c-430b-bed8-4cad928dade5", "sentences": [["We", "use", "PyTorch", "as", "our", "training", "framework", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.3", "which", "is", "then", "adjusted", "by", "cosine", "annealing", "."], ["SGD", "optimizer", "is", "adopted", "with", "a", "weight", "decay", "of", "1e-4", "."], ["We", "train", "our", "PSS-Net", "for", "a", "total", "of", "250", "epochs", "with", "a", "batch", "size", "of", "1024", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[2, 2, "a"]], [[21, 22, "a"]], [[24, 24, "a"]], [[44, 44, "p"], [50, 50, "v"], [47, 48, "p"], [38, 38, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[10, 11, "p"], [15, 15, "v"], [21, 22, "a"]], [[24, 24, "a"], [30, 31, "p"], [33, 33, "v"]], [[38, 38, "a"], [43, 43, "v"], [44, 44, "p"], [47, 48, "p"], [50, 50, "v"]], []], "predicted_relations": [[], [], [], [[44, 44, 38, 38, "USED-FOR"]], []]}
{"doc_key": "2109.05411-d8581a20-c482-4ea7-90ac-b390dc4b6b74", "sentences": [["For", "all", "experiments", ",", "we", "initialize", "our", "model", "with", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "_0=\\mathbf", "-LCB-", "0", "-RCB-", "\\", "-RRB-", "and", "SGD", "batch", "size", "\\", "-LRB-", "b=64\\", "-RRB-", "."], ["In", "each", "round", ",", "we", "uniformly", "sample", "\\", "-LRB-", "K\\", "-RRB-", "devices", "at", "random", ",", "which", "run", "\\", "-LRB-", "E\\", "-RRB-", "steps", "of", "SGD", "in", "parallel", "."], ["For", "all", "experiments", ",", "we", "use", "an", "initial", "learning", "rate", "\\", "-LRB-", "\\eta", "_0=0.1\\", "-RRB-", "with", "decay", "rate", "\\", "-LRB-", "\\frac", "-LCB-", "-LCB-", "\\eta", "-RCB-", "_0", "-RCB-", "-LCB-", "1+r", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "r\\", "-RRB-", "is", "communication", "round", "index", "."], ["We", "evaluate", "the", "aggregated", "model", "in", "each", "round", "on", "the", "global", "loss", "function", "."], ["Each", "result", "is", "averaged", "over", "50", "experiments", "."]], "ner": [[[22, 22, "a"], [23, 24, "p"], [27, 27, "v"]], [[53, 53, "a"]], [[64, 66, "p"], [70, 70, "v"], [73, 74, "p"]], [[110, 112, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [22, 22, "a"], [27, 27, "v"]], [[39, 39, "p"], [53, 53, "a"]], [[65, 66, "p"], [73, 74, "p"], [93, 93, "p"]], [], [[119, 119, "v"]]], "predicted_relations": [[[23, 24, 22, 22, "USED-FOR"], [27, 27, 23, 24, "USED-FOR"]], [], [[70, 70, 73, 74, "USED-FOR"]], [], []]}
{"doc_key": "2105.13318-7e190c3b-6433-49c9-ba18-41f8c42e8317", "sentences": [["All", "our", "grammar", "correction", "models", "are", "standard", "Seq2Seq", "-LRB-", "not", "Seq2Edits", "-RRB-", "Transformers", "-LSB-", "37", "-RSB-", "trained", "with", "Adafactor", "-LSB-", "32", "-RSB-", "using", "the", "Tensor2Tensor", "-LSB-", "36", "-RSB-", "TensorFlow", "-LSB-", "0", "-RSB-", "library", "."], ["Our", "corruption", "models", "are", "either", "standard", "Transformers", "or", "Seq2Edits", "models", "-LSB-", "34", "-RSB-", ".The", "focus", "of", "our", "work", "was", "to", "examine", "techniques", "for", "synthetic", "data", "correction", "while", "keeping", "the", "correction", "model", "fixed", "."], ["Hence", ",", "we", "do", "not", "use", "Seq2Edits", "models", "for", "correction", "."], ["We", "use", "a", "Tensor2Tensor", "joint", "32K", "subword", "vocabulary", "and", "the", "`", "Big", "'", "hyper-parameter", "set", "for", "all", "our", "models", "."], ["For", "our", "tagged", "corruption", "models", "we", "extend", "the", "subword", "vocabulary", "by", "the", "25", "ERRANT", "error", "tags", "."]], "ner": [[[18, 18, "a"], [24, 24, "a"], [28, 28, "a"]], [[42, 43, "a"]], [[73, 74, "a"]], [[81, 81, "a"], [84, 85, "p"], [83, 83, "v"]], [[106, 107, "p"], [110, 113, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 12, "a"], [18, 18, "a"], [24, 24, "a"]], [[42, 43, "a"]], [[73, 74, "a"]], [[81, 81, "a"], [83, 83, "v"]], [[110, 110, "v"]]], "predicted_relations": [[], [], [], [[84, 85, 81, 81, "USED-FOR"], [83, 83, 84, 85, "USED-FOR"]], []]}
{"doc_key": "2108.07794-c55889d6-54b6-4949-8cf1-181bebdc6ff1", "sentences": [["We", "perform", "the", "pre-training", "on", "ShapeNet", "-LSB-", "0", "-RSB-", ",", "a", "dataset", "composed", "of", "richly-annotated", "shapes", "represented", "by", "3D", "CAD", "models", "of", "objects", "from", "55", "common", "categories", "."], ["To", "generate", "the", "random", "room", ",", "we", "first", "need", "to", "randomly", "sample", "multiple", "objects", "from", "the", "the", "dataset", "."], ["The", "number", "of", "objects", "we", "sample", "is", "a", "random", "integer", "from", "12", "to", "18", ",", "which", "is", "similar", "to", "the", "average", "number", "of", "objects", "in", "ScanNetV2", "scenes", "."], ["Then", "for", "each", "sampled", "object", ",", "we", "perform", "the", "random", "room", "generation", "algorithm", "mentioned", "in", "Section", "REF", "."], ["The", "object-level", "contrastive", "learning", "loss", "is", "used", "to", "train", "the", "model", "in", "an", "unsupervised", "manner", "."]], "ner": [[[5, 5, "a"]], [], [], [[84, 87, "a"]], [[94, 97, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [24, 24, "v"]], [], [[58, 58, "v"], [60, 60, "v"], [72, 72, "a"]], [], [[95, 97, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2108.07794-7aba5602-a62d-49b6-a775-fb8fd2e06a74", "sentences": [["For", "the", "downstream", "3D", "object", "detection", "task", ",", "we", "use", "the", "backbone", "models", "proposed", "in", "-LSB-", "34", "-RSB-", "and", "-LSB-", "62", "-RSB-", ",", "which", "take", "as", "input", "40,000", "points", "."], ["Following", "the", "network", "configurations", "in", "these", "two", "works", ",", "we", "use", "the", "1024-point", "feature", "as", "the", "output", "of", "the", "backbone", "models", "and", "perform", "contrastive", "learning", "on", "this", "feature", "."], ["During", "pre-training", ",", "we", "use", "the", "Adam", "optimizer", "-LSB-", "22", "-RSB-", "with", "initial", "learning", "0.001", "."], ["We", "train", "the", "model", "for", "300", "epochs", "and", "the", "learning", "rate", "is", "multiplied", "by", "0.1", "at", "the", "100-th", "and", "200-th", "epcoh", "."], ["The", "batch", "size", "is", "set", "to", "16", "such", "that", "roughly", "200\\", "-LRB-", "\\sim", "\\", "-RRB-", "300", "unique", "objects", "are", "involved", "in", "the", "contrastive", "learning", "at", "every", "iteration", "."]], "ner": [[[11, 12, "a"], [26, 26, "p"], [27, 28, "v"]], [[49, 50, "a"], [46, 46, "p"], [42, 43, "v"]], [[65, 66, "a"], [71, 72, "p"], [73, 73, "v"]], [[84, 85, "p"], [89, 89, "v"], [90, 95, "c"]], [[98, 99, "p"], [103, 103, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[27, 27, "v"]], [[36, 36, "v"], [42, 42, "v"]], [[65, 65, "a"], [73, 73, "v"]], [[80, 80, "v"], [81, 81, "p"], [84, 85, "p"], [89, 89, "v"], [92, 92, "v"], [94, 94, "v"]], [[98, 99, "p"], [103, 103, "v"], [112, 112, "v"]]], "predicted_relations": [[[26, 26, 11, 12, "USED-FOR"]], [[46, 46, 49, 50, "USED-FOR"]], [[71, 72, 65, 66, "USED-FOR"]], [[90, 95, 89, 89, "USED-FOR"]], []]}
{"doc_key": "2102.08602-23ad6e13-df9a-4961-a6a0-1eb21ae3834f", "sentences": [["We", "consider", "two", "training", "setups", "for", "the", "ImageNet", "classification", "task", "."], ["The", "90", "epochs", "training", "setup", "trains", "models", "for", "90", "epochs", "using", "standard", "preprocessing", "and", "allows", "for", "fair", "comparisons", "with", "classic", "works", "."], ["The", "350", "epochs", "training", "setup", "trains", "models", "for", "350", "epochs", "using", "improved", "data", "augmentation", "and", "regularization", "and", "is", "closer", "to", "training", "methodologies", "used", "in", "modern", "works", "with", "state-of-the-art", "accuracies", "."]], "ner": [[[7, 9, "a"]], [[12, 15, "a"], [13, 13, "p"], [20, 20, "p"], [12, 12, "v"], [19, 19, "v"], [13, 13, "p"], [20, 20, "p"]], [[35, 35, "p"], [42, 42, "p"], [34, 37, "a"], [35, 35, "p"], [42, 42, "p"], [34, 34, "v"], [41, 41, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "v"], [7, 7, "a"]], [[12, 12, "v"], [13, 13, "p"], [19, 19, "v"], [20, 20, "p"]], [[34, 34, "v"], [35, 35, "p"], [41, 41, "v"], [42, 42, "p"]]], "predicted_relations": [[], [[13, 13, 12, 15, "USED-FOR"], [20, 20, 12, 15, "USED-FOR"], [12, 12, 13, 13, "USED-FOR"], [12, 12, 20, 20, "USED-FOR"], [12, 12, 13, 13, "USED-FOR"], [12, 12, 20, 20, "USED-FOR"], [19, 19, 20, 20, "USED-FOR"], [19, 19, 20, 20, "USED-FOR"], [13, 13, 12, 15, "USED-FOR"], [20, 20, 12, 15, "USED-FOR"]], [[35, 35, 34, 37, "USED-FOR"], [42, 42, 34, 37, "USED-FOR"], [35, 35, 34, 37, "USED-FOR"], [42, 42, 34, 37, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 42, 42, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 42, 42, "USED-FOR"], [41, 41, 42, 42, "USED-FOR"], [41, 41, 42, 42, "USED-FOR"]]]}
{"doc_key": "2102.08602-1af147d2-9aa2-4458-a4bb-f7694d4f715a", "sentences": [["In", "the", "90", "epoch", "setup", ",", "we", "use", "the", "vanilla", "ResNet", "for", "fair", "comparison", "with", "prior", "works", "."], ["We", "used", "the", "default", "hyperparameters", "as", "found", "in", "official", "implementations", "without", "doing", "additional", "tuning", "."], ["All", "networks", "are", "trained", "end-to-end", "for", "90", "epochs", "via", "backpropagation", "using", "SGD", "with", "momentum", "0.9", "."], ["The", "batch", "size", "\\", "-LRB-", "B\\", "-RRB-", "is", "4096", "distributed", "across", "32", "TPUv3", "cores", "-LSB-", "33", "-RSB-", "and", "the", "weight", "decay", "is", "set", "to", "1e-4", "."], ["The", "learning", "rate", "is", "scaled", "linearly", "from", "0", "to", "0.1B/256", "for", "5", "epochs", "and", "then", "decayed", "using", "the", "cosine", "schedule", "-LSB-", "42", "-RSB-", "."], ["We", "use", "batch", "normalization", "with", "decay", "0.9999", "and", "exponential", "moving", "average", "with", "weight", "0.9999", "over", "trainable", "parameters", "and", "a", "label", "smoothing", "of", "0.1", "."], ["The", "input", "image", "size", "is", "set", "to", "224x224", "."], ["We", "use", "standard", "training", "data", "augmentation", "-LRB-", "random", "crops", "and", "horizontal", "flip", "with", "50", "%", "probability", "-RRB-", "."]], "ner": [[[10, 10, "a"]], [], [[44, 44, "a"], [46, 46, "p"], [47, 47, "v"]], [[50, 51, "p"], [57, 57, "v"], [68, 69, "p"], [73, 73, "v"]], [[76, 77, "p"], [79, 94, "v"]], [[105, 105, "v"], [112, 112, "v"], [105, 105, "v"], [112, 112, "v"], [118, 119, "p"], [121, 121, "v"]], [[124, 126, "p"], [130, 130, "v"]], [[135, 137, "p"], [139, 147, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [3, 3, "p"], [10, 10, "a"]], [], [[39, 39, "v"], [40, 40, "p"], [42, 42, "a"], [44, 44, "a"], [46, 46, "p"], [47, 47, "v"]], [[50, 51, "p"], [54, 54, "p"], [57, 57, "v"], [60, 60, "v"], [61, 61, "a"], [68, 69, "p"], [73, 73, "v"]], [[76, 77, "p"], [82, 82, "v"], [86, 86, "v"], [87, 87, "p"]], [[101, 102, "a"], [104, 104, "p"], [105, 105, "v"], [112, 112, "v"], [121, 121, "v"]], [[124, 126, "c"], [130, 130, "v"]], [[145, 146, "v"]]], "predicted_relations": [[], [], [[46, 46, 44, 44, "USED-FOR"]], [[57, 57, 50, 51, "USED-FOR"], [73, 73, 68, 69, "USED-FOR"]], [], [], [[130, 130, 124, 126, "USED-FOR"]], []]}
{"doc_key": "2102.08602-2a96bf80-4e08-4eb4-9bd9-09c6ebd8dca5", "sentences": [["All", "mobilenet", "architectures", "are", "trained", "for", "350", "epochs", "on", "Imagenet", "with", "standard", "preprocessing", "at", "224x224", "resolution", "."], ["We", "use", "the", "same", "hyperparameters", "as", "-LSB-", "25", "-RSB-", "."], ["More", "specifically", ",", "we", "use", "RMSProp", "with", "0.9", "momentum", "and", "a", "batch", "size", "of", "4096", "split", "across", "32", "TPUv3", "cores", "."], ["The", "learning", "rate", "is", "warmed", "up", "linearly", "to", "0.1", "and", "then", "multiplied", "by", "0.99", "every", "3", "epochs", "."], ["We", "use", "a", "weight", "decay", "1e-5", "and", "dropout", "with", "drop", "probability", "of", "0.2"]], "ner": [[[9, 9, "a"]], [], [[32, 32, "a"], [35, 35, "p"], [34, 34, "v"], [38, 39, "a"]], [[49, 50, "a"], [54, 56, "v"], [59, 60, "p"], [61, 61, "v"], [62, 64, "c"]], [[69, 70, "a"], [71, 71, "v"], [73, 73, "a"], [75, 76, "p"], [78, 78, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [6, 6, "v"], [7, 7, "p"], [9, 9, "a"], [14, 14, "v"]], [], [[32, 32, "a"], [34, 34, "v"], [35, 35, "p"], [38, 39, "p"], [41, 41, "v"], [44, 44, "v"], [45, 45, "a"]], [[49, 50, "p"], [56, 56, "v"], [61, 61, "v"], [63, 63, "v"], [64, 64, "p"]], [[69, 70, "p"], [71, 71, "v"], [73, 73, "a"], [78, 78, "v"]]], "predicted_relations": [[], [], [[35, 35, 32, 32, "USED-FOR"]], [[59, 60, 49, 50, "USED-FOR"], [61, 61, 59, 60, "USED-FOR"], [62, 64, 54, 56, "USED-FOR"], [62, 64, 61, 61, "USED-FOR"]], []]}
{"doc_key": "2106.13638-d091b316-14a7-4e91-84d7-73a24345ecbe", "sentences": [["We", "use", "the", "machine", "learning", "platform", "TensorFlow", "-LSB-", "13", "-RSB-", "for", "the", "implementation", "of", "the", "NNs", "and", "the", "training", "process", "utilises", "the", "Adam-Optimiser", "-LSB-", "14", "-RSB-", "with", "a", "decaying", "learning", "ratePlease", "refer", "to", "the", "published", "code", "for", "details", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "values", "between", "0.01", "and", "0.001", "and", "the", "decay", "leads", "to", "reduction", "between", "one", "and", "two", "orders", "of", "magnitude", "at", "the", "end", "of", "the", "training", "."], ["For", "all", "variants", "of", "the", "NNs", "we", "use", "two", "hidden", "layers", "and", "150", "nodes", "per", "layer", "."], ["The", "training", "data", "are", "selected", "from", "a", "simulated", "database", "which", "segments", "the", "input", "domain", "-LSB-", "time", "and", "power", "disturbance", "-RSB-", "into", "a", "equally", "spaced", "grid", "with", "a", "0.001s", "and", "0.002", "p.u", "."], ["granularity", "."], ["The", "exact", "training", "dataset", "used", "in", "the", "results", "section", "will", "be", "specified", "by", "the", "number", "of", "trajectories", "\\", "-LRB-", "N_", "-LCB-", "traj", "-RCB-", "\\", "-RRB-", ",", "i.e", "."], ["each", "trajectory", "links", "to", "a", "power", "disturbance", ",", "and", "the", "number", "of", "data", "points", "along", "each", "trajectory", "\\", "-LRB-", "N_", "-LCB-", "TS", "-RCB-", "\\", "-RRB-", ",", "hence", "the", "total", "number", "of", "data", "points", "\\", "-LRB-", "N_", "-LCB-", "x", "-RCB-", "=", "N_", "-LCB-", "traj", "-RCB-", "\\cdot", "N_", "-LCB-", "TS", "-RCB-", "\\", "-RRB-", "."], ["The", "collocation", "points", "for", "PINNs", "form", "an", "equally", "spaced", "grid", "with", "25", "trajectories", "and", "41", "instances", "along", "each", "trajectory", "."], ["We", "test", "all", "types", "of", "NN", "on", "the", "entire", "simulated", "database", ",", "i.e", "\\", "-LRB-", "N_", "-LCB-", "traj", "-RCB-", "=", "301\\", "-RRB-", ",", "\\", "-LRB-", "N_", "-LCB-", "TS", "-RCB-", "=", "2001\\", "-RRB-", "."], ["The", "reason", "for", "not", "using", "a", "validation", "dataset", "is", "that", "this", "work", "does", "not", "aim", "for", "comparing", "how", "well", "each", "NN", "type", "can", "be", "tuned", "with", "respect", "to", "its", "hyper-parameters", "."], ["Instead", "we", "opted", "for", "choosing", "hyper-parameters", ",", "e.g", "."], ["the", "loss", "term", "weights", ",", "that", "robustly", "yield", "a", "fair", "comparison", "so", "that", "we", "can", "explore", "the", "characteristic", "of", "each", "methodology", "."], ["For", "a", "regular", "use", "case", "the", "partitioning", "into", "a", "validation", "and", "test", "dataset", "is", "strongly", "encouraged", "."], ["The", "data", "creation", "and", "training", "is", "all", "performed", "on", "a", "regular", "machine", "-LRB-", "i5-7200U", "CPU", "@", "2.50GHz", ",", "16GB", "RAM", "-RRB-", "."]], "ner": [[[6, 6, "a"], [22, 22, "a"]], [], [[79, 81, "a"]], [[95, 96, "a"]], [[120, 120, "p"]], [[136, 138, "p"]], [[160, 166, "p"]], [[216, 216, "v"], [203, 206, "c"]], [[252, 252, "v"], [231, 232, "a"], [230, 232, "c"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [15, 15, "a"], [22, 22, "a"]], [[41, 42, "p"], [48, 48, "v"], [50, 50, "v"], [58, 58, "v"], [60, 60, "v"]], [[76, 76, "a"], [79, 79, "v"], [80, 81, "p"], [83, 83, "v"]], [[115, 115, "v"], [117, 117, "v"]], [], [], [], [[206, 206, "a"], [213, 213, "v"], [216, 216, "v"]], [[242, 242, "v"], [252, 252, "v"]], [], [], [], [], [[347, 347, "v"], [350, 350, "v"], [352, 352, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [[203, 206, 216, 216, "USED-FOR"]], [[230, 232, 252, 252, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2106.13552-460b5347-3df8-46a4-9561-1ca001e913fa", "sentences": [["1", "-RRB-", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "determines", "the", "significance", "of", "the", "unpaired", "distance", "preserving", "loss", "."], ["If", "\\", "-LRB-", "\\alpha", "=", "0\\", "-RRB-", ",", "graph", "pattern", "loss", "only", "considers", "the", "pairwise", "distance", "between", "representations", "of", "the", "same", "objects", "from", "different", "modalities", "and", "the", "mutual", "distance", "preserving", "loss", "."], ["However", ",", "only", "providing", "mutual", "distance", "does", "not", "give", "the", "correct", "guidance", "of", "the", "unpaired", "distance", "."], ["From", "Figure", "."], ["REF", "-", "-LRB-", "a", "-RRB-", ",", "we", "can", "observe", "that", "both", "higher", "or", "lower", "values", "of", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "result", "in", "poor", "performance", "."], ["Based", "on", "the", "above", "analysis", ",", "the", "unpaired", "distance", "preserving", "loss", "plays", "an", "important", "role", "in", "cross-modal", "retrieval", "."]], "ner": [[[12, 15, "a"], [4, 4, "p"]], [[20, 20, "p"], [22, 22, "v"]], [], [], [[87, 87, "p"], [80, 82, "v"]], [[102, 105, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 4, "p"]], [[20, 20, "p"], [25, 27, "a"]], [], [], [[87, 87, "p"]], []], "predicted_relations": [[], [], [], [], [[80, 82, 87, 87, "USED-FOR"]], []]}
{"doc_key": "2105.02103-8fe926d9-7124-4d1c-996a-ea5440707f32", "sentences": [["We", "use", "face", "images", "of", "size", "\\", "-LRB-", "112", "\\times", "112\\", "-RRB-", ",", "detected", "and", "cropped", "by", "RetinaFace", "detector", "-LSB-", "40", "-RSB-", ",", "and", "employ", "ResNet-34", "and", "ResNet-100", "-LSB-", "83", "-RSB-", "architectures", "for", "the", "encoder", "."], ["Final", "\\", "-LRB-", "L_2\\", "-RRB-", "-normalized", "embeddings", "are", "of", "size", "\\", "-LRB-", "D=256\\", "-RRB-", "for", "ResNet-34", "and", "\\", "-LRB-", "D=512\\", "-RRB-", "for", "ResNet-100", "models", "."], ["For", "experiments", "with", "Prototype", "Memory", "hyperparameters", "we", "used", "CosFace", "-LSB-", "5", "-RSB-", "loss", "with", "\\", "-LRB-", "s=64\\", "-RRB-", "and", "\\", "-LRB-", "m=0.4\\", "-RRB-", "."], ["The", "learning", "rate", "started", "from", "\\", "-LRB-", "0.1\\", "-RRB-", "and", "divided", "by", "10", "at", "\\", "-LRB-", "100k\\", "-RRB-", ",", "\\", "-LRB-", "200k\\", "-RRB-", ",", "\\", "-LRB-", "250k\\", "-RRB-", ",", "\\", "-LRB-", "275k\\", "-RRB-", "iterations", "finishing", "at", "\\", "-LRB-", "300K\\", "-RRB-", "iterations", "."], ["For", "the", "experiments", "with", "larger", "networks", ",", "we", "used", "PM-100", ":", "ResNet-100", ",", "pre-trained", "using", "Prototype", "Memory", "-LRB-", "\\", "-LRB-", "M=200,000\\", "-RRB-", ",", "\\", "-LRB-", "r=0.2\\", "-RRB-", "-RRB-", "and", "CosFace", "with", "\\", "-LRB-", "s=64\\", "-RRB-", "and", "\\", "-LRB-", "m=0.4\\", "-RRB-", "."], ["The", "learning", "rate", "started", "from", "\\", "-LRB-", "0.1\\", "-RRB-", "and", "divided", "by", "10", "at", "\\", "-LRB-", "200k\\", "-RRB-", ",", "\\", "-LRB-", "400k\\", "-RRB-", ",", "and", "\\", "-LRB-", "500k\\", "-RRB-", "iterations", ",", "finishing", "at", "\\", "-LRB-", "540K\\", "-RRB-", "."], ["Mini-batch", "size", "is", "512", "for", "all", "models", ",", "mini-batch", "sampling", "is", "group-based", "iterate-and-shuffle", "."]], "ner": [[[17, 18, "a"], [25, 25, "a"], [27, 27, "a"]], [[51, 51, "a"], [58, 58, "a"]], [[69, 69, "a"], [77, 77, "p"], [77, 77, "v"], [82, 82, "p"], [82, 82, "v"], [64, 65, "a"]], [], [[138, 138, "a"], [156, 156, "a"], [160, 160, "p"], [160, 160, "v"], [165, 165, "p"], [165, 165, "v"], [142, 143, "a"], [147, 147, "p"], [152, 152, "p"], [152, 152, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "v"], [10, 10, "v"], [17, 18, "a"], [25, 25, "a"], [27, 27, "a"]], [[39, 39, "v"], [48, 48, "v"], [51, 51, "a"], [55, 55, "v"]], [[69, 69, "a"], [77, 77, "v"], [82, 82, "v"]], [[86, 87, "p"], [92, 92, "v"], [97, 97, "v"], [101, 101, "v"], [106, 106, "v"], [111, 111, "v"], [116, 116, "v"], [123, 123, "v"]], [[136, 136, "a"], [138, 138, "a"], [147, 147, "v"], [152, 152, "v"], [156, 156, "a"], [160, 160, "v"], [165, 165, "v"]], [[169, 170, "p"], [175, 175, "v"], [180, 180, "v"], [184, 184, "v"], [189, 189, "v"], [195, 195, "v"], [203, 203, "v"]], [[206, 207, "p"], [209, 209, "v"], [210, 212, "c"], [214, 215, "a"]]], "predicted_relations": [[], [], [[77, 77, 69, 69, "USED-FOR"], [77, 77, 77, 77, "USED-FOR"], [77, 77, 64, 65, "USED-FOR"], [77, 77, 77, 77, "USED-FOR"], [82, 82, 69, 69, "USED-FOR"], [82, 82, 82, 82, "USED-FOR"], [82, 82, 77, 77, "USED-FOR"], [82, 82, 82, 82, "USED-FOR"]], [], [[160, 160, 138, 138, "USED-FOR"], [160, 160, 156, 156, "USED-FOR"], [160, 160, 160, 160, "USED-FOR"], [160, 160, 142, 143, "USED-FOR"], [160, 160, 160, 160, "USED-FOR"], [160, 160, 147, 147, "USED-FOR"], [160, 160, 152, 152, "USED-FOR"], [165, 165, 156, 156, "USED-FOR"], [165, 165, 165, 165, "USED-FOR"], [165, 165, 160, 160, "USED-FOR"], [165, 165, 165, 165, "USED-FOR"], [165, 165, 147, 147, "USED-FOR"], [165, 165, 152, 152, "USED-FOR"], [147, 147, 138, 138, "USED-FOR"], [147, 147, 142, 143, "USED-FOR"], [152, 152, 138, 138, "USED-FOR"], [152, 152, 156, 156, "USED-FOR"], [152, 152, 152, 152, "USED-FOR"], [152, 152, 147, 147, "USED-FOR"], [152, 152, 152, 152, "USED-FOR"]], [], []]}
{"doc_key": "2102.00461-26161125-65b5-4f34-936e-d228349d1264", "sentences": [["During", "training", ",", "XLM-RoBERTa", "'s", "weights", "were", "kept", "frozen", "and", "only", "the", "BiLSTM", "and", "CRF", "layers", "were", "updated", "."], ["We", "experimented", "BiLSTM", "with", "\\", "-LRB-", "16", ",", "32", ",", "64", ",", "128", ",", "256\\", "-RRB-", "and", "512", "hidden", "units", "and", "more", "layers", ",", "but", "in", "the", "end", ",", "having", "a", "small", "segmentation", "module", ",", "with", "64", "hidden", "units", "and", "1", "layer", ",", "generically", "yielded", "the", "best", "performances", "in", "the", "validation", "splits", "."], ["We", "used", "a", "dropout", "layer", "of", "value", "0.25", "between", "the", "BiLSTM", "and", "the", "CRF", ",", "and", "the", "RMSprop", "optimizer", "with", "a", "fixed", "learning", "rate", "of", "0.001", "."]], "ner": [[[3, 3, "a"], [12, 12, "a"], [14, 14, "a"]], [[21, 21, "a"], [27, 27, "v"], [29, 29, "v"], [55, 55, "v"], [31, 31, "v"], [33, 33, "v"], [36, 36, "v"]], [[82, 82, "a"], [94, 95, "p"], [97, 97, "v"], [85, 85, "a"], [75, 76, "a"], [89, 89, "a"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [12, 12, "a"], [14, 14, "a"]], [[21, 21, "a"], [33, 33, "v"], [36, 36, "v"], [40, 40, "v"], [55, 55, "v"], [56, 57, "p"], [59, 59, "v"]], [[75, 75, "a"], [75, 76, "p"], [79, 79, "v"], [82, 82, "a"], [85, 85, "a"], [89, 89, "a"], [94, 95, "p"], [97, 97, "v"]]], "predicted_relations": [[], [], [[94, 95, 82, 82, "USED-FOR"], [94, 95, 85, 85, "USED-FOR"], [94, 95, 75, 76, "USED-FOR"], [94, 95, 89, 89, "USED-FOR"]]]}
{"doc_key": "2107.00708-61f4bf7a-9ead-447c-9f74-a348b9e2f3db", "sentences": [["Following", "-LSB-", "34", "-RSB-", ",", "-LSB-", "37", "-RSB-", ",", "-LSB-", "8", "-RSB-", ",", "we", "train", "our", "network", "by", "using", "the", "training", "sets", "of", "DIV2K", "-LSB-", "0", "-RSB-", "and", "Flickr2K", "-LSB-", "33", "-RSB-", "."], ["The", "evaluations", "-LRB-", "in", "PSNR", "-RRB-", "are", "performed", "over", "four", "standard", "datasets", "Set5", "-LSB-", "2", "-RSB-", ",", "Set14", "-LSB-", "41", "-RSB-", ",", "B100", "-LSB-", "25", "-RSB-", "and", "Urban100", "-LSB-", "13", "-RSB-", "."], ["We", "apply", "the", "degradation", "in", "Eq.REF", "to", "generate", "LR", "images", "in", "both", "training", "and", "testing", "."], ["Specifically", ",", "we", "first", "train", "a", "model", "by", "applying", "degradations", "of", "isotropic", "Gaussian", "kernels", "and", "noises", ",", "where", "the", "kernel", "size", "is", "fixed", "at", "\\", "-LRB-", "21", "\\times", "21\\", "-RRB-", ",", "the", "kernel", "width", "is", "set", "to", "the", "range\\", "-LRB-", "-LSB-", "0.2", ",", "4.0", "-RSB-", "\\", "-RRB-", "and", "the", "noise", "level", "is", "set", "at", "\\", "-LRB-", "-LSB-", "0", ",", "75", "-RSB-", "\\", "-RRB-", "as", "in", "-LSB-", "37", "-RSB-", ",", "-LSB-", "34", "-RSB-", "."], ["We", "also", "train", "our", "model", "on", "degradations", "with", "anisotropic", "Gaussian", "kernels", "and", "noises", ",", "where", "the", "kernels", "have", "a", "Gaussian", "density", "function", "\\", "-LRB-", "N", "-LRB-", "0", ",", "\\Sigma", "-RRB-", "\\", "-RRB-", ",", "the", "covariance", "matrix", "\\", "-LRB-", "\\Sigma", "\\", "-RRB-", "is", "determined", "by", "a", "random", "rotation", "angle", "\\", "-LRB-", "\\theta", "\\sim", "-LCB-", "U", "-LRB-", "0", ",", "\\pi", "-RRB-", "-RCB-", "\\", "-RRB-", "and", "two", "random", "eigenvalues", "\\", "-LRB-", "\\lambda", "_1", ",", "\\lambda", "_2", "\\sim", "-LCB-", "U", "-LRB-", "0.2,4", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "and", "the", "noise", "is", "set", "to", "the", "range", "\\", "-LRB-", "-LSB-", "0", ",", "25", "-RSB-", "\\", "-RRB-", ",", "as", "in", "-LSB-", "34", "-RSB-"]], "ner": [[[23, 23, "a"], [28, 28, "a"]], [[45, 45, "a"], [50, 50, "a"], [55, 55, "a"], [60, 60, "a"]], [[68, 68, "a"], [68, 68, "a"]], [[100, 101, "p"], [113, 114, "p"], [130, 131, "p"], [130, 131, "p"]], [[188, 189, "p"], [200, 201, "p"], [219, 219, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[16, 16, "a"], [23, 23, "a"], [28, 28, "a"]], [[42, 42, "v"], [45, 45, "a"], [50, 50, "a"], [55, 55, "a"], [60, 60, "a"]], [], [[109, 109, "v"], [138, 141, "v"]], [[158, 158, "a"], [217, 217, "v"], [222, 223, "p"], [225, 226, "p"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2112.08761-fdba39e0-9478-4027-ac21-8c7173fa9119", "sentences": [["This", "section", "lists", "parameters", "used", "in", "the", "FL", "experiments", "that", "have", "not", "been", "included", "in", "the", "description", "of", "the", "experimental", "setup", "."], ["The", "local", "training", "on", "each", "device", "uses", "mini-batches", "of", "size", "64", "."], ["The", "optimizer", "is", "the", "same", "as", "for", "the", "fitness", "evaluation", "-LRB-", "SGD", "with", "momentum", "set", "at", "0.9", "and", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "-RRB-", "."], ["The", "learning", "rates", "are", "set", "at", "0.035", "for", "the", "network", "with", "FEMNIST", "-LRB-", "as", "in", "-LSB-", "9", "-RSB-", "-RRB-", ",", "and", "0.05", "for", "DenseNet-40/100", "."], ["The", "NN", "for", "FEMNIST", "is", "also", "similar", "to", "the", "one", "used", "in", "-LSB-", "9", "-RSB-", ",", "i.e.", ",", "CNN", "with", "two", "\\", "-LRB-", "5", "-LCB-", "\\times", "-RCB-", "5\\", "-RRB-", "convolutional", "layers", "with", "32", "and", "64", "filters", ",", "respectively", ",", "each", "with", "ReLU", "activation", "and", "each", "followed", "by", "a", "\\", "-LRB-", "2", "-LCB-", "\\times", "-RCB-", "2\\", "-RRB-", "max", "pooling", "."], ["The", "convolutional", "part", "is", "followed", "by", "two", "fully", "connected", "layers", "with", "512", "and", "62", "neurons", "-LRB-", "number", "of", "classes", "-RRB-", ",", "respectively", "."], ["The", "implementation", "of", "this", "NN", "with", "structured", "dropout", "is", "depicted", "in", "fig", ":", "feminstnetwork", "."], ["-LRB-", "The", "NN", "for", "CIFAR-10/100", "are", "explained", "in", "the", "description", "of", "the", "experimental", "setup", "."]], "ner": [[], [[32, 32, "v"], [32, 32, "v"]], [[45, 45, "a"], [47, 47, "p"], [50, 50, "v"], [52, 53, "p"]], [], [[124, 124, "v"], [108, 108, "a"], [119, 120, "p"], [140, 140, "v"], [144, 144, "v"], [122, 122, "v"], [124, 124, "v"], [131, 131, "v"], [140, 140, "v"], [144, 144, "v"]], [[156, 158, "p"], [160, 160, "v"], [162, 162, "v"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[29, 29, "a"], [32, 32, "v"]], [[50, 50, "v"], [52, 53, "p"], [57, 59, "v"]], [[66, 67, "p"], [71, 71, "v"], [76, 76, "a"], [86, 86, "v"]], [[93, 93, "a"], [99, 99, "v"], [108, 108, "a"], [110, 110, "v"], [113, 113, "v"], [117, 117, "v"], [122, 122, "v"], [124, 124, "v"], [131, 131, "a"], [137, 137, "v"], [140, 140, "v"], [144, 144, "v"], [146, 147, "a"]], [[155, 155, "v"], [160, 160, "v"], [162, 162, "v"]], [[176, 176, "a"], [179, 179, "a"], [185, 185, "a"]], [[191, 191, "a"]]], "predicted_relations": [[], [], [[47, 47, 45, 45, "USED-FOR"], [52, 53, 45, 45, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2104.09839-3e4aeb90-ab20-4af1-acc9-af0029edc950", "sentences": [["The", "Adam", "algorithm", "-LSB-", "8", "-RSB-", "is", "used", "for", "gradient-based", "optimization", "."], ["The", "number", "\\", "-LRB-", "n\\", "-RRB-", "of", "iterations", "is", "chosen", "sufficiently", "large", "to", "reach", "a", "cost", "function", "plateau", "."], ["The", "learning", "rate", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "adjusted", "by", "a", "rough", "trial", "and", "error", "."], ["All", "static", "non-linearities", "are", "modeled", "as", "feed-forward", "Neural", "Networks", "with", "a", "single", "hidden", "layer", "containing", "10", "neurons", "and", "hyperbolic", "tangent", "activation", "function", "."]], "ner": [[[1, 2, "a"]], [], [[32, 33, "p"]], [[54, 56, "a"], [60, 61, "p"], [63, 64, "v"], [68, 69, "p"], [66, 67, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"]], [[16, 16, "p"]], [[32, 33, "p"], [36, 36, "p"]], [[54, 56, "a"], [60, 61, "p"], [63, 63, "v"], [66, 67, "a"]]], "predicted_relations": [[], [], [], [[63, 64, 68, 69, "USED-FOR"], [66, 67, 60, 61, "USED-FOR"], [66, 67, 68, 69, "USED-FOR"]]]}
{"doc_key": "2111.05805-631b51d9-0eb4-42c3-8c6f-8effd3de927b", "sentences": [["We", "use", "the", "cache", "of", "pretrained", "models", "of", "Transformers", "to", "initialize", "the", "model", "."], ["For", "MNLI", "finetuning", ",", "we", "train", "the", "model", "with", "32", "batch", "size", "and", "128", "max", "sequence", "length", "for", "3", "epochs", "."], ["We", "use", "AdamW", "-LSB-", "19", "-RSB-", "optimizer", "with", "2e-5", "learning", "rate", "."], ["For", "SQuAD", "finetuning", ",", "we", "train", "the", "model", "with", "12", "batch", "size", ",", "384", "max", "sequence", "length", "and", "128", "document", "stride", "for", "2", "epochs", "."], ["We", "use", "AdamW", "optimizer", "with", "3e-5", "learning", "rate", "."], ["For", "both", "datasets", "we", "only", "use", "the", "training", "data", "to", "finetune", "the", "model", "."]], "ner": [[[8, 8, "a"]], [[15, 16, "a"], [24, 25, "p"], [23, 23, "v"], [28, 30, "p"], [27, 27, "v"], [33, 33, "p"], [32, 32, "v"], [24, 25, "p"], [28, 30, "p"], [27, 27, "v"], [33, 33, "p"], [15, 16, "c"]], [[37, 37, "a"], [44, 45, "p"], [43, 43, "v"]], [[57, 58, "p"], [61, 63, "p"], [65, 65, "v"], [70, 70, "p"], [48, 49, "a"], [57, 58, "p"], [56, 56, "v"], [61, 63, "p"], [60, 60, "v"], [66, 67, "p"], [65, 65, "v"], [70, 70, "p"], [69, 69, "v"], [48, 49, "c"]], [[74, 74, "a"], [78, 79, "p"], [77, 77, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[15, 15, "a"], [23, 23, "v"], [24, 25, "p"], [27, 27, "v"], [28, 30, "p"], [32, 32, "v"], [33, 33, "p"]], [[37, 37, "a"], [43, 43, "v"], [44, 45, "p"]], [[48, 48, "a"], [56, 56, "v"], [57, 58, "p"], [60, 60, "v"], [65, 65, "v"], [66, 67, "p"], [69, 69, "v"], [70, 70, "p"]], [[74, 74, "a"], [77, 77, "v"], [78, 79, "p"]], []], "predicted_relations": [[], [[24, 25, 15, 16, "USED-FOR"], [23, 23, 28, 30, "USED-FOR"], [23, 23, 33, 33, "USED-FOR"], [23, 23, 28, 30, "USED-FOR"], [23, 23, 33, 33, "USED-FOR"], [28, 30, 15, 16, "USED-FOR"], [27, 27, 28, 30, "USED-FOR"], [27, 27, 33, 33, "USED-FOR"], [27, 27, 28, 30, "USED-FOR"], [27, 27, 33, 33, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"], [24, 25, 15, 16, "USED-FOR"], [28, 30, 15, 16, "USED-FOR"], [27, 27, 28, 30, "USED-FOR"], [27, 27, 33, 33, "USED-FOR"], [27, 27, 28, 30, "USED-FOR"], [27, 27, 33, 33, "USED-FOR"]], [[44, 45, 37, 37, "USED-FOR"], [43, 43, 44, 45, "USED-FOR"]], [[57, 58, 48, 49, "USED-FOR"], [61, 63, 48, 49, "USED-FOR"], [65, 65, 61, 63, "USED-FOR"], [65, 65, 70, 70, "USED-FOR"], [65, 65, 61, 63, "USED-FOR"], [65, 65, 66, 67, "USED-FOR"], [65, 65, 70, 70, "USED-FOR"], [57, 58, 48, 49, "USED-FOR"], [56, 56, 61, 63, "USED-FOR"], [56, 56, 61, 63, "USED-FOR"], [61, 63, 48, 49, "USED-FOR"], [60, 60, 57, 58, "USED-FOR"], [60, 60, 61, 63, "USED-FOR"], [60, 60, 70, 70, "USED-FOR"], [60, 60, 57, 58, "USED-FOR"], [60, 60, 61, 63, "USED-FOR"], [60, 60, 70, 70, "USED-FOR"], [65, 65, 61, 63, "USED-FOR"], [65, 65, 70, 70, "USED-FOR"], [65, 65, 61, 63, "USED-FOR"], [65, 65, 66, 67, "USED-FOR"], [65, 65, 70, 70, "USED-FOR"], [69, 69, 70, 70, "USED-FOR"], [69, 69, 66, 67, "USED-FOR"], [69, 69, 70, 70, "USED-FOR"]], [[78, 79, 74, 74, "USED-FOR"], [77, 77, 78, 79, "USED-FOR"]], []]}
{"doc_key": "2111.05805-e668aed8-8d96-4a31-abdf-7cd3f9801aff", "sentences": [["For", "XLA-MAML", ",", "for", "both", "datasets", "we", "use", "the", "same", "data", "preprocessing", "parameters", "as", "the", "English", "model", "."], ["We", "use", "batch", "size", "8", "for", "both", "inner-step", "update", "and", "meta-step", "update", "."], ["We", "use", "learning", "rate", "of", "1e-5", "with", "SGD", "optimizer", "for", "the", "inner-step", "update", ",", "and", "use", "learning", "rate", "of", "1e-5", ",", "weight", "decay", "of", "0.01", "with", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "and", "a", "linear", "learning", "rate", "scheduler", "for", "the", "meta-step", "update", "."], ["NLI", "models", "with", "memory", "usage", "of", "around", "10G", "use", "1", "minute", "for", "each", "100", "meta", "steps", "trained", "on", "GeForce", "GTX", "1080Ti", "and", "QA", "models", "with", "memory", "usage", "of", "around", "22G", "use", "2", "minutes", "for", "each", "100", "meta", "steps", "trained", "on", "TITAN", "RTX", "."]], "ner": [[[1, 1, "a"]], [[20, 21, "p"], [22, 22, "v"]], [[33, 34, "p"], [47, 48, "p"], [65, 66, "p"], [36, 36, "v"], [50, 50, "v"], [38, 39, "c"], [36, 36, "v"], [50, 50, "v"], [57, 58, "c"], [52, 53, "p"], [55, 55, "v"], [57, 58, "c"], [65, 67, "p"], [64, 64, "v"], [57, 58, "a"], [38, 39, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"]], [[20, 21, "p"], [22, 22, "v"]], [[33, 34, "p"], [36, 36, "v"], [47, 48, "p"], [50, 50, "v"], [52, 53, "p"], [55, 55, "v"], [57, 57, "a"]], [[80, 80, "v"], [82, 82, "v"], [86, 86, "v"], [102, 102, "v"], [104, 104, "v"], [108, 108, "v"]]], "predicted_relations": [[], [], [[47, 48, 38, 39, "USED-FOR"], [65, 66, 57, 58, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [38, 39, 55, 55, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [52, 53, 38, 39, "USED-FOR"], [55, 55, 52, 53, "USED-FOR"], [65, 67, 57, 58, "USED-FOR"]], []]}
{"doc_key": "2110.07560-d67d3ad4-d901-4aac-9af3-946c05fc8ec5", "sentences": [["Training", "Setup", "and", "Hyper-parameters", "."], ["For", "both", "SFTs", "and", "adapters", ",", "we", "train", "for", "the", "lesser", "of", "100", "epochs", "or", "100,000", "steps", "of", "batch", "size", "8", "and", "maximum", "sequence", "length", "256", ",", "subject", "to", "an", "absolute", "minimum", "of", "30,000", "steps", "since", "100", "epochs", "seemed", "insufficient", "for", "some", "languages", "with", "very", "small", "corpora", "."], ["Model", "checkpoints", "are", "evaluated", "every", "1,000", "steps", "-LRB-", "5,000", "for", "high-resource", "languages", "-RRB-", "on", "a", "held-out", "set", "of", "5", "%", "of", "the", "corpus", "-LRB-", "1", "%", "for", "high-resource", "languages", "-RRB-", ",", "and", "the", "one", "with", "the", "smallest", "loss", "is", "selected", "at", "the", "end", "of", "training", "."], ["We", "use", "the", "AdamW", "optimizer", "-LSB-", "21", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "5\\", "-LRB-", "e\\", "-RRB-", "-5", "which", "is", "linearly", "reduced", "to", "0", "over", "the", "course", "of", "training", "."]], "ner": [[], [[23, 24, "a"], [27, 29, "a"]], [[68, 69, "a"]], [[102, 103, "a"], [109, 111, "p"], [113, 117, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[7, 7, "a"], [17, 17, "v"], [18, 18, "p"], [20, 20, "v"], [23, 24, "p"], [25, 25, "v"], [30, 30, "v"], [38, 38, "v"], [41, 41, "v"]], [[58, 58, "v"], [61, 61, "v"], [71, 72, "v"], [77, 78, "v"], [86, 86, "v"]], [[102, 102, "a"], [110, 111, "p"], [115, 115, "p"], [123, 123, "v"]]], "predicted_relations": [[], [], [], [[109, 111, 102, 103, "USED-FOR"], [113, 117, 109, 111, "USED-FOR"]]]}
{"doc_key": "2110.07560-6f23705b-ce35-4afc-b9e4-9c0d599e71a0", "sentences": [["Following", "-LSB-", "28", "-RSB-", ",", "the", "adapter", "reduction", "factor", "-LRB-", "i.e.", ",", "the", "ratio", "between", "model", "hidden", "size", "and", "adapter", "size", "-RRB-", "was", "set", "to", "2", "for", "a", "total", "of", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "7.6M", "trainable", "parameters", "."], ["For", "comparability", ",", "we", "set", "the", "same", "number", "of", "trainable", "parameters", "\\", "-LRB-", "K\\", "-RRB-", "for", "our", "language", "SFTs", "."], ["This", "results", "in", "language", "SFTs", "with", "a", "sparsity", "of", "4.3", "%", "for", "mBERT", "and", "2.8", "%", "for", "XLM-R", "."]], "ner": [[[6, 8, "a"], [15, 17, "p"], [19, 20, "p"], [36, 37, "a"]], [[48, 49, "a"], [56, 57, "a"]], [[62, 63, "a"], [66, 66, "p"], [71, 71, "c"], [76, 76, "c"]]], "relations": [[], [], []], "predicted_ner": [[[25, 25, "v"], [35, 35, "v"]], [[52, 52, "p"]], [[68, 69, "v"], [71, 71, "a"], [73, 74, "v"], [76, 76, "a"]]], "predicted_relations": [[[15, 17, 6, 8, "USED-FOR"], [19, 20, 6, 8, "USED-FOR"]], [], [[66, 66, 62, 63, "USED-FOR"]]]}
{"doc_key": "2110.07560-c7a6bc5d-bd70-4385-b95d-7dd56b2b58a3", "sentences": [["Importantly", ",", "during", "language", "sparse", "fine-tuning", ",", "we", "decouple", "the", "input", "and", "output", "embedding", "matrices", "and", "fix", "the", "parameters", "of", "the", "output", "matrix", ";", "otherwise", ",", "we", "find", "that", "the", "vast", "majority", "of", "the", "\\", "-LRB-", "K\\", "-RRB-", "most", "changed", "parameters", "during", "full", "fine-tuning", "belong", "to", "the", "embedding", "matrix", ",", "seemingly", "due", "to", "its", "proximity", "to", "the", "model", "output", ",", "and", "downstream", "performance", "is", "poor", "."], ["We", "also", "fix", "the", "layer", "normalization", "parameters", ";", "all", "other", "parameters", "are", "trainable", "."], ["For", "language", "adaptation", ",", "we", "apply", "L1", "regularization", "as", "described", "in", "\u00a7REF", "with", "\\", "-LRB-", "\\lambda", "=", "0.1\\", "-RRB-", "."], ["Note", "that", "the", "specified", "training", "regime", "is", "applied", "in", "the", "same", "way", "during", "both", "phases", "of", "LT-SFT", "."]], "ner": [[], [], [[86, 87, "a"], [95, 95, "p"], [97, 97, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[36, 36, "p"]], [], [[86, 87, "a"], [97, 97, "v"]], [[116, 116, "a"]]], "predicted_relations": [[], [], [[95, 95, 86, 87, "USED-FOR"], [97, 97, 95, 95, "USED-FOR"]], []]}
{"doc_key": "2110.07560-14305b3b-4fb0-409f-8b74-917ef429efe8", "sentences": [["For", "NLI", ",", "we", "employ", "the", "same", "fine-tuning", "hyperparameters", "as", "-LSB-", "11", "-RSB-", ":", "5", "epochs", "with", "batch", "size", "32", ",", "with", "checkpoint", "evaluation", "on", "the", "validation", "set", "every", "625", "steps", ",", "and", "an", "initial", "learning", "rate", "of", "2\\", "-LRB-", "e\\", "-RRB-", "-5", "."], ["We", "apply", "a", "two-layer", "multi-class", "classification", "head", "atop", "the", "MMT", "output", "corresponding", "to", "the", "-LSB-", "CLS", "-RSB-", "token", "."]], "ner": [[[1, 1, "a"], [15, 15, "p"], [14, 14, "v"], [42, 42, "v"], [17, 18, "p"], [19, 19, "v"], [22, 23, "p"], [24, 30, "v"], [34, 36, "p"], [38, 42, "v"]], [[47, 50, "p"]]], "relations": [[], []], "predicted_ner": [[[14, 14, "v"], [15, 15, "p"], [17, 18, "p"], [19, 19, "v"], [29, 29, "v"], [35, 36, "p"], [38, 42, "v"]], []], "predicted_relations": [[[14, 14, 15, 15, "USED-FOR"], [42, 42, 34, 36, "USED-FOR"], [17, 18, 1, 1, "USED-FOR"], [19, 19, 15, 15, "USED-FOR"], [19, 19, 22, 23, "USED-FOR"], [22, 23, 1, 1, "USED-FOR"], [24, 30, 22, 23, "USED-FOR"], [38, 42, 34, 36, "USED-FOR"]], []]}
{"doc_key": "2108.02768-a8cce255-2707-468e-9e22-d8c95160a3c9", "sentences": [["We", "ran", "experiments", "with", "the", "Lookahead", "optimizer", "-LSB-", "31", "-RSB-", "with", "its", "default", "hyperparameters", ",", "and", "found", "that", "it", "significantly", "helps", "with", "training", "DeepSet", "models", ",", "while", "its", "effect", "on", "other", "architectures", "is", "minimal", "."], ["We", "did", "n't", "use", "any", "form", "of", "regularization", "\u2014", "at", "no", "point", "in", "our", "experiments", "we", "observed", "overfitting", "behaviour", "thanks", "to", "the", "infinite", "supply", "of", "synthetic", "data", "."], ["We", "also", "clipped", "gradients", "whose", "L2", "norm", "surpassed", "1", "for", "increase", "training", "stability", "."], ["We", "trained", "all", "of", "the", "networks", "using", "the", "PyTorch", "framework", "-LSB-", "20", "-RSB-", ",", "on", "NVIDIA", "T4", "GPUs", "."], ["Depending", "on", "the", "task", "and", "model", ",", "each", "training", "run", "took", "about", "1", "to", "8", "days", "to", "complete", "."]], "ner": [[[5, 6, "a"]], [], [], [[85, 86, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [], [[71, 71, "v"]], [], [[108, 108, "v"], [110, 110, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2105.01904-9e3db8a8-32c4-4a42-b009-17b987f188f2", "sentences": [["Training", "epochs", "."], ["In", "each", "iteration", ",", "the", "155", "training", "levels", "are", "randomly", "permuted", "and", "searched", "by", "the", "agent", "until", "a", "reward", "is", "received", ",", "with", "a", "cap", "of", "50", ",", "100", "search", "nodes", "for", "the", "backward", "and", "forward", "agents", ",", "respectively", "."], ["We", "perform", "100", "training", "iterations", "starting", "with", "a", "\\", "-LRB-", "TD", "-LRB-", "0", "-RRB-", "\\", "-RRB-", "learning", "rate", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "=0.01", ",", "and", "multiplying", "it", "by", "\\", "-LRB-", "0.98\\", "-RRB-", "at", "each", "iteration", "."], ["Training", "takes", "a", "few", "minutes", "on", "a", "single", "core", "."]], "ner": [[[0, 1, "a"]], [[32, 33, "p"], [29, 29, "v"], [31, 31, "v"], [38, 39, "c"], [31, 31, "v"]], [[59, 60, "p"], [66, 66, "v"], [45, 45, "v"], [46, 47, "p"], [45, 45, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[0, 1, "p"]], [[8, 8, "v"], [29, 29, "v"], [31, 31, "v"], [32, 33, "p"]], [[45, 45, "v"], [46, 47, "p"], [59, 60, "p"], [63, 63, "p"], [66, 66, "v"], [74, 74, "v"]], []], "predicted_relations": [[], [[29, 29, 32, 33, "USED-FOR"]], [[45, 45, 46, 47, "USED-FOR"], [45, 45, 46, 47, "USED-FOR"]], []]}
{"doc_key": "2109.00373-d6188e2c-6128-4843-bffe-bb471d2e4367", "sentences": [["fine-tuning", "stage", "."], ["The", "initial", "learning", "rate", "is", "set", "as", "\\", "-LRB-", "0.00002\\", "-RRB-", "and", "the", "weight", "decay", "is", "\\", "-LRB-", "0.05\\", "-RRB-", "."], ["We", "set", "the", "crop", "size", "of", "the", "input", "image", "as", "\\", "-LRB-", "512", "\\times", "512\\", "-RRB-", "and", "batch", "size", "as", "16", "by", "default", "."], ["Besides", ",", "the", "networks", "are", "fine-tuned", "for", "240", "epochs", "on", "the", "train", "set", "."], ["For", "each", "iteration", ",", "we", "randomly", "select", "one", "frame", "from", "the", "videos", "to", "train", "our", "framework", "."]], "ner": [[], [[4, 6, "a"], [16, 17, "a"]], [[27, 32, "a"], [41, 42, "a"]], [[56, 56, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[5, 6, "p"], [12, 12, "v"], [16, 17, "p"], [21, 21, "v"]], [[27, 28, "p"], [36, 36, "v"], [38, 38, "v"], [41, 42, "p"], [44, 44, "v"]], [[55, 55, "v"], [56, 56, "p"]], [[69, 69, "v"], [77, 77, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2103.13858-c4e74757-ee7a-4954-b4c1-c69a8c41f4b0", "sentences": [["Under", "the", "architecture", "of", "CGI", ",", "the", "training", "data", "comes", "from", "bucket", "signal", "after", "multiple", "sampling", "of", "target", "based", "on", "a", "set", "of", "fixed", "random", "speckles", "sequence", "."], ["The", "size", "of", "speckle", "and", "target", "is", "both", "28", "*", "28", "."], ["Each", "pixel", "of", "the", "target", "is", "sampled", "once", ",", "and", "784", "bucket", "signal", "values", "are", "formed", "."], ["We", "construct", "the", "bucket", "signal", "sequence", "into", "a", "bucket", "signal", "array", "as", "an", "input", "of", "CGAN", "."], ["Consequently", ",", "the", "size", "of", "bucket", "signal", "array", "is", "28", "*", "28", "."], ["In", "the", "following", "description", ",", "each", "input", "of", "CGAN", "is", "formed", "after", "a", "complete", "round", "of", "sampling", ",", "that", "is", ",", "784", "."], ["The", "targets", "in", "our", "experiment", "are", "handwritten", "letters", "and", "numbers", "."], ["Letter", "targets", "include", "10", "categories", "of", "``", "A", ",", "B", ",", "C", ",", "D", ",", "E", ",", "F", ",", "G", ",", "H", ",", "I", ",", "J", "''", ",", "and", "number", "targets", "include", "10", "categories", "of", "``", "0,1,2,3,4,5,6,7,8,9", "''", "."], ["We", "trained", "four", "networks", "using", "5000", ",", "10000", ",", "20000", "and", "60000", "samples", ",", "and", "each", "category", "of", "target", "contains", "500", ",", "1000", ",", "2000", "and", "6000", "in", "four", "networks", ",", "respectively", "."], ["Meanwhile", ",", "500", ",", "1000", ",", "2000", "and", "5000", "epochs", "are", "performed", "in", "each", "network", "."], ["Fig", "."], ["REF", "shows", "the", "handwritten", "targets", "in", "our", "experiment", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[15, 15, "a"]], [], [], [[72, 72, "a"]], [], [[95, 95, "a"], [103, 103, "a"]], [], [], [[180, 180, "v"], [182, 182, "v"], [184, 184, "v"], [165, 165, "v"]], [[195, 195, "v"], [202, 202, "a"], [197, 197, "v"], [199, 199, "v"], [201, 201, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"]], [[36, 36, "v"], [38, 38, "v"]], [[50, 50, "v"]], [[72, 72, "a"]], [[83, 83, "v"], [85, 85, "v"]], [[95, 95, "a"], [108, 108, "v"]], [], [[124, 124, "v"], [153, 153, "v"]], [[162, 162, "v"], [165, 165, "v"], [167, 167, "v"], [169, 169, "v"], [171, 171, "v"], [180, 180, "v"], [182, 182, "v"], [184, 184, "v"], [186, 186, "v"], [188, 188, "v"]], [[195, 195, "v"], [197, 197, "v"], [199, 199, "v"], [201, 201, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2111.07556-6e295a42-43de-4228-80da-399e5192d11d", "sentences": [["However", ",", "the", "current", "distillation", "is", "mainly", "used", "in", "classification", "tasks", "."], ["By", "increasing", "the", "temperature", ",", "teachers", "can", "output", "the", "soft", "knowledge", "of", "``", "6", "is", "not", "only", "like", "6", ",", "6", "is", "also", "like", "4", "''", ",", "so", "as", "to", "enhance", "the", "generalization", "ability", "of", "students", "'", "models", "."], ["There", "are", "only", "two", "papers", "on", "the", "application", "of", "distillation", "to", "regression", "tasks", "."], ["\\", "-LRB-", "L_", "-LCB-", "distill", "-RCB-", "=\\left\\lbrace", "\\begin", "-LCB-", "array", "-RCB-", "-LCB-", "rcl", "-RCB-", "||O_", "-LCB-", "student", "-RCB-", "-O_", "-LCB-", "teacher", "-RCB-", "||^2_2", "&", "&", "-LCB-", "if", "\\", "\\", "||y-O_", "-LCB-", "teacher", "-RCB-", "||_2", ">", "\\mu", "-RCB-", "\\\\f", "-LRB-", "O_", "-LCB-", "student", "-RCB-", ",", "m", "-RRB-", "&", "&", "-LCB-", "if", "\\", "\\", "||y-O_", "-LCB-", "teacher", "-RCB-", "||_2", "<", "\\mu", "-RCB-", "\\\\\\end", "-LCB-", "array", "-RCB-", "\\right.\\", "-RRB-"]], "ner": [[], [], [], [[100, 100, "p"], [123, 123, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "a"]], [[30, 30, "v"], [32, 32, "v"], [36, 36, "v"]], [[54, 54, "v"], [60, 60, "a"]], [[67, 70, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.01606-e7852911-04cf-413e-987f-891948c6ecb9", "sentences": [["Threat", "models", "."], ["We", "further", "consider", "the", "\\", "-LRB-", "\\ell", "_2\\", "-RRB-", "-norm", "threat", "model", ",", "in", "which", "we", "set", "\\", "-LRB-", "\\epsilon", "=1.0\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "=0.25\\", "-RRB-", "in", "the", "10-step", "PGD", "adversary", "."], ["The", "learning", "curves", "of", "PGD-AT", "and", "TRADES", "are", "shown", "in", "Fig", "."], ["REF", ",", "which", "also", "exhibit", "similar", "results", "."]], "ner": [[[0, 1, "a"]], [[23, 23, "v"], [29, 29, "v"], [34, 35, "a"], [33, 33, "p"]], [[41, 41, "a"], [43, 43, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[28, 28, "p"], [29, 29, "v"], [33, 33, "v"], [34, 34, "a"]], [[41, 41, "a"]], []], "predicted_relations": [[], [[33, 33, 34, 35, "USED-FOR"]], [], []]}
{"doc_key": "2106.01583-5853aacd-97a0-465b-b48c-3c5c63e0acb4", "sentences": [["where", "\\", "-LRB-", "\\alpha", "^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "\\", "-RRB-", "are", "per-graph", "weight", "of", "the", "training", "procedure", "."], ["When", "we", "have", "two", "graphs", ",", "\\", "-LRB-", "\\alpha", "^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "+", "\\alpha", "^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "=", "1\\", "-RRB-", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[15, 21, "p"]], [[35, 35, "v"], [48, 54, "p"]]], "predicted_relations": [[], []]}
{"doc_key": "2106.01583-d706812a-12b9-4989-8dd5-fd91e57945ee", "sentences": [["When", "the", "number", "of", "graphs", "is", "two", ",", "we", "can", "perform", "alternatives", "to", "save", "one", "linear", "transformation", "matrix", "."], ["Alternative", "1", "is", "to", "use", "\\", "-LRB-", "Q^", "-LCB-", "-LSB-", "A", "\\rightarrow", "B", "-RSB-", "-RCB-", "\\in", "\\mathcal", "-LCB-", "R", "-RCB-", "^", "-LCB-", "m_A", "\\times", "m_B", "-RCB-", "\\", "-RRB-", "to", "align", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "\\", "-RRB-", "'s", "raw", "attribute", "space", "to", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "\\", "-RRB-", "'s", ":", "\\", "-LRB-", "\\scalebox", "-LCB-", "0.8", "-RCB-", "-LCB-", "f", "-LRB-", "Q^", "-LCB-", "-LSB-", "A", "\\rightarrow", "B", "-RSB-", "-RCB-", ";", "W^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "_", "-LCB-", "-LRB-", "1", "-RRB-", "-RCB-", ",", "W_", "-LCB-", "-LRB-", "2", "-RRB-", "-RCB-", "-RRB-", "=", "\\alpha", "^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "\\cdot", "\\mathcal", "-LCB-", "L", "-RCB-", "\\left", "-LRB-", "g", "-LRB-", "X^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "Q^", "-LCB-", "-LSB-", "A", "\\rightarrow", "B", "-RSB-", "-RCB-", ",", "A^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", ",", "W^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "_", "-LCB-", "-LRB-", "1", "-RRB-", "-RCB-", ",", "W_", "-LCB-", "-LRB-", "2", "-RRB-", "-RCB-", "-RRB-", ",", "~A^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "\\right", "-RRB-", "-RCB-", "\\nonumber", "\\\\\\scalebox", "-LCB-", "0.8", "-RCB-", "-LCB-", "+~\\alpha", "^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "\\cdot", "\\mathcal", "-LCB-", "L", "-RCB-", "\\left", "-LRB-", "g", "-LRB-", "X^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", ","]], "ner": [[[15, 17, "a"]], [[26, 26, "a"], [93, 93, "a"], [145, 145, "a"], [91, 91, "a"], [26, 26, "p"], [93, 93, "p"], [145, 145, "p"], [102, 102, "p"], [161, 161, "p"], [123, 123, "p"], [197, 197, "p"], [133, 133, "p"], [207, 207, "p"], [137, 137, "p"], [211, 211, "p"], [133, 133, "a"], [207, 207, "a"], [137, 137, "a"], [211, 211, "a"]]], "relations": [[], []], "predicted_ner": [[[6, 6, "v"], [14, 14, "v"]], [[20, 20, "v"]]], "predicted_relations": [[], [[26, 26, 26, 26, "USED-FOR"], [26, 26, 93, 93, "USED-FOR"], [26, 26, 91, 91, "USED-FOR"], [26, 26, 133, 133, "USED-FOR"], [93, 93, 26, 26, "USED-FOR"], [93, 93, 93, 93, "USED-FOR"], [93, 93, 145, 145, "USED-FOR"], [93, 93, 91, 91, "USED-FOR"], [93, 93, 133, 133, "USED-FOR"], [93, 93, 137, 137, "USED-FOR"], [145, 145, 26, 26, "USED-FOR"], [145, 145, 93, 93, "USED-FOR"], [145, 145, 145, 145, "USED-FOR"], [145, 145, 91, 91, "USED-FOR"], [145, 145, 133, 133, "USED-FOR"], [145, 145, 207, 207, "USED-FOR"], [145, 145, 137, 137, "USED-FOR"], [145, 145, 211, 211, "USED-FOR"], [102, 102, 26, 26, "USED-FOR"], [102, 102, 93, 93, "USED-FOR"], [102, 102, 145, 145, "USED-FOR"], [102, 102, 91, 91, "USED-FOR"], [102, 102, 133, 133, "USED-FOR"], [102, 102, 137, 137, "USED-FOR"], [161, 161, 26, 26, "USED-FOR"], [161, 161, 93, 93, "USED-FOR"], [161, 161, 145, 145, "USED-FOR"], [161, 161, 91, 91, "USED-FOR"], [161, 161, 133, 133, "USED-FOR"], [161, 161, 207, 207, "USED-FOR"], [161, 161, 137, 137, "USED-FOR"], [123, 123, 26, 26, "USED-FOR"], [123, 123, 93, 93, "USED-FOR"], [123, 123, 145, 145, "USED-FOR"], [123, 123, 91, 91, "USED-FOR"], [123, 123, 133, 133, "USED-FOR"], [123, 123, 137, 137, "USED-FOR"], [197, 197, 93, 93, "USED-FOR"], [197, 197, 145, 145, "USED-FOR"], [197, 197, 91, 91, "USED-FOR"], [197, 197, 133, 133, "USED-FOR"], [197, 197, 207, 207, "USED-FOR"], [197, 197, 137, 137, "USED-FOR"], [197, 197, 211, 211, "USED-FOR"], [133, 133, 26, 26, "USED-FOR"], [133, 133, 93, 93, "USED-FOR"], [133, 133, 145, 145, "USED-FOR"], [133, 133, 91, 91, "USED-FOR"], [133, 133, 133, 133, "USED-FOR"], [133, 133, 137, 137, "USED-FOR"], [207, 207, 26, 26, "USED-FOR"], [207, 207, 93, 93, "USED-FOR"], [207, 207, 145, 145, "USED-FOR"], [207, 207, 133, 133, "USED-FOR"], [207, 207, 207, 207, "USED-FOR"], [207, 207, 137, 137, "USED-FOR"], [207, 207, 211, 211, "USED-FOR"], [137, 137, 26, 26, "USED-FOR"], [137, 137, 93, 93, "USED-FOR"], [137, 137, 145, 145, "USED-FOR"], [137, 137, 91, 91, "USED-FOR"], [137, 137, 133, 133, "USED-FOR"], [137, 137, 137, 137, "USED-FOR"], [211, 211, 26, 26, "USED-FOR"], [211, 211, 93, 93, "USED-FOR"], [211, 211, 145, 145, "USED-FOR"], [211, 211, 207, 207, "USED-FOR"], [211, 211, 211, 211, "USED-FOR"]]]}
{"doc_key": "2106.01583-e99fc95a-3958-4f35-b77f-29886685d344", "sentences": [["And", "alternative", "2", "is", "to", "use", "\\", "-LRB-", "Q^", "-LCB-", "-LSB-", "B", "\\rightarrow", "A", "-RSB-", "-RCB-", "\\in", "\\mathcal", "-LCB-", "R", "-RCB-", "^", "-LCB-", "m_B", "\\times", "m_A", "-RCB-", "\\", "-RRB-", "to", "align", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "^", "-LCB-", "-LSB-", "B", "-RSB-", "-RCB-", "\\", "-RRB-", "'s", "raw", "attribute", "space", "to", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "^", "-LCB-", "-LSB-", "A", "-RSB-", "-RCB-", "\\", "-RRB-", "'s", "."]], "ner": [[]], "relations": [[]], "predicted_ner": [[[2, 2, "v"]]], "predicted_relations": [[]]}
{"doc_key": "2106.01598-860b2582-db93-4cb6-b4f6-15ce9ab90879", "sentences": [["We", "implemented", "the", "Logistic", "Regression", "and", "SVM", "with", "random_state", "equal", "to", "0", ",", "C", "equal", "to", "1", ",", "and", "max_feature", "equal", "to", "13,000", "."], ["In", "addition", ",", "we", "implemeneted", "the", "Text-CNN", "and", "GRU", "with", "5", "epochs", ",", "batch_size", "equal", "to", "512", ",", "sequence_length", "equal", "to", "300", ",", "conv_layer_size", "equal", "to", "5", ",", "128", "units", ",", "dropout", "equal", "to", "0.1", ",", "and", "using", "sigmoid", "activation", "function", "."], ["Finally", ",", "we", "implement", "the", "Toxic-BERT", "with", "5", "epochs", ",", "train_batch_size", "equal", "to", "16", ",", "and", "test_batch_size", "equal", "to", "8", "."], ["We", "used", "the", "Simple", "transformerhttps", ":", "//simpletransformers.ai/", "for", "implementing", "the", "Toxic-BERT", "model", "."]], "ner": [[[3, 4, "a"], [8, 8, "p"], [11, 11, "v"], [13, 13, "p"], [16, 16, "v"], [19, 19, "p"], [22, 22, "v"], [6, 6, "a"], [8, 8, "p"], [11, 11, "v"], [13, 13, "p"], [16, 16, "v"], [19, 19, "p"], [22, 22, "v"]], [[58, 58, "v"], [58, 58, "v"], [58, 58, "v"], [58, 58, "v"], [30, 30, "a"], [35, 35, "p"], [34, 34, "v"], [50, 50, "v"], [37, 37, "p"], [40, 40, "v"], [42, 42, "p"], [45, 45, "v"], [47, 47, "p"], [34, 34, "v"], [50, 50, "v"], [53, 53, "p"], [52, 52, "v"], [55, 55, "p"], [58, 58, "v"], [63, 64, "p"], [62, 62, "v"], [32, 32, "a"], [35, 35, "p"], [34, 34, "v"], [50, 50, "v"], [37, 37, "p"], [40, 40, "v"], [42, 42, "p"], [45, 45, "v"], [47, 47, "p"], [34, 34, "v"], [50, 50, "v"], [53, 53, "p"], [52, 52, "v"], [55, 55, "p"], [58, 58, "v"], [63, 64, "p"], [62, 62, "v"], [35, 35, "p"], [34, 34, "v"], [50, 50, "v"]], [[74, 74, "p"], [73, 73, "v"], [73, 73, "v"], [74, 74, "p"], [73, 73, "v"], [73, 73, "v"], [71, 71, "a"], [74, 74, "p"], [73, 73, "v"], [76, 76, "p"], [79, 79, "v"], [82, 82, "p"], [85, 85, "v"]], [[97, 97, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "a"], [6, 6, "a"], [8, 8, "p"], [11, 11, "v"], [13, 13, "p"], [16, 16, "v"], [22, 22, "v"]], [[30, 30, "a"], [32, 32, "a"], [34, 34, "v"], [35, 35, "p"], [37, 37, "p"], [40, 40, "v"], [42, 42, "p"], [45, 45, "v"], [47, 47, "p"], [50, 50, "v"], [52, 52, "v"], [53, 53, "p"], [55, 55, "p"], [58, 58, "v"], [62, 62, "a"]], [[71, 71, "a"], [73, 73, "v"], [74, 74, "p"], [76, 76, "p"], [79, 79, "v"], [82, 82, "p"], [85, 85, "v"]], [[97, 97, "a"]]], "predicted_relations": [[[8, 8, 6, 6, "USED-FOR"], [11, 11, 8, 8, "USED-FOR"], [11, 11, 13, 13, "USED-FOR"], [11, 11, 8, 8, "USED-FOR"], [11, 11, 13, 13, "USED-FOR"], [13, 13, 6, 6, "USED-FOR"], [19, 19, 6, 6, "USED-FOR"], [8, 8, 6, 6, "USED-FOR"], [11, 11, 8, 8, "USED-FOR"], [11, 11, 13, 13, "USED-FOR"], [11, 11, 8, 8, "USED-FOR"], [11, 11, 13, 13, "USED-FOR"], [13, 13, 6, 6, "USED-FOR"], [19, 19, 6, 6, "USED-FOR"]], [[58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [35, 35, 30, 30, "USED-FOR"], [35, 35, 32, 32, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [37, 37, 30, 30, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [40, 40, 42, 42, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [40, 40, 42, 42, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [42, 42, 30, 30, "USED-FOR"], [42, 42, 32, 32, "USED-FOR"], [45, 45, 42, 42, "USED-FOR"], [45, 45, 42, 42, "USED-FOR"], [47, 47, 30, 30, "USED-FOR"], [47, 47, 32, 32, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [53, 53, 30, 30, "USED-FOR"], [53, 53, 32, 32, "USED-FOR"], [55, 55, 30, 30, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [62, 62, 63, 64, "USED-FOR"], [62, 62, 63, 64, "USED-FOR"], [35, 35, 30, 30, "USED-FOR"], [35, 35, 32, 32, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [37, 37, 30, 30, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [40, 40, 42, 42, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [40, 40, 42, 42, "USED-FOR"], [40, 40, 35, 35, "USED-FOR"], [42, 42, 30, 30, "USED-FOR"], [42, 42, 32, 32, "USED-FOR"], [45, 45, 42, 42, "USED-FOR"], [45, 45, 42, 42, "USED-FOR"], [47, 47, 30, 30, "USED-FOR"], [47, 47, 32, 32, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [53, 53, 30, 30, "USED-FOR"], [53, 53, 32, 32, "USED-FOR"], [55, 55, 30, 30, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [58, 58, 55, 55, "USED-FOR"], [58, 58, 63, 64, "USED-FOR"], [62, 62, 63, 64, "USED-FOR"], [62, 62, 63, 64, "USED-FOR"], [35, 35, 30, 30, "USED-FOR"], [35, 35, 32, 32, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"]], [[74, 74, 71, 71, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [74, 74, 71, 71, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [74, 74, 71, 71, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [73, 73, 74, 74, "USED-FOR"], [76, 76, 71, 71, "USED-FOR"], [79, 79, 74, 74, "USED-FOR"], [79, 79, 74, 74, "USED-FOR"], [79, 79, 74, 74, "USED-FOR"], [82, 82, 71, 71, "USED-FOR"]], []]}
{"doc_key": "2106.01560-f1dc3daa-b1f0-4e23-b9c1-77b3de05aa78", "sentences": [["For", "PyTorch", ",", "we", "use", "seeds", "133,133/1337/13370", "is", "the", "default", "seed", "setting", "in", "AllenNLP", "."], ["11", ",", "and", "22", "For", "Numpy", ",", "we", "use", "seeds", "1337", ",", "111", ",", "and", "222", "For", "Python", "'s", "random", "library", ",", "we", "use", "seeds", "11370", ",", "1111", ",", "and", "2222"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[1, 1, "a"]], [[18, 18, "v"], [25, 25, "v"], [27, 27, "v"], [30, 30, "v"], [40, 40, "v"], [42, 42, "v"], [45, 45, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2101.06021-6555eb62-2725-4720-b6e9-f34cf12a91e1", "sentences": [["All", "our", "experiments", "are", "implemented", "in", "PyTorch", "and", "evaluated", "on", "a", "single", "NVIDIA", "RTX", "1080Ti", "GPU", "."], ["To", "train", "our", "network", ",", "we", "randomly", "crop", "input", "images", "to", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "pixel", "size", "."], ["The", "batch", "size", "is", "set", "to", "6", "during", "training", "."], ["The", "Adam", "solver", "is", "used", "to", "train", "our", "models", "for", "3000", "epochs", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "0.0001", ",", "the", "decay", "rate", "set", "to", "0.5", "and", "step", "size", "is", "500", "."], ["We", "normalize", "image", "to", "range", "-LSB-", "0,1", "-RSB-", "and", "then", "subtract", "0.5", ",", "so", "that", "our", "input", "'s", "range", "is", "-LSB-", "-0.5,0.5", "-RSB-", "."]], "ner": [[[6, 6, "a"], [12, 15, "a"]], [[23, 26, "a"], [33, 34, "p"]], [[37, 38, "a"], [37, 38, "p"], [42, 42, "v"]], [[47, 48, "a"], [57, 57, "a"], [57, 57, "p"], [56, 56, "v"]], [[60, 62, "p"], [66, 66, "v"], [69, 70, "p"], [73, 73, "v"], [75, 76, "p"], [78, 78, "v"]], [[91, 91, "v"], [101, 101, "v"], [101, 101, "v"], [81, 82, "a"], [84, 84, "p"], [98, 98, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[20, 20, "a"], [31, 31, "v"]], [[37, 38, "p"], [42, 42, "v"], [43, 44, "c"]], [[47, 48, "a"], [56, 56, "v"], [57, 57, "p"]], [[61, 62, "p"], [66, 66, "v"], [69, 70, "p"], [73, 73, "v"], [78, 78, "v"]], [[86, 87, "v"], [91, 91, "v"]]], "predicted_relations": [[], [[33, 34, 23, 26, "USED-FOR"]], [], [[57, 57, 47, 48, "USED-FOR"], [57, 57, 57, 57, "USED-FOR"], [56, 56, 57, 57, "USED-FOR"]], [[66, 66, 69, 70, "USED-FOR"], [73, 73, 69, 70, "USED-FOR"], [78, 78, 75, 76, "USED-FOR"]], [[91, 91, 98, 98, "USED-FOR"], [101, 101, 98, 98, "USED-FOR"], [101, 101, 98, 98, "USED-FOR"], [84, 84, 81, 82, "USED-FOR"], [98, 98, 81, 82, "USED-FOR"]]]}
{"doc_key": "2112.13408-b1d95cc2-1ecd-4cf1-90b7-16a68c042c30", "sentences": [["For", "low", "resolution", "dataset", ",", "we", "use", "batch", "size", "of", "128", "by", "default", "because", "larger", "batch", "size", "even", "makes", "models", "slower", "to", "converge", "."], ["For", "high", "resolution", "dataset", ",", "we", "use", "batch", "size", "of", "32", "to", "pre", ",", "because", "of", "the", "memory", "limit", "of", "experiment", "equipment", "."], ["We", "use", "NAdam", "optimizer", "-LSB-", "29", "-RSB-", "for", "all", "our", "experiments", "but", "adjust", "learning", "rate", "and", "use", "decay", "at", "different", "experiments", "."]], "ner": [[[6, 6, "v"], [7, 8, "a"], [15, 16, "a"], [1, 3, "a"]], [[30, 30, "v"], [31, 32, "a"], [25, 27, "a"]], [[49, 50, "a"], [60, 61, "p"], [59, 59, "v"], [64, 64, "p"], [48, 48, "v"], [63, 63, "v"]]], "relations": [[], [], []], "predicted_ner": [[[7, 8, "p"], [10, 10, "v"]], [[31, 32, "p"], [34, 34, "v"], [36, 36, "v"]], [[49, 50, "a"], [60, 61, "p"], [64, 64, "a"]]], "predicted_relations": [[], [], [[60, 61, 49, 50, "USED-FOR"], [64, 64, 49, 50, "USED-FOR"]]]}
{"doc_key": "2110.03215-5dee65fd-2cc3-497e-aa3f-5311c99a5d9d", "sentences": [["The", "input", "and", "output", "sequence", "length", "is", "fixed", "to", "350", "."], ["We", "use", "gradient", "accumulation", "for", "cases", "where", "the", "same", "number", "of", "training", "batches", "could", "not", "be", "loaded", "on", "the", "GPUs", "due", "to", "the", "varying", "memory", "consumption", "required", "for", "different", "methods", "and", "set", "the", "global", "batch", "size", "to", "60", "."], ["We", "use", "Adafactor", "optimizer", "with", "an", "initial", "learning", "rate", "of", "1e-3", "."], ["We", "show", "the", "effects", "of", "learning", "rate", "variation", "regarding", "the", "trade-off", "between", "maintaining", "previous", "knowledge", "and", "acquiring", "new", "knowledge", "in", "Appendix", "."], ["We", "use", "learning", "rate", "warm-up", "for", "the", "first", "10", "%", "of", "training", "and", "linearly", "decay", "the", "learning", "rate", "to", "half", "of", "the", "initial", "learning", "rate", "towards", "the", "end", "of", "training", "."], ["For", "all", "of", "the", "experiments", ",", "we", "use", "4", "32GB", "V100", "GPUs", "for", "training", "with", "each", "method", "except", "Mix-Review", ",", "where", "we", "use", "16", "32GB", "V100", "GPUs", "."], ["The", "details", "of", "the", "configurations", "used", "for", "evaluation", "on", "each", "individual", "CKL", "task", "are", "provided", "in", "Appendix", "REF", "."]], "ner": [[], [], [[52, 53, "a"], [56, 58, "p"], [60, 60, "v"]], [], [[106, 108, "p"], [86, 88, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "v"]], [[13, 14, "a"], [48, 48, "v"]], [[52, 52, "a"], [57, 58, "p"], [60, 60, "v"]], [], [[86, 88, "a"], [92, 93, "v"], [100, 101, "p"], [103, 103, "v"], [107, 108, "p"]], [[123, 123, "v"], [124, 124, "v"], [125, 125, "a"], [133, 133, "a"], [138, 138, "v"], [139, 139, "v"], [140, 140, "a"]], []], "predicted_relations": [[], [], [[56, 58, 52, 53, "USED-FOR"], [60, 60, 56, 58, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2102.13326-dd4ed77c-9235-4c0c-8319-ceb4575656c2", "sentences": [["Different", "hyperparameters", "are", "set", "to", "evaluate", "their", "effect", "on", "the", "model", "."], ["Fig.REF", ",", "REF", "show", "the", "generalized", "accuracy", "curves", "on", "the", "two", "benchmark", "datasets", "with", "varying", "methods", "of", "splitting", "and", "different", "hyperparameters", "."], ["As", "shown", "in", "Fig.REF", "and", "Fig.REF", ",", "the", "value", "of", "hyperparameter", "setting", "is", "represented", "with", "the", "horizontal", "axis", ",", "the", "generalization", "accuracy", "of", "the", "seen", "classes", "is", "represented", "with", "the", "vertical", "axis", ",", "and", "the", "corresponding", "accuracy", "of", "the", "seen", "class", "is", "represented", "with", "red", "value", "in", "the", "curve", "."], ["The", "hyperparameters", "with", "the", "highest", "generalization", "accuracy", "will", "be", "selected", "as", "the", "parameter", "of", "the", "model", "."], ["Therefore", ",", "the", "model", "needs", "different", "hyperparameters", "values", "for", "different", "settings", "."], ["For", "CUB", ",", "the", "\\", "-LRB-", "k\\", "-RRB-", "value", "of", "\\", "-LRB-", "top-k\\", "-RRB-", "is", "set", "as", "4", "and", "1", "in", "SCS", "and", "SCE", "cases", ",", "respectively", "."], ["While", "for", "NAB", ",", "the", "\\", "-LRB-", "k\\", "-RRB-", "value", "of", "\\", "-LRB-", "top-k\\", "-RRB-", "is", "3", "and", "1", "in", "the", "case", "of", "SCS", "and", "SCE", ",", "respectively", "."], ["\\", "-LRB-", "top-k\\", "-RRB-", "represents", "the", "sharing", "of", "k", "classes", "of", "text", "."]], "ner": [[[1, 1, "a"]], [[32, 32, "a"]], [], [[85, 85, "a"]], [[107, 107, "a"]], [[119, 119, "p"], [125, 125, "p"], [130, 130, "v"], [114, 114, "c"], [132, 132, "v"], [134, 134, "c"], [132, 132, "v"], [136, 136, "c"], [125, 125, "a"]], [[148, 148, "p"], [154, 154, "p"], [159, 159, "v"], [164, 164, "c"], [157, 157, "v"], [143, 143, "c"], [159, 159, "v"], [166, 166, "c"], [154, 154, "a"]], [[172, 172, "p"], [178, 178, "p"], [172, 172, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[22, 22, "v"]], [], [], [], [[114, 114, "a"], [119, 119, "p"], [130, 130, "v"], [132, 132, "v"], [136, 136, "a"]], [[143, 143, "a"], [148, 148, "p"], [157, 157, "v"], [159, 159, "v"], [166, 166, "a"]], [[178, 178, "v"]]], "predicted_relations": [[], [], [], [], [], [[119, 119, 125, 125, "USED-FOR"], [125, 125, 125, 125, "USED-FOR"], [130, 130, 119, 119, "USED-FOR"], [130, 130, 125, 125, "USED-FOR"], [132, 132, 119, 119, "USED-FOR"], [132, 132, 125, 125, "USED-FOR"], [132, 132, 119, 119, "USED-FOR"], [132, 132, 125, 125, "USED-FOR"]], [[148, 148, 154, 154, "USED-FOR"], [154, 154, 154, 154, "USED-FOR"], [159, 159, 148, 148, "USED-FOR"], [159, 159, 154, 154, "USED-FOR"], [157, 157, 148, 148, "USED-FOR"], [157, 157, 154, 154, "USED-FOR"], [159, 159, 148, 148, "USED-FOR"], [159, 159, 154, 154, "USED-FOR"]], [[172, 172, 172, 172, "USED-FOR"], [178, 178, 172, 172, "USED-FOR"]]]}
{"doc_key": "2109.03787-346f30e6-2502-48ed-8d72-0d5a27486d65", "sentences": [["For", "the", "data", "augmentation", ",", "we", "followed", "other", "papers", "to", "do", "the", "rotation", "and", "flipping", "along", "the", "y", "axis", ",", "."], ["We", "set", "the", "batch", "size", "as", "2", "and", "adopted", "the", "Adam", "optimizer", "with", "a", "one-cycle", "learning", "rate", "policy", "."], ["The", "maximum", "learning", "rate", "was", "set", "to", "0.002", ",", "and", "the", "total", "training", "epoch", "was", "set", "to", "30", "."], ["For", "the", "loss", "function", ",", "we", "combined", "the", "weighted", "cross-entropy", "loss", "and", "the", "Lov\u00e1sz-Softmax", "loss", "together", "."], ["Thanks", "to", "the", "parameter-free", "FID", "-LRB-", "fully", "interpolation", "decoding", "-RRB-", "module", ",", "all", "our", "experiments", "were", "conducted", "on", "a", "single", "RTX", "2080", "Ti", "with", "the", "mix-precision", "choice", "in", "PyTorch", "."]], "ner": [[[2, 3, "a"]], [[24, 25, "p"], [27, 27, "v"], [32, 32, "p"], [31, 32, "a"], [35, 38, "a"]], [[41, 43, "p"], [47, 47, "v"], [51, 53, "p"], [57, 57, "v"]], [[67, 69, "a"], [72, 73, "a"]], [[101, 102, "a"], [80, 86, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[24, 25, "p"], [27, 27, "v"], [31, 31, "a"], [35, 35, "v"], [36, 37, "p"]], [[42, 43, "p"], [47, 47, "v"], [52, 53, "p"], [57, 57, "v"]], [[67, 69, "a"], [72, 73, "a"]], [[96, 98, "a"], [104, 104, "a"]]], "predicted_relations": [[], [[32, 32, 31, 32, "USED-FOR"]], [[57, 57, 51, 53, "USED-FOR"]], [], []]}
{"doc_key": "2102.06191-d90a23f1-cbcb-4963-b59d-ef042c5fbf08", "sentences": [["We", "use", "a", "DeepLab-v3", "-LSB-", "9", "-RSB-", "model", "with", "dilated", "-LSB-", "84", "-RSB-", "ResNet-50", "backbone", "-LSB-", "24", "-RSB-", "."], ["The", "backbone", "is", "initialized", "from", "MoCo", "v2", "-LSB-", "12", "-RSB-", "pre-trained", "on", "ImageNet", ",", "unless", "defined", "otherwise", "."], ["We", "train", "the", "model", "for", "60", "epochs", "using", "batches", "of", "size", "64", "."], ["The", "model", "weights", "are", "updated", "through", "SGD", "with", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "weight", "decay", "\\", "-LRB-", "1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "initial", "learning", "is", "set", "to", "\\", "-LRB-", "0.004\\", "-RRB-", "and", "decayed", "with", "a", "poly", "learning", "rate", "scheme", "."], ["We", "use", "the", "same", "set", "of", "augmentations", "as", "SimCLR", "-LSB-", "10", "-RSB-", "to", "generate", "positive", "pairs", "\\", "-LRB-", "-LRB-", "X", ",", "X^+", "-RRB-", "\\", "-RRB-", ",", "while", "making", "sure", "that", "each", "image", "contains", "at", "least", "a", "part", "of", "the", "salient", "object", "\\", "-LRB-", "-LRB-", "\\text", "-LCB-", "area", "-RCB-", ">", "10\\", "%", "-RRB-", "\\", "-RRB-", "."], ["The", "features", "of", "negatives", "\\", "-LRB-", "\\left\\lbrace", "\\mathbf", "-LCB-", "z", "-RCB-", "_", "-LCB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_", "-LCB-", "X^-_0", "-RCB-", "-RCB-", ",", "\\ldots", ",", "\\mathbf", "-LCB-", "z", "-RCB-", "_", "-LCB-", "\\mathcal", "-LCB-", "M", "-RCB-", "_", "-LCB-", "X^-_K", "-RCB-", "-RCB-", "\\right\\rbrace", "\\", "-RRB-", "are", "saved", "in", "a", "memory", "bank", ",", "with", "\\", "-LRB-", "K\\", "-RRB-", "set", "to", "128", "."], ["The", "negatives", "are", "encoded", "with", "a", "momentum-updated", "version", "of", "the", "network", "following", "-LSB-", "23", "-RSB-", "."], ["We", "use", "dimension", "\\", "-LRB-", "D=32\\", "-RRB-", "and", "temperature", "\\", "-LRB-", "\\tau", "=0.5\\", "-RRB-", "."]], "ner": [[[3, 3, "a"]], [[24, 25, "a"]], [], [[56, 56, "a"], [58, 58, "p"], [61, 61, "v"], [64, 65, "p"]], [[76, 77, "p"], [83, 83, "v"], [89, 92, "a"]], [[102, 102, "a"]], [], [[214, 214, "p"], [214, 218, "a"]], [[226, 226, "p"], [229, 229, "v"], [232, 232, "p"], [236, 236, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [13, 13, "a"]], [[24, 25, "a"], [31, 31, "a"]], [[42, 42, "v"], [43, 43, "p"], [48, 48, "v"]], [[56, 56, "a"], [58, 58, "p"], [61, 61, "v"], [64, 65, "p"], [68, 70, "v"]], [[83, 83, "v"]], [[102, 102, "a"], [143, 144, "v"]], [[202, 202, "p"], [206, 206, "v"]], [], [[229, 229, "v"], [232, 232, "p"]]], "predicted_relations": [[], [], [], [[58, 58, 56, 56, "USED-FOR"], [61, 61, 58, 58, "USED-FOR"], [61, 61, 64, 65, "USED-FOR"], [64, 65, 56, 56, "USED-FOR"]], [[83, 83, 76, 77, "USED-FOR"]], [], [], [[214, 214, 214, 218, "USED-FOR"]], [[229, 229, 226, 226, "USED-FOR"], [236, 236, 226, 226, "USED-FOR"]]]}
{"doc_key": "2102.02888-1a439101-026c-4130-b3e4-2f8089a3266e", "sentences": [["For", "GLUE", "benchmarks", "we", "use", "original", "Adam", "optimizer", "and", "perform", "single-task", "training", "on", "the", "dev", "set", "."], ["We", "search", "over", "the", "hyperparameter", "space", "with", "batch", "sizes", "\\", "-LRB-", "\\in", "\\lbrace", "8,16\\rbrace", "\\", "-RRB-", "and", "learning", "rates", "\\", "-LRB-", "\\in", "\\lbrace", "1\\times", "10^", "-LCB-", "-5", "-RCB-", ",3\\times", "10^", "-LCB-", "-5", "-RCB-", ",5\\times", "10^", "-LCB-", "-5", "-RCB-", ",8\\times", "10^", "-LCB-", "-5", "-RCB-", "\\rbrace", "\\", "-RRB-", "."], ["Other", "setting", "are", "the", "same", "as", "pre-training", "task", "."]], "ner": [[[6, 7, "a"]], [[30, 30, "v"], [55, 55, "v"], [30, 30, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"]], [[24, 25, "p"], [29, 30, "v"], [34, 35, "p"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2102.02723-2f17acd8-747c-4d43-8709-87b7b8c9d881", "sentences": [["We", "tuned", "the", "model", "hyperparameters", "on", "the", "development", "set", "."], ["For", "training", "the", "macro", "planning", "and", "the", "text", "generation", "stages", ",", "we", "used", "the", "Adagrad", "-LSB-", "9", "-RSB-", "optimizer", "."], ["Furthermore", ",", "the", "text", "generation", "stage", "made", "use", "of", "truncated", "BPTT", "-LSB-", "59", "-RSB-", "with", "truncation", "length", "100", "."], ["We", "learn", "subword", "vocabulary", "-LSB-", "51", "-RSB-", "for", "paragraph", "plans", "in", "the", "macro", "planning", "stage", "."], ["We", "used", "2.5K", "merge", "operations", "for", "RotoWire", "and", "8K", "merge", "operations", "for", "MLB", "."], ["In", "text", "generation", ",", "we", "learn", "a", "joint", "subword", "vocabulary", "for", "the", "macro", "plan", "and", "game", "summaries", "."], ["We", "used", "6K", "merge", "operations", "for", "RotoWire", "and", "16K", "merge", "operations", "for", "MLB", "."], ["All", "models", "were", "implemented", "on", "OpenNMT-py", "-LSB-", "23", "-RSB-", "."], ["We", "add", "to", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "\\", "-RRB-", "the", "paragraph", "plans", "corresponding", "to", "the", "output", "summary", "paragraphs", ",", "to", "ensure", "full", "coverage", "during", "training", "of", "the", "macro", "planner", "."], ["During", "inference", "for", "predicting", "macro", "plans", ",", "we", "employ", "length", "normalization", "-LSB-", "0", "-RSB-", "to", "avoid", "penalizing", "longer", "outputs", ";", "specifically", ",", "we", "divide", "the", "scores", "of", "beam", "search", "by", "the", "length", "of", "the", "output", "."], ["In", "addition", ",", "we", "adopt", "bigram", "blocking", "-LSB-", "41", "-RSB-", "."], ["For", "MLB", ",", "we", "further", "block", "beams", "containing", "more", "than", "two", "repetitions", "of", "a", "unigram", "."], ["This", "helps", "improve", "the", "diversity", "of", "the", "predicted", "macro", "plans", "."]], "ner": [[], [[24, 24, "a"]], [[39, 40, "a"]], [[51, 52, "a"]], [[68, 69, "p"], [74, 75, "p"], [71, 71, "c"], [77, 77, "c"]], [[87, 88, "a"]], [[100, 101, "p"], [106, 107, "p"], [99, 99, "v"], [103, 103, "c"], [105, 105, "v"], [109, 109, "c"]], [[116, 116, "a"]], [], [[163, 164, "a"]], [[195, 196, "a"]], [[202, 202, "c"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[24, 24, "a"]], [[40, 40, "a"], [47, 47, "v"]], [], [[67, 67, "v"], [71, 71, "a"], [73, 73, "v"], [77, 77, "a"]], [], [[99, 99, "v"], [103, 103, "a"], [105, 105, "v"], [109, 109, "a"]], [[116, 116, "a"]], [], [], [[195, 196, "a"]], [[202, 202, "a"], [211, 211, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [[99, 99, 100, 101, "USED-FOR"], [109, 109, 99, 99, "USED-FOR"], [109, 109, 105, 105, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2103.03457-e624abb7-e3bf-40f0-94ea-a4e08e16619a", "sentences": [["Optimization", "We", "adopt", "the", "default", "optimization", "setting", "in", "-LSB-", "45", "-RSB-", "."], ["Adam", "-LSB-", "21", "-RSB-", "optimizer", "with", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2=0.98\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-9", "-RCB-", "\\", "-RRB-", "."], ["The", "learning", "rate", "scheduler", "is", "inverse_sqrt", "with", "warmup", "steps", "\\", "-LRB-", "4,000\\", "-RRB-", ",", "default", "learning", "rate", "is", "\\", "-LRB-", "0.0005\\", "-RRB-", "."], ["Label", "smoothing", "-LSB-", "44", "-RSB-", "is", "used", "with", "value", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["As", "introduced", ",", "to", "learn", "the", "predictors", ",", "we", "clamp", "the", "\\", "-LRB-", "\\operatorname", "-LCB-", "softmax", "-RCB-", "\\", "-RRB-", "output", "with", "value", "\\", "-LRB-", "0.05\\", "-RRB-", "."]], "ner": [[], [[12, 12, "a"], [21, 21, "v"], [24, 24, "v"], [29, 29, "p"]], [[38, 40, "a"], [44, 45, "p"], [51, 53, "p"], [57, 57, "v"]], [[68, 68, "p"], [71, 71, "v"], [68, 68, "p"]], [[95, 95, "p"], [95, 95, "p"], [98, 98, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"]], [[42, 42, "a"], [44, 45, "p"], [48, 48, "v"], [52, 53, "p"], [57, 57, "v"]], [[60, 61, "a"], [71, 71, "v"]], [[98, 98, "v"]]], "predicted_relations": [[], [[29, 29, 12, 12, "USED-FOR"]], [[44, 45, 38, 40, "USED-FOR"]], [], []]}
{"doc_key": "2106.05124-21c7dd3e-ad7b-4014-a500-f51009c24a06", "sentences": [["We", "set", "the", "scales", "for", "the", "phase", "congruency", "estimation", "as", "4", ",", "with", "the", "scaling", "factor", "between", "successive", "filters", "being", "2", "."], ["For", "different", "scales", "of", "the", "learnable", "Gabor", "kernels", ",", "the", "size", "of", "learnable", "convolutional", "kernels", "are", "set", "as", "\\", "-LRB-", "7\\times", "7\\", "-RRB-", ",", "\\", "-LRB-", "13\\times", "13\\", "-RRB-", ",", "\\", "-LRB-", "19\\times", "19\\", "-RRB-", ",", "and", "\\", "-LRB-", "25", "\\times", "25\\", "-RRB-", "."], ["It", "is", "worth", "noting", "that", "although", "the", "above", "kernels", "seem", "to", "be", "overly", "large", "for", "the", "common", "CNN", ",", "they", "actually", "function", "well", "during", "our", "experiments", "under", "the", "regularization", "of", "the", "Gabor", "wavelets", "."], ["As", "for", "the", "three", "trainable", "layers", ",", "we", "set", "the", "initial", "value", "of", "\\", "-LRB-", "\\alpha", "=", "2\\", "-RRB-", "as", "it", "is", "originally", "defined", "as", "the", "scaling", "factor", ",", "and", "we", "set", "\\", "-LRB-", "\\beta", "=", "1\\", "-RRB-", ",", "\\", "-LRB-", "\\gamma", "=", "1\\", "-RRB-", "."]], "ner": [[[10, 10, "v"], [20, 20, "v"], [20, 20, "v"]], [], [], [[117, 117, "v"], [117, 117, "v"], [136, 136, "v"], [143, 143, "v"], [136, 136, "v"], [143, 143, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "v"], [20, 20, "v"]], [[43, 43, "v"], [49, 49, "v"], [55, 55, "v"], [61, 61, "v"], [63, 63, "v"]], [[83, 83, "a"]], [[103, 103, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2106.05142-1e7c5537-7ed2-4709-8d90-15b5777bfb4e", "sentences": [["We", "trained", "all", "unsupervised", "methods", "for", "25k", "steps", "with", "a", "batch", "size", "of", "2048", "."], ["We", "used", "an", "Adam", "optimizer", "with", "a", "linear", "warm-up", "between", "1e-5", "and", "1e-3", "for", "2.5k", "steps", "followed", "by", "cosine", "decay", "schedule", "as", "introduced", "by", "-LSB-", "5", "-RSB-", "."], ["We", "selected", "the", "common", "contrastive", "parameters", "from", "performances", "on", "the", "validation", "set", "for", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "^", "-LCB-", "\\textsc", "-LCB-", "CL", "-RCB-", "-RCB-", "\\", "-RRB-", "objective", "."], ["More", "details", "can", "be", "found", "in", "Appendix", "."], ["We", "used", "a", "temperature", "of", "0.1", ",", "a", "queue", "of", "size", "65536", ",", "and", "an", "embedding", "size", "of", "64", "for", "all", "tasks", "."], ["We", "set", "the", "momentum", "to", "0.999", "for", "MIMIC-III", "Benchmark", "tasks", "and", "0.99", "for", "Physionet", "2019", "."], ["Concerning", "parameters", "specific", "to", "our", "method", ",", "for", "\\", "-LRB-", "\\textsc", "-LCB-", "NCL", "-RCB-", "-LRB-", "n_w", "-RRB-", "\\", "-RRB-", "we", "chose", "\\", "-LRB-", "\\alpha", "=", "0.3\\", "-RRB-", "and", "\\", "-LRB-", "w", "=", "16", "\\", "-RRB-", "on", "MIMIC-III", "Benchmark", "and", "\\", "-LRB-", "\\alpha", "=", "0.4\\", "-RRB-", "and", "\\", "-LRB-", "w", "=", "12", "\\", "-RRB-", "on", "Physionet", "2019", "."], ["For", "\\", "-LRB-", "\\textsc", "-LCB-", "NCL", "-RCB-", "-LRB-", "n_Y", "-RRB-", "\\", "-RRB-", ",", "we", "use", "\\", "-LRB-", "\\alpha", "=", "0.9\\", "-RRB-", "for", "all", "tasks", "."], ["These", "parameters", "were", "selected", "using", "grid", "searches", "reported", "in", "Appendix", "."], ["For", "auto-encoding", "methods", ",", "we", "used", "a", "decoder", "with", "a", "mirrored", "architecture", "to", "the", "common", "encoder", "."], ["However", ",", "we", "did", "not", "normalize", "the", "representations", "to", "the", "unit", "sphere", "."]], "ner": [[], [[18, 19, "a"], [22, 23, "p"], [25, 25, "v"], [27, 27, "v"], [33, 35, "p"]], [[47, 48, "a"]], [], [[84, 84, "p"], [86, 86, "v"], [92, 92, "v"], [96, 97, "p"], [99, 99, "v"]], [[111, 112, "c"], [117, 118, "c"], [111, 112, "c"], [117, 118, "c"]], [[143, 143, "p"], [161, 161, "p"], [145, 145, "v"], [156, 157, "c"], [163, 163, "v"], [174, 175, "c"], [150, 150, "p"], [168, 168, "p"], [152, 152, "v"], [156, 157, "c"], [170, 170, "v"], [174, 175, "c"], [143, 143, "p"], [161, 161, "p"]], [[194, 194, "p"], [194, 194, "p"], [196, 196, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [10, 11, "p"], [13, 13, "v"]], [[18, 18, "a"], [22, 23, "a"], [25, 25, "v"], [27, 27, "v"], [29, 29, "v"]], [], [], [[84, 84, "p"], [86, 86, "v"], [92, 92, "v"], [96, 97, "p"], [99, 99, "v"], [100, 102, "c"]], [[107, 107, "p"], [109, 109, "v"], [111, 111, "a"], [115, 115, "v"], [116, 118, "c"]], [[125, 125, "a"], [143, 143, "p"], [145, 145, "v"], [152, 153, "v"], [163, 163, "v"], [170, 171, "v"]], [[196, 196, "v"]], [], [], []], "predicted_relations": [[], [[25, 25, 22, 23, "USED-FOR"], [25, 25, 33, 35, "USED-FOR"], [27, 27, 22, 23, "USED-FOR"], [27, 27, 33, 35, "USED-FOR"], [33, 35, 18, 19, "USED-FOR"]], [], [], [[92, 92, 84, 84, "USED-FOR"], [92, 92, 96, 97, "USED-FOR"], [99, 99, 96, 97, "USED-FOR"]], [], [[145, 145, 150, 150, "USED-FOR"], [156, 157, 145, 145, "USED-FOR"], [156, 157, 163, 163, "USED-FOR"], [156, 157, 152, 152, "USED-FOR"], [156, 157, 170, 170, "USED-FOR"], [163, 163, 161, 161, "USED-FOR"], [163, 163, 168, 168, "USED-FOR"], [163, 163, 161, 161, "USED-FOR"], [152, 152, 150, 150, "USED-FOR"], [152, 152, 168, 168, "USED-FOR"], [156, 157, 145, 145, "USED-FOR"], [156, 157, 163, 163, "USED-FOR"], [156, 157, 152, 152, "USED-FOR"], [156, 157, 170, 170, "USED-FOR"], [170, 170, 168, 168, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2109.02248-e3e5ced3-a623-4673-a77f-c659b423ebb4", "sentences": [["We", "have", "used", "two", "different", "types", "of", "training", "in", "our", "experiments", ":", "resourceful", "and", "frugal", "."], ["For", "the", "resourceful", "training", ",", "we", "trained", "our", "models", "in", "the", "conventional", "train/test", "approach", "."], ["To", "do", "so", ",", "we", "have", "made", "3-fold", "and", "5-fold", "cross-validation", "strategies", "."], ["In", "addition", "to", "the", "resourceful", "training", "approach", "based", "on", "the", "\\", "-LRB-", "k\\", "-RRB-", "-", "fold", "cross-validation", ",", "we", "also", "evaluated", "our", "experiments", "with", "a", "frugal", "training", "approach", "based", "on", "few-shot", "learning", "."], ["Here", ",", "we", "only", "trained", "the", "model", "on", "2", "samples", "per", "class", "for", "each", "dataset", "."], ["To", "ensure", "generalizability", "of", "the", "findings", "of", "the", "experiments", ",", "we", "made", "100", "runs", "with", "different", "randomizations", "so", "that", "the", "samples", "selected", "for", "the", "training", "will", "not", "be", "redundant", "."], ["We", "also", "used", "4", "thresholds", "for", "the", "top", "biomarkers", "extraction", "which", "are", "5", ",", "10", ",", "15", "and", "20", "."], ["All", "the", "hyperparameters", "were", "selected", "using", "grid", "search", "."], ["For", "all", "models", ",", "the", "learning", "rates", "ranged", "between", "0.0001", "and", "0.001", "."], ["For", "DiffPool", ",", "the", "hidden", "dimension", ",", "the", "output", "dimension", ",", "the", "assignment", "ratio", "and", "the", "number", "of", "convolution", "layers", "were", "equal", "to", "256", ",", "512", ",", "0.1", "and", "3", ",", "respectively", "."], ["For", "GAT", ",", "the", "numbers", "of", "hidden", "units", "and", "head", "attentions", "were", "equal", "to", "8", "."], ["For", "GCN", ",", "the", "number", "of", "hidden", "units", "is", "equal", "to", "64", "."], ["For", "g-U-Nets", ",", "the", "number", "of", "layers", ",", "hidden", "and", "convolution", "layer", "dimensions", "were", "equal", "to", "3", ",", "512", "and", "48", ",", "respectively", "."], ["For", "SAGPool", ",", "the", "hidden", "dimension", "and", "the", "pooling", "ratio", "were", "equal", "to", "256", "and", "0.5", ",", "respectively", "."]], "ner": [[], [[28, 29, "a"]], [[38, 42, "a"]], [[74, 75, "a"]], [], [], [[126, 127, "a"], [139, 139, "v"], [141, 141, "v"]], [[149, 150, "a"]], [[163, 163, "v"]], [[169, 170, "p"], [166, 166, "a"], [181, 184, "p"]], [[199, 199, "a"]], [[215, 215, "a"]], [[228, 228, "a"]], [[255, 256, "p"], [266, 266, "v"], [259, 260, "p"], [252, 252, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "v"], [14, 14, "a"]], [], [[38, 38, "v"], [40, 40, "v"], [41, 41, "a"]], [[56, 56, "p"], [60, 60, "a"]], [[85, 85, "v"]], [[105, 105, "v"]], [[126, 126, "v"], [135, 135, "v"], [137, 137, "v"], [139, 139, "v"], [141, 141, "v"]], [[149, 150, "c"]], [[157, 158, "p"], [161, 161, "v"], [163, 163, "v"]], [[166, 166, "a"], [169, 170, "p"], [188, 188, "v"], [190, 190, "v"], [192, 192, "v"], [194, 194, "v"]], [[199, 199, "a"], [212, 212, "v"]], [[215, 215, "a"], [225, 225, "v"]], [[228, 228, "a"], [243, 243, "v"], [245, 245, "v"], [247, 247, "v"]], [[252, 252, "a"], [264, 264, "v"], [266, 266, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], [[255, 256, 252, 252, "USED-FOR"], [259, 260, 252, 252, "USED-FOR"]]]}
{"doc_key": "2109.02247-1c693381-1f54-450e-9a87-bac57f2ccfc5", "sentences": [["Training", "is", "performed", "by", "optimizing", "the", "binary", "cross-entropy", "loss", "function", "for", "pairwise", "edge", "classification", "."], ["We", "use", "the", "AdamW", "optimizer", "with", "a", "learning", "rate", "of", "1e-6", "for", "the", "parameters", "of", "the", "transformer", "models", "used", "in", "extracting", "node", "embeddings", "."], ["For", "the", "parameters", "of", "the", "RGCN", "encoder", "and", "edge", "classifier", ",", "we", "use", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "1e-4", "."], ["We", "train", "our", "models", "for", "10", "epochs", "with", "a", "batch", "size", "of", "8", "documents", "."], ["Test", "results", "are", "reported", "corresponding", "to", "the", "best", "validation", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "."]], "ner": [[[6, 9, "a"]], [[18, 19, "a"], [22, 23, "p"], [25, 25, "v"], [22, 23, "p"]], [[57, 58, "p"], [53, 54, "a"], [57, 58, "p"], [60, 60, "v"]], [[68, 68, "a"], [71, 72, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[18, 18, "a"], [22, 23, "p"], [25, 25, "v"]], [[44, 44, "a"], [53, 53, "a"], [57, 58, "p"], [60, 60, "v"]], [[65, 65, "a"], [67, 67, "v"], [68, 68, "p"], [71, 72, "p"], [74, 74, "v"]], []], "predicted_relations": [[], [[22, 23, 18, 19, "USED-FOR"], [25, 25, 22, 23, "USED-FOR"], [25, 25, 22, 23, "USED-FOR"], [22, 23, 18, 19, "USED-FOR"]], [[57, 58, 53, 54, "USED-FOR"], [57, 58, 53, 54, "USED-FOR"], [60, 60, 57, 58, "USED-FOR"], [60, 60, 57, 58, "USED-FOR"]], [], []]}
{"doc_key": "2109.14879-d2ffa294-5024-48c1-b22a-c30438dae542", "sentences": [["All", "models", "are", "trained", "using", "a", "mini-batch", "size", "of", "2", "using", "\\", "-LRB-", "180\\times", "180\\times", "4\\", "-RRB-", "image", "patches", "that", "are", "padded", "-LRB-", "reflect", "mode", "-RRB-", "on", "each", "side", "with", "92", "voxels", "along", "\\", "-LRB-", "x\\", "-RRB-", "and", "\\", "-LRB-", "y\\", "-RRB-", "and", "20", "along", "\\", "-LRB-", "z\\", "-RRB-", "spatial", "dimension", "to", "account", "for", "valid", "convolutions", "."], ["Optimization", "is", "done", "using", "the", "Adam", "optimizer", "with", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "learning", "rate", "."], ["The", "model", "is", "applied", "to", "the", "validation", "data", "every", "1000", "iterations", "and", "the", "best", "model", "according", "to", "the", "Jaccard", "index", "is", "used", "for", "the", "final", "evaluation", "."]], "ner": [[], [[62, 63, "a"], [73, 74, "p"]], [[94, 95, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 7, "p"], [9, 9, "v"], [15, 15, "v"], [30, 30, "v"], [43, 43, "v"]], [[62, 62, "a"], [67, 71, "v"], [73, 74, "p"]], [[85, 85, "v"]]], "predicted_relations": [[], [[73, 74, 62, 63, "USED-FOR"]], []]}
{"doc_key": "2109.14879-8089187a-03dd-4bad-901a-f7080c955bd2", "sentences": [["Stratified", "patch", "sampling", "is", "employed", "to", "speed", "up", "the", "training", "by", "ensuring", "that", "at", "least", "one", "patch", "in", "a", "mini-batch", "contains", "liver", "pixels", "."], ["We", "use", "a", "weighted", "soft", "dice", "loss", "to", "enable", "training", "with", "partially", "annotated", "patches", "-LRB-", "required", "for", "slice", "sampling", "strategies", "-RRB-", "-LSB-", "16", "-RSB-", ":", "\\", "-LRB-", "L_", "-LCB-", "DSC", "-RCB-", "=", "1", "-", "\\frac", "-LCB-", "2", "\\sum", "_", "-LCB-", "i", "-RCB-", "-LCB-", "w_i", "y_i", "p_i", "-RCB-", "-RCB-", "-LCB-", "\\sum", "_i", "w_i", "y_i", "+", "\\sum", "_i", "w_i", "p_i", "-RCB-", "\\", "-RRB-"]], "ner": [[[0, 2, "a"]], [[67, 67, "p"], [75, 75, "p"], [80, 80, "p"], [68, 68, "v"], [76, 76, "v"], [69, 69, "v"], [81, 81, "v"]]], "relations": [[], []], "predicted_ner": [[[15, 15, "v"]], [[28, 30, "a"], [51, 54, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2112.02906-98264c92-7d4c-4e31-927a-982bce63bea4", "sentences": [["The", "images", "were", "cropped", "and", "resized", "to", "\\", "-LRB-", "480\\times", "480\\", "-RRB-", "in", "the", "training", "."], ["The", "network", "was", "trained", "using", "the", "ADAM", "optimizer", "-LSB-", "43", "-RSB-", ",", "with", "the", "learning", "rate", "starting", "at", "zero", "and", "warming", "up", "to", "\\", "-LRB-", "3e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "in", "500", "steps", "before", "remaining", "at", "\\", "-LRB-", "3e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["We", "set", "the", "batch", "size", "to", "one", ",", "but", "accumulated", "the", "gradient", "over", "16", "batches", "."], ["Under", "these", "settings", ",", "the", "proposed", "model", "converges", "on", "NVIDIA", "Titan", "RTX", "in", "about", "two", "days", "."]], "ner": [[[9, 9, "v"], [10, 10, "v"], [9, 9, "v"], [10, 10, "v"]], [[22, 23, "a"], [30, 31, "p"]], [[65, 66, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "v"]], [[22, 22, "a"], [30, 31, "p"], [34, 34, "v"], [41, 45, "v"], [48, 48, "v"], [55, 59, "v"]], [[65, 66, "p"], [68, 68, "v"], [75, 75, "v"]], [[84, 84, "a"], [92, 92, "v"]]], "predicted_relations": [[], [[30, 31, 22, 23, "USED-FOR"]], [], []]}
{"doc_key": "2106.05681-c51b4a82-b8c1-4c58-81c1-a294fe4f421f", "sentences": [["\\", "-LRB-", "\\bullet", "\\", "-RRB-", "SGD", "method", "is", "adopted", "to", "optimize", "the", "model", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "be", "0.005", "in", "a", "single", "GTX", "1080Ti", "with", "batchsize", "4", "and", "is", "decreased", "by", "0.1", "at", "the", "8th", "and", "11th", "epoch", ",", "respectively", "."], ["WarmUp", "-LSB-", "9", "-RSB-", "is", "also", "employed", "in", "the", "first", "500", "iterations", "."], ["Totally", "there", "are", "12", "training", "epochs", "."]], "ner": [[[5, 6, "a"]], [[15, 17, "p"], [22, 22, "v"], [29, 29, "p"], [30, 30, "v"], [35, 35, "v"], [36, 41, "c"]], [[45, 45, "p"], [55, 56, "v"]], [[62, 63, "p"], [61, 61, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 6, "a"]], [[16, 17, "p"], [22, 22, "v"], [26, 27, "a"], [29, 29, "p"], [30, 30, "v"], [35, 35, "v"], [38, 38, "v"], [40, 40, "v"]], [[45, 45, "a"], [55, 55, "v"]], [[61, 61, "v"], [62, 63, "p"]]], "predicted_relations": [[], [[36, 41, 30, 30, "USED-FOR"], [36, 41, 35, 35, "USED-FOR"]], [], [[61, 61, 62, 63, "USED-FOR"]]]}
{"doc_key": "2106.05656-5f306634-be48-456e-9239-24f874d030df", "sentences": [["Dataset", "and", "Models", "Our", "method", "is", "validated", "on", "the", "popular", "ImageNet", "1k", "dataset", "-LSB-", "8", "-RSB-", "."], ["This", "dataset", "contains", "1.28M", "images", "in", "the", "training", "set", "and", "5K", "images", "in", "the", "validation", "set", "from", "1000", "classes", "."], ["We", "only", "use", "the", "training", "set", "during", "the", "process", "of", "self-supervised", "learning", "."], ["As", "to", "models", ",", "we", "choose", "the", "classical", "DeiT-S", "-LSB-", "24", "-RSB-", "and", "popular", "Swin-T", "-LSB-", "19", "-RSB-", "as", "representatives", "of", "all", "transformer-based", "architectures", "."], ["After", "the", "backbone", ",", "a", "3-layer", "MLP", "with", "hidden", "dimension", "2048", "is", "added", "as", "the", "projection", "head", "."], ["When", "evaluating", "our", "pretrained", "model", ",", "we", "both", "use", "the", "k-NN", "algorithm", "and", "train", "a", "linear", "classification", "for", "100", "epochs", "as", "former", "works", "."], ["Top-1", "accuracy", "is", "reported", "."]], "ner": [[[10, 12, "a"]], [], [], [[58, 58, "a"], [64, 64, "a"]], [], [[103, 104, "a"], [108, 109, "a"]], [[117, 118, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [10, 12, "a"]], [[20, 20, "v"], [27, 27, "v"], [34, 34, "v"]], [], [[58, 58, "a"], [64, 64, "a"]], [[81, 81, "a"], [83, 84, "p"], [85, 85, "v"]], [[103, 104, "a"], [111, 111, "v"], [112, 112, "p"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2106.05656-523d7197-4a4a-4923-a5b2-55a149b655d8", "sentences": [["Training", "Configurations", "Our", "model", "is", "optimized", "by", "AdamW", "-LSB-", "21", "-RSB-", "with", "learning", "rate", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "and", "batch", "size", "1024", "."], ["Weight", "decay", "is", "set", "to", "be", "0.04", "."], ["We", "adopt", "learning", "rate", "warmup", "-LSB-", "11", "-RSB-", "in", "the", "first", "10", "epochs", ",", "and", "after", "warmup", "the", "learning", "rate", "follows", "a", "cosine", "decay", "schedule", "-LSB-", "20", "-RSB-", "."], ["The", "model", "uses", "multi-crop", "similar", "to", "-LSB-", "0", "-RSB-", "and", "data", "augmentations", "similar", "to", "-LSB-", "12", "-RSB-", "."], ["The", "setting", "of", "momentum", ",", "temperature", "coefficient", ",", "and", "weight", "decay", "follows", "-LSB-", "1", "-RSB-", "."], ["The", "coefficient", "\\", "-LRB-", "\\lambda", "_1\\", "-RRB-", "of", "basic", "instance", "discrimination", "task", "is", "set", "as", "1.0", "while", "the", "restoration", "task", "\\", "-LRB-", "\\lambda", "_2\\", "-RRB-", "is", "set", "as", "0.6", "."]], "ner": [[[7, 7, "a"], [12, 13, "p"], [24, 25, "p"], [26, 26, "v"], [17, 17, "v"]], [[34, 34, "v"]], [[38, 39, "p"], [54, 55, "p"], [38, 40, "a"], [48, 48, "p"], [47, 47, "v"], [58, 60, "a"]], [[68, 68, "a"], [75, 76, "a"]], [[92, 93, "p"], [89, 89, "p"], [89, 89, "p"]], [[107, 110, "a"], [100, 100, "p"], [114, 114, "v"], [117, 118, "a"], [100, 100, "p"], [127, 127, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [7, 7, "a"], [12, 13, "p"], [17, 19, "v"], [24, 25, "p"], [26, 26, "v"]], [[28, 29, "p"], [34, 34, "v"]], [[38, 40, "a"], [47, 47, "v"], [48, 48, "p"], [54, 55, "p"]], [[68, 68, "a"]], [[86, 86, "p"], [88, 89, "p"], [92, 93, "p"]], [[103, 104, "p"], [114, 114, "v"], [121, 122, "p"], [127, 127, "v"]]], "predicted_relations": [[[12, 13, 7, 7, "USED-FOR"], [24, 25, 7, 7, "USED-FOR"], [17, 17, 12, 13, "USED-FOR"]], [], [[48, 48, 38, 40, "USED-FOR"], [47, 47, 48, 48, "USED-FOR"]], [], [], []]}
{"doc_key": "2112.07225-bfa23de6-21ae-4d98-937b-71224419f298", "sentences": [["For", "a", "fair", "comparison", ",", "our", "experiments", "are", "conducted", "under", "the", "most", "commonly", "used", "codebase", "of", "long-tailed", "studies", ":", "Open", "Long-Tailed", "Recognition", "-LRB-", "OLTR", "-RRB-", "-LSB-", "19", "-RSB-", ",", "using", "PyTorch", "-LSB-", "21", "-RSB-", "framework", "."], ["The", "model", "structures", "used", "for", "CIFAR", ",", "ImageNet-LT", ",", "Places-LT", "and", "iNaturalist18", "datasets", "are", "ResNet32", ",", "ResNeXt50", ",", "ResNet152", "and", "ResNet50", ",", "respectively", "."], ["The", "model", "for", "Places-LT", "is", "pre-trained", "on", "the", "full", "ImageNet-2012", "dataset", "while", "models", "for", "other", "datasets", "are", "trained", "from", "scratch", "."], ["For", "ImageNet-LT", ",", "Places-LT", ",", "and", "iNaturalist18", ",", "we", "train", "90", ",", "30", ",", "and", "200", "epochs", "in", "the", "first", "standard", "training", "stage", ";", "and", "10", ",", "10", ",", "and", "30", "epochs", "in", "the", "second", "margin", "calibration", "stage", ",", "with", "the", "batch", "size", "of", "256", ",", "128", ",", "and", "256", ",", "respectively", "."], ["For", "CIFAR-10-LT", "and", "CIFAR-100-LT", ",", "the", "models", "are", "trained", "for", "13,000", "iterations", "with", "a", "batch", "size", "of", "512", "."], ["We", "use", "the", "SGD", "optimizer", "with", "momentum", "0.9", "and", "weight", "decay", "\\", "-LRB-", "5e-4\\", "-RRB-", "for", "all", "datasets", "except", "for", "iNaturalist18", "where", "the", "weight", "decay", "is", "\\", "-LRB-", "1e-4\\", "-RRB-", "."], ["In", "the", "standard", "training", "stage", ",", "we", "use", "a", "cosine", "learning", "rate", "schedule", "with", "an", "initial", "value", "of", "0.05", "for", "CIFAR", "and", "0.1", "for", "other", "datasets", ",", "which", "gradually", "decays", "to", "0", "."], ["In", "the", "margin", "calibration", "stage", ",", "we", "use", "a", "cosine", "learning", "rate", "schedule", "with", "an", "initial", "learning", "rate", "starting", "from", "0.05", "to", "0", "for", "all", "datasets", "."], ["\\", "-LRB-", "\\gamma", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "1.2\\", "-RRB-", "for", "all", "datasets", "."], ["The", "hyper-parameters", "of", "compared", "methods", "follow", "their", "paper", "."], ["For", "fairness", ",", "we", "use", "the", "same", "pre-trained", "model", "for", "decision", "boundary", "adjustment", "methods", "."]], "ner": [[[30, 30, "a"]], [[50, 50, "a"], [52, 52, "a"], [54, 54, "a"], [56, 56, "a"], [47, 47, "c"], [41, 41, "c"]], [[74, 75, "c"]], [[87, 87, "c"]], [[135, 135, "c"], [137, 137, "c"]], [[156, 156, "a"], [159, 159, "p"], [160, 160, "v"], [162, 163, "p"], [176, 177, "p"], [166, 166, "v"], [181, 181, "v"], [173, 173, "c"], [160, 160, "v"]], [[193, 196, "a"], [199, 200, "p"], [202, 202, "v"], [204, 204, "c"], [206, 206, "v"], [208, 209, "c"], [202, 202, "v"], [206, 206, "v"], [215, 215, "v"], [200, 200, "p"]], [[226, 229, "a"], [237, 237, "v"], [237, 237, "v"], [239, 239, "v"]], [[254, 254, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[19, 24, "a"], [30, 30, "a"]], [[41, 41, "a"], [43, 43, "a"], [45, 45, "a"], [47, 47, "a"], [50, 50, "a"], [52, 52, "a"], [54, 54, "a"], [56, 56, "a"]], [[63, 63, "a"], [69, 70, "a"]], [[84, 84, "a"], [87, 87, "a"], [91, 91, "v"], [93, 93, "v"], [96, 96, "v"], [97, 97, "p"], [106, 106, "v"], [108, 108, "v"], [111, 111, "v"], [112, 112, "p"], [122, 123, "p"], [125, 125, "v"], [127, 127, "v"], [130, 130, "v"]], [[135, 135, "a"], [137, 137, "a"], [144, 144, "v"], [145, 145, "p"], [148, 149, "p"], [151, 151, "v"]], [[156, 156, "a"], [159, 159, "p"], [160, 160, "v"], [162, 163, "p"], [166, 166, "v"], [168, 170, "c"], [173, 173, "a"], [176, 177, "p"], [181, 181, "v"]], [[202, 202, "v"], [203, 204, "c"], [204, 204, "a"], [206, 206, "v"], [207, 209, "c"], [215, 215, "v"]], [[233, 234, "p"], [237, 237, "v"], [239, 239, "v"], [240, 242, "c"]], [[246, 246, "p"], [254, 254, "v"], [256, 258, "c"]], [], []], "predicted_relations": [[], [], [], [], [], [[159, 159, 156, 156, "USED-FOR"], [162, 163, 156, 156, "USED-FOR"], [176, 177, 156, 156, "USED-FOR"], [166, 166, 159, 159, "USED-FOR"], [166, 166, 162, 163, "USED-FOR"], [181, 181, 176, 177, "USED-FOR"]], [[199, 200, 193, 196, "USED-FOR"], [204, 204, 202, 202, "USED-FOR"], [204, 204, 206, 206, "USED-FOR"], [204, 204, 202, 202, "USED-FOR"], [204, 204, 206, 206, "USED-FOR"], [208, 209, 202, 202, "USED-FOR"], [208, 209, 206, 206, "USED-FOR"], [208, 209, 202, 202, "USED-FOR"], [208, 209, 206, 206, "USED-FOR"], [208, 209, 215, 215, "USED-FOR"], [200, 200, 193, 196, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2106.03714-5c45a716-b479-4fe0-8e0e-6aa024b69e44", "sentences": [["All", "the", "experiments", "are", "conducted", "upon", "PyTorch", "-LSB-", "35", "-RSB-", "and", "the", "timm", "-LSB-", "55", "-RSB-", "library", "."], ["The", "models", "are", "trained", "on", "ImageNet-1k", "from", "scratch", "without", "auxiliary", "dataset", "."], ["For", "the", "ablation", "experiments", ",", "we", "follow", "the", "standard", "training", "schedule", "and", "train", "our", "models", "on", "the", "ImageNet", "dataset", "for", "300", "epochs", "."], ["When", "compared", "to", "state-of-the-art", "-LRB-", "SOTA", "-RRB-", "models", ",", "we", "use", "the", "advanced", "training", "recipes", "as", "proposed", "in", "-LSB-", "47", "-RSB-", "."], ["Detailed", "training", "hyper-parameters", "are", "listed", "in", "the", "appendix", "."]], "ner": [[[6, 6, "a"], [12, 12, "a"]], [[23, 23, "a"]], [], [[56, 60, "a"], [65, 67, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [12, 12, "a"]], [[23, 23, "a"]], [[47, 48, "a"], [50, 50, "v"], [51, 51, "p"]], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1401.6497-e6b8c99f-89e2-42ef-a13d-51784e0ff2d1", "sentences": [["The", "variational", "Bayesian", "inference", "is", "guaranteed", "to", "converge", "only", "to", "a", "local", "minimum", "."], ["To", "avoid", "getting", "stuck", "in", "poor", "local", "solutions", ",", "it", "is", "important", "to", "choose", "an", "initialization", "point", "."], ["In", "our", "model", ",", "the", "top", "level", "hyperparameters", "including", "\\", "-LRB-", "\\mathbf", "-LCB-", "c", "-RCB-", "_0", ",", "\\mathbf", "-LCB-", "d", "-RCB-", "_0\\", "-RRB-", ",", "\\", "-LRB-", "a_0", ",", "b_0\\", "-RRB-", "are", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", ",", "resulting", "in", "a", "noninformative", "prior", "."], ["Thus", ",", "we", "have", "\\", "-LRB-", "\\mathbb", "-LCB-", "E", "-RCB-", "-LSB-", "\\Lambda", "-RSB-", "=\\mathbf", "-LCB-", "I", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathbb", "-LCB-", "E", "-RCB-", "-LSB-", "\\tau", "-RSB-", "=1\\", "-RRB-", "."], ["For", "the", "factor", "matrices", ",", "\\", "-LRB-", "\\lbrace", "\\mathbb", "-LCB-", "E", "-RCB-", "-LSB-", "\\mathbf", "-LCB-", "A", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "-RSB-", "\\rbrace", "_", "-LCB-", "n=1", "-RCB-", "^N\\", "-RRB-", "can", "be", "initialized", "by", "two", "different", "strategies", ",", "one", "is", "randomly", "drawn", "from", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "-LRB-", "\\mathbf", "-LCB-", "0", "-RCB-", ",", "\\mathbf", "-LCB-", "I", "-RCB-", "-RRB-", "\\", "-RRB-", "for", "\\", "-LRB-", "\\mathbf", "-LCB-", "a", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "_", "-LCB-", "i_n", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\forall", "i_n\\in", "-LSB-", "1", ",", "I_n", "-RSB-", ",", "\\forall", "n\\in", "-LSB-", "1", ",", "N", "-RSB-", "\\", "-RRB-", "."], ["The", "other", "is", "set", "to", "\\", "-LRB-", "\\mathbf", "-LCB-", "A", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "=", "\\mathbf", "-LCB-", "U", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "\\Sigma", "^", "-LCB-", "-LRB-", "n", "-RRB-", "^", "-LCB-", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "2", "-RCB-", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "\\mathbf", "-LCB-", "U", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "\\", "-RRB-", "denotes", "the", "left", "singular", "vectors", "and", "\\", "-LRB-", "\\Sigma", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "\\", "-RRB-", "denotes", "the", "diagonal", "singular", "values", "matrix", ",", "obtained", "by", "SVD", "of", "mode-\\", "-LRB-", "n\\", "-RRB-", "matricization", "of", "tensor", "\\", "-LRB-", "\\mathcal", "-LCB-", "Y", "-RCB-", "\\", "-RRB-", "."], ["The", "covariance", "matrix", "\\", "-LRB-", "\\mathbf", "-LCB-", "V", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "simply", "set", "to", "\\", "-LRB-", "\\mathbf", "-LCB-", "I", "-RCB-", "\\", "-RRB-", "."], ["The", "tensor", "rank", "\\", "-LRB-", "R\\", "-RRB-", "is", "usually", "initialized", "by", "the", "weak", "upper", "bound", "on", "its", "maximum", "rank", ",", "i.e.", ",", "\\", "-LRB-", "R\\le", "\\min", "_n", "P_n\\", "-RRB-", ",", "where", "\\", "-LRB-", "P_n=", "\\prod", "_", "-LCB-", "i\\ne", "n", "-RCB-", "I_i\\", "-RRB-", "."], ["In", "practice", ",", "we", "can", "also", "manually", "define", "the", "initialization", "value", "of", "\\", "-LRB-", "R\\", "-RRB-", "for", "computational", "efficiency", "."]], "ner": [[], [], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 3, "a"]], [], [[34, 34, "a"]], [], [[147, 147, "v"], [151, 151, "v"]], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "1401.6497-ea818d08-be5b-4aae-bb23-f8f53efc96c8", "sentences": [["-LSB-", "tb", "-RSB-", "Fully", "Bayesian", "CP", "Factorization", "-LRB-", "FBCP", "-RRB-", "Input", ":", "an", "\\", "-LRB-", "N\\", "-RRB-", "th-order", "incomplete", "tensor", "\\", "-LRB-", "\\mathcal", "-LCB-", "Y", "-RCB-", "_\\Omega", "\\", "-RRB-", "and", "an", "indicator", "tensor", "\\", "-LRB-", "\\mathcal", "-LCB-", "O", "-RCB-", "\\", "-RRB-", "."], ["Initialization", ":", "\\", "-LRB-", "\\tilde", "-LCB-", "\\mathbf", "-LCB-", "A", "-RCB-", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", ",", "\\mathbf", "-LCB-", "V", "-RCB-", "_", "-LCB-", "i_n", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", ",", "\\forall", "i_n\\in", "-LSB-", "1", ",", "I_n", "-RSB-", ",", "\\forall", "n\\in", "-LSB-", "1", ",", "N", "-RSB-", "\\", "-RRB-", ",", "\\", "-LRB-", "a_0", ",", "b_0", ",", "\\mathbf", "-LCB-", "c", "-RCB-", "_0", ",", "\\mathbf", "-LCB-", "d", "-RCB-", "_0\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\tau", "=a_0/b_0\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_r=c_0^r/d_0^r", ",", "\\forall", "r\\in", "-LSB-", "1", ",", "R", "-RSB-", "\\", "-RRB-", "."], ["\\", "-LRB-", "n=1\\", "-RRB-", "to", "\\", "-LRB-", "N\\", "-RRB-", "Update", "the", "posterior", "\\", "-LRB-", "q", "-LRB-", "\\mathbf", "-LCB-", "A", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "-RRB-", "\\", "-RRB-", "using", "-LRB-", "REF", "-RRB-", ";", "Update", "the", "posterior", "\\", "-LRB-", "q", "-LRB-", "\\lambda", "-RRB-", "\\", "-RRB-", "using", "-LRB-", "REF", "-RRB-", ";", "Update", "the", "posterior", "\\", "-LRB-", "q", "-LRB-", "\\tau", "-RRB-", "\\", "-RRB-", "using", "-LRB-", "REF", "-RRB-", ";", "Evaluate", "the", "lower", "bound", "using", "-LRB-", "REF", "-RRB-", ";", "Reduce", "rank", "\\", "-LRB-", "R\\", "-RRB-", "by", "eliminating", "zero-components", "of", "\\", "-LRB-", "\\left\\lbrace", "\\mathbf", "-LCB-", "A", "-RCB-", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "\\right\\rbrace", "\\", "-RRB-", "-LRB-", "an", "optional", "procedure", "-RRB-", ";", "convergence", "."], ["Computation", "of", "predictive", "distributions", "using", "-LRB-", "REF", "-RRB-", "."]], "ner": [[[15, 15, "p"]], [[88, 88, "p"], [129, 129, "p"]], [[141, 141, "p"], [217, 217, "v"], [213, 213, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 9, "a"]], [], [], []], "predicted_relations": [[], [], [[217, 217, 213, 213, "USED-FOR"]], []]}
{"doc_key": "1410.2535-451d5db6-f323-4bde-a652-805c514e2ee9", "sentences": [["The", "origin", "of", "the", "coordinate", "system", "is", "assumed", "to", "be", "aligned", "with", "the", "left", "camera", "position", "and", "orientation", ",", "so", "that", "only", "the", "right", "camera", "has", "to", "be", "calibrated", "in", "order", "to", "define", "the", "camera", "pair", "\\", "-LRB-", "-LRB-", "C_", "-LCB-", "\\ell", "-RCB-", ",", "C_", "-LCB-", "\\mathrm", "-LCB-", "r", "-RCB-", "-RCB-", "-RRB-", "\\", "-RRB-", "."], ["Let", "\\", "-LRB-", "\\mathbb", "-LCB-", "S", "-RCB-", "_", "-LCB-", "\\mathrm", "-LCB-", "r", "-RCB-", "-RCB-", "=", "\\mathbb", "-LCB-", "R", "-RCB-", "^d\\", "-RRB-", ",", "\\", "-LRB-", "d", ">", "0\\", "-RRB-", ",", "be", "the", "space", "in", "which", "the", "state", "of", "the", "right", "camera", "is", "described", "."], ["In", "general", ",", "the", "components", "of", "a", "given", "state", "vector", "\\", "-LRB-", "\\mathbf", "-LCB-", "s", "-RCB-", "\\", "-RRB-", "in", "\\", "-LRB-", "\\mathbb", "-LCB-", "S", "-RCB-", "_", "-LCB-", "\\mathrm", "-LCB-", "r", "-RCB-", "-RCB-", "\\", "-RRB-", "can", "be"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1412.5567-57fa7eb6-bcdd-443b-a1cc-5498b06bff94", "sentences": [["The", "core", "of", "our", "system", "is", "a", "recurrent", "neural", "network", "-LRB-", "RNN", "-RRB-", "trained", "to", "ingest", "speech", "spectrograms", "and", "generate", "English", "text", "transcriptions", "."], ["Let", "a", "single", "utterance", "\\", "-LRB-", "x\\", "-RRB-", "and", "label", "\\", "-LRB-", "y\\", "-RRB-", "be", "sampled", "from", "a", "training", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "X", "-RCB-", "=\\lbrace", "-LRB-", "x^", "-LCB-", "-LRB-", "1", "-RRB-", "-RCB-", ",", "y^", "-LCB-", "-LRB-", "1", "-RRB-", "-RCB-", "-RRB-", ",", "-LRB-", "x^", "-LCB-", "-LRB-", "2", "-RRB-", "-RCB-", ",", "y^", "-LCB-", "-LRB-", "2", "-RRB-", "-RCB-", "-RRB-", ",", "\\ldots", "\\rbrace", "\\", "-RRB-", "."], ["Each", "utterance", ",", "\\", "-LRB-", "x^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "is", "a", "time-series", "of", "length", "\\", "-LRB-", "T^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\", "-RRB-", "where", "every", "time-slice", "is", "a", "vector", "of", "audio", "features", ",", "\\", "-LRB-", "x_t^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", ",", "t=1", ",", "\\ldots", ",", "T^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "spectrograms", "as", "our", "features", ",", "so", "\\", "-LRB-", "x^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "_", "-LCB-", "t", ",", "p", "-RCB-", "\\", "-RRB-", "denotes", "the", "power", "of", "the", "\\", "-LRB-", "p\\", "-RRB-", "'th", "frequency", "bin", "in", "the", "audio", "frame", "at", "time", "\\", "-LRB-", "t\\", "-RRB-", "."], ["The", "goal", "of", "our", "RNN", "is", "to", "convert", "an", "input", "sequence", "\\", "-LRB-", "x\\", "-RRB-", "into", "a", "sequence", "of", "character", "probabilities", "for", "the", "transcription", "\\", "-LRB-", "y\\", "-RRB-", ",", "with", "\\", "-LRB-", "\\hat", "-LCB-", "y_t", "-RCB-", "=", "\\mathbb", "-LCB-", "P", "-RCB-", "-LRB-", "c_t|x", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "c_t", "\\in", "\\lbrace", "\\textrm", "-LCB-", "a", ",", "b", ",", "c", ",", "-RCB-", "\\ldots", ",", "\\textrm", "-LCB-", "z", "-RCB-", ",", "\\textit", "-LCB-", "space", "-RCB-", ",", "\\textit", "-LCB-", "apostrophe", "-RCB-", ",", "\\textit", "-LCB-", "blank", "-RCB-", "\\rbrace", "\\", "-RRB-", "."]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [7, 12, "a"]], [], [], [], [[200, 200, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1412.5567-9e6839de-3cc2-435b-9782-ee549c804382", "sentences": [["Our", "RNN", "model", "is", "composed", "of", "5", "layers", "of", "hidden", "units", "."], ["For", "an", "input", "\\", "-LRB-", "x\\", "-RRB-", ",", "the", "hidden", "units", "at", "layer", "\\", "-LRB-", "l\\", "-RRB-", "are", "denoted", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\", "-RRB-", "with", "the", "convention", "that", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "0", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "the", "input", "."], ["The", "first", "three", "layers", "are", "not", "recurrent", "."], ["For", "the", "first", "layer", ",", "at", "each", "time", "\\", "-LRB-", "t\\", "-RRB-", ",", "the", "output", "depends", "on", "the", "spectrogram", "frame", "\\", "-LRB-", "x_t\\", "-RRB-", "along", "with", "a", "context", "of", "\\", "-LRB-", "C\\", "-RRB-", "frames", "on", "each", "side.We", "typically", "use", "\\", "-LRB-", "C\\in", "\\lbrace", "5", ",", "7", ",", "9\\rbrace", "\\", "-RRB-", "for", "our", "experiments", "."], ["The", "remaining", "non-recurrent", "layers", "operate", "on", "independent", "data", "for", "each", "time", "step", "."], ["Thus", ",", "for", "each", "time", "\\", "-LRB-", "t\\", "-RRB-", ",", "the", "first", "3", "layers", "are", "computed", "by", ":", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "_t", "&", "=", "g", "-LRB-", "W^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "h^", "-LCB-", "-LRB-", "l-1", "-RRB-", "-RCB-", "_t", "+", "b^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "-RRB-", "\\", "-RRB-"]], "ner": [[[1, 2, "a"], [6, 6, "v"], [6, 6, "v"]], [], [], [[110, 110, "v"], [94, 94, "p"], [110, 110, "v"], [112, 112, "v"], [114, 114, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [6, 6, "v"]], [], [[61, 61, "v"]], [], [], [[146, 146, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1412.5567-6abd5ce9-6d70-4ded-a95f-f0cb2ddedfa5", "sentences": [["where", "\\", "-LRB-", "g", "-LRB-", "z", "-RRB-", "=", "\\min", "\\lbrace", "\\max", "\\lbrace", "0", ",", "z\\rbrace", ",", "20\\rbrace", "\\", "-RRB-", "is", "the", "clipped", "rectified-linear", "-LRB-", "ReLu", "-RRB-", "activation", "function", "and", "\\", "-LRB-", "W^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", ",", "b^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\", "-RRB-", "are", "the", "weight", "matrix", "and", "bias", "parameters", "for", "layer", "\\", "-LRB-", "l\\", "-RRB-", ".The", "ReLu", "units", "are", "clipped", "in", "order", "to", "keep", "the", "activations", "in", "the", "recurrent", "layer", "from", "exploding", ";", "in", "practice", "the", "units", "rarely", "saturate", "at", "the", "upper", "bound", "."], ["The", "fourth", "layer", "is", "a", "bi-directional", "recurrent", "layer", "-LSB-", "37", "-RSB-", "."], ["This", "layer", "includes", "two", "sets", "of", "hidden", "units", ":", "a", "set", "with", "forward", "recurrence", ",", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "f", "-RRB-", "-RCB-", "\\", "-RRB-", ",", "and", "a", "set", "with", "backward", "recurrence", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "b", "-RRB-", "-RCB-", "\\", "-RRB-", ":", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "f", "-RRB-", "-RCB-", "_t", "&", "=", "g", "-LRB-", "W^", "-LCB-", "-LRB-", "4", "-RRB-", "-RCB-", "h^", "-LCB-", "-LRB-", "3", "-RRB-", "-RCB-", "_t", "+", "W_r^", "-LCB-", "-LRB-", "f", "-RRB-", "-RCB-", "h^", "-LCB-", "-LRB-", "f", "-RRB-", "-RCB-", "_", "-LCB-", "t-1", "-RCB-", "+", "b^", "-LCB-", "-LRB-", "4", "-RRB-", "-RCB-", "-RRB-", "\\\\h^", "-LCB-", "-LRB-", "b", "-RRB-", "-RCB-", "_t", "&", "=", "g", "-LRB-", "W^", "-LCB-", "-LRB-", "4", "-RRB-", "-RCB-", "h^", "-LCB-", "-LRB-", "3", "-RRB-", "-RCB-", "_t", "+", "W_r^", "-LCB-", "-LRB-", "b", "-RRB-", "-RCB-", "h^", "-LCB-", "-LRB-", "b", "-RRB-", "-RCB-", "_", "-LCB-", "t+1", "-RCB-", "+", "b^", "-LCB-", "-LRB-", "4", "-RRB-", "-RCB-", "-RRB-", "\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[60, 60, "a"]], [], [[103, 103, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1412.5567-52c11d3d-7d2b-45b9-b405-0fe1080174c5", "sentences": [["Note", "that", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "f", "-RRB-", "-RCB-", "\\", "-RRB-", "must", "be", "computed", "sequentially", "from", "\\", "-LRB-", "t=1\\", "-RRB-", "to", "\\", "-LRB-", "t=T^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\", "-RRB-", "for", "the", "\\", "-LRB-", "i\\", "-RRB-", "'th", "utterance", ",", "while", "the", "units", "\\", "-LRB-", "h^", "-LCB-", "-LRB-", "b", "-RRB-", "-RCB-", "\\", "-RRB-", "must", "be", "computed", "sequentially", "in", "reverse", "from", "\\", "-LRB-", "t=T^", "-LCB-", "-LRB-", "i", "-RRB-", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "t=1\\", "-RRB-", "."]], "ner": [[]], "relations": [[]], "predicted_ner": [[]], "predicted_relations": [[]]}
{"doc_key": "1810.00378-bb91da66-6f85-43b1-8eb0-70ab71efe006", "sentences": [["In", "each", "experiment", "we", "train", "the", "GAN", "for", "200,000", "epochs", "over", "mini-batches", "of", "2,048", "samples", ",", "with", "the", "generator", "performing", "one", "gradient", "update", "per", "mini-batch", "and", "the", "adversary", "performing", "three", "."], ["We", "set", "the", "learning", "rate", "of", "the", "networks", "to", "0.02", "."], ["The", "generator", "outputs", "floating-point", "numbers", "constrained", "to", "the", "range", "\\", "-LRB-", "-LSB-", "0", ",", "2^", "-LCB-", "16", "-RCB-", "-1", "-RSB-", "\\", "-RRB-", ",", "which", "are", "rounded", "to", "the", "nearest", "16-bit", "integer", "for", "evaluation", "."], ["The", "evaluation", "dataset", "consists", "of", "400", "mini-batches", "of", "2,048", "input", "vectors", "each", ",", "for", "a", "total", "of", "819,200", "input", "samples", "."], ["The", "generator", "outputs", "8", "floating-point", "numbers", "for", "each", "input", ",", "each", "yielding", "16", "bits", "for", "the", "full", "output", "sequence", "."], ["In", "total", ",", "each", "evaluation", "output", "thus", "consists", "of", "104,857,600", "bits", ",", "produced", "from", "a", "single", "random", "seed", "."], ["Larger", "outputs", "were", "not", "produced", "due", "to", "disk", "quotas", "on", "the", "cluster", "used", "to", "run", "the", "models", "."]], "ner": [[[6, 6, "a"]], [[34, 35, "p"], [40, 40, "v"]], [], [[77, 78, "a"]], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "v"], [9, 9, "p"], [13, 13, "v"], [20, 20, "v"], [21, 22, "p"], [29, 29, "v"]], [[34, 35, "p"], [40, 40, "v"]], [[71, 71, "v"]], [[81, 81, "v"], [84, 84, "v"], [93, 93, "v"]], [[100, 100, "v"], [109, 109, "v"]], [[126, 126, "v"], [132, 132, "v"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1804.00079-e2fe6058-2f42-44ee-8cfa-4922a3057124", "sentences": [["A", "set", "of", "\\", "-LRB-", "k\\", "-RRB-", "tasks", "with", "a", "common", "source", "language", ",", "a", "shared", "encoder", "\\", "-LRB-", "\\mathbf", "-LCB-", "E", "-RCB-", "\\", "-RRB-", "across", "all", "tasks", "and", "a", "set", "of", "\\", "-LRB-", "k\\", "-RRB-", "task", "specific", "decoders", "\\", "-LRB-", "\\mathbf", "-LCB-", "D_1", "-RCB-", "\\ldots", "\\mathbf", "-LCB-", "D_k", "-RCB-", "\\", "-RRB-", "."], ["Let", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "denote", "each", "model", "'s", "parameters", ",", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "a", "probability", "vector", "-LRB-", "\\", "-LRB-", "p_1", "\\ldots", "p_k\\", "-RRB-", "-RRB-", "denoting", "the", "probability", "of", "sampling", "a", "task", "such", "that", "\\", "-LRB-", "\\Sigma", "_", "-LCB-", "i", "-RCB-", "^", "-LCB-", "k", "-RCB-", "p_i", "=", "1\\", "-RRB-", ",", "datasets", "for", "each", "task", "\\", "-LRB-", "\\rm", "I\\", "!", "P_1", "\\ldots", "\\rm", "I\\", "!", "P_k\\", "-RRB-", "and", "a", "loss", "function", "\\", "-LRB-", "L\\", "-RRB-", "."]], "ner": [[[15, 16, "a"], [36, 38, "a"]], [[63, 63, "p"], [63, 63, "p"], [71, 72, "a"], [76, 76, "v"], [78, 78, "v"], [106, 106, "a"], [124, 125, "a"]]], "relations": [[], []], "predicted_ner": [[[5, 5, "p"], [34, 34, "p"]], [[67, 67, "p"]]], "predicted_relations": [[], [[78, 78, 63, 63, "USED-FOR"], [78, 78, 63, 63, "USED-FOR"]]]}
{"doc_key": "1803.11284-57ffab05-63f6-4e94-a0fc-4a8f41161a09", "sentences": [["We", "obtained", "product", "titles", "from", "online", "catalogs", "containing", "a", "variety", "of", "products", "."], ["Our", "experiments", "pertaining", "to", "this", "paper", "concentrate", "around", "the", "attribute", "`", "Brand", "'", "."], ["For", "`", "Brand", "'", ",", "we", "collect", "\\", "-LRB-", "61,374\\", "-RRB-", "product", "titles", "for", "the", "experiment", "."], ["Training", ",", "validation", ",", "and", "test", "data", "are", "generated", "with", "a", "60/20/20", "split", "ratio", "respectively", "."], ["Titles", "are", "further", "tokenized", "by", "whitespace", "and", "labeled", "according", "to", "the", "annotation", "scheme", "described", "in", "Section", "1", "."], ["For", "accurate", "labels", "to", "train", "and", "validate", "our", "model", ",", "we", "acquire", "`", "Brand", "'", "attributes", "for", "the", "set", "of", "product", "titles", "through", "crowdsourcing", "tasks", "."]], "ner": [[], [[24, 24, "a"]], [[29, 29, "a"]], [[44, 50, "a"], [56, 57, "p"], [55, 55, "v"]], [], [[91, 91, "a"], [101, 102, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[36, 36, "v"]], [], [], [[86, 86, "a"]]], "predicted_relations": [[], [], [], [[56, 57, 44, 50, "USED-FOR"], [55, 55, 56, 57, "USED-FOR"]], [], []]}
{"doc_key": "1809.02838-3d0d352f-056d-4b5b-be98-e4a75d688cef", "sentences": [["We", "train", "two", "separate", "Graph", "Convolutional", "Networks", "-LRB-", "GCN", "-RRB-", "-LSB-", "11", "-RSB-", "for", "\\", "-LRB-", "\\mu", "_i\\", "-RRB-", "and", "\\", "-LRB-", "\\mathbf", "-LCB-", "L", "-RCB-", "_i\\", "-RRB-", ",", "as", "the", "inference", "network", "\\", "-LRB-", "\\mathcal", "-LCB-", "M", "-RCB-", "\\", "-RRB-", "."], ["A", "GCN", "computes", "hidden", "layers", "with", "the", "adjacency", "matrix", "of", "a", "graph", "and", "takes", "input", "from", "graph", "node", "values", "."], ["Here", "we", "treat", "data", "points", "\\", "-LRB-", "-LCB-", "i", "-RCB-", "\\cup", "\\alpha", "-LRB-", "i", "-RRB-", "\\", "-RRB-", "as", "a", "small", "graph", "with", "\\", "-LRB-", "-LCB-", "\\Sigma", "-RCB-", "_", "-LCB-", "-LRB-", "i", ",", "\\alpha", "-LRB-", "i", "-RRB-", "-RRB-", ",", "-LRB-", "i", ",", "\\alpha", "-LRB-", "i", "-RRB-", "-RRB-", "-RCB-", "\\", "-RRB-", "as", "the", "adjacency", "matrix", "and", "\\", "-LRB-", "\\mathbf", "-LCB-", "y", "-RCB-", "_", "-LCB-", "-LRB-", "i", ",", "\\alpha", "-LRB-", "i", "-RRB-", "-RRB-", "-RCB-", "\\", "-RRB-", "as", "values", "at", "graph", "nodes", "."], ["In", "this", "graph", ",", "\\", "-LRB-", "i\\", "-RRB-", "is", "unique", "because", "we", "are", "computing", "parameters", "for", "\\", "-LRB-", "i\\", "-RRB-", "."], ["To", "break", "the", "symmetry", "relation", "between", "\\", "-LRB-", "i\\", "-RRB-", "and", "any", "other", "data", "point", "in", "\\", "-LRB-", "\\alpha", "-LRB-", "i", "-RRB-", "\\", "-RRB-", ",", "we", "set", "\\", "-LRB-", "\\mathbf", "-LCB-", "A", "-RCB-", "=", "-LSB-", "-LCB-", "\\Sigma", "-RCB-", "_", "-LCB-", "i", ",", "i", "-RCB-", ",", "0", ";", "-LCB-", "\\Sigma", "-RCB-", "_", "-LCB-", "\\alpha", "-LRB-", "i", "-RRB-", ",", "i", "-RCB-", ",", "-LCB-", "\\Sigma", "-RCB-", "_", "-LCB-", "\\alpha", "-LRB-", "i", "-RRB-", ",", "\\alpha", "-LRB-", "i", "-RRB-", "-RCB-", "-RSB-", "\\", "-RRB-", "as", "the", "adjacency", "matrix", "for", "the", "GCN", "."], ["The", "input", "to", "the", "GCN", "is", "\\", "-LRB-", "\\mathbf", "-LCB-", "y", "-RCB-", "_", "-LCB-", "-LRB-", "i", ",", "\\alpha", "-LRB-", "i", "-RRB-", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["In", "the", "GCN", ",", "the", "hidden", "layer", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "^", "-LCB-", "-LRB-", "l+1", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "computed", "from", "a", "previous", "layer", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\", "-RRB-", "as", "follows", ",", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "^", "-LCB-", "-LRB-", "l+1", "-RRB-", "-RCB-", "=", "\\sigma", "-LRB-", "\\mathbf", "-LCB-", "D", "-RCB-", "^", "-LCB-", "-\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "2", "-RCB-", "-RCB-", "\\mathbf", "-LCB-", "A", "-RCB-", "\\mathbf", "-LCB-", "D", "-RCB-", "^", "-LCB-", "-\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "2", "-RCB-", "-RCB-", "\\mathbf", "-LCB-", "H", "-RCB-", "^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "\\mathbf", "-LCB-", "W", "-RCB-", "^", "-LCB-", "-LRB-", "l", "-RRB-", "-RCB-", "-RRB-", ".\\", "-RRB-"]], "ner": [[], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [4, 9, "a"]], [[43, 43, "a"]], [], [], [[207, 207, "v"], [246, 246, "a"]], [[252, 252, "a"]], [[276, 276, "a"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1804.06512-848ae61c-73cf-4338-8b35-26c8401de4bf", "sentences": [["The", "size", "of", "the", "dialogue-level", "and", "utterance-level", "LSTM", "state", "is", "set", "as", "200", "and", "150", "respectively", "."], ["Word", "embedding", "size", "is", "300", "."], ["Embedding", "size", "for", "system", "action", "and", "slot", "values", "is", "set", "as", "32", "."], ["Hidden", "layer", "size", "of", "the", "policy", "network", "is", "set", "as", "100", "."], ["We", "use", "Adam", "optimization", "method", "-LSB-", "12", "-RSB-", "with", "initial", "learning", "rate", "of", "1e-3", "."], ["Dropout", "rate", "of", "0.5", "is", "applied", "during", "supervised", "training", "to", "prevent", "the", "model", "from", "over-fitting", "."]], "ner": [[], [], [], [], [[50, 52, "a"], [57, 59, "p"], [61, 61, "v"]], [[63, 64, "a"], [63, 64, "p"], [66, 66, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [12, 12, "v"], [14, 14, "v"]], [[21, 21, "v"]], [[34, 34, "v"]], [[41, 42, "a"], [46, 46, "v"]], [[50, 52, "a"], [58, 59, "p"], [61, 61, "v"]], [[63, 64, "p"], [66, 66, "v"]]], "predicted_relations": [[], [], [], [], [[61, 61, 57, 59, "USED-FOR"]], [[63, 64, 63, 64, "USED-FOR"], [66, 66, 63, 64, "USED-FOR"]]]}
{"doc_key": "1804.06512-bfb4b878-e88f-46f9-a270-0bcd2e49ef4f", "sentences": [["In", "imitation", "learning", ",", "we", "perform", "mini-batch", "model", "update", "after", "collecting", "every", "25", "dialogues", "."], ["System", "actions", "are", "sampled", "from", "the", "learned", "policy", "to", "encourage", "exploration", "."], ["The", "system", "action", "is", "defined", "with", "the", "act", "and", "slot", "types", "from", "a", "dialogue", "act", "-LSB-", "7", "-RSB-", "."], ["For", "example", ",", "the", "dialogue", "act", "\u201c", "\\", "-LRB-", "confirm", "-LRB-", "date=monday", "-RRB-", "\\", "-RRB-", "\u201d", "is", "mapped", "to", "a", "system", "action", "\u201c", "\\", "-LRB-", "confirm\\_date\\", "-RRB-", "\u201d", "and", "a", "candidate", "value", "\u201c", "\\", "-LRB-", "monday\\", "-RRB-", "\u201d", "for", "slot", "type", "\u201c", "\\", "-LRB-", "date\\", "-RRB-", "\u201d", "."], ["The", "slot", "types", "and", "values", "are", "from", "the", "dialogue", "state", "tracking", "output", "."]], "ner": [[[6, 8, "a"]], [], [[40, 41, "a"]], [[50, 51, "a"]], [[95, 98, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [6, 8, "a"], [12, 12, "v"]], [], [], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1804.06512-6cb902df-cb72-4ead-8f6d-c8dce7b7415a", "sentences": [["In", "RL", "optimization", ",", "we", "update", "the", "model", "with", "every", "mini-batch", "of", "25", "samples", "."], ["Dialogue", "is", "considered", "successful", "based", "on", "two", "conditions", ":", "-LRB-", "1", "-RRB-", "the", "goal", "slot", "values", "estimated", "from", "dialogue", "state", "tracking", "fully", "match", "to", "the", "user", "'s", "true", "goal", "values", ",", "and", "-LRB-", "2", "-RRB-", "the", "system", "is", "able", "to", "confirm", "with", "the", "user", "the", "tracked", "goal", "values", "and", "offer", "an", "entity", "which", "is", "finally", "accepted", "by", "the", "user", "."], ["Maximum", "allowed", "number", "of", "dialogue", "turn", "is", "set", "as", "15", "."], ["A", "positive", "reward", "of", "+15.0", "is", "given", "at", "the", "end", "of", "a", "successful", "dialogue", ",", "and", "a", "zero", "reward", "is", "given", "to", "a", "failed", "case", "."], ["We", "apply", "a", "step", "penalty", "of", "-1.0", "for", "each", "turn", "to", "encourage", "shorter", "dialogue", "for", "task", "completion", "."]], "ner": [[[1, 2, "a"], [12, 12, "v"]], [], [[84, 84, "v"]], [[90, 90, "v"], [87, 88, "p"], [90, 90, "v"]], [[115, 116, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 12, "v"]], [[21, 21, "v"]], [[84, 84, "v"]], [[90, 90, "v"], [103, 103, "v"]], [[118, 118, "v"]]], "predicted_relations": [[], [], [], [[90, 90, 87, 88, "USED-FOR"], [90, 90, 87, 88, "USED-FOR"]], []]}
{"doc_key": "1804.06679-d444b0f0-a72a-4510-91bf-08155538620b", "sentences": [["MNIST", ":", "The", "data", "samples", "are", "784-dimensional", "vectors", ",", "each", "entry", "assuming", "a", "grayscale", "value", "of", "a", "\\", "-LRB-", "28\\times", "28\\", "-RRB-", "image", "representing", "a", "handwritten", "digit", "."], ["This", "dataset", "is", "divided", "into", "60000", "training", "samples", "and", "10000", "test", "samples", "."], ["We", "further", "performed", "a", "\\", "-LRB-", "80\\", "%", "-20\\", "%", "\\", "-RRB-", "split", "off", "the", "training", "samples", "as", "a", "labeled", "training", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "_t\\", "-RRB-", "and", "a", "labeled", "validation", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[0, 0, "a"]], [], [[53, 53, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "v"], [20, 20, "v"]], [[33, 33, "v"], [37, 37, "v"]], [[47, 48, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1804.06679-4d1a1e54-6a87-473c-a476-bf1a785fc2c1", "sentences": [["CIFAR-10", ":", "The", "dataset", "samples", "are", "3072-dimensional", "vectors", ",", "each", "entry", "assuming", "a", "\\", "-LRB-", "32\\times", "32", "\\times", "3\\", "-RRB-", "colored", "image", "of", "one", "of", "the", "ten", "items", "in", "the", "dataset", "."], ["This", "dataset", "is", "divided", "into", "50000", "training", "samples", "and", "10000", "test", "samples", "."], ["We", "further", "performed", "a", "\\", "-LRB-", "80\\", "%", "-20\\", "%", "\\", "-RRB-", "split", "off", "the", "training", "samples", "as", "a", "labeled", "training", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "_t\\", "-RRB-", "and", "a", "labeled", "validation", "set", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[0, 0, "a"]], [], [[57, 57, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"], [6, 6, "v"], [16, 16, "v"], [18, 18, "v"], [23, 23, "v"], [26, 26, "v"]], [[37, 37, "v"], [41, 41, "v"]], [[51, 52, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1804.06202-e3db62f9-e333-42cf-abe8-6dd481c68f73", "sentences": [["Training", "settings", "."], ["For", "CIFAR", ",", "we", "adopt", "the", "same", "training", "settings", "as", "-LSB-", "45", "-RSB-", "."], ["We", "use", "SGD", "with", "Nesterov", "momentum", "to", "update", "network", ",", "starting", "from", "learning", "rate", "0.1", "and", "multiplying", "with", "a", "factor", "0.1", "at", "200", "epochs", ",", "300", "epochs", "and", "350", "epochs", "."], ["Weight", "decay", "is", "set", "as", "0.0001", "and", "momentum", "as", "0.9", "."], ["We", "train", "the", "network", "with", "batch", "size", "as", "64", "for", "400", "epochs", "and", "report", "the", "accuracy", "at", "the", "final", "iteration", "."], ["The", "implementation", "is", "based", "on", "Caffe", "-LSB-", "15", "-RSB-", "."], ["For", "Tiny", "ImageNet", ",", "we", "use", "the", "similar", "training", "settings", "as", "CIFAR", ",", "except", "that", "we", "train", "for", "totally", "200", "epochs", "and", "multiply", "the", "learning", "rate", "with", "a", "factor", "0.1", "at", "100", "epochs", ",", "150", "epochs", "and", "175", "epochs", "."], ["To", "adapt", "Tiny", "ImageNet", "to", "the", "networks", "designed", "for", "CIFAR", ",", "we", "set", "the", "stride", "of", "the", "first", "convolution", "layer", "as", "2", ",", "which", "is", "adopted", "in", "-LSB-", "9", "-RSB-", "as", "well", "."]], "ner": [[], [], [[19, 19, "a"], [29, 30, "p"], [31, 31, "v"], [37, 37, "v"], [22, 22, "p"], [21, 22, "a"]], [[55, 55, "p"], [57, 57, "v"], [53, 53, "v"]], [], [[85, 85, "a"]], [[114, 115, "p"], [119, 119, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[4, 4, "a"]], [[19, 19, "a"], [21, 22, "a"], [29, 30, "p"], [31, 31, "v"], [37, 37, "v"], [39, 39, "v"], [40, 40, "p"], [42, 42, "v"], [43, 43, "p"], [45, 45, "v"], [46, 46, "p"]], [[48, 49, "p"], [53, 53, "v"], [55, 55, "p"], [57, 57, "v"]], [[64, 65, "p"], [67, 67, "v"], [69, 69, "v"], [70, 70, "p"]], [[85, 85, "a"]], [[91, 92, "a"], [101, 101, "a"], [109, 109, "v"], [110, 110, "p"], [114, 115, "p"], [119, 119, "v"], [121, 121, "v"], [122, 122, "p"], [124, 124, "v"], [125, 125, "p"], [127, 127, "v"], [128, 128, "p"]], [[132, 133, "a"], [139, 139, "a"], [151, 151, "v"]]], "predicted_relations": [[], [], [[29, 30, 19, 19, "USED-FOR"], [29, 30, 21, 22, "USED-FOR"], [22, 22, 19, 19, "USED-FOR"], [22, 22, 21, 22, "USED-FOR"]], [[53, 53, 55, 55, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1804.05805-7b8ec793-ffa6-44f5-8468-9f93f54bc203", "sentences": [["Hardware", ":", "Notebook", "PC", "with", "I7-7700HQ", ",", "16GB", "RAM", ",", "GTX", "1050", "GPU", "Software", ":", "Matlab", "2018a", ",", "Neural", "Network", "Toolbox", ",", "Image", "Processing", "Toolbox", ",", "Parallel", "Computing", "Toolbox", "Parameter", "Optimization", "Settings", ":", "SGDM", ",", "Max", "Epochs", "=", "20", ",", "Mini-Batch", "Size", "=", "128", "Training", "Dataset", ":", "MNIST", "training", "dataset", "with", "50,000", "images", "Training", "Accuracy", ":", "99.5", "%", "Testing", "Dataset", ":", "MNIST", "testing", "dataset", "with", "10,000", "images", "Testing", "Accuracy", ":", "98.73", "%"]], "ner": [[[33, 33, "a"], [35, 36, "p"], [38, 38, "v"], [40, 41, "p"], [43, 43, "v"], [47, 49, "a"], [61, 63, "a"]]], "relations": [[]], "predicted_ner": [[[7, 7, "v"], [33, 33, "a"], [35, 36, "p"], [38, 38, "v"], [40, 41, "p"], [43, 43, "v"], [51, 51, "v"], [56, 57, "v"], [65, 65, "v"], [70, 71, "v"]]], "predicted_relations": [[[35, 36, 33, 33, "USED-FOR"], [35, 36, 47, 49, "USED-FOR"], [38, 38, 35, 36, "USED-FOR"], [40, 41, 33, 33, "USED-FOR"], [40, 41, 47, 49, "USED-FOR"]]]}
{"doc_key": "1804.05805-7c957790-abd4-433e-a0e7-3578c0fcf11b", "sentences": [["Hardware", ":", "Notebook", "PC", "with", "I7-7700HQ", ",", "16GB", "RAM", ",", "GTX", "1050", "GPU", "Software", ":", "Matlab", "2018a", ",", "Neural", "Network", "Toolbox", ",", "Image", "Processing", "Toolbox", ",", "Parallel", "Computing", "Toolbox", "Parameter", "Optimization", "Settings", ":", "SGDM", ",", "Max", "Epochs", "=", "30", ",", "Mini-Batch", "Size", "=", "128", "Training", "Dataset", ":", "MNIST", "training", "dataset", "with", "50,000", "images", "Training", "Accuracy", ":", "100", "%", "Testing", "Dataset", ":", "MNIST", "testing", "dataset", "with", "10,000", "images", "Testing", "Accuracy", ":", "99.16", "%"]], "ner": [[[33, 33, "a"], [35, 36, "p"], [38, 38, "v"], [40, 41, "p"], [43, 43, "v"], [47, 49, "a"], [61, 63, "a"]]], "relations": [[]], "predicted_ner": [[[7, 7, "v"], [33, 33, "a"], [35, 36, "p"], [38, 38, "v"], [40, 41, "p"], [43, 43, "v"], [51, 51, "v"], [56, 57, "v"], [65, 65, "v"], [70, 71, "v"]]], "predicted_relations": [[[35, 36, 33, 33, "USED-FOR"], [35, 36, 47, 49, "USED-FOR"], [38, 38, 35, 36, "USED-FOR"], [40, 41, 33, 33, "USED-FOR"], [40, 41, 47, 49, "USED-FOR"]]]}
{"doc_key": "1804.05805-e1074755-ea46-4dd1-80d9-3a6fe499014c", "sentences": [["Parameter", "Optimization", "Option", ":", "Batch", "Size", "=", "128", ",", "Epochs", "=", "50", ",", "Loss", "Function", "=", "tf.nn.softmax_cross_entropy_with_logits", ",", "Optimizer", "=", "SGD", "-LRB-", "lr=0.01", ",", "decay=1e-6", ",", "momentum=0.9", ",", "nesterov=True", "-RRB-", "Training", "Accuracy", ":", "MNIST", "-LRB-", "99.99", "%", "on", "60,000", "images", "-RRB-", "CIFAR-10", "-LRB-", "99.83", "%", "on", "50,000", "images", "-RRB-", "Testing", "Accuracy", ":", "MNIST", "-LRB-", "99.36", "%", "on", "10,000", "images", "-RRB-", "CIFAR-10", "-LRB-", "78.30", "%", "on", "10,000", "images", "-RRB-"]], "ner": [[[4, 5, "a"], [9, 9, "a"], [13, 14, "a"], [16, 16, "p"], [18, 18, "a"], [22, 22, "p"], [22, 22, "v"], [24, 24, "p"], [24, 24, "v"], [26, 26, "p"], [26, 26, "v"], [28, 28, "p"], [28, 28, "v"], [33, 33, "a"], [52, 52, "a"], [41, 41, "a"], [60, 60, "a"]]], "relations": [[]], "predicted_ner": [[[4, 5, "p"], [7, 7, "v"], [9, 9, "p"], [11, 11, "v"], [13, 14, "p"], [20, 20, "a"], [33, 33, "a"], [35, 36, "v"], [38, 38, "v"], [41, 41, "a"], [43, 44, "v"], [46, 46, "v"], [52, 52, "a"], [54, 55, "v"], [57, 57, "v"], [60, 60, "a"], [62, 63, "v"], [65, 65, "v"]]], "predicted_relations": [[[22, 22, 9, 9, "USED-FOR"], [22, 22, 13, 14, "USED-FOR"], [22, 22, 22, 22, "USED-FOR"], [22, 22, 24, 24, "USED-FOR"], [22, 22, 26, 26, "USED-FOR"], [22, 22, 28, 28, "USED-FOR"], [24, 24, 4, 5, "USED-FOR"], [24, 24, 9, 9, "USED-FOR"], [24, 24, 13, 14, "USED-FOR"], [24, 24, 18, 18, "USED-FOR"], [24, 24, 22, 22, "USED-FOR"], [24, 24, 24, 24, "USED-FOR"], [24, 24, 26, 26, "USED-FOR"], [24, 24, 28, 28, "USED-FOR"], [26, 26, 9, 9, "USED-FOR"], [26, 26, 13, 14, "USED-FOR"], [26, 26, 26, 26, "USED-FOR"], [26, 26, 22, 22, "USED-FOR"], [26, 26, 24, 24, "USED-FOR"], [26, 26, 26, 26, "USED-FOR"], [26, 26, 28, 28, "USED-FOR"], [28, 28, 4, 5, "USED-FOR"], [28, 28, 9, 9, "USED-FOR"], [28, 28, 13, 14, "USED-FOR"], [28, 28, 18, 18, "USED-FOR"], [28, 28, 28, 28, "USED-FOR"], [28, 28, 33, 33, "USED-FOR"], [28, 28, 16, 16, "USED-FOR"], [28, 28, 22, 22, "USED-FOR"], [28, 28, 24, 24, "USED-FOR"], [28, 28, 26, 26, "USED-FOR"], [28, 28, 28, 28, "USED-FOR"]]]}
{"doc_key": "1806.02070-038eb900-0a43-45e8-b70a-c310182e0a12", "sentences": [["We", "set", "the", "network", "parameters", "as", "follows", ":", "The", "weights", "of", "each", "convolution", "layer", "of", "the", "stacked", "hourglass", "network", "are", "initialized", "with", "the", "method", "as", "described", "in", ",", "the", "biases", "with", "0", "."], ["The", "networks", "do", "not", "employ", "any", "normalization", "layers", "or", "dropout", ",", "but", "use", "an", "L2", "weight", "regularization", "factor", "of", "0.00001", "."], ["Due", "to", "the", "demanding", "training", "of", "recurrent", "neural", "networks", ",", "in", "terms", "of", "both", "memory", "and", "computational", "requirements", ",", "we", "set", "the", "mini-batch", "size", "to", "1", "."], ["We", "train", "the", "recurrent", "networks", "for", "sequences", "of", "10", "consecutive", "frames", "."], ["For", "the", "non-recurrent", "neural", "networks", ",", "we", "use", "a", "mini-batch", "size", "of", "10", "."], ["We", "train", "all", "networks", "with", "ADAM", "for", "total", "40000", "iterations", "and", "a", "learning", "rate", "of", "0.0001", ",", "while", "the", "learning", "rate", "is", "reduced", "to", "0.00001", "after", "20000", "iterations", "."], ["Training", "of", "a", "recurrent", "networks", "took", "\\", "-LRB-", "\\approx", "12\\", "-RRB-", "hours", ",", "training", "of", "the", "non-recurrent", "networks", "took", "\\", "-LRB-", "\\approx", "8\\", "-RRB-", "hours", "on", "a", "single", "NVIDIA", "Titan", "Xp", "with", "12", "GB", "."]], "ner": [[[16, 18, "a"], [9, 9, "p"], [23, 26, "v"]], [[47, 50, "a"], [52, 52, "v"], [52, 52, "v"]], [[76, 77, "a"], [60, 62, "p"], [79, 79, "v"]], [[89, 89, "v"]], [[102, 103, "a"], [95, 97, "p"], [95, 97, "p"], [105, 105, "v"]], [[131, 131, "v"], [112, 112, "a"], [115, 115, "v"], [119, 120, "p"], [126, 127, "p"], [122, 122, "v"], [131, 131, "v"], [132, 134, "c"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[17, 18, "a"], [31, 31, "v"]], [[42, 42, "a"], [47, 50, "p"], [52, 52, "v"]], [[76, 77, "p"], [79, 79, "v"]], [[84, 85, "a"], [89, 89, "v"]], [[102, 103, "p"], [105, 105, "v"]], [[112, 112, "a"], [115, 115, "v"], [119, 120, "p"], [122, 122, "v"], [126, 127, "p"], [131, 131, "v"], [133, 133, "v"]], [[139, 140, "a"], [145, 145, "v"], [158, 158, "v"], [168, 169, "v"]]], "predicted_relations": [[], [], [], [], [], [[119, 120, 112, 112, "USED-FOR"], [126, 127, 112, 112, "USED-FOR"], [122, 122, 119, 120, "USED-FOR"], [122, 122, 126, 127, "USED-FOR"], [132, 134, 131, 131, "USED-FOR"], [132, 134, 115, 115, "USED-FOR"], [132, 134, 122, 122, "USED-FOR"], [132, 134, 131, 131, "USED-FOR"]], []]}
{"doc_key": "1805.03616-43ade446-8097-4558-abad-c829c3c3fb19", "sentences": [["We", "employ", "six", "convolutional", "layers", "for", "both", "the", "encoder", "and", "decoder", "."], ["All", "embeddings", ",", "including", "the", "initialized", "embedding", "and", "the", "output", "produced", "by", "the", "decoder", "before", "the", "final", "linear", "layer", ",", "have", "a", "dimensionality", "of", "256", "."], ["We", "also", "adopt", "the", "same", "dimensionality", "for", "the", "size", "of", "linear", "layer", "mapping", "between", "hidden", "and", "embedding", "states", "."], ["We", "use", "a", "learning", "rate", "of", "0.25", "and", "reduce", "it", "by", "a", "decay", "rate", "of", "0.1", "once", "the", "validation", "ROUGE", "score", "stops", "increasing", "after", "each", "epoch", "until", "the", "learning", "rate", "falls", "below", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["We", "first", "train", "the", "basic", "topic-aware", "convolutional", "model", "with", "respect", "to", "a", "standard", "maximum", "likelihood", "objective", ",", "and", "then", "switch", "to", "further", "minimize", "a", "mixed", "training", "objective", "-LSB-", "18", "-RSB-", ",", "incorporating", "the", "reinforcement", "learning", "objective", "\\", "-LRB-", "L_\\text", "-LCB-", "rl", "-RCB-", "\\", "-RRB-", "and", "the", "original", "maximum", "likelihood", "\\", "-LRB-", "L_\\text", "-LCB-", "ml", "-RCB-", "\\", "-RRB-", ",", "which", "is", "given", "as", "\\", "-LRB-", "L_\\text", "-LCB-", "mixed", "-RCB-", "=", "\\lambda", "L_\\text", "-LCB-", "rl", "-RCB-", "+", "-LRB-", "1", "-", "\\lambda", "-RRB-", "L_\\text", "-LCB-", "ml", "-RCB-", ",", "\\", "-RRB-"]], "ner": [[[3, 4, "a"]], [[13, 13, "a"]], [], [[60, 61, "a"], [85, 86, "a"], [69, 70, "a"]], [[167, 167, "p"], [176, 176, "p"], [122, 124, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "v"]], [[36, 36, "v"]], [], [[60, 61, "p"], [63, 63, "v"], [69, 70, "p"], [72, 72, "v"], [85, 86, "p"], [91, 93, "v"]], [[103, 105, "a"], [162, 165, "a"], [167, 167, "p"], [176, 176, "p"]]], "predicted_relations": [[], [], [], [], [[167, 167, 122, 124, "USED-FOR"], [176, 176, 122, 124, "USED-FOR"]]]}
{"doc_key": "1805.06556-7a882142-fcff-44b2-b8c3-53e36dda4b66", "sentences": [["We", "preserve", "the", "settings", "used", "in", "-LSB-", "41", "-RSB-", "where", "possible", "."], ["As", "a", "result", ",", "the", "size", "of", "the", "hidden", "dimensions", "of", "the", "LSTM", "and", "the", "feedforward", "network", "is", "250", "."], ["The", "dropout", "ratio", "for", "the", "LSTM", "is", "set", "to", "\\", "-LRB-", "0.4~\\", "-RRB-", "."], ["Unlike", "the", "model", "it", "is", "based", "on", ",", "our", "model", "uses", "word", "embeddings", "of", "length", "1124", "."], ["These", "result", "from", "concatenating", "a", "100", "dimension", "learned", "word", "embedding", ",", "with", "a", "1024", "dimension", "learned", "linear", "combination", "of", "the", "internal", "states", "of", "a", "bidirectional", "language", "model", "run", "on", "the", "input", "sentence", "as", "described", "in", "-LSB-", "32", "-RSB-", "."], ["We", "refer", "to", "them", "below", "as", "ELMo", "-LRB-", "Embeddings", "from", "Language", "Models", "-RRB-", "."], ["For", "the", "learned", "embeddings", ",", "words", "with", "\\", "-LRB-", "n\\", "-RRB-", "occurrences", "in", "the", "training", "data", "are", "replaced", "by", "\\", "-LRB-", "\\langle", "\\text", "-LCB-", "UNK", "-RCB-", "\\rangle", "\\", "-RRB-", "with", "probability", "\\", "-LRB-", "\\frac", "-LCB-", "1", "+", "\\frac", "-LCB-", "n", "-RCB-", "-LCB-", "10", "-RCB-", "-RCB-", "-LCB-", "1", "+", "n", "-RCB-", "\\", "-RRB-", "."], ["This", "does", "not", "affect", "the", "ELMo", "component", "of", "the", "word", "embeddings", "."], ["As", "a", "result", ",", "even", "common", "words", "are", "replaced", "with", "probability", "at", "least", "\\", "-LRB-", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "10", "-RCB-", "\\", "-RRB-", ",", "making", "the", "model", "rely", "on", "the", "ELMo", "embeddings", "instead", "of", "the", "learned", "embeddings", "."], ["To", "make", "the", "model", "self-contained", ",", "it", "does", "not", "take", "part-of-speech", "tags", "as", "input", "."], ["Using", "a", "linear", "layer", "over", "the", "last", "hidden", "layer", "of", "the", "classification", "model", ",", "part-of-speech", "tags", "are", "predicted", "for", "spans", "containing", "single", "words", "."]], "ner": [[], [[24, 24, "a"], [20, 21, "p"], [30, 30, "v"]], [[37, 37, "a"], [33, 34, "p"], [43, 43, "v"]], [[57, 58, "a"], [60, 60, "p"], [61, 61, "v"]], [], [], [[140, 140, "p"], [146, 146, "c"]], [[178, 179, "a"]], [[191, 191, "c"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[24, 24, "a"], [27, 28, "a"], [30, 30, "v"]], [[33, 34, "p"], [37, 37, "a"]], [[55, 55, "a"], [61, 61, "v"]], [[68, 68, "v"], [69, 69, "p"], [76, 76, "v"], [77, 77, "p"]], [[108, 108, "a"]], [], [[174, 174, "a"]], [[212, 212, "a"]], [], []], "predicted_relations": [[], [[20, 21, 24, 24, "USED-FOR"]], [[33, 34, 37, 37, "USED-FOR"], [43, 43, 33, 34, "USED-FOR"]], [[60, 60, 57, 58, "USED-FOR"], [61, 61, 60, 60, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1806.10866-f0b15822-a135-4c11-9d33-5f245a23f54a", "sentences": [["For", "training", "the", "different", "cnn", ",", "we", "use", "hyper", "parameters", "as", "suggested", "by", "-LSB-", "16", "-RSB-", ":", "All", "networks", "are", "trained", "using", "the", "bcel", "and", "adam", "-LSB-", "25", "-RSB-", "."], ["As", "labels", ",", "we", "use", "phoc", "vectors", "with", "levels", "1", ",", "2", ",", "4", ",", "8", "and", "omit", "bi-", "or", "trigrams", "."], ["The", "momentum", "values", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "for", "the", "mean", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "for", "the", "variance", "are", "set", "to", "the", "recommended", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "0.999\\", "-RRB-", "respectively", "while", "the", "variance", "flooring", "parameter", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-8", "-RCB-", "\\", "-RRB-", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "divided", "by", "10", "after", "\\", "-LRB-", "70\\,000\\", "-RRB-", "training", "iterations", "for", "the", "gw", "and", "Botany", "."], ["Training", "on", "these", "two", "data", "sets", "is", "carried", "out", "for", "a", "total", "of", "\\", "-LRB-", "80\\,000\\", "-RRB-", "iterations", "For", "the", "iam", "the", "step", "size", "is", "set", "to", "\\", "-LRB-", "100\\,000\\", "-RRB-", "and", "training", "is", "run", "for", "\\", "-LRB-", "240\\,000\\", "-RRB-", "iterations", "."]], "ner": [[[23, 23, "a"], [25, 25, "a"]], [], [[53, 54, "p"], [84, 84, "v"], [89, 91, "p"]], [[110, 112, "p"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [23, 23, "a"], [25, 25, "a"]], [[35, 35, "a"], [45, 45, "v"]], [[53, 54, "p"], [79, 79, "v"], [84, 84, "v"], [102, 105, "v"]], [[111, 112, "p"], [118, 121, "v"], [127, 127, "v"], [131, 131, "v"], [137, 137, "a"]], [[144, 144, "v"], [156, 156, "v"], [161, 161, "a"], [163, 164, "p"], [170, 170, "v"], [179, 179, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1806.10866-930f1e27-cbf5-4c20-816b-658a5432d2cf", "sentences": [["Similar", "to", "-LSB-", "16", "-RSB-", ",", "the", "images", "are", "not", "preprocessed", "but", "the", "pixel", "values", "are", "scaled", "such", "that", "black", "pixels", "have", "a", "pixel", "value", "of", "\\", "-LRB-", "1.0\\", "-RRB-", "while", "white", "pixels", "\\", "-LRB-", "0.0\\", "-RRB-", "."], ["We", "also", "augment", "the", "training", "set", "using", "the", "algorithm", "presented", "in", "-LSB-", "16", "-RSB-", "."], ["This", "way", ",", "training", "images", "are", "generated", "such", "that", "there", "exists", "an", "equal", "amount", "of", "images", "per", "class", "used", "during", "training", "and", "the", "total", "amount", "of", "images", "is", "\\", "-LRB-", "500\\,000\\", "-RRB-", "."]], "ner": [[], [[42, 43, "a"]], [[76, 79, "p"]]], "relations": [[], [], []], "predicted_ner": [[[28, 28, "v"], [35, 35, "v"]], [], [[83, 83, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1804.07878-227a042b-b33e-4be7-867e-4ec5910f7117", "sentences": [["In", "all", "our", "experiments", ",", "we", "use", "a", "minibatch", "size", "of", "64", ",", "dropout", "rate", "of", "0.3", ",", "4", "RNN", "layers", "of", "size", "1000", ",", "a", "word", "vector", "size", "of", "600", ",", "learning", "rate", "of", "0.8", "across", "all", "LSTM-based", "multilingual", "experiments", "."], ["For", "single-source", "single-target", "translation", ",", "we", "use", "2", "RNN", "layers", "of", "size", "500", ",", "a", "word", "vector", "size", "of", "500", ",", "and", "learning", "rate", "of", "1.0", "."], ["All", "learning", "rates", "are", "decaying", "at", "the", "rate", "of", "0.7", "if", "the", "validation", "score", "is", "not", "improving", "or", "it", "is", "past", "epoch", "9", "."], ["We", "use", "SGD", "as", "our", "learning", "algorithm", "."], ["We", "build", "our", "code", "based", "on", "OpenNMT", "-LSB-", "31", "-RSB-", "."], ["For", "the", "ablation", "study", ",", "we", "train", "on", "BLEU", "scores", "directly", "until", "the", "Generalization", "Loss", "-LRB-", "GL", "-RRB-", "exceeds", "a", "threshold", "of", "\\", "-LRB-", "\\alpha", "=", "0.1\\", "-RRB-", "-LSB-", "44", "-RSB-", "."], ["GL", "at", "epoch", "\\", "-LRB-", "t\\", "-RRB-", "is", "defined", "as", "\\", "-LRB-", "GL", "-LRB-", "t", "-RRB-", "=", "100", "-LRB-", "1-", "\\frac", "-LCB-", "E_", "-LCB-", "val", "-RCB-", "^t", "-RCB-", "-LCB-", "E_", "-LCB-", "opt", "-RCB-", "^t", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "modified", "by", "us", "to", "suit", "our", "objective", "using", "BLEU", "scores", "-LSB-", "44", "-RSB-", "."], ["\\", "-LRB-", "E_", "-LCB-", "val", "-RCB-", "^t\\", "-RRB-", "is", "the", "validation", "score", "at", "epoch", "\\", "-LRB-", "t\\", "-RRB-", "and", "\\", "-LRB-", "E_", "-LCB-", "opt", "-RCB-", "^t\\", "-RRB-", "is", "the", "optimal", "score", "up", "to", "epoch", "\\", "-LRB-", "t\\", "-RRB-", "."], ["We", "evaluate", "our", "models", "using", "both", "BLEU", "scores", "-LSB-", "41", "-RSB-", "and", "qualitative", "evaluation", "."]], "ner": [[[19, 19, "a"], [9, 9, "p"], [22, 22, "p"], [28, 28, "p"], [23, 23, "v"], [18, 20, "c"], [26, 28, "a"], [9, 9, "p"], [22, 22, "p"], [28, 28, "p"], [30, 30, "v"], [32, 33, "a"], [14, 14, "p"], [33, 33, "p"], [35, 35, "v"], [36, 40, "c"], [8, 9, "a"], [9, 9, "p"], [22, 22, "p"], [28, 28, "p"], [11, 11, "v"], [13, 14, "a"], [14, 14, "p"], [33, 33, "p"], [16, 16, "v"]], [[50, 50, "a"], [53, 53, "p"], [59, 59, "p"], [54, 54, "v"], [61, 61, "v"], [49, 51, "c"], [57, 59, "a"], [53, 53, "p"], [59, 59, "p"], [54, 54, "v"], [61, 61, "v"], [64, 65, "a"], [65, 65, "p"], [67, 67, "v"], [43, 45, "c"], [53, 53, "p"], [59, 59, "p"], [65, 65, "p"]], [[76, 76, "p"], [78, 78, "v"], [76, 76, "p"]], [[95, 95, "a"]], [[107, 107, "a"]], [[120, 121, "a"], [125, 126, "a"], [136, 136, "p"], [138, 138, "v"]], [[191, 192, "a"]], [], [[242, 243, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 9, "p"], [11, 11, "v"], [13, 14, "p"], [16, 16, "v"], [18, 18, "v"], [19, 19, "a"], [23, 23, "v"], [30, 30, "v"], [32, 33, "p"], [35, 35, "v"]], [[49, 49, "v"], [50, 50, "a"], [54, 54, "v"], [61, 61, "v"], [64, 65, "p"], [67, 67, "v"]], [[70, 71, "p"], [78, 78, "v"], [91, 91, "v"]], [[95, 95, "a"]], [[104, 104, "a"], [107, 107, "a"]], [[136, 136, "p"], [138, 138, "v"]], [[144, 144, "a"], [149, 149, "p"], [161, 161, "v"]], [], []], "predicted_relations": [[[9, 9, 19, 19, "USED-FOR"], [9, 9, 8, 9, "USED-FOR"], [22, 22, 19, 19, "USED-FOR"], [22, 22, 8, 9, "USED-FOR"], [22, 22, 13, 14, "USED-FOR"], [28, 28, 19, 19, "USED-FOR"], [28, 28, 26, 28, "USED-FOR"], [28, 28, 8, 9, "USED-FOR"], [28, 28, 13, 14, "USED-FOR"], [23, 23, 9, 9, "USED-FOR"], [23, 23, 22, 22, "USED-FOR"], [23, 23, 28, 28, "USED-FOR"], [23, 23, 9, 9, "USED-FOR"], [23, 23, 22, 22, "USED-FOR"], [23, 23, 28, 28, "USED-FOR"], [23, 23, 9, 9, "USED-FOR"], [23, 23, 22, 22, "USED-FOR"], [23, 23, 28, 28, "USED-FOR"], [18, 20, 23, 23, "USED-FOR"], [18, 20, 30, 30, "USED-FOR"], [18, 20, 11, 11, "USED-FOR"], [9, 9, 19, 19, "USED-FOR"], [9, 9, 8, 9, "USED-FOR"], [22, 22, 19, 19, "USED-FOR"], [22, 22, 8, 9, "USED-FOR"], [22, 22, 13, 14, "USED-FOR"], [28, 28, 19, 19, "USED-FOR"], [28, 28, 26, 28, "USED-FOR"], [28, 28, 8, 9, "USED-FOR"], [28, 28, 13, 14, "USED-FOR"], [30, 30, 22, 22, "USED-FOR"], [30, 30, 28, 28, "USED-FOR"], [30, 30, 22, 22, "USED-FOR"], [30, 30, 28, 28, "USED-FOR"], [30, 30, 33, 33, "USED-FOR"], [30, 30, 22, 22, "USED-FOR"], [30, 30, 28, 28, "USED-FOR"], [30, 30, 33, 33, "USED-FOR"], [14, 14, 19, 19, "USED-FOR"], [14, 14, 8, 9, "USED-FOR"], [14, 14, 13, 14, "USED-FOR"], [33, 33, 19, 19, "USED-FOR"], [33, 33, 26, 28, "USED-FOR"], [33, 33, 32, 33, "USED-FOR"], [33, 33, 8, 9, "USED-FOR"], [33, 33, 13, 14, "USED-FOR"], [36, 40, 23, 23, "USED-FOR"], [36, 40, 30, 30, "USED-FOR"], [36, 40, 35, 35, "USED-FOR"], [36, 40, 11, 11, "USED-FOR"], [36, 40, 16, 16, "USED-FOR"], [9, 9, 19, 19, "USED-FOR"], [9, 9, 8, 9, "USED-FOR"], [22, 22, 19, 19, "USED-FOR"], [22, 22, 8, 9, "USED-FOR"], [22, 22, 13, 14, "USED-FOR"], [28, 28, 19, 19, "USED-FOR"], [28, 28, 26, 28, "USED-FOR"], [28, 28, 8, 9, "USED-FOR"], [28, 28, 13, 14, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 14, 14, "USED-FOR"], [11, 11, 9, 9, "USED-FOR"], [11, 11, 14, 14, "USED-FOR"], [14, 14, 19, 19, "USED-FOR"], [14, 14, 8, 9, "USED-FOR"], [14, 14, 13, 14, "USED-FOR"], [33, 33, 19, 19, "USED-FOR"], [33, 33, 26, 28, "USED-FOR"], [33, 33, 32, 33, "USED-FOR"], [33, 33, 8, 9, "USED-FOR"], [33, 33, 13, 14, "USED-FOR"]], [[53, 53, 50, 50, "USED-FOR"], [59, 59, 50, 50, "USED-FOR"], [59, 59, 57, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [49, 51, 54, 54, "USED-FOR"], [49, 51, 61, 61, "USED-FOR"], [49, 51, 54, 54, "USED-FOR"], [49, 51, 61, 61, "USED-FOR"], [49, 51, 67, 67, "USED-FOR"], [53, 53, 50, 50, "USED-FOR"], [59, 59, 50, 50, "USED-FOR"], [59, 59, 57, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [54, 54, 53, 53, "USED-FOR"], [54, 54, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [61, 61, 59, 59, "USED-FOR"], [65, 65, 50, 50, "USED-FOR"], [65, 65, 57, 59, "USED-FOR"], [65, 65, 64, 65, "USED-FOR"], [43, 45, 54, 54, "USED-FOR"], [43, 45, 61, 61, "USED-FOR"], [43, 45, 54, 54, "USED-FOR"], [43, 45, 61, 61, "USED-FOR"], [43, 45, 67, 67, "USED-FOR"], [53, 53, 50, 50, "USED-FOR"], [59, 59, 50, 50, "USED-FOR"], [59, 59, 57, 59, "USED-FOR"], [65, 65, 50, 50, "USED-FOR"], [65, 65, 57, 59, "USED-FOR"], [65, 65, 64, 65, "USED-FOR"]], [], [], [], [[136, 136, 120, 121, "USED-FOR"], [136, 136, 125, 126, "USED-FOR"], [138, 138, 136, 136, "USED-FOR"]], [], [], []]}
{"doc_key": "1802.09232-724e8d21-a160-4ce3-854c-485f77204299", "sentences": [["In", "order", "to", "merge", "different", "datasets", ",", "we", "convert", "the", "poses", "to", "a", "common", "layout", ",", "with", "a", "fixed", "number", "of", "joints", "equal", "to", "the", "dataset", "with", "more", "joints", "."], ["For", "example", ",", "when", "merging", "the", "datasets", "Human3.6M", "and", "MPII", ",", "we", "use", "all", "the", "17", "joints", "in", "the", "first", "dataset", "and", "include", "one", "joint", "on", "MPII", "."], ["All", "the", "included", "joints", "have", "an", "invalid", "value", "that", "is", "not", "taken", "into", "account", "in", "the", "loss", "function", "."], ["Additionally", ",", "we", "use", "and", "alternated", "human", "pose", "layout", ",", "similar", "to", "the", "layout", "from", "the", "Penn", "Action", "dataset", ",", "which", "experimentally", "lead", "to", "better", "scores", "on", "action", "recognition", "."]], "ner": [[], [[37, 37, "a"], [39, 39, "a"], [56, 56, "a"]], [[74, 75, "a"], [64, 65, "p"]], [[93, 94, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[37, 37, "a"], [39, 39, "a"], [45, 45, "v"], [53, 53, "v"], [56, 56, "a"]], [], [[93, 95, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1802.09232-8427c04b-17b2-4167-9a66-416ed7fa20b8", "sentences": [["We", "optimize", "the", "pose", "regression", "part", "using", "the", "RMSprop", "optimizer", "with", "initial", "learning", "rate", "of", "0.001", ",", "which", "is", "reduced", "by", "a", "factor", "of", "0.2", "when", "validation", "score", "plateaus", ",", "and", "batches", "of", "24", "images", "."], ["For", "the", "action", "recognition", "task", ",", "we", "train", "both", "pose", "and", "appearance", "models", "simultaneously", "using", "a", "pre-trained", "pose", "estimation", "model", "with", "weights", "initially", "frozen", "."], ["In", "that", "case", ",", "we", "use", "a", "classical", "SGD", "optimizer", "with", "Nesterov", "momentum", "of", "0.98", "and", "initial", "learning", "rate", "of", "0.0002", ",", "reduced", "by", "a", "factor", "of", "0.2", "when", "validation", "plateaus", ",", "and", "batches", "of", "2", "video", "clips", "."], ["When", "validation", "accuracy", "stagnates", ",", "we", "divide", "the", "final", "learning", "rate", "by", "10", "and", "fine", "tune", "the", "full", "network", "for", "more", "5", "epochs", "."], ["When", "reporting", "only", "pose", "estimation", "scores", ",", "we", "use", "eight", "prediction", "blocks", "-LRB-", "\\", "-LRB-", "\\mathnormal", "-LCB-", "K", "-RCB-", "-LCB-", "-RCB-", "=8\\", "-RRB-", "-RRB-", ",", "and", "for", "action", "recognition", ",", "we", "use", "four", "prediction", "blocks", "-LRB-", "\\", "-LRB-", "\\mathnormal", "-LCB-", "K", "-RCB-", "-LCB-", "-RCB-", "=4\\", "-RRB-", "-RRB-", "."], ["For", "all", "experiments", ",", "we", "use", "cropped", "RGB", "images", "of", "size", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "."], ["We", "augment", "the", "training", "data", "by", "performing", "random", "rotations", "from", "\\", "-LRB-", "-45^", "-LCB-", "\\circ", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "+45^", "-LCB-", "\\circ", "-RCB-", "\\", "-RRB-", ",", "scaling", "from", "\\", "-LRB-", "0.7\\", "-RRB-", "to", "\\", "-LRB-", "1.3\\", "-RRB-", ",", "vertical", "and", "horizontal", "translations", "respectively", "from", "\\", "-LRB-", "-40\\", "-RRB-", "to", "\\", "-LRB-", "+40\\", "-RRB-", "pixels", ",", "video", "subsampling", "by", "a", "factor", "from", "1", "to", "3", ",", "and", "random", "horizontal", "flipping", "."]], "ner": [[[8, 9, "a"], [15, 15, "v"], [22, 22, "p"], [24, 24, "v"], [31, 31, "p"], [33, 34, "v"], [22, 22, "p"], [24, 24, "v"], [31, 31, "p"], [22, 22, "p"]], [], [[77, 79, "p"], [86, 86, "p"], [88, 88, "v"], [94, 94, "p"], [69, 70, "a"], [75, 75, "v"], [77, 79, "p"], [81, 81, "v"], [86, 86, "p"], [88, 88, "v"], [94, 94, "p"], [96, 98, "v"], [86, 86, "p"]], [[108, 110, "a"]], [[141, 141, "a"], [164, 164, "a"]], [], [[250, 250, "p"], [250, 250, "p"], [196, 197, "a"], [217, 217, "a"], [221, 221, "v"], [226, 226, "v"], [244, 244, "p"], [246, 247, "a"], [250, 250, "p"], [226, 226, "v"], [252, 252, "v"], [226, 226, "v"], [254, 254, "v"], [257, 259, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [12, 13, "p"], [15, 15, "v"], [24, 24, "v"], [33, 33, "v"]], [], [[72, 73, "p"], [75, 75, "v"], [78, 79, "p"], [81, 81, "v"], [88, 88, "v"], [96, 96, "v"]], [[109, 110, "p"], [112, 112, "v"], [117, 118, "a"], [121, 121, "v"], [122, 122, "p"]], [[133, 133, "v"], [145, 145, "v"], [156, 156, "v"], [168, 168, "v"]], [[186, 186, "v"]], [[221, 221, "v"], [226, 226, "v"], [237, 237, "v"], [242, 242, "v"], [252, 252, "v"], [254, 254, "v"]]], "predicted_relations": [[[22, 22, 8, 9, "USED-FOR"], [31, 31, 8, 9, "USED-FOR"], [33, 34, 22, 22, "USED-FOR"], [33, 34, 31, 31, "USED-FOR"], [33, 34, 22, 22, "USED-FOR"], [33, 34, 31, 31, "USED-FOR"], [33, 34, 22, 22, "USED-FOR"], [22, 22, 8, 9, "USED-FOR"], [31, 31, 8, 9, "USED-FOR"], [22, 22, 8, 9, "USED-FOR"]], [], [[77, 79, 69, 70, "USED-FOR"], [86, 86, 69, 70, "USED-FOR"], [94, 94, 69, 70, "USED-FOR"], [75, 75, 77, 79, "USED-FOR"], [75, 75, 77, 79, "USED-FOR"], [77, 79, 69, 70, "USED-FOR"], [81, 81, 77, 79, "USED-FOR"], [81, 81, 86, 86, "USED-FOR"], [81, 81, 77, 79, "USED-FOR"], [81, 81, 86, 86, "USED-FOR"], [81, 81, 86, 86, "USED-FOR"], [86, 86, 69, 70, "USED-FOR"], [94, 94, 69, 70, "USED-FOR"], [86, 86, 69, 70, "USED-FOR"]], [], [], [], [[250, 250, 196, 197, "USED-FOR"], [250, 250, 246, 247, "USED-FOR"], [250, 250, 196, 197, "USED-FOR"], [250, 250, 246, 247, "USED-FOR"], [244, 244, 217, 217, "USED-FOR"], [244, 244, 246, 247, "USED-FOR"], [250, 250, 196, 197, "USED-FOR"], [250, 250, 246, 247, "USED-FOR"]]]}
{"doc_key": "1802.09130-eb9dd8fc-2912-4a7d-a737-37fe2b97ca6b", "sentences": [["To", "train", "and", "evaluate", "all", "of", "the", "methods", "in", "a", "fair", "and", "consistent", "way", ",", "we", "used", "the", "standard", "10", "fold", "Cross-Validation", "in", "FLU2013", "dataset", ",", "and", "within", "each", "topic", "of", "PHM2017", "dataset", "."], ["The", "results", "reported", "in", "the", "next", "section", "are", "the", "averages", "over", "the", "test", "folds", "."], ["To", "build", "the", "folds", ",", "we", "preserved", "the", "original", "distribution", "of", "the", "labels", ",", "and", "randomly", "assigned", "the", "tweets", "to", "each", "fold", "."], ["Since", "the", "set", "of", "the", "positive", "tweets", "is", "small", ",", "we", "kept", "the", "folds", "fixed", "across", "all", "of", "the", "cross", "validation", "experiments", ",", "to", "ensure", "that", "all", "of", "the", "methods", "were", "trained", "and", "tested", "in", "identical", "train/validate/test", "folds", "and", "thus", "the", "results", "can", "be", "compared", "directly", "."]], "ner": [[[21, 21, "a"], [19, 19, "v"], [23, 24, "a"], [31, 32, "a"]], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[19, 20, "v"], [21, 21, "a"]], [], [], [[91, 92, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1802.02733-b49bf9a2-f8b4-4d97-b02a-e6939e63e686", "sentences": [["We", "implement", "our", "proposed", "method", "based", "on", "the", "Caffe", "framework", ",", "and", "the", "proposed", "alternating", "optimization", "algorithm", "is", "implemented", "using", "CUDA", "."], ["All", "experiments", "are", "conducted", "on", "a", "GPU", "Server", "which", "has", "8", "Nvidia", "Titan", "Xp", "GPUs", "."]], "ner": [[[8, 9, "a"], [14, 16, "a"]], [[33, 36, "a"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "a"], [14, 16, "a"]], [[32, 32, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1802.02733-a467803c-f648-4582-bf0f-be0843cd9ffd", "sentences": [["During", "layer-wise", "optimization", ",", "we", "set", "maximum", "iterations", "of", "the", "proposed", "alternating", "optimization", "method", "to", "20", "which", "is", "enough", "for", "training", "according", "to", "Figure", "REF", "."], ["We", "adopt", "different", "fine-tuning", "settings", "for", "different", "network", "architecture", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[11, 13, "a"], [15, 15, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "1802.02733-722f3d88-7cdf-4fff-af29-16fe08d43c6d", "sentences": [["AlexNet", "We", "fine-tune", "AlexNet", "using", "a", "SGD", "solver", "with", "momentum=0.9", ",", "weight", "decay=0.0005", "."], ["The", "learning", "rate", "starts", "at", "0.001", ",", "and", "is", "divided", "by", "10", "after", "100k", ",", "150k", ",", "and", "180k", "iterations", "."], ["The", "network", "is", "fine-tuned", "for", "200k", "iterations", "with", "batch-size", "equals", "to", "256", "."], ["Before", "training", ",", "images", "are", "resized", "to", "have", "256", "pixels", "at", "their", "smaller", "side", "."], ["Random", "cropping", "and", "mirroring", "are", "adopted", "in", "the", "training", "stage", "and", "center", "cropping", "is", "used", "in", "the", "testing", "stage", "."]], "ner": [[[0, 0, "a"], [3, 3, "a"], [6, 7, "a"], [9, 9, "p"], [11, 12, "p"]], [[15, 16, "p"], [33, 33, "p"], [29, 29, "v"], [32, 32, "v"]], [[46, 46, "v"], [41, 41, "p"], [40, 40, "v"], [43, 43, "p"]], [[56, 56, "v"], [57, 57, "p"]], [[63, 64, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [3, 3, "a"], [6, 7, "a"]], [[15, 16, "p"], [19, 19, "v"], [25, 25, "v"], [27, 27, "v"], [29, 29, "v"], [32, 32, "v"]], [[40, 40, "v"], [43, 43, "p"], [46, 46, "v"]], [[56, 56, "v"]], []], "predicted_relations": [[[9, 9, 3, 3, "USED-FOR"], [9, 9, 6, 7, "USED-FOR"], [11, 12, 0, 0, "USED-FOR"], [11, 12, 3, 3, "USED-FOR"], [11, 12, 6, 7, "USED-FOR"]], [[29, 29, 33, 33, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"]], [[40, 40, 41, 41, "USED-FOR"]], [], []]}
{"doc_key": "1802.02733-b174e11a-d6e0-4d99-ae48-0e4961dd5a1e", "sentences": [["ResNet-18", "We", "fine-tune", "the", "ResNet-18", "using", "a", "SGD", "solver", "with", "momentum=0.9", ",", "weight", "decay=0.0005", "."], ["The", "learning", "rate", "starts", "at", "0.0005", ",", "and", "is", "divided", "by", "10", "every", "200k", "iterations", "."], ["We", "run", "the", "training", "algorithm", "for", "650k", "iterations", "with", "batch", "size", "equal", "to", "128", "."], ["We", "use", "random", "cropping", "and", "mirroring", "for", "data", "augmentation", "."], ["Like", "AlexNet", ",", "images", "are", "resized", "to", "have", "256", "pixels", "at", "their", "smaller", "side", "."]], "ner": [[[0, 0, "a"], [4, 4, "a"], [8, 8, "p"], [7, 7, "v"], [10, 10, "p"], [10, 10, "v"], [12, 13, "p"], [13, 13, "v"], [13, 13, "v"], [7, 7, "a"]], [[20, 20, "v"], [16, 17, "p"], [20, 20, "v"], [29, 29, "p"], [28, 28, "v"], [24, 27, "c"]], [[38, 38, "p"], [37, 37, "v"], [40, 41, "p"], [44, 44, "v"]], [[53, 54, "p"], [48, 51, "v"], [48, 51, "a"]], [[64, 65, "v"], [68, 69, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [4, 4, "a"]], [[16, 17, "p"], [20, 20, "v"], [26, 26, "v"], [28, 28, "v"]], [[37, 37, "v"], [40, 41, "p"], [44, 44, "v"]], [], [[57, 57, "a"], [64, 64, "v"]]], "predicted_relations": [[[8, 8, 0, 0, "USED-FOR"], [8, 8, 4, 4, "USED-FOR"], [8, 8, 7, 7, "USED-FOR"], [10, 10, 4, 4, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 7, 7, "USED-FOR"], [10, 10, 8, 8, "USED-FOR"], [10, 10, 10, 10, "USED-FOR"], [10, 10, 12, 13, "USED-FOR"], [12, 13, 0, 0, "USED-FOR"], [12, 13, 4, 4, "USED-FOR"], [12, 13, 7, 7, "USED-FOR"], [13, 13, 8, 8, "USED-FOR"], [13, 13, 10, 10, "USED-FOR"], [13, 13, 12, 13, "USED-FOR"], [13, 13, 8, 8, "USED-FOR"], [13, 13, 10, 10, "USED-FOR"], [13, 13, 12, 13, "USED-FOR"]], [[28, 28, 29, 29, "USED-FOR"], [24, 27, 28, 28, "USED-FOR"]], [[37, 37, 38, 38, "USED-FOR"]], [], []]}
{"doc_key": "1802.02745-ee294580-8348-4232-b06a-399315b5dbde", "sentences": [["For", "both", "the", "MLP", "and", "the", "CNN", ",", "we", "train", "the", "network", "to", "minimize", "negative", "log-likelihood", "loss", ",", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "the", "RMSprop", "update", "rule", "and", "a", "typical", "batch", "size", "of", "32", "."], ["There", "are", "a", "few", "exceptions", "to", "this", "batch", "size", ":", "when", "the", "training", "set", "is", "very", "small", ",", "we", "adjust", "the", "batch", "size", "to", "ensure", "there", "are", "at", "least", "5", "training", "batches", "."], ["Thus", ",", "for", "a", "training", "set", "with", "\\", "-LRB-", "N\\", "-RRB-", "categories", "and", "\\", "-LRB-", "K\\", "-RRB-", "examples", "per", "category", "-LRB-", "a", "total", "of", "\\", "-LRB-", "N", "*", "K\\", "-RRB-", "training", "points", "-RRB-", ",", "we", "use", "a", "batch", "size", "of", "min", "-LRB-", "32", ",", "\\", "-LRB-", "\\frac", "-LCB-", "N", "*", "K", "-RCB-", "-LCB-", "5", "-RCB-", "\\", "-RRB-", "-RRB-", "."], ["The", "number", "of", "training", "epochs", "was", "chosen", "such", "that", "the", "network", "loss", "reaches", "an", "asymptote", "for", "each", "the", "MLP", "and", "CNN", "."], ["Training", "loss", "is", "monitored", "and", "used", "to", "save", "the", "best", "model", "."]], "ner": [[[3, 3, "a"], [6, 6, "a"], [14, 16, "a"], [33, 34, "p"], [36, 36, "v"], [27, 29, "a"]], [[45, 46, "p"], [59, 60, "p"], [48, 54, "c"]], [[108, 109, "p"], [113, 113, "v"]], [[148, 148, "a"], [150, 150, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [6, 6, "a"], [11, 11, "a"], [19, 24, "a"], [27, 29, "a"], [33, 34, "p"], [36, 36, "v"]], [[67, 67, "v"]], [[80, 80, "p"], [86, 86, "p"], [108, 109, "p"], [113, 113, "v"]], [[150, 150, "a"]], []], "predicted_relations": [[[33, 34, 3, 3, "USED-FOR"], [33, 34, 27, 29, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1803.05785-ecb0aabc-68f0-45a1-9bdd-3149b81f1579", "sentences": [["Our", "models", "are", "trained", "using", "Tensorflow", "-LSB-", "16", "-RSB-", "with", "the", "\\", "-LRB-", "L^1\\", "-RRB-", "norm", "loss", "function", ",", "we", "set", "the", "learning", "rate", "as", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "use", "Adam", "-LSB-", "17", "-RSB-", "optimisation", "method", "to", "train", "the", "model", ",", "all", "weights", "to", "be", "trained", "in", "the", "model", "are", "initialised", "using", "Xavier", "-LSB-", "18", "-RSB-", "initialisation", "method", "."]], "ner": [[[5, 5, "a"], [35, 35, "a"], [57, 57, "a"], [22, 23, "a"], [22, 23, "p"]]], "relations": [[]], "predicted_ner": [[[5, 5, "a"], [22, 23, "p"], [27, 30, "v"], [35, 35, "a"], [57, 57, "a"]]], "predicted_relations": [[[22, 23, 5, 5, "USED-FOR"]]]}
{"doc_key": "1811.07344-00c91219-1549-40bb-91e1-592af416110f", "sentences": [["To", "compare", "the", "effects", "of", "changes", "in", "transfer", "learning", "techniques", ",", "all", "training", "parameters", "are", "kept", "consistent", "unless", "otherwise", "specified", "."], ["For", "MORPH-II", ",", "all", "images", "are", "scaled", "down", "to", "200x240", "."], ["All", "input", "is", "standardized", "before", "being", "fed", "into", "the", "network", "."], ["The", "batch", "size", "is", "set", "to", "50", ",", "and", "models", "are", "trained", "for", "60", "epochs", "."], ["The", "original", "dropout", "rate", "of", "0.5", "is", "retained", ",", "and", "the", "ReLU", "activation", "function", "is", "used", "in", "all", "weight", "layers", "."], ["The", "Adadelta", "optimizer", "is", "used", "with", "its", "default", "values", "."], ["Gender", "models", "use", "the", "binary", "cross", "entropy", "loss", "function", ",", "and", "age", "models", "use", "mean", "absolute", "error", "-LRB-", "MAE", "-RRB-", "."], ["Results", "for", "age", "estimation", "are", "reported", "as", "an", "MAE", ",", "which", "is", "defined", "as", ":", "\\", "-LRB-", "-LCB-", "\\text", "-LCB-", "M", "-RCB-", "AE", "-RCB-", "=", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "n", "-RCB-", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "n", "-RCB-", "|y_i", "-", "\\hat", "-LCB-", "y_i", "-RCB-", "|.\\", "-RRB-"]], "ner": [[], [], [], [], [[70, 72, "a"]], [[81, 82, "a"], [87, 88, "p"]], [[94, 98, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[22, 22, "a"], [30, 30, "v"]], [], [[44, 45, "p"], [49, 49, "v"], [56, 56, "v"], [57, 57, "p"]], [[61, 62, "p"], [64, 64, "v"], [70, 70, "a"]], [[81, 81, "a"]], [[94, 96, "a"]], []], "predicted_relations": [[], [], [], [], [], [[87, 88, 81, 82, "USED-FOR"]], [], []]}
{"doc_key": "1811.07344-0139cf57-fae8-48cf-99db-505ed428a24f", "sentences": [["\\", "-LRB-", "S_1\\", "-RRB-", "is", "used", "to", "train", "the", "models", "."], ["During", "the", "parameter", "training", "process", ",", "models", "are", "supplied", "with", "a", "validation", "set", "of", "500", "random", "samples", "from", "\\", "-LRB-", "S_3\\", "-RRB-", "."], ["To", "show", "the", "performance", "of", "models", "as", "data", "are", "added", ",", "the", "training", "set", "is", "split", "into", "several", "sets", "that", "are", "trained", "upon", "serially", "."], ["This", "also", "helps", "avoid", "the", "issues", "that", "arise", "from", "using", "too", "much", "computer", "memory", "."], ["The", "model", "parameters", "with", "the", "lowest", "loss", "on", "the", "validation", "set", "sample", "is", "saved", "and", "then", "fully", "validated", "on", "\\", "-LRB-", "S_2\\cup", "S_3\\", "-RRB-", ",", "a", "set", "of", "44,624", "images", "."]], "ner": [[[2, 2, "a"], [9, 9, "a"]], [[31, 31, "a"], [17, 17, "a"], [13, 15, "p"], [22, 23, "p"], [25, 27, "v"]], [[39, 39, "a"], [46, 47, "a"]], [], [[96, 96, "a"], [95, 95, "a"], [83, 84, "p"], [79, 80, "a"], [90, 91, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[25, 25, "v"]], [], [], [[102, 102, "v"]]], "predicted_relations": [[], [[22, 23, 17, 17, "USED-FOR"], [25, 27, 22, 23, "USED-FOR"]], [], [], [[83, 84, 79, 80, "USED-FOR"], [83, 84, 90, 91, "USED-FOR"]]]}
{"doc_key": "1805.08688-816219dd-ea2e-40d6-983f-429d94255135", "sentences": [["To", "train", "the", "pedestrian", "candidate", "generator", ",", "both", "the", "original", "images", "and", "the", "horizontally", "flipped", "images", "which", "contain", "at", "least", "one", "annotated", "bounding", "box", "are", "used", ",", "which", "results", "in", "around", "\\", "-LRB-", "68,000\\", "-RRB-", "training", "images", "in", "total", "."], ["Among", "all", "the", "annotated", "bounding", "boxes", ",", "there", "are", "about", "\\", "-LRB-", "109,000\\", "-RRB-", "annotated", "bounding", "boxes", "in", "'Person_full", "'", "class", ",", "\\", "-LRB-", "60,000\\", "-RRB-", "annotated", "bounding", "boxes", "in", "'Person_occluded", "'", "class", ",", "and", "\\", "-LRB-", "35,000\\", "-RRB-", "bounding", "boxes", "in", "'People", "'", "class", "."], ["All", "the", "images", "are", "of", "size", "\\", "-LRB-", "480\\times", "640\\", "-RRB-", "."], ["The", "model", "is", "fine-tuned", "from", "the", "Microsoft", "COCO", "-LSB-", "13", "-RSB-", "pre-trained", "SSD", "model", "for", "\\", "-LRB-", "40,000\\", "-RRB-", "iterations", "using", "the", "standard", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "algorithm", "and", "the", "back-propagation", "algorithm", "at", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."]], "ner": [[], [], [], [[104, 105, "a"], [134, 135, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 5, "a"], [20, 20, "v"], [33, 33, "v"]], [[52, 52, "v"], [64, 64, "v"], [77, 77, "v"]], [[95, 95, "v"]], [[110, 111, "a"], [115, 115, "v"], [121, 127, "a"], [130, 131, "a"], [134, 135, "p"], [139, 142, "v"]]], "predicted_relations": [[], [], [], [[134, 135, 104, 105, "USED-FOR"]]]}
{"doc_key": "1805.08688-3d43c2f1-5435-4b68-a8ea-03a31a2e9bf4", "sentences": [["To", "train", "the", "classification", "system", ",", "all", "the", "ground-truth", "annotations", "and", "the", "pedestrian", "candidates", "generated", "from", "the", "previous", "stage", "with", "height", "greater", "than", "40", "pixels", "and", "confidence", "score", "larger", "than", "\\", "-LRB-", "0.01\\", "-RRB-", "are", "selected", ",", "and", "rescaled", "into", "a", "fixed", "size", "of", "\\", "-LRB-", "250\\times", "250\\", "-RRB-", "to", "represent", "the", "training", "samples", "."], ["For", "data", "augmentation", ",", "a", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "patch", "is", "randomly", "cropped", "out", "of", "each", "training", "sample", "and", "horizontally", "flipped", "with", "probability", "\\", "-LRB-", "0.5\\", "-RRB-", "."], ["To", "label", "the", "training", "samples", ",", "the", "soft-label", "method", "as", "described", "by", "Equations", "-LRB-", "REF", "-RRB-", "and", "-LRB-", "REF", "-RRB-", "is", "implemented", "."], ["The", "thresholds", "\\", "-LRB-", "th_a\\", "-RRB-", "and", "\\", "-LRB-", "th_b\\", "-RRB-", "are", "set", "to", "\\", "-LRB-", "0.4\\", "-RRB-", "and", "\\", "-LRB-", "0.6\\", "-RRB-", ",", "respectively", "."], ["To", "build", "the", "classification", "networks", ",", "one", "ResNet-50", "-LSB-", "14", "-RSB-", "and", "one", "GoogleNet", "-LSB-", "15", "-RSB-", "are", "used", "as", "the", "classification", "networks", "."], ["Both", "of", "the", "classifiers", "are", "fine-tuned", "from", "the", "ImageNet", "pre-trained", "models", "using", "the", "standard", "SGD", "algorithm", "and", "the", "back-propagation", "algorithm", "at", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."]], "ner": [[], [], [], [[111, 111, "p"], [123, 123, "v"], [116, 116, "p"], [128, 128, "v"]], [[140, 140, "a"], [146, 146, "a"]], [[179, 180, "p"], [179, 180, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[23, 23, "v"], [32, 32, "v"], [47, 47, "v"]], [[63, 63, "v"], [81, 81, "v"]], [[91, 92, "a"]], [[123, 123, "v"], [128, 128, "v"]], [[136, 137, "a"], [139, 139, "v"], [140, 140, "a"], [145, 145, "v"], [146, 146, "a"]], [[165, 165, "a"], [171, 172, "a"], [175, 176, "a"], [179, 180, "p"], [184, 186, "v"]]], "predicted_relations": [[], [], [], [[123, 123, 116, 116, "USED-FOR"], [128, 128, 116, 116, "USED-FOR"]], [], []]}
{"doc_key": "1807.09388-ef6670b8-a114-4487-934e-2bc95487eb12", "sentences": [["We", "train", "and", "evaluate", "the", "proposed", "LAPRAN", "with", "three", "widely", "used", "benchmarking", "datasets", "."], ["The", "first", "two", "are", "MNIST", "and", "CIFAR10", "."], ["The", "third", "dataset", "is", "made", "following", "the", "rule", "used", "in", "prior", "SR", "work", "-LSB-", "21", "-RSB-", ",", "-LSB-", "23", "-RSB-", ",", "-LSB-", "32", "-RSB-", ",", "which", "uses", "91", "images", "from", "Yang", "et", "al", "."], ["-LSB-", "38", "-RSB-", "and", "200", "images", "from", "the", "Berkeley", "Segmentation", "Dataset", "-LRB-", "BSD", "-RRB-", "-LSB-", "0", "-RSB-", "."], ["The", "291", "images", "are", "augmented", "-LRB-", "rotation", "and", "flip", "-RRB-", "and", "cut", "into", "\\", "-LRB-", "228,688\\", "-RRB-", "patches", "as", "the", "training", "data", "."], ["Set5", "-LSB-", "3", "-RSB-", "and", "Set14", "-LSB-", "41", "-RSB-", "are", "pre-processed", "using", "the", "same", "method", "and", "used", "for", "testing", "."]], "ner": [[[6, 6, "a"]], [[18, 18, "a"], [20, 20, "a"]], [], [], [[80, 80, "p"], [82, 82, "p"]], [[97, 97, "a"], [102, 102, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "v"]], [[16, 16, "v"], [18, 18, "a"], [20, 20, "a"]], [[23, 23, "v"], [49, 49, "v"]], [[60, 60, "v"], [64, 69, "a"]], [[75, 75, "v"], [89, 89, "v"]], [[97, 97, "a"], [102, 102, "a"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1807.09388-4a82ee49-6ace-4c29-a28a-808759bbf7ba", "sentences": [["We", "implemented", "a", "4-stage", "LAPRAN", "for", "CS", "image", "reconstruction", "."], ["We", "resize", "each", "training", "image", "to", "\\", "-LRB-", "64", "\\times", "64\\", "-RRB-", "and", "train", "the", "LAPRAN", "with", "a", "batch", "size", "of", "128", "for", "100", "epochs", "with", "early", "stopping", "."], ["We", "use", "Adam", "solver", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "1", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "training", "takes", "roughly", "two", "days", "on", "a", "single", "NVidia", "Titan", "X", "GPU", "."]], "ner": [[[4, 4, "a"]], [[25, 25, "a"], [28, 29, "p"], [31, 31, "v"], [34, 34, "p"], [33, 33, "v"], [13, 14, "a"], [29, 29, "p"]], [[42, 42, "p"], [41, 41, "v"], [45, 46, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "v"], [4, 4, "a"]], [[18, 18, "v"], [20, 20, "v"], [25, 25, "a"], [28, 29, "p"], [31, 31, "v"], [33, 33, "v"], [34, 34, "p"]], [[41, 42, "a"], [45, 46, "p"], [50, 50, "v"], [52, 54, "v"]], [[63, 63, "v"]]], "predicted_relations": [[], [[28, 29, 25, 25, "USED-FOR"], [28, 29, 13, 14, "USED-FOR"], [31, 31, 34, 34, "USED-FOR"], [34, 34, 25, 25, "USED-FOR"], [34, 34, 13, 14, "USED-FOR"], [33, 33, 34, 34, "USED-FOR"], [33, 33, 29, 29, "USED-FOR"], [29, 29, 25, 25, "USED-FOR"], [29, 29, 13, 14, "USED-FOR"]], [], []]}
{"doc_key": "1812.09926-07e05147-b066-403f-b989-8708aa48c528", "sentences": [["In", "the", "searching", "stage", ",", "we", "train", "a", "small", "network", "stacked", "by", "8", "cells", "-LRB-", "parent", "graphs", "-RRB-", "using", "SNAS", "with", "three", "levels", "of", "resource", "constraint", "for", "150", "epochs", "."], ["This", "network", "size", "is", "determined", "to", "fit", "into", "a", "single", "GPU", "."], ["Single-level", "optimization", "is", "employed", "to", "optimize", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\alpha", "-RCB-", "\\", "-RRB-", "over", "the", "same", "dataset", "as", "opposed", "to", "bilevel", "optimization", "employed", "by", "DARTS", "."], ["The", "rest", "of", "the", "setup", "follows", "DARTS", "-LRB-", "Appendix", "G.1", "-RRB-", "."], ["The", "search", "takes", "32", "hoursThe", "batch", "size", "of", "SNAS", "is", "64", "and", "that", "of", "ENAS", "is", "160.", "on", "a", "single", "GPUAll", "the", "experiments", "were", "performed", "using", "NVIDIA", "TITAN", "Xp", "GPUs", "."]], "ner": [[[19, 19, "a"]], [], [[76, 76, "a"], [42, 43, "a"]], [[84, 84, "a"]], [[98, 98, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 12, "v"], [19, 19, "a"], [21, 21, "v"], [27, 27, "v"]], [], [[76, 76, "a"]], [[84, 84, "a"]], [[93, 93, "v"], [98, 98, "a"], [100, 100, "v"], [104, 104, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1812.09926-dbe872d5-d155-4a17-82f6-50b624453cf9", "sentences": [["We", "follow", "the", "training", "settings", "as", "in", "-LSB-", "13", "-RSB-", "."], ["The", "neural", "operation", "parameters", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\theta", "-RCB-", "\\", "-RRB-", "are", "optimized", "using", "momentum", "SGD", ",", "with", "initial", "learning", "rate", "\\", "-LRB-", "\\eta", "_", "-LCB-", "\\mathbf", "-LCB-", "\\theta", "-RCB-", "-RCB-", "=", "0.025\\", "-RRB-", "-LRB-", "annealed", "down", "to", "zero", "following", "a", "cosine", "schedule", "-RRB-", ",", "momentum", "0.9", ",", "and", "weight", "decay", "\\", "-LRB-", "3", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "architecture", "distribution", "parameters", "\\", "-LRB-", "\\mathbf", "-LCB-", "\\alpha", "-RCB-", "\\", "-RRB-", "are", "optimized", "by", "Adam", ",", "with", "initial", "learning", "rate", "\\", "-LRB-", "\\eta", "_", "-LCB-", "\\mathbf", "-LCB-", "\\alpha", "-RCB-", "-RCB-", "=", "3", "\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "momentum", "\\", "-LRB-", "\\beta", "=", "-LRB-", "0.5", ",", "0.999", "-RRB-", "\\", "-RRB-", "and", "weight", "decay", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["The", "batch", "size", "employed", "is", "64", "and", "the", "initial", "number", "of", "channels", "is", "16", "."]], "ner": [[], [[26, 27, "a"], [30, 32, "p"], [44, 44, "v"], [26, 26, "p"], [57, 57, "p"], [58, 58, "v"], [61, 62, "p"], [30, 32, "p"], [26, 26, "p"], [57, 57, "p"], [61, 62, "p"]], [[92, 94, "p"], [115, 115, "p"], [128, 129, "p"], [89, 89, "a"], [92, 94, "p"], [115, 115, "p"], [128, 129, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[26, 27, "a"], [31, 32, "p"], [35, 42, "p"], [44, 44, "v"], [50, 50, "v"], [58, 58, "v"], [61, 62, "p"], [65, 65, "v"], [67, 70, "v"]], [[89, 89, "a"], [93, 94, "p"], [106, 106, "v"], [108, 111, "v"], [115, 115, "p"], [121, 123, "v"], [128, 129, "p"], [132, 135, "v"]], [[140, 141, "p"], [144, 144, "v"], [152, 152, "v"]]], "predicted_relations": [[], [[30, 32, 26, 27, "USED-FOR"], [26, 26, 26, 27, "USED-FOR"], [57, 57, 26, 27, "USED-FOR"], [61, 62, 26, 27, "USED-FOR"], [30, 32, 26, 27, "USED-FOR"], [26, 26, 26, 27, "USED-FOR"], [57, 57, 26, 27, "USED-FOR"], [61, 62, 26, 27, "USED-FOR"]], [[92, 94, 89, 89, "USED-FOR"], [115, 115, 89, 89, "USED-FOR"], [128, 129, 89, 89, "USED-FOR"], [92, 94, 89, 89, "USED-FOR"], [115, 115, 89, 89, "USED-FOR"], [128, 129, 89, 89, "USED-FOR"]], []]}
{"doc_key": "1812.05276-79705688-5c23-4cd9-83a4-20fc73079c13", "sentences": [["During", "training", ",", "we", "use", "ADAM", "-LSB-", "17", "-RSB-", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.001", "for", "the", "first", "90", "epochs", "and", "then", "decay", "the", "learning", "rate", "by", "0.1", "in", "every", "10", "epochs", "."], ["We", "train", "120", "epochs", "in", "total", "."], ["Each", "batch", "consists", "of", "8", "point", "clouds", "evenly", "distributed", "on", "4", "GPU", "cards", "."], ["For", "each", "input", "point", "cloud", ",", "we", "sample", "64", "proposals", ",", "with", "a", "ratio", "of", "1:3", "for", "positives", "and", "negatives", "."], ["Our", "implementation", "is", "based", "on", "Tensorflow", "-LSB-", "1", "-RSB-", "."], ["During", "training", "the", "car", "model", ",", "a", "proposal", "is", "considered", "positive", "if", "its", "PointsIoU", "with", "a", "certain", "ground-truth", "box", "is", "higher", "than", "0.55", "and", "negative", "if", "its", "PointsIoU", "is", "less", "than", "0.55", "with", "all", "ground-truth", "boxes", "."], ["The", "positive", "and", "negative", "PointsIoU", "thresholds", "are", "0.5", "and", "0.5", "for", "the", "pedestrian", "and", "cyclist", "model", "."]], "ner": [[[5, 5, "a"], [12, 14, "p"], [16, 16, "v"], [29, 29, "v"]], [], [], [], [[82, 82, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [13, 14, "p"], [16, 16, "v"], [20, 20, "v"], [21, 21, "p"], [26, 27, "p"], [29, 29, "v"], [32, 32, "v"], [33, 33, "p"]], [[37, 37, "v"], [38, 38, "p"]], [[46, 46, "v"], [52, 52, "v"]], [[64, 64, "v"], [71, 71, "v"]], [[82, 82, "a"]], [[90, 91, "a"], [109, 109, "v"], [118, 118, "v"]], [[131, 131, "v"], [133, 133, "v"], [134, 139, "c"]]], "predicted_relations": [[[12, 14, 5, 5, "USED-FOR"], [16, 16, 12, 14, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "1807.10675-d3ee7e57-d032-46cb-8423-7b9903353fd7", "sentences": [["To", "remain", "comparable", "with", "the", "baseline", "models", "on", "CoNLL", "-LSB-", "0", "-RSB-", "and", "GermEval", "-LSB-", "12", "-RSB-", ",", "we", "train", "the", "word", "embeddings", "with", "dimension", "100Lample", "et", "al", "."], ["-LSB-", "0", "-RSB-", "use", "dimension", "100", "for", "English", ",", "but", "64", "for", "German", "."], ["We", "increase", "this", "dimension", "to", "close", "the", "gap.", ",", "window", "size", "of", "8", "and", "minimum", "word", "count", "threshold", "of", "4", ",", "consequently", ",", "setting", "the", "LSTM", "dimension", "to", "100", "as", "wellFor", "word2vec", ",", "we", "performed", "an", "extensive", "search", "on", "numerous", "embeddings", "with", "dimension", "values", "\\", "-LRB-", "-LRB-", "50,100,150,200,300", "-RRB-", "\\", "-RRB-", "along", "with", "minimum", "word", "count", "threshold", "and", "window", "size", "values", "in", "the", "range", "of", "\\", "-LRB-", "-LSB-", "4,200", "-RSB-", "\\", "-RRB-", "and", "\\", "-LRB-", "-LSB-", "5,10", "-RSB-", "\\", "-RRB-", ",", "respectively", "."], ["However", ",", "no", "major", "differences", "were", "observed", "in", "the", "final", "results", "..", "We", "choose", "dimension", "25", "for", "character-based", "embeddings", "and", "the", "final", "CRF-layer", ",", "and", "train", "the", "network", "in", "100", "epochs", "with", "a", "batch-size", "of", "1", "and", "dropout", "rate", "of", "0.5", "."], ["As", "an", "optimization", "method", ",", "we", "use", "the", "stochastic", "gradient", "descent", "with", "a", "learning", "rate", "of", "0.005", "."], ["Apart", "from", "fitting", "the", "LSTM", "dimension", "to", "300", "while", "using", "the", "300-dimensional", "pretrained", "German", "fastText", "embeddings", "-LSB-", "24", "-RSB-", ",", "the", "model", "is", "fixed", "throughout", "our", "experiments", "to", "these", "settings", "."], ["Any", "further", "sophisticated", "hyperparameter", "tuning", "-LRB-", "e.g", "."], ["Population", "Based", "Training", "-RRB-", "is", "left", "for", "future", "work", "."]], "ner": [[[21, 22, "a"], [24, 24, "p"], [24, 24, "p"], [24, 24, "p"]], [[33, 33, "p"], [34, 34, "v"], [34, 34, "v"], [36, 36, "c"], [39, 39, "v"], [41, 41, "c"], [34, 34, "v"], [33, 33, "p"], [34, 34, "v"], [33, 33, "p"]], [[46, 46, "p"], [69, 69, "p"], [85, 85, "p"], [71, 71, "v"], [90, 90, "v"], [90, 90, "v"], [71, 71, "v"], [90, 90, "v"], [71, 71, "v"], [90, 90, "v"], [90, 90, "v"], [52, 53, "p"], [101, 102, "p"], [55, 55, "v"], [119, 119, "v"], [119, 119, "v"], [57, 60, "p"], [96, 99, "p"], [62, 62, "v"], [111, 111, "v"], [62, 62, "v"], [111, 111, "v"], [90, 90, "v"], [111, 111, "v"], [68, 68, "a"], [46, 46, "p"], [69, 69, "p"], [85, 85, "p"], [71, 71, "v"], [90, 90, "v"], [90, 90, "v"], [46, 46, "p"], [69, 69, "p"], [85, 85, "p"]], [[140, 140, "p"], [155, 155, "v"], [155, 155, "v"], [141, 141, "v"], [155, 155, "v"], [166, 166, "v"], [140, 140, "p"], [155, 155, "v"], [148, 148, "a"], [140, 140, "p"], [141, 141, "v"], [163, 164, "a"], [163, 164, "p"], [166, 166, "v"]], [[176, 178, "a"], [181, 182, "p"], [184, 184, "v"]], [[191, 191, "p"], [199, 199, "c"], [193, 193, "v"], [197, 197, "v"], [190, 190, "a"], [191, 191, "p"], [193, 193, "v"], [197, 197, "v"], [191, 191, "p"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [13, 13, "a"], [24, 24, "p"]], [[33, 33, "p"], [34, 34, "v"], [39, 39, "v"]], [[52, 53, "p"], [55, 55, "v"], [62, 62, "v"], [68, 68, "a"], [71, 71, "v"], [74, 74, "a"]], [[140, 140, "p"], [141, 141, "v"], [155, 155, "v"], [156, 156, "p"], [159, 159, "p"], [161, 161, "v"], [163, 164, "p"], [166, 166, "v"]], [[176, 178, "a"], [181, 182, "p"], [184, 184, "v"]], [[190, 190, "a"], [190, 191, "p"], [193, 193, "v"], [197, 197, "v"]], [], []], "predicted_relations": [[[24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [[34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [36, 36, 34, 34, "USED-FOR"], [36, 36, 34, 34, "USED-FOR"], [36, 36, 34, 34, "USED-FOR"], [36, 36, 34, 34, "USED-FOR"], [39, 39, 33, 33, "USED-FOR"], [39, 39, 33, 33, "USED-FOR"], [39, 39, 33, 33, "USED-FOR"], [41, 41, 34, 34, "USED-FOR"], [41, 41, 34, 34, "USED-FOR"], [41, 41, 39, 39, "USED-FOR"], [41, 41, 34, 34, "USED-FOR"], [41, 41, 34, 34, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"], [34, 34, 33, 33, "USED-FOR"]], [[46, 46, 68, 68, "USED-FOR"], [69, 69, 68, 68, "USED-FOR"], [85, 85, 68, 68, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [52, 53, 68, 68, "USED-FOR"], [101, 102, 68, 68, "USED-FOR"], [55, 55, 46, 46, "USED-FOR"], [55, 55, 69, 69, "USED-FOR"], [55, 55, 46, 46, "USED-FOR"], [55, 55, 69, 69, "USED-FOR"], [55, 55, 46, 46, "USED-FOR"], [55, 55, 69, 69, "USED-FOR"], [57, 60, 68, 68, "USED-FOR"], [96, 99, 68, 68, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [62, 62, 57, 60, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [62, 62, 57, 60, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [62, 62, 46, 46, "USED-FOR"], [62, 62, 69, 69, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [46, 46, 68, 68, "USED-FOR"], [69, 69, 68, 68, "USED-FOR"], [85, 85, 68, 68, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [71, 71, 69, 69, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 52, 53, "USED-FOR"], [90, 90, 57, 60, "USED-FOR"], [90, 90, 96, 99, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [90, 90, 46, 46, "USED-FOR"], [90, 90, 69, 69, "USED-FOR"], [90, 90, 85, 85, "USED-FOR"], [46, 46, 68, 68, "USED-FOR"], [69, 69, 68, 68, "USED-FOR"], [85, 85, 68, 68, "USED-FOR"]], [[140, 140, 148, 148, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [166, 166, 163, 164, "USED-FOR"], [140, 140, 148, 148, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [155, 155, 140, 140, "USED-FOR"], [140, 140, 148, 148, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [141, 141, 140, 140, "USED-FOR"], [163, 164, 148, 148, "USED-FOR"], [163, 164, 163, 164, "USED-FOR"], [166, 166, 163, 164, "USED-FOR"]], [], [[191, 191, 190, 190, "USED-FOR"], [199, 199, 193, 193, "USED-FOR"], [199, 199, 197, 197, "USED-FOR"], [199, 199, 193, 193, "USED-FOR"], [199, 199, 197, 197, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [191, 191, 190, 190, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [193, 193, 191, 191, "USED-FOR"], [191, 191, 190, 190, "USED-FOR"]], [], []]}
{"doc_key": "1802.02601-197e1dc4-e8f3-477d-a414-b10d5721d4f7", "sentences": [["In", "all", "our", "experiments", ",", "we", "set", "\\", "-LRB-", "N", "=", "1\\", "-RRB-", "and", "\\", "-LRB-", "k", "=", "4\\", "-RRB-", ",", "and", "used", "SGD", "with", "Nesterov", "momentum", "-LSB-", "0", "-RSB-", ",", "-LSB-", "38", "-RSB-", ",", "-LSB-", "42", "-RSB-", "and", "cross-entropy", "loss", "in", "training", "."], ["The", "initial", "learning", "rate", "was", "set", "at", "0.1", ",", "weight", "decay", "to", "\\", "-LRB-", "5.0", "-LCB-", "\\times", "-RCB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "momentum", "to", "0.9", "and", "minibatch", "size", "to", "64", "."], ["The", "learning", "rate", "was", "dropped", "by", "a", "factor", "of", "0.2", "at", "60", ",", "120", "and", "160", "epochs", ",", "and", "we", "trained", "for", "a", "total", "of", "200", "epochs", ",", "following", "the", "settings", "used", "in", "-LSB-", "51", "-RSB-", "."]], "ner": [[[23, 23, "a"], [26, 26, "p"], [25, 26, "a"], [39, 40, "a"]], [[46, 47, "p"], [51, 51, "v"], [53, 54, "p"], [69, 69, "p"], [71, 71, "v"], [73, 74, "p"], [76, 76, "v"]], [[79, 80, "p"]]], "relations": [[], [], []], "predicted_ner": [[[9, 9, "p"], [9, 11, "v"], [16, 16, "p"], [16, 18, "v"], [23, 23, "a"], [25, 26, "a"], [39, 40, "a"]], [[46, 47, "p"], [51, 51, "v"], [53, 54, "p"], [58, 58, "v"], [62, 65, "v"], [69, 69, "p"], [71, 71, "v"], [73, 74, "p"], [76, 76, "v"]], [[79, 80, "p"], [87, 87, "v"], [89, 89, "v"], [91, 91, "v"], [93, 93, "v"], [94, 94, "p"], [103, 103, "v"], [104, 104, "p"]]], "predicted_relations": [[[26, 26, 23, 23, "USED-FOR"], [26, 26, 25, 26, "USED-FOR"]], [[51, 51, 53, 54, "USED-FOR"], [71, 71, 73, 74, "USED-FOR"], [76, 76, 69, 69, "USED-FOR"]], []]}
{"doc_key": "1809.04730-45c3e6a5-2279-47d9-87b9-61de1f3a3342", "sentences": [["As", "real-time", "processing", "is", "required", "for", "autonomous", "vehicle", "operation", ",", "we", "adopted", "the", "ENet", "-LSB-", "11", "-RSB-", "architecture", "for", "semantic", "segmentation", "."], ["The", "model", "was", "trained", "and", "tested", "on", "a", "GTX", "1080", "Ti", "GPU", "and", "also", "tested", "on", "a", "NVIDIA", "DRIVE", "PX2", "."], ["The", "network", "can", "take", "arbitrary", "sized", "images", "for", "both", "training", "and", "testing", ",", "and", "can", "predict", "a", "segmented", "image", "with", "a", "resolution", "of", "\\", "-LRB-", "640", "\\times", "360\\", "-RRB-", "."], ["The", "learning", "rate", "was", "set", "to", "be", "\\", "-LRB-", "5e-6\\", "-RRB-", "at", "the", "beginning", "and", "decayed", "by", "\\", "-LRB-", "1e-1\\", "-RRB-", "when", "the", "validation", "error", "stopped", "improving", "for", "100", "epochs", "."]], "ner": [[[13, 13, "a"]], [], [], [[74, 75, "a"], [82, 82, "v"], [92, 92, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[13, 13, "a"]], [], [[44, 44, "a"], [68, 68, "v"], [70, 70, "v"]], [[74, 75, "p"], [82, 82, "v"], [92, 92, "v"], [101, 101, "v"], [102, 102, "p"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1809.04730-288f3741-0ff1-412f-b1fe-6d936dbd4261", "sentences": [["Models", "were", "firstly", "trained", "on", "the", "Cityscapes", "dataset", "-LSB-", "1", "-RSB-", ",", "then", "fine-tuned", "using", "our", "USYD_Cloudy_Set", "."], ["The", "original", "Cityscapes", "dataset", "has", "more", "than", "30", "classes", ",", "of", "which", "a", "number", "are", "not", "relevant", "to", "our", "local", "environment", "."], ["To", "optimize", "the", "network", ",", "we", "remapped", "these", "30", "classes", "into", "12", "categories", "to", "better", "represent", "the", "categories", "expected", "in", "the", "USYD", "datasets", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 7, "a"], [16, 16, "a"]], [[20, 21, "a"], [26, 26, "p"], [25, 25, "v"]], [[43, 43, "a"], [49, 49, "p"], [48, 48, "v"], [51, 51, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 7, "a"], [16, 16, "a"]], [[20, 21, "a"], [25, 25, "v"]], [[48, 48, "v"], [51, 51, "v"]], []], "predicted_relations": [[], [[26, 26, 20, 21, "USED-FOR"], [25, 25, 26, 26, "USED-FOR"]], [[49, 49, 43, 43, "USED-FOR"], [48, 48, 49, 49, "USED-FOR"], [51, 51, 49, 49, "USED-FOR"]], []]}
{"doc_key": "1805.05151-b889d3db-4af5-4189-a506-ca3a17fd4e2e", "sentences": [["We", "use", "100", ",", "150", ",", "and", "200", "filters", "each", "having", "the", "window", "size", "of", "2", ",", "3", ",", "and", "4", ",", "respectively", ",", "and", "pooling", "length", "of", "2", ",", "3", ",", "and", "4", ",", "respectively", "."], ["We", "do", "not", "tune", "these", "hyperparameters", "in", "any", "experimental", "setting", "since", "the", "goal", "was", "to", "have", "an", "end-to-end", "comparison", "with", "the", "same", "hyperparameter", "setting", "and", "understand", "whether", "our", "approach", "can", "outperform", "the", "baselines", "or", "not", "."], ["Furthermore", ",", "we", "do", "not", "filter", "out", "any", "vocabulary", "item", "in", "any", "settings", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[2, 2, "v"], [4, 4, "v"], [7, 7, "v"], [15, 15, "v"], [17, 17, "v"], [20, 20, "v"], [28, 28, "v"], [30, 30, "v"], [33, 33, "v"]], [[65, 65, "a"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1807.08447-84f7255a-05ed-4f1d-88db-7622463c3ea6", "sentences": [["\u2013", "Entity", "Embedding", "Size", ":", "256", ",", "Relation", "Embedding", "Size=64", ",", "Attribute", "Embedding", "Size", "=", "16", ",", "Type", "Embedding", "Size", "=", "16", ",", "Attribute", "Value", "Embedding", "Size", "=", "512", "."], ["We", "tried", "multiple", "batch", "sizes", "with", "very", "minor", "difference", "in", "performance", "and", "finally", "used", "size", "of", "2000", "."], ["For", "hidden", "units", "per", "layer", ",", "we", "use", "size", "=", "64", "."], ["We", "used", "\\", "-LRB-", "C=50\\", "-RRB-", "negative", "samples", "and", "\\", "-LRB-", "Z=20\\", "-RRB-", "negative", "labels", "."], ["The", "learning", "rate", "was", "initialized", "as", "0.01", "and", "then", "decayed", "over", "epochs", "."], ["We", "ran", "our", "experiments", "for", "5", "epochs", "after", "which", "the", "training", "starts", "to", "convert", "as", "the", "dataset", "is", "very", "large", "."], ["We", "use", "loss", "weights", "\\", "-LRB-", "b\\", "-RRB-", "as", "0.6", "and", "margin", "as", "1", "."], ["Further", ",", "we", "use", "\\", "-LRB-", "K", "=", "50\\", "-RRB-", "random", "walks", "of", "length", "\\", "-LRB-", "l", "=", "3\\", "-RRB-", "for", "each", "entity", "We", "used", "a", "train/test", "split", "of", "60", "%", "/40", "%", "for", "both", "the", "triples", "set", "and", "labels", "set", "."], ["For", "baselines", ",", "we", "used", "the", "implementations", "provided", "by", "the", "respective", "authors", "and", "performed", "grid", "search", "for", "all", "methods", "according", "to", "their", "requirements", "."]], "ner": [[[1, 2, "a"], [3, 3, "p"], [9, 9, "p"], [13, 13, "p"], [19, 19, "p"], [26, 26, "p"], [5, 5, "v"], [9, 9, "v"], [15, 15, "v"], [21, 21, "v"], [28, 28, "v"]], [], [[58, 58, "v"]], [[64, 64, "a"], [71, 71, "a"]], [], [], [], [[131, 131, "a"], [141, 141, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [15, 15, "v"], [21, 21, "v"], [28, 28, "v"]], [[46, 46, "v"]], [[58, 58, "v"]], [[64, 64, "v"], [71, 71, "v"]], [[77, 78, "p"], [82, 82, "v"]], [[94, 94, "v"], [95, 95, "p"]], [[119, 119, "v"], [123, 123, "v"]], [[131, 131, "p"], [131, 133, "v"], [141, 141, "p"], [143, 143, "v"], [154, 155, "v"]], []], "predicted_relations": [[[3, 3, 1, 2, "USED-FOR"], [9, 9, 1, 2, "USED-FOR"], [13, 13, 1, 2, "USED-FOR"], [19, 19, 1, 2, "USED-FOR"], [9, 9, 3, 3, "USED-FOR"], [9, 9, 9, 9, "USED-FOR"], [9, 9, 13, 13, "USED-FOR"], [15, 15, 9, 9, "USED-FOR"], [15, 15, 13, 13, "USED-FOR"], [15, 15, 19, 19, "USED-FOR"], [21, 21, 9, 9, "USED-FOR"], [21, 21, 13, 13, "USED-FOR"], [21, 21, 19, 19, "USED-FOR"], [21, 21, 26, 26, "USED-FOR"]], [], [], [], [], [], [], [], []]}
{"doc_key": "1807.02609-f48cacfd-8f50-442e-8659-8bad3c65ac30", "sentences": [["Datasets", "."], ["We", "use", "CIFAR-10/100", ",", "ImageNet", "and", "Caltech-UCSD", "Birds", "-LRB-", "CUB", "-RRB-", "datasets", "."], ["The", "CIFAR", "datasets", "have", "\\", "-LRB-", "50", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "training", "images", "and", "\\", "-LRB-", "10", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "test", "images", "."], ["Each", "image", "has", "\\", "-LRB-", "32^2\\", "-RRB-", "size", "and", "each", "pixel", "has", "RGB", "color", "."], ["CIFAR-10/100", "have", "10", "and", "100", "classes", ",", "respectively", "."], ["Following", ",", "we", "use", "data-augmentation", "techniques", "to", "the", "training", "images", ":", "random", "horizontal", "flip", ",", "random-crop", "with", "4", "pixel", "zero-padding", ",", "normalizing", "pixel", "value", "by", "channel", "means", "and", "standard", "deviations", "."], ["ImageNet", "has", "\\", "-LRB-", "1.2\\", "-RRB-", "million", "training", "images", "and", "\\", "-LRB-", "50", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "validation", "images", "of", "\\", "-LRB-", "1,000\\", "-RRB-", "classes", "."], ["Similarly", ",", "CUB", "has", "\\", "-LRB-", "5", "-LCB-", ",", "-RCB-", "994\\", "-RRB-", "training", "images", "and", "\\", "-LRB-", "5", "-LCB-", ",", "-RCB-", "794\\", "-RRB-", "test", "images", "of", "200", "fine-grained", "bird", "species", "."], ["For", "hierarchical", "anytime", "prediction", ",", "we", "obtain", "a", "hierarchical", "taxonomy", "of", "the", "CUB", "dataset", "from", "WordNet", "by", "following", "."], ["We", "obtain", "99", "non-leaf", "nodes", "-LRB-", "i.e.", ",", "coarse", "labels", "-RRB-", "from", "the", "taxonomy", "with", "maximum", "depth", "8", "."], ["By", "taking", "ancestors", "-LRB-", "i.e.", ",", "coarse", "labels", "-RRB-", "of", "the", "leaf", "nodes", "-LRB-", "i.e.", ",", "original", "fine-grained", "labels", "-RRB-", "up", "to", "distance", "3", ",", "we", "build", "\\", "-LRB-", "D=4\\", "-RRB-", "different", "levels", "of", "labels", ":", "200", ",", "183", ",", "149", "and", "80", "labels", "from", "fine-grained", "to", "coarse-grained", "."], ["Note", "that", "CIFAR-100", "has", "its", "own", "20", "coarse-grained", "labels", "."], ["We", "use", "the", "same", "augmentation", "techniques", "as", "for", "training", "ImageNet", "and", "CUB", "images", "."], ["Note", "that", "the", "image", "size", "after", "the", "augmentations", "is", "\\", "-LRB-", "224^2\\", "-RRB-", "."]], "ner": [[], [[4, 4, "a"], [4, 4, "v"], [4, 4, "c"], [4, 4, "v"], [6, 6, "a"]], [[38, 39, "p"], [32, 32, "v"], [38, 39, "p"]], [[46, 46, "v"]], [[56, 56, "a"], [61, 61, "p"], [56, 56, "v"], [58, 58, "v"], [56, 56, "c"], [56, 56, "v"], [60, 60, "v"], [61, 61, "p"], [61, 61, "p"]], [[73, 74, "p"], [73, 74, "p"], [73, 74, "p"], [69, 70, "a"]], [[103, 104, "p"], [121, 121, "p"], [96, 96, "a"], [103, 104, "p"], [114, 115, "p"], [121, 121, "p"], [119, 119, "v"], [103, 104, "p"], [121, 121, "p"]], [[135, 136, "p"], [146, 147, "p"], [135, 136, "p"], [135, 136, "p"], [146, 147, "p"], [149, 149, "v"], [150, 152, "c"], [149, 149, "v"], [150, 150, "c"]], [[169, 169, "a"]], [[181, 182, "p"], [175, 175, "v"], [176, 177, "c"], [188, 189, "p"], [190, 190, "v"]], [[228, 228, "v"], [198, 199, "p"], [214, 214, "p"], [215, 215, "v"], [224, 226, "p"], [228, 228, "v"], [209, 209, "c"], [237, 237, "c"], [230, 230, "v"], [232, 232, "v"], [234, 234, "v"], [239, 239, "c"]], [[243, 243, "v"], [243, 243, "c"], [248, 248, "c"]], [[260, 260, "a"]], [[268, 269, "p"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[6, 6, "a"]], [[16, 16, "a"], [21, 25, "v"], [32, 36, "v"]], [[46, 46, "v"]], [[58, 58, "v"], [60, 60, "v"]], [[82, 82, "v"]], [[96, 96, "a"], [100, 100, "v"], [108, 112, "v"], [119, 119, "v"]], [[125, 125, "a"], [129, 133, "v"], [140, 144, "v"], [149, 149, "v"]], [[166, 167, "a"], [169, 169, "a"]], [[175, 175, "v"], [190, 190, "v"]], [[215, 215, "v"], [221, 221, "v"], [228, 228, "v"], [234, 234, "v"]], [[243, 243, "a"], [247, 247, "v"]], [[260, 260, "a"], [262, 262, "a"]], [[276, 276, "v"]]], "predicted_relations": [[], [[4, 4, 4, 4, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"]], [[32, 32, 38, 39, "USED-FOR"], [32, 32, 38, 39, "USED-FOR"]], [], [[61, 61, 56, 56, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [58, 58, 61, 61, "USED-FOR"], [58, 58, 61, 61, "USED-FOR"], [58, 58, 61, 61, "USED-FOR"], [56, 56, 56, 56, "USED-FOR"], [56, 56, 58, 58, "USED-FOR"], [56, 56, 56, 56, "USED-FOR"], [56, 56, 60, 60, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [56, 56, 61, 61, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [60, 60, 61, 61, "USED-FOR"], [61, 61, 56, 56, "USED-FOR"], [61, 61, 56, 56, "USED-FOR"]], [[73, 74, 69, 70, "USED-FOR"], [73, 74, 69, 70, "USED-FOR"], [73, 74, 69, 70, "USED-FOR"]], [[103, 104, 96, 96, "USED-FOR"], [103, 104, 96, 96, "USED-FOR"], [114, 115, 96, 96, "USED-FOR"], [119, 119, 121, 121, "USED-FOR"], [119, 119, 114, 115, "USED-FOR"], [119, 119, 121, 121, "USED-FOR"], [119, 119, 121, 121, "USED-FOR"], [103, 104, 96, 96, "USED-FOR"]], [[149, 149, 135, 136, "USED-FOR"], [149, 149, 146, 147, "USED-FOR"], [149, 149, 135, 136, "USED-FOR"], [149, 149, 135, 136, "USED-FOR"], [149, 149, 146, 147, "USED-FOR"], [150, 152, 149, 149, "USED-FOR"], [150, 152, 149, 149, "USED-FOR"], [149, 149, 135, 136, "USED-FOR"], [149, 149, 146, 147, "USED-FOR"], [149, 149, 135, 136, "USED-FOR"], [149, 149, 135, 136, "USED-FOR"], [149, 149, 146, 147, "USED-FOR"], [150, 150, 149, 149, "USED-FOR"], [150, 150, 149, 149, "USED-FOR"]], [], [[175, 175, 188, 189, "USED-FOR"], [190, 190, 188, 189, "USED-FOR"]], [[228, 228, 214, 214, "USED-FOR"], [215, 215, 214, 214, "USED-FOR"], [228, 228, 214, 214, "USED-FOR"], [209, 209, 228, 228, "USED-FOR"], [209, 209, 228, 228, "USED-FOR"], [209, 209, 232, 232, "USED-FOR"], [237, 237, 228, 228, "USED-FOR"], [237, 237, 228, 228, "USED-FOR"], [237, 237, 230, 230, "USED-FOR"], [237, 237, 232, 232, "USED-FOR"], [237, 237, 234, 234, "USED-FOR"], [239, 239, 232, 232, "USED-FOR"]], [[243, 243, 243, 243, "USED-FOR"], [248, 248, 243, 243, "USED-FOR"]], [], []]}
{"doc_key": "1807.02609-1354950e-632d-41c0-8197-731280fe449e", "sentences": [["Optimization", "."], ["All", "models", "are", "trained", "by", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "Nesterov", "momentum", "of", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "without", "dampening", "and", "MSRA", "initialization", "."], ["We", "use", "a", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "for", "all", "experiments", "."], ["The", "models", "for", "CIFAR", "and", "CUB", "are", "trained", "for", "300", "and", "150", "epochs", ",", "respectively", ",", "with", "a", "batch", "size", "of", "64", "."], ["The", "learning", "rate", "is", "divided", "by", "10", "after", "\\", "-LRB-", "50\\", "%", "\\", "-RRB-", "and", "\\", "-LRB-", "75\\", "%", "\\", "-RRB-", "epochs", "."], ["For", "ImageNet", ",", "we", "use", "same", "hyperparameters", "as", "CIFAR", "except", "the", "learning", "schedule", ",", "where", "the", "total", "number", "of", "epochs", "is", "90", "and", "learing", "rate", "is", "diveded", "at", "30", "and", "60", "epochs", ",", "and", "the", "batch", "size", "of", "96", "."], ["We", "randomly", "select", "\\", "-LRB-", "5", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", ",", "\\", "-LRB-", "50", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", ",", "\\", "-LRB-", "1", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "images", "of", "the", "training", "set", "for", "validation", "in", "CIFAR", ",", "ImageNet", ",", "and", "CUB", "datasets", ",", "respectively", "."], ["Note", "that", "we", "use", "the", "original", "validation", "set", "as", "test", "set", "in", "ImageNet", "."], ["All", "models", "are", "averaged", "on", "5", "trials", "."]], "ner": [[], [[15, 15, "p"], [17, 17, "p"], [20, 20, "v"]], [[31, 32, "p"], [44, 46, "p"], [50, 50, "v"]], [[59, 61, "a"], [68, 68, "p"], [65, 65, "v"], [59, 59, "c"], [67, 67, "v"], [61, 61, "c"], [74, 75, "p"], [77, 77, "v"], [68, 68, "p"], [74, 75, "p"], [59, 59, "c"], [61, 61, "c"]], [[100, 100, "p"], [100, 100, "p"]], [[121, 121, "p"], [133, 133, "p"], [110, 110, "c"], [137, 138, "p"], [103, 103, "a"], [121, 121, "p"], [133, 133, "p"], [123, 123, "v"], [137, 138, "p"], [140, 140, "v"], [130, 130, "v"], [132, 132, "v"], [110, 110, "c"], [103, 103, "c"]], [[179, 179, "c"], [184, 184, "c"], [181, 181, "a"], [179, 179, "c"], [181, 181, "c"], [184, 184, "c"]], [[201, 201, "a"], [201, 201, "c"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[7, 12, "a"], [14, 15, "a"], [17, 17, "p"], [20, 20, "v"], [25, 25, "a"]], [[31, 32, "p"], [36, 39, "v"], [45, 46, "p"], [50, 50, "v"]], [[59, 59, "a"], [61, 61, "a"], [65, 65, "v"], [67, 67, "v"], [68, 68, "p"], [74, 75, "p"], [77, 77, "v"]], [[80, 81, "p"], [85, 85, "v"], [89, 90, "v"], [96, 97, "v"]], [[103, 103, "a"], [110, 110, "a"], [113, 114, "p"], [121, 121, "p"], [123, 123, "v"], [125, 126, "p"], [130, 130, "v"], [132, 132, "v"], [133, 133, "p"], [137, 138, "p"], [140, 140, "v"]], [[147, 151, "v"], [156, 160, "v"], [165, 169, "v"], [179, 179, "a"], [181, 181, "a"], [184, 184, "a"]], [[201, 201, "a"]], [[208, 208, "v"]]], "predicted_relations": [[], [[20, 20, 17, 17, "USED-FOR"]], [], [[68, 68, 59, 61, "USED-FOR"], [65, 65, 68, 68, "USED-FOR"], [65, 65, 68, 68, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [67, 67, 68, 68, "USED-FOR"], [74, 75, 59, 61, "USED-FOR"], [77, 77, 68, 68, "USED-FOR"], [77, 77, 68, 68, "USED-FOR"], [68, 68, 59, 61, "USED-FOR"], [74, 75, 59, 61, "USED-FOR"]], [], [[121, 121, 103, 103, "USED-FOR"], [110, 110, 132, 132, "USED-FOR"], [121, 121, 103, 103, "USED-FOR"], [123, 123, 121, 121, "USED-FOR"], [123, 123, 133, 133, "USED-FOR"], [123, 123, 121, 121, "USED-FOR"], [123, 123, 133, 133, "USED-FOR"], [140, 140, 133, 133, "USED-FOR"], [140, 140, 133, 133, "USED-FOR"], [130, 130, 121, 121, "USED-FOR"], [130, 130, 133, 133, "USED-FOR"], [130, 130, 121, 121, "USED-FOR"], [130, 130, 133, 133, "USED-FOR"], [132, 132, 133, 133, "USED-FOR"], [132, 132, 133, 133, "USED-FOR"], [110, 110, 132, 132, "USED-FOR"]], [], [], []]}
{"doc_key": "1810.12836-0ed8fa19-38b9-4f28-8632-5acae86dffe2", "sentences": [["Conversational", "Response", "Prediction", "."], ["We", "model", "the", "conversational", "response", "prediction", "task", "in", "the", "same", "manner", "as", "-LSB-", "25", "-RSB-", "."], ["We", "minimize", "the", "negative", "log-likelihood", "of", "\\", "-LRB-", "\\widetilde", "-LCB-", "P", "-RCB-", "-LRB-", "s_i^R", "\\mid", "s_i^I", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "s_i^I\\", "-RRB-", "is", "a", "single", "comment", "and", "\\", "-LRB-", "s_i^R\\", "-RRB-", "is", "its", "associated", "response", "comment", "."], ["For", "the", "response", "side", ",", "we", "model", "\\", "-LRB-", "g^R", "-LRB-", "s_i^R", "-RRB-", "\\", "-RRB-", "as", "\\", "-LRB-", "g", "-LRB-", "s_i^R", "-RRB-", "\\", "-RRB-", "followed", "by", "two", "fully-connected", "feedforward", "layers", "of", "size", "320", "and", "512", "with", "\\", "-LRB-", "tanh\\", "-RRB-", "activation", "."], ["For", "the", "input", "representation", ",", "however", ",", "we", "simply", "let", "\\", "-LRB-", "g^I", "-LRB-", "s_i^I", "-RRB-", "=", "g", "-LRB-", "s_i^I", "-RRB-", "\\", "-RRB-", ".In", "early", "experiments", ",", "letting", "the", "optimization", "of", "the", "conversational", "response", "task", "more", "directly", "influence", "the", "parameters", "of", "the", "underlying", "sentence", "encoder", "\\", "-LRB-", "g\\", "-RRB-", "led", "to", "better", "downstream", "task", "performance", "."]], "ner": [[[0, 2, "a"]], [], [[23, 24, "a"]], [[87, 89, "a"], [91, 91, "p"], [98, 98, "v"], [94, 94, "v"], [100, 100, "p"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[86, 86, "v"], [92, 92, "v"], [94, 94, "v"]], []], "predicted_relations": [[], [], [], [[91, 91, 87, 89, "USED-FOR"], [100, 100, 87, 89, "USED-FOR"]], []]}
{"doc_key": "1810.12836-7e62ef4a-564f-4343-b824-f56ae991c3ec", "sentences": [["Quick", "Thought", "."], ["We", "use", "a", "modified", "version", "of", "the", "Quick", "Thought", "task", "detailed", "by", "-LSB-", "13", "-RSB-", "."], ["We", "minimize", "the", "sum", "of", "the", "negative", "log-likelihoods", "of", "\\", "-LRB-", "\\widetilde", "-LCB-", "P", "-RCB-", "-LRB-", "s_i^R", "\\mid", "s_i^I", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\widetilde", "-LCB-", "P", "-RCB-", "-LRB-", "s_i^P", "\\mid", "s_i^I", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "s_i^I\\", "-RRB-", "is", "a", "sentence", "taken", "from", "an", "article", "and", "\\", "-LRB-", "s_i^P\\", "-RRB-", "and", "\\", "-LRB-", "s_i^R\\", "-RRB-", "are", "its", "predecessor", "and", "successor", "sentences", ",", "respectively", "."], ["For", "this", "task", ",", "we", "model", "all", "three", "of", "\\", "-LRB-", "g^P", "-LRB-", "s_i^P", "-RRB-", "\\", "-RRB-", ",", "\\", "-LRB-", "g^I", "-LRB-", "s_i^I", "-RRB-", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "g^R", "-LRB-", "s_i^R", "-RRB-", "\\", "-RRB-", "by", "\\", "-LRB-", "g\\", "-RRB-", "followed", "by", "separate", ",", "fully-connected", "feedforward", "layers", "of", "size", "320", "and", "512", "and", "using", "\\", "-LRB-", "tanh\\", "-RRB-", "activation", "."]], "ner": [[[0, 1, "a"]], [[10, 11, "a"]], [[22, 26, "a"]], [[132, 134, "a"], [136, 136, "p"], [144, 144, "v"], [139, 139, "v"], [146, 146, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [], [[94, 94, "v"], [137, 137, "v"], [139, 139, "v"]]], "predicted_relations": [[], [], [], [[136, 136, 132, 134, "USED-FOR"], [146, 146, 132, 134, "USED-FOR"]]]}
{"doc_key": "1810.12836-9cb44ec5-012e-4bb2-aae9-20c01992c07f", "sentences": [["Natural", "Language", "Inference", "-LRB-", "NLI", "-RRB-", "."], ["We", "also", "include", "an", "English-only", "natural", "language", "inference", "task", "-LSB-", "1", "-RSB-", "."], ["For", "this", "task", ",", "we", "first", "encode", "an", "input", "sentence", "\\", "-LRB-", "s_i^I\\", "-RRB-", "and", "its", "corresponding", "response", "hypothesis", "\\", "-LRB-", "s_i^R\\", "-RRB-", "into", "vectors", "\\", "-LRB-", "u_1\\", "-RRB-", "and", "\\", "-LRB-", "u_2\\", "-RRB-", "using", "\\", "-LRB-", "g\\", "-RRB-", "."], ["Following", "infersent17", ",", "the", "vectors", "\\", "-LRB-", "u_1\\", "-RRB-", ",", "\\", "-LRB-", "u_2\\", "-RRB-", "are", "then", "used", "to", "construct", "a", "relation", "feature", "vector", "\\", "-LRB-", "-LRB-", "u_1", ",", "u_2", ",", "|u_1-u_2|", ",", "u_1", "*", "u_2", "-RRB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "represents", "concatenation", "and", "\\", "-LRB-", "*", "\\", "-RRB-", "represents", "element-wise", "multiplication", "."], ["The", "relation", "vector", "is", "then", "fed", "into", "a", "single", "feedforward", "layer", "of", "size", "512", "followed", "by", "a", "softmax", "output", "layer", "that", "is", "used", "to", "perform", "the", "3-way", "NLI", "classification", "."]], "ner": [[], [], [[57, 57, "a"]], [[61, 61, "a"]], [[127, 129, "a"], [131, 131, "p"], [132, 132, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [[61, 61, "a"]], [[132, 132, "v"], [136, 136, "a"]]], "predicted_relations": [[], [], [], [], [[131, 131, 127, 129, "USED-FOR"]]]}
{"doc_key": "1810.12836-b2f36a58-3730-4dfd-a1bc-fc5f468578df", "sentences": [["Translation", "Ranking", "."], ["Our", "translation", "task", "setup", "is", "identical", "to", "the", "one", "used", "by", "-LSB-", "9", "-RSB-", "for", "bi-text", "retrieval", "."], ["We", "minimize", "the", "negative", "log-likelihood", "of", "\\", "-LRB-", "\\widetilde", "-LCB-", "P", "-RCB-", "-LRB-", "s_i", "\\mid", "t_i", "-RRB-", "\\", "-RRB-", ",", "where", "-LRB-", "\\", "-LRB-", "s_i\\", "-RRB-", ",", "\\", "-LRB-", "t_i\\", "-RRB-", "-RRB-", "is", "a", "source-target", "translation", "pair", "."], ["Since", "the", "translation", "task", "is", "intended", "to", "align", "the", "sentence", "representations", "of", "the", "source", "and", "target", "languages", ",", "we", "do", "not", "use", "any", "kind", "of", "task-specific", "feedforward", "layers", "and", "instead", "use", "\\", "-LRB-", "g\\", "-RRB-", "as", "both", "\\", "-LRB-", "g^I\\", "-RRB-", "and", "\\", "-LRB-", "g^R\\", "-RRB-", "."], ["Following", "-LSB-", "9", "-RSB-", ",", "we", "append", "5", "incorrect", "translations", "that", "are", "semantically", "similar", "to", "the", "correct", "translation", "for", "each", "training", "example", "as", "\u201c", "hard-negatives", "\u201d", "."], ["Similarity", "is", "determined", "via", "a", "version", "of", "our", "model", "trained", "only", "on", "the", "translation", "ranking", "task", "."], ["We", "did", "not", "see", "additional", "gains", "from", "using", "more", "than", "5", "hard-negatives", "."]], "ner": [[[0, 1, "a"]], [], [], [], [[113, 113, "v"]], [], [[160, 160, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [[113, 113, "v"]], [[141, 141, "a"]], [[160, 160, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1806.03863-25289fcd-c44f-40ec-a18f-0e3a4adc17b8", "sentences": [["We", "used", "randomly", "extracted", "subsequences", "of", "32", "frames", "for", "pose", "and", "64", "frames", "for", "action", "in", "training", ";", "the", "evaluation", "was", "done", "on", "the", "full", "sequences", ",", "that", "have", "up", "to", "250", "frames", "\u2013", "10", "seconds", "of", "video", "."], ["The", "spatial", "resolution", "of", "the", "input", "frames", "at", "both", "training", "and", "evaluation", "time", "is", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", ",", "obtained", "by", "random", "cropping", "at", "training", "time", "and", "central", "cropping", "for", "evaluation", "."], ["We", "also", "randomly", "flipped", "the", "videos", "horizontally", "during", "training", "."]], "ner": [[[2, 4, "a"], [7, 7, "p"], [12, 12, "p"], [32, 32, "p"], [6, 6, "v"], [9, 9, "c"], [11, 11, "v"], [14, 14, "c"]], [[45, 45, "p"], [40, 41, "a"], [41, 41, "p"]], []], "relations": [[], [], []], "predicted_ner": [[[6, 6, "v"], [11, 11, "v"], [31, 31, "v"], [34, 34, "v"]], [[56, 56, "v"]], []], "predicted_relations": [[[7, 7, 2, 4, "USED-FOR"], [12, 12, 2, 4, "USED-FOR"], [6, 6, 7, 7, "USED-FOR"], [6, 6, 12, 12, "USED-FOR"], [11, 11, 7, 7, "USED-FOR"], [11, 11, 12, 12, "USED-FOR"]], [[45, 45, 40, 41, "USED-FOR"], [41, 41, 40, 41, "USED-FOR"]], []]}
{"doc_key": "1806.03863-25192064-c42b-41f3-95e6-5a825d20a1be", "sentences": [["All", "our", "models", "were", "trained", "using", "SGD", "with", "momentum", "0.9", "."], ["For", "both", "tasks", ",", "the", "Par-Inception", "models", "were", "trained", "with", "initial", "learning", "rate", "of", "0.1", ",", "and", "batch", "size", "of", "4", "."], ["For", "keypoint", "localisation", ",", "the", "learning", "rate", "was", "decreased", "by", "a", "factor", "of", "10", "after", "35k", "and", "55k", "iterations", "of", "training", ",", "whereas", "for", "action", "classification", ",", "it", "was", "decreased", "after", "50k", "and", "60k", "iterations", "."], ["For", "both", "tasks", ",", "we", "ran", "70k", "iterations", "of", "training", "."]], "ner": [[[6, 6, "a"], [8, 8, "p"], [9, 9, "v"]], [[16, 16, "a"], [21, 23, "p"], [25, 25, "v"], [28, 29, "p"], [31, 31, "v"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"], [9, 9, "v"]], [[16, 16, "a"], [22, 23, "p"], [25, 25, "v"], [28, 29, "p"], [31, 31, "v"]], [[38, 39, "p"], [46, 46, "v"], [48, 48, "v"], [50, 50, "v"], [64, 64, "v"], [66, 66, "v"]], [[75, 75, "v"]]], "predicted_relations": [[[8, 8, 6, 6, "USED-FOR"]], [[21, 23, 16, 16, "USED-FOR"], [28, 29, 16, 16, "USED-FOR"], [31, 31, 28, 29, "USED-FOR"]], [], []]}
{"doc_key": "1806.03863-0fe727e8-d60d-4078-8b5b-006bc2198123", "sentences": [["The", "Par-DenseNet", "models", "were", "more", "memory", "intensive", "so", "we", "used", "a", "smaller", "batch", "size", ",", "1", "for", "keypoint", "localization", ",", "and", "2", "for", "classification", "."], ["We", "trained", "the", "models", "with", "learning", "rate", "1.0", "for", "keypoints", "and", "0.1", "for", "actions", ",", "for", "a", "total", "of", "150k", "iterations", ",", "lowering", "the", "learning", "rate", "by", "a", "factor", "of", "10", "at", "100k", "iterations", "."]], "ner": [[[1, 2, "a"], [12, 13, "p"], [15, 15, "v"], [17, 18, "c"], [21, 21, "v"], [23, 23, "c"]], [[32, 32, "v"], [36, 36, "v"], [30, 31, "p"], [49, 50, "p"], [32, 32, "v"], [34, 34, "c"], [36, 36, "v"], [38, 38, "c"], [44, 44, "v"], [55, 55, "v"], [56, 58, "c"]]], "relations": [[], []], "predicted_ner": [[[1, 1, "a"], [12, 13, "p"], [15, 15, "v"], [21, 21, "v"]], [[30, 31, "p"], [32, 32, "v"], [36, 36, "v"], [44, 44, "v"], [49, 50, "p"], [55, 55, "v"], [57, 57, "v"]]], "predicted_relations": [[[17, 18, 21, 21, "USED-FOR"]], [[34, 34, 44, 44, "USED-FOR"], [38, 38, 44, 44, "USED-FOR"], [56, 58, 44, 44, "USED-FOR"], [56, 58, 55, 55, "USED-FOR"]]]}
{"doc_key": "1808.01426-3c57cbe5-6dd8-4bfd-8f44-a61b9356970d", "sentences": [["The", "corresponding", "parameters", "of", "controlled", "experimental", "models", "are", "described", "as", "follows", "."], ["For", "all", "models", ",", "we", "have", "set", "the", "word", "embeddings", "and", "RNN", "hidden", "states", "to", "be", "128-dimensional", "and", "256-dimensional", "respectively", "for", "source", "encoders", ",", "extractive", "encoders", "and", "decoders", "."], ["Contrary", "to", "-LSB-", "10", "-RSB-", ",", "we", "learn", "the", "word", "embeddings", "from", "scratch", "during", "training", ",", "because", "our", "training", "dataset", "is", "large", "enough", "."], ["We", "apply", "the", "optimization", "technique", "Adagrad", "with", "learning", "rate", "0.15", "and", "an", "initial", "accumulator", "value", "of", "0.1", ",", "as", "well", "as", "employ", "the", "gradient", "clipping", "with", "a", "maximum", "gradient", "norm", "of", "2", "."]], "ner": [[], [[20, 21, "a"], [28, 28, "v"], [23, 25, "a"], [30, 30, "v"]], [[50, 51, "a"]], [[70, 70, "a"], [72, 73, "p"], [74, 74, "v"], [77, 79, "p"], [81, 81, "v"], [92, 94, "p"], [96, 96, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[23, 23, "a"], [28, 28, "v"], [30, 30, "v"]], [], [[70, 70, "a"], [72, 73, "p"], [74, 74, "v"], [81, 81, "v"], [88, 89, "a"], [92, 94, "p"], [96, 96, "v"]]], "predicted_relations": [[], [], [], [[72, 73, 70, 70, "USED-FOR"], [74, 74, 72, 73, "USED-FOR"], [77, 79, 70, 70, "USED-FOR"], [92, 94, 70, 70, "USED-FOR"], [96, 96, 92, 94, "USED-FOR"]]]}
{"doc_key": "1808.01426-922247ef-e59a-477f-bcc1-11d308d47dff", "sentences": [["We", "train", "on", "a", "single", "GeForce", "GTX", "1080", "GPU", "with", "a", "memory", "of", "8114", "MiB", ",", "and", "the", "batch", "size", "is", "set", "to", "be", "16", ",", "as", "well", "as", "the", "beam", "size", "is", "4", "for", "beam", "search", "in", "decoding", "mode", "."], ["For", "the", "seq2seq", "dual", "attentional", "models", "without", "pointer-generator", ",", "we", "trained", "them", "for", "about", "two", "days", "."], ["Models", "with", "pointer-generator", "expedite", "the", "training", ",", "the", "time", "cost", "is", "reduced", "to", "about", "one", "day", "."], ["When", "we", "add", "coverage", ",", "the", "coverage", "loss", "weight", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "set", "to", "1.0", ",", "and", "the", "model", "needs", "about", "one", "hour", "for", "training", "."]], "ner": [[[5, 8, "a"], [18, 19, "a"], [30, 31, "a"]], [[43, 48, "a"]], [], [[81, 83, "p"], [92, 92, "v"], [81, 83, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[13, 13, "v"], [18, 19, "p"], [24, 24, "v"], [30, 31, "p"], [33, 33, "v"]], [[43, 43, "a"], [55, 55, "v"]], [[72, 72, "v"]], [[81, 83, "p"], [86, 86, "p"], [92, 92, "v"], [99, 99, "v"]]], "predicted_relations": [[], [], [], [[81, 83, 81, 83, "USED-FOR"]]]}
{"doc_key": "1810.12081-50d9dec7-ce89-45ef-a48f-ac8e6a3e9f5e", "sentences": [["where", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\omega", "_", "-LCB-", "t+1", "-RCB-", "-RCB-", "-LCB-", "\\partial", "\\theta", "-RCB-", "|_t\\", "-RRB-", "represents", "the", "effect", "of", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "to", "the", "value", "of", "\\", "-LRB-", "\\omega", "_", "-LCB-", "t+1", "-RCB-", "\\", "-RRB-", "happened", "only", "at", "timestep", "\\", "-LRB-", "t\\", "-RRB-", ",", "but", "not", "related", "with", "the", "effect", "to", "the", "value", "of", "\\", "-LRB-", "\\omega", "_t\\", "-RRB-", "."], ["Therefore", "we", "equivalently", "have", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\omega", "_", "-LCB-", "t", "-RCB-", "-RCB-", "-LCB-", "\\partial", "\\theta", "-RCB-", "=0\\", "-RRB-", "in", "calculating", "\\", "-LRB-", "\\frac", "-LCB-", "\\partial", "\\omega", "_", "-LCB-", "t+1", "-RCB-", "-RCB-", "-LCB-", "\\partial", "\\theta", "-RCB-", "|_t\\", "-RRB-", "."], ["The", "last", "equation", "in", "Eqn", "."], ["-LRB-", "REF", "-RRB-", "again", "leverages", "the", "symmetry", "of", "Hessian", "matrix", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[], [], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1810.05221-a7145d01-44e4-4103-b807-12aec51a105c", "sentences": [["Stopping", "criteria", "\u2013", "all", "models", "were", "trained", "for", "30", "epochs", "."], ["We", "then", "chose", "the", "architecture", "configuration", "that", "was", "in", "place", "for", "the", "epoch", "with", "the", "highest", "score", "on", "validation", "set", "."], ["Learning", "rate", "and", "optimizers", "\u2013", "\\", "-LRB-", "D1\\", "-RRB-", "was", "optimized", "using", "a", "stochastic", "gradient", "descent", "optimizer", "with", "a", "learning", "rate", "of", "0.01", "."], ["\\", "-LRB-", "D2\\", "-RRB-", "and", "\\", "-LRB-", "G\\", "-RRB-", "were", "optimized", "using", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "0.001", "."], ["Dropout", "and", "batch", "normalization", "\u2013", "\\", "-LRB-", "G\\", "-RRB-", "contains", "a", "10", "%", "rate", "dropout", "after", "each", "hidden", "layer", "."], ["\\", "-LRB-", "D1\\", "-RRB-", "contains", "batch", "normalization", "after", "each", "hidden", "layer", "."], ["Warm", "up", "values", "\u2013", "we", "evaluated", "\\", "-LRB-", "D2\\", "-RRB-", "with", "warm", "up", "values", "of", "zero", ",", "one", ",", "three", ",", "and", "six", "epochs", "-LRB-", "see", "``", "Training", "and", "initialization", "strategies", "''", "in", "the", "previous", "section", "for", "more", "details", "-RRB-", "."], ["Initialization", "\u2013", "each", "experiment", "was", "run", "30", "times", ",", "using", "different", "initialization", "parameters", "."]], "ner": [[[0, 1, "a"], [9, 9, "c"], [9, 9, "c"], [9, 9, "c"], [9, 9, "c"], [8, 8, "v"]], [], [[32, 35, "a"], [39, 39, "p"], [54, 54, "v"], [51, 52, "c"], [51, 52, "c"], [51, 52, "c"], [39, 39, "p"]], [[73, 74, "c"], [58, 58, "p"], [76, 76, "v"], [73, 74, "c"], [63, 63, "p"], [76, 76, "v"], [73, 74, "c"], [63, 63, "p"], [58, 58, "p"]], [[85, 85, "p"], [78, 81, "a"], [85, 85, "p"]], [[100, 100, "p"], [100, 100, "p"]], [[118, 118, "p"], [110, 112, "a"], [118, 118, "p"], [125, 125, "v"], [133, 133, "c"], [127, 127, "v"], [133, 133, "c"], [129, 129, "v"], [133, 133, "c"], [132, 132, "v"], [133, 133, "c"]], [[151, 151, "a"], [154, 154, "p"], [157, 157, "v"], [158, 158, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "v"], [9, 9, "p"]], [], [[32, 33, "p"], [45, 47, "a"], [51, 52, "p"], [54, 54, "v"]], [[69, 69, "a"], [73, 74, "p"], [76, 76, "v"]], [[78, 78, "a"], [80, 81, "a"], [89, 90, "v"], [92, 92, "a"], [95, 96, "p"]], [[103, 104, "a"], [107, 108, "p"]], [[121, 123, "p"], [125, 125, "v"], [127, 127, "v"], [129, 129, "v"], [132, 132, "v"], [133, 133, "p"]], [[157, 157, "v"]]], "predicted_relations": [[], [], [[39, 39, 32, 35, "USED-FOR"], [51, 52, 54, 54, "USED-FOR"], [51, 52, 54, 54, "USED-FOR"], [51, 52, 54, 54, "USED-FOR"], [39, 39, 32, 35, "USED-FOR"]], [[73, 74, 76, 76, "USED-FOR"], [73, 74, 76, 76, "USED-FOR"], [73, 74, 76, 76, "USED-FOR"], [73, 74, 76, 76, "USED-FOR"], [73, 74, 76, 76, "USED-FOR"], [73, 74, 76, 76, "USED-FOR"]], [], [], [], [[154, 154, 151, 151, "USED-FOR"], [157, 157, 154, 154, "USED-FOR"]]]}
{"doc_key": "1810.05436-6314b565-c52e-4680-98bd-3906a8a1b4eb", "sentences": [["As", "noted", "above", ",", "the", "topic", "modeling", "approach", "used", "in", "our", "experiments", "with", "HiTR", "is", "LDA", "."], ["Following", "-LSB-", "0", "-RSB-", ",", "-LSB-", "6", "-RSB-", ",", "-LSB-", "30", "-RSB-", "we", "set", "the", "number", "of", "topics", "to", "100", "."], ["We", "set", "the", "two", "hyperparameters", "to", "\\", "-LRB-", "\\alpha", "=1/T\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "=0.01\\", "-RRB-", ",", "where", "\\", "-LRB-", "T\\", "-RRB-", "is", "the", "number", "of", "topics", ",", "following", "-LSB-", "15", "-RSB-", "."], ["In", "the", "re-estimation", "process", ",", "at", "each", "step", "of", "the", "EM", "algorithm", ",", "we", "set", "the", "threshold", "for", "removing", "unnecessary", "components", "from", "the", "model", "to", "\\", "-LRB-", "0.01\\", "-RRB-", "and", "remove", "terms", "with", "an", "estimated", "probability", "less", "than", "this", "threshold", "from", "the", "language", "models", ",", "as", "in", "-LSB-", "9", "-RSB-", "."]], "ner": [[[15, 15, "a"]], [[32, 34, "p"], [36, 36, "v"]], [[63, 65, "p"], [46, 46, "p"], [47, 47, "v"], [52, 52, "p"], [53, 53, "v"], [53, 53, "v"]], [[99, 99, "v"], [88, 92, "p"], [99, 99, "v"], [82, 83, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[13, 13, "a"], [15, 15, "a"]], [[36, 36, "v"]], [[41, 41, "v"], [46, 46, "p"], [52, 52, "p"], [53, 53, "v"], [59, 59, "p"]], [[82, 83, "a"], [99, 99, "v"]]], "predicted_relations": [[], [], [[47, 47, 46, 46, "USED-FOR"], [47, 47, 52, 52, "USED-FOR"], [53, 53, 52, 52, "USED-FOR"], [53, 53, 52, 52, "USED-FOR"]], [[88, 92, 82, 83, "USED-FOR"]]]}
{"doc_key": "1811.07157-b93d16bc-c8ce-4e15-b836-e06137f8863c", "sentences": [["As", "explained", "above", ",", "we", "have", "GPU", "memory", "constrained", ",", "we", "will", "report", "results", "of", "previous", "basic", "3D", "models", "-LSB-", "50", "-RSB-", ",", "-LSB-", "6", "-RSB-", "re-implemented", "and", "trained", "by", "using", "the", "same", "amount", "of", "resources", "as", "our", "RCN", "."], ["The", "main", "hyperparameters", "involved", "in", "the", "training", "of", "a", "3D", "network", "are", "learning", "rate", ",", "batch", "size", ",", "and", "the", "number", "of", "iterations", "."], ["These", "parameters", "are", "interdependent", ",", "and", "their", "optimal", "setting", "depends", "on", "the", "computational", "power", "at", "disposal", "."], ["For", "instance", ",", "Tran", "-LSB-", "50", "-RSB-", "would", "use", "64", "GPUs", ",", "with", "the", "training", "process", "distributed", "across", "multiple", "machines", "."], ["In", "such", "a", "case", ",", "when", "vast", "computational", "resources", "are", "available", "-LSB-", "50", "-RSB-", ",", "-LSB-", "6", "-RSB-", ",", "-LSB-", "5", "-RSB-", ",", "training", "takes", "10-15", "hours", "-LSB-", "50", "-RSB-", ",", "allowing", "for", "time", "to", "identify", "the", "optimal", "parameters", "."], ["The", "availability", "of", "such", "computational", "power", ",", "however", ",", "is", "scarce", "."]], "ner": [[[17, 18, "a"]], [[52, 53, "p"], [55, 56, "p"], [60, 62, "p"]], [], [[84, 84, "a"], [90, 90, "v"], [95, 96, "p"], [97, 100, "v"]], [[127, 128, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[38, 38, "a"]], [[52, 53, "p"]], [], [[84, 84, "a"], [90, 90, "v"]], [[127, 127, "v"]], []], "predicted_relations": [[], [], [], [[90, 90, 95, 96, "USED-FOR"], [95, 96, 84, 84, "USED-FOR"]], [], []]}
{"doc_key": "1811.07017-b7918422-6f3f-4bda-b8d3-b4b7e5b7d151", "sentences": [["All", "the", "models", "are", "implemented", "using", "PyTorch", "0.4.1", "-LSB-", "22", "-RSB-", "."], ["Adam", "optimizer", "-LSB-", "12", "-RSB-", "is", "used", "with", "a", "learning", "rate", "of", "0.001", "."], ["We", "used", "one", "layer", "LSTM", "models", "with", "hidden", "dimensions", "of", "size", "128", "and", "256", "."], ["Net2Net", "is", "used", "to", "expand", "LSTM", "models", "of", "size", "128", "to", "256", "."], ["For", "the", "GEM", "model", ",", "we", "keep", "one", "minibatch", "-LRB-", "10", "examples", "-RRB-", "of", "data", "per", "task", "for", "obtaining", "the", "projected", "gradients", "."], ["We", "follow", "the", "guidelines", "and", "hyperparameter", "configurations", "as", "specified", "in", "the", "respective", "papers", "for", "both", "GEM", "and", "Net2Net", "models", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 6, "a"]], [[12, 13, "a"], [21, 22, "p"], [24, 24, "v"]], [[30, 30, "a"], [33, 34, "p"], [37, 37, "v"], [39, 39, "v"]], [[46, 46, "a"], [50, 50, "v"], [52, 52, "v"], [41, 41, "a"]], [[56, 56, "a"], [62, 62, "p"], [64, 64, "v"], [65, 65, "c"]], [[94, 94, "a"], [92, 92, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[12, 12, "a"], [21, 22, "p"], [24, 24, "v"]], [[28, 28, "v"], [29, 29, "p"], [30, 31, "a"], [33, 34, "p"], [37, 37, "v"], [39, 39, "v"]], [[41, 41, "a"], [46, 47, "a"], [50, 50, "v"], [52, 52, "v"]], [[56, 57, "a"], [61, 61, "v"], [64, 64, "v"]], [[92, 92, "a"], [94, 94, "a"]], []], "predicted_relations": [[], [[21, 22, 12, 13, "USED-FOR"]], [[33, 34, 30, 30, "USED-FOR"]], [], [[62, 62, 56, 56, "USED-FOR"], [64, 64, 62, 62, "USED-FOR"]], [], []]}
{"doc_key": "1811.07056-ca0d3fb5-128e-419e-b4f1-b12d434c8205", "sentences": [["Hence", ",", "we", "created", "pre-training", "datasets", "by", "sampling", "examples", "from", "the", "source", "dataset", "using", "the", "importance", "weights", "."], ["We", "start", "by", "choosing", "a", "desired", "pre-training", "dataset", "size", ",", "often", "large", "."], ["We", "then", "sample", "examples", "from", "the", "source", "dataset", "at", "a", "rate", "proportional", "to", "the", "importance", "weights", ",", "repeating", "examples", "as", "needed", "."], ["We", "report", "results", "that", "construct", "a", "pre-training", "dataset", "of", "80", "million", "examples", "for", "JFT", ",", "and", "2", "million", "examples", "for", "ImageNet", "."], ["We", "used", "the", "same", "sampled", "pre-training", "dataset", "with", "both", "the", "Inception", "v3", "and", "AmoebaNet-B", "experiments", "."]], "ner": [[[4, 5, "a"]], [[23, 26, "p"]], [], [[62, 64, "v"], [66, 66, "c"], [69, 71, "v"], [73, 73, "c"]], [[85, 86, "a"], [88, 88, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[4, 5, "a"]], [[24, 25, "a"]], [], [[59, 60, "a"], [62, 62, "v"], [66, 66, "a"], [69, 69, "v"], [73, 73, "a"]], [[80, 81, "a"], [85, 86, "a"], [88, 88, "a"]]], "predicted_relations": [[], [], [], [[66, 66, 62, 64, "USED-FOR"], [66, 66, 69, 71, "USED-FOR"], [73, 73, 69, 71, "USED-FOR"]], []]}
{"doc_key": "1812.06158-3208ad4e-921d-40f0-a9c8-ce9e1843350b", "sentences": [["In", "all", "our", "experiments", "we", "set", "\\", "-LRB-", "N\\", "-RRB-", "-LRB-", "number", "of", "instances", "of", "the", "target", "class", "in", "in-domain", "training", "data", "-RRB-", "to", "20", "."], ["This", "number", "of", "examples", "is", "small", "enough", "and", "can", "be", "easily", "labelled", "by", "hand", "."], ["At", "the", "same", "time", ",", "it", "produces", "models", "of", "reasonable", "quality", "."], ["Figure", "REF", "compares", "the", "performance", "of", "models", "trained", "on", "10", "and", "20", "examples", "."], ["We", "see", "the", "significant", "boost", "in", "performance", "for", "the", "latter", "case", "."], ["Moreover", ",", "in", "the", "rightmost", "plot", "the", "learning", "curve", "for", "the", "smaller", "dataset", "goes", "down", "after", "the", "40-th", "epoch", ",", "which", "does", "not", "happen", "when", "the", "larger", "dataset", "is", "used", "."], ["This", "shows", "that", "\\", "-LRB-", "N=20\\", "-RRB-", "is", "a", "reasonable", "trade-off", "between", "model", "performance", "and", "cost", "of", "labelling", "."]], "ner": [[[11, 21, "a"], [8, 8, "p"], [24, 24, "v"]], [], [[48, 48, "a"]], [[64, 64, "v"], [59, 59, "a"]], [], [[86, 87, "a"]], [[115, 115, "p"], [115, 115, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "p"], [24, 24, "v"]], [], [], [[62, 62, "v"], [64, 64, "v"]], [], [[96, 96, "v"]], [[115, 115, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[115, 115, 115, 115, "USED-FOR"], [115, 115, 115, 115, "USED-FOR"]]]}
{"doc_key": "1812.06158-97d1dd14-b2f7-4141-b24d-7d10bd89f87f", "sentences": [["In", "the", "Protonet", "model", "we", "set", "\\", "-LRB-", "p\\", "-RRB-", "to", "0.5", "."], ["Therefore", ",", "the", "model", "is", "trained", "on", "the", "instances", "of", "the", "target", "class", "\\", "-LRB-", "C\\", "-RRB-", "half", "of", "the", "steps", ",", "and", "another", "half", "of", "the", "times", "it", "is", "shown", "instances", "of", "some", "other", "randomly", "chosen", "class", "."]], "ner": [[[2, 3, "a"], [8, 8, "p"], [11, 11, "v"]], []], "relations": [[], []], "predicted_ner": [[[2, 3, "a"], [11, 11, "v"]], []], "predicted_relations": [[[8, 8, 2, 3, "USED-FOR"]], []]}
{"doc_key": "1812.06158-6692cf49-1916-4969-9b6a-9cc0ffbaf9f6", "sentences": [["We", "optimize", "all", "models", "with", "Adam", "optimizer", "in", "pytorch", "implementation", "."], ["Base", "and", "WarmBase", "methods", "use", "batches", "of", "10", "sentences", "during", "in-domain", "training", "."], ["We", "train", "out-of-domain", "RNN", "baseline", "-LRB-", "warm-up", "for", "WarmBase", "and", "WarmProto", "*", "models", "-RRB-", "using", "batch", "of", "size", "32", "."], ["All", "models", "based", "on", "prototypical", "network", "use", "batches", "of", "size", "100", "\u2014", "40", "in", "support", "set", "and", "60", "in", "query", "set", "."], ["We", "also", "use", "L2-regularization", "with", "a", "multiplier", "0.1", "."], ["All", "models", "are", "evaluated", "in", "terms", "of", "chunk-based", "\\", "-LRB-", "F_1\\", "-RRB-", "-score", "for", "the", "target", "class", "-LSB-", "14", "-RSB-", "."]], "ner": [[[5, 6, "a"]], [], [], [], [[69, 69, "a"], [72, 72, "p"], [73, 73, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[11, 11, "a"], [13, 13, "a"], [18, 18, "v"]], [[27, 27, "a"], [32, 32, "a"], [42, 42, "v"]], [[54, 54, "v"], [56, 56, "v"], [61, 61, "v"]], [[69, 69, "a"], [73, 73, "v"]], []], "predicted_relations": [[], [], [], [], [[72, 72, 69, 69, "USED-FOR"]], []]}
{"doc_key": "1808.03986-dedb6a9f-702e-4b80-a2df-73146a65fc2b", "sentences": [["We", "have", "used", "RMSPROP", "optimizer", "to", "update", "the", "model", "parameter", "and", "configured", "hyper-parameter", "values", "to", "be", "as", "follows", ":", "\\", "-LRB-", "\\text", "-LCB-", "learning", "rate", "-RCB-", "=0.0004", ",", "\\text", "-LCB-", "batch", "size", "-RCB-", "=", "200", ",", "\\alpha", "=", "0.99", ",", "\\epsilon", "=1e-8\\", "-RRB-", "to", "train", "the", "classification", "network", "."], ["In", "order", "to", "train", "a", "triplet", "model", ",", "we", "have", "used", "RMSPROP", "to", "optimize", "the", "triplet", "model", "model", "parameter", "and", "configure", "hyper-parameter", "values", "to", "be", ":", "\\", "-LRB-", "\\text", "-LCB-", "learning", "rate", "-RCB-", "=0.001", ",", "\\text", "-LCB-", "batch", "size", "-RCB-", "=", "200", ",", "\\alpha", "=", "0.9", ",", "\\epsilon", "=1e-8\\", "-RRB-", "."], ["We", "also", "used", "learning", "rate", "decay", "to", "decrease", "the", "learning", "rate", "on", "every", "epoch", "by", "a", "factor", "given", "by", ":", "\\", "-LRB-", "Decay\\_factor=exp\\left", "-LRB-", "\\frac", "-LCB-", "log", "-LRB-", "0.1", "-RRB-", "-RCB-", "-LCB-", "a", "*", "b", "-RCB-", "\\right", "-RRB-", "\\", "-RRB-"]], "ner": [[[3, 4, "a"], [23, 24, "p"], [26, 26, "v"], [30, 31, "p"], [34, 34, "v"], [36, 36, "p"], [38, 38, "v"], [40, 40, "p"], [41, 41, "v"]], [[79, 80, "p"], [82, 82, "v"], [86, 87, "p"], [90, 90, "v"], [92, 92, "p"], [94, 94, "v"], [96, 96, "p"], [97, 97, "v"]], [[103, 104, "p"], [109, 110, "p"], [103, 105, "a"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [26, 26, "v"], [34, 34, "v"], [38, 38, "v"], [46, 47, "a"]], [[54, 55, "a"], [60, 60, "a"], [64, 65, "a"], [90, 90, "v"], [92, 92, "p"], [94, 94, "v"]], [[103, 105, "a"], [109, 110, "p"], [128, 128, "v"]]], "predicted_relations": [[[23, 24, 3, 4, "USED-FOR"], [26, 26, 23, 24, "USED-FOR"], [26, 26, 36, 36, "USED-FOR"], [30, 31, 3, 4, "USED-FOR"], [34, 34, 30, 31, "USED-FOR"], [34, 34, 40, 40, "USED-FOR"], [36, 36, 3, 4, "USED-FOR"], [38, 38, 40, 40, "USED-FOR"], [40, 40, 3, 4, "USED-FOR"], [41, 41, 36, 36, "USED-FOR"], [41, 41, 40, 40, "USED-FOR"]], [[82, 82, 79, 80, "USED-FOR"], [82, 82, 92, 92, "USED-FOR"], [90, 90, 86, 87, "USED-FOR"], [90, 90, 96, 96, "USED-FOR"], [97, 97, 92, 92, "USED-FOR"], [97, 97, 96, 96, "USED-FOR"]], [[103, 104, 103, 105, "USED-FOR"], [109, 110, 103, 105, "USED-FOR"]]]}
{"doc_key": "1812.08781-82373c24-42f7-4749-9b39-868bc3d903f9", "sentences": [["Our", "model", "depends", "on", "two", "parameters", ":", "the", "number", "of", "eigen", "components", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "used", "for", "spectral", "clustering", ",", "and", "the", "temperature", "\\", "-LRB-", "\\sigma", "\\", "-RRB-", "used", "for", "controlling", "the", "confidence", "."], ["We", "used", "\\", "-LRB-", "\\eta", "=200\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "=40\\", "-RRB-", "in", "our", "main", "submission", "."], ["In", "Figure", "REF", ",", "we", "show", "the", "effects", "of", "the", "two", "parameters", "respectively", "."]], "ner": [[[1, 1, "a"], [8, 11, "p"], [24, 24, "p"]], [[41, 41, "v"], [47, 47, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [4, 4, "v"], [24, 24, "p"], [27, 27, "p"]], [[41, 41, "v"], [47, 47, "v"]], [[64, 64, "v"]]], "predicted_relations": [[[8, 11, 1, 1, "USED-FOR"]], [], []]}
{"doc_key": "1802.10529-235e1edc-a17e-45a7-bda8-bbb74c1d416c", "sentences": [["Unfortunately", ",", "this", "approach", "is", "of", "little", "use", "in", "the", "streaming", "data", "scenario", "we", "have", "been", "focussing", "on", ";", "it", "would", "entail", "storing", "the", "groupings", "in", "a", "way", "which", "would", "complicate", "the", "fitting", "algorithm", "."], ["Luckily", ",", "however", ",", "having", "repeated", "observations", "is", "not", "the", "only", "sufficient", "condition", "for", "a", "mixture", "model", "to", "be", "identifiable", "-LRB-", "and", "note", "that", "it", "is", "not", "a", "necessary", "condition", "-RRB-", "."], ["A", "mixture", "of", "logistic", "regression", "models", "can", "also", "be", "identified", ",", "informally", ",", "when", "the", "\u00d2pattern\u00d3", "within", "each", "individual", "logistic", "regression", "is", "clear", "enough", "."], ["If", "enough", "unique", "values", "are", "available", "for", "the", "independent", "variables", ",", "then", "this", "can", "be", "used", "as", "a", "sufficient", "criteria", "for", "identifiability", "."], ["showed", "that", "for", "a", "single", "independent", "variable", "having", "\\", "-LRB-", "q\\", "-RRB-", "unique", "values", ",", "a", "mixture", "with", "\\", "-LRB-", "k", "\\le", "\\sqrt", "-LCB-", "q+2", "-RCB-", "-1\\", "-RRB-", "can", "be", "identified", ",", "at", "least", "if", "each", "of", "the", "logistic", "regressions", "is", "itself", "also", "identified", "-LRB-", "in", "the", "same", "way", "as", "a", "standard", "non-mixture", "logistic", "regression", "can", "not", "be", "fit", "without", "additional", "constraints", "if", "the", "number", "of", "parameters", "is", "larger", "than", "the", "number", "of", "observations", "-RRB-", "."], ["Hence", ",", "when", "treating", "the", "observations", "as", "Bernoulli", ",", "sufficient", "criteria", "for", "identifying", "mixtures", "logistic", "regression", "models", "can", "also", "be", "obtained", "in", "the", "data", "stream", "."], ["However", ",", "we", "should", "note", "that", "the", "number", "of", "components", "that", "can", "be", "identified", "as", "more", "unique", "values", "of", "an", "independent", "variable", "are", "observed", "grows", "slowly", ":", "for", "100", "unique", "values", ",", "Theorem", "only", "guarantees", "sufficiency", "for", "identifying", "9", "mixture", "components", "."], ["Since", "we", "are", "considering", "large", ",", "continuous", ",", "data", "streams", "here", ",", "we", "consider", "the", "situation", "of", "more", "than", "100", "unique", "values", "of", "an", "independent", "variable", "quite", "likely", ",", "but", "we", "must", "still", "caution", "for", "over-enthusiasm", "when", "choosing", "a", "high", "number", "of", "mixture", "components", "."], ["A", "formal", "discussion", "of", "identifiability", "for", "mixture", "models", "in", "general", "can", "be", "found", "in", "or", ",", "while", "discuss", "specifically", "the", "mixture", "of", "logistic", "models", "."]], "ner": [[], [[50, 51, "a"]], [[68, 72, "a"], [70, 71, "a"], [86, 87, "a"]], [[113, 113, "a"]], [[168, 169, "a"]], [[205, 206, "a"]], [[224, 226, "p"], [255, 255, "v"], [249, 249, "c"]], [], [[324, 327, "a"], [308, 308, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [[135, 135, "p"]], [], [[245, 245, "v"], [255, 255, "v"]], [[278, 278, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [[249, 249, 255, 255, "USED-FOR"]], [], []]}
{"doc_key": "1802.10529-c24d1701-4e82-4e6e-8b5c-b170182b0303", "sentences": [["Formally", "choosing", "the", "\u201c", "best", "\u201d", "number", "of", "components", "\\", "-LRB-", "K\\", "-RRB-", "is", "more", "challenging", ":", "although", "we", "can", "easily", "fit", "multiple", "models", "with", "different", "choices", "of", "\\", "-LRB-", "K\\", "-RRB-", "in", "parallel", ",", "formal", "tests", "to", "determine", "the", "value", "of", "\\", "-LRB-", "K\\", "-RRB-", "in", "the", "face", "of", "streaming", "data", "are", "still", "actively", "being", "developed", "."], ["The", "traditional", ",", "offline", ",", "methods", "for", "selecting", "the", "number", "of", "components", "mostly", "rely", "on", "comparing", "either", "the", "likelihood", "or", "the", "\\", "-LRB-", "AIC\\", "-RRB-", "or", "\\", "-LRB-", "BIC\\", "-RRB-", "values", "of", "the", "competing", "models", ",", "."], ["The", "likelihood", "\\", "-LRB-", "L", "-LRB-", "\\hat", "-LCB-", "\\theta", "-RCB-", "|", "\\mathcal", "-LCB-", "D", "-RCB-", "-RRB-", "\\", "-RRB-", "-LRB-", "or", "log-likelihood", "\\", "-LRB-", "l", "-LRB-", "\\hat", "-LCB-", "\\theta", "-RCB-", "|", "\\mathcal", "-LCB-", "D", "-RCB-", "-RRB-", "\\", "-RRB-", "of", "the", "mixture", "of", "logistic", "regression", "is", "easily", "computed", "for", "a", "static", "dataset", "-LRB-", "see", "also", "Eq", "."], ["REF", "-RRB-", "and", "a", "set", "of", "parameter", "estimates", "."], ["Subsequently", "computing", "the", "\\", "-LRB-", "AIC\\", "-RRB-", "or", "\\", "-LRB-", "BIC\\", "-RRB-", "to", "enable", "model", "comparisons", "is", "straightforward", ":", "\\", "-LRB-", "AIC", "&", "=", "&", "2k", "-", "2", "\\ln", "-LRB-", "\\hat", "-LCB-", "L", "-RCB-", "-RRB-", "\\\\BIC", "&", "=", "&", "-2", "\\ln", "-LRB-", "\\hat", "-LCB-", "L", "-RCB-", "-RRB-", "k", "\\ln", "-LRB-", "n", "-RRB-", "\\", "-RRB-"]], "ner": [[], [[76, 76, "a"], [81, 81, "a"], [86, 86, "a"]], [[96, 96, "a"], [115, 115, "a"], [103, 103, "p"], [122, 122, "p"], [108, 108, "p"], [127, 127, "p"], [99, 99, "p"], [99, 99, "p"]], [], [[164, 164, "a"], [180, 180, "a"], [206, 206, "p"], [191, 191, "p"], [203, 203, "p"], [169, 169, "a"], [194, 194, "a"], [191, 191, "p"], [203, 203, "p"], [206, 206, "p"], [209, 209, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[11, 11, "p"], [30, 30, "p"], [44, 44, "p"]], [], [], [], [[206, 206, "p"]]], "predicted_relations": [[], [], [[103, 103, 96, 96, "USED-FOR"], [122, 122, 96, 96, "USED-FOR"], [122, 122, 115, 115, "USED-FOR"], [127, 127, 115, 115, "USED-FOR"], [99, 99, 96, 96, "USED-FOR"], [99, 99, 96, 96, "USED-FOR"]], [], [[206, 206, 180, 180, "USED-FOR"], [206, 206, 194, 194, "USED-FOR"], [206, 206, 180, 180, "USED-FOR"], [206, 206, 194, 194, "USED-FOR"]]]}
{"doc_key": "1807.05698-88aedd21-c936-46dc-8bcd-210c52e3bba6", "sentences": [["In", "the", "training", "process", ",", "we", "randomly", "generate", "100", "patch", "pairs", "with", "a", "size", "of", "\\", "-LRB-", "64\\times", "64", "\\", "-RRB-", "from", "every", "training", "image", "pairs", "."], ["The", "entire", "network", "is", "trained", "on", "an", "Nvidia", "1080Ti", "GPU", "based", "on", "Pytorch", "."], ["We", "use", "a", "batch", "size", "of", "64", "and", "set", "the", "depth", "of", "SCAN", "as", "\\", "-LRB-", "d=7\\", "-RRB-", "with", "the", "receptive", "field", "size", "\\", "-LRB-", "35\\times", "35\\", "-RRB-", "."], ["For", "the", "nonlinear", "operation", ",", "we", "use", "leaky", "ReLU", "-LSB-", "33", "-RSB-", "with", "\\", "-LRB-", "\\alpha", "=0.2\\", "-RRB-", "."], ["For", "optimization", ",", "the", "ADAM", "algorithm", "-LSB-", "34", "-RSB-", "is", "adopted", "with", "a", "start", "learning", "rate", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["During", "training", ",", "the", "learning", "rate", "is", "divided", "by", "10", "at", "\\", "-LRB-", "15,000\\", "-RRB-", "and", "\\", "-LRB-", "17,500\\", "-RRB-", "iterations", "."]], "ner": [[], [], [[53, 53, "a"], [51, 51, "p"], [57, 57, "v"], [61, 63, "p"]], [[85, 85, "p"], [86, 86, "v"]], [[93, 94, "a"], [102, 104, "p"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 8, "v"], [18, 19, "v"]], [], [[44, 45, "p"], [47, 47, "v"], [57, 57, "v"], [67, 67, "v"]], [[77, 78, "a"], [85, 85, "p"], [86, 86, "v"]], [[93, 94, "a"], [103, 104, "p"], [108, 110, "v"]], [[119, 120, "p"], [124, 124, "v"], [128, 128, "v"], [133, 133, "v"]]], "predicted_relations": [[], [], [[51, 51, 53, 53, "USED-FOR"], [57, 57, 61, 63, "USED-FOR"], [61, 63, 53, 53, "USED-FOR"]], [[86, 86, 85, 85, "USED-FOR"]], [[102, 104, 93, 94, "USED-FOR"]], []]}
{"doc_key": "1809.01498-69ef794d-ac05-4975-9d22-dc8305343cf3", "sentences": [["Word", "embeddings", "are", "trained", "on", "a", "2013", "dump", "of", "Wikipedia", "that", "has", "been", "filtered", "to", "contain", "only", "pages", "with", "at", "least", "20", "page", "views.Available", "at", "https", ":", "//storage.googleapis.com/lateral-datadumps/wikipedia_utf8_filtered_20pageviews.csv.gz", "The", "raw", "text", "has", "been", "preprocessed", "as", "outlined", "in", "appendix", "REF", "."], ["This", "results", "in", "a", "corpus", "of", "463k", "documents", "with", "498", "Million", "words", "."], ["For", "learning", "word", "embeddings", "in", "Euclidean", "space", "we", "use", "the", "skip-gram", "implementation", "of", "fastTexthttps", ":", "//github.com/facebookresearch/fastText", ",", "whereas", "the", "hyperbolic", "model", "has", "been", "implemented", "in", "C++", "based", "on", "the", "fastText", "code", "."], ["For", "the", "hyperbolic", "model", ",", "the", "two", "layers", "of", "parameters", "were", "identified", "as", "this", "resulted", "in", "better", "performance", "in", "informal", "experiments", "."], ["The", "detailed", "hyperparameters", "for", "both", "models", "are", "described", "in", "appendix", "REF", "."]], "ner": [[[0, 1, "a"], [6, 9, "a"]], [], [], [], [[109, 109, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [21, 21, "v"]], [[46, 46, "v"], [49, 49, "v"]], [[72, 73, "a"]], [[87, 88, "a"], [91, 91, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1805.02718-c0d14c71-6d97-4b21-b37e-b17bf1ef23db", "sentences": [["We", "used", "Adam", "to", "minimize", "the", "L2", "loss", "w.r.t", "."], ["a", "signed", "Euclidean", "distance", "transform", "-LRB-", "SEDT", "-RRB-", "of", "the", "binary", "labels", "."], ["As", "the", "SEDT", "is", "not", "meaningful", "far", "away", "from", "synapses", ",", "we", "scaled", "it", "and", "applied", "a", "\\", "-LRB-", "\\tanh", "\\", "-RRB-", "nonlinearity", "that", "saturates", "between", "-LSB-", "-1,1", "-RSB-", ":", "\\", "-LRB-", "STDT", "=", "\\tanh", "-LRB-", "SEDT/s", "-RRB-", "\\", "-RRB-", "."], ["Our", "experiments", "indicated", "that", "the", "scaling", "factor", "has", "little", "effect", "on", "performance", "-LRB-", "data", "not", "shown", "-RRB-", "."], ["We", "chose", "\\", "-LRB-", "s=50\\", "-RRB-", "as", "the", "default", "parameter", "."], ["Simple", "thresholding", "converts", "the", "predicted", "\\", "-LRB-", "STDT\\", "-RRB-", "into", "binary", "labels", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[2, 2, "a"], [6, 7, "a"]], [], [], [[69, 70, "p"]], [[86, 86, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 7, "a"]], [], [[50, 51, "v"]], [], [[86, 86, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1807.06583-91935de3-c59e-4360-93ab-97c4da2d9def", "sentences": [["Across", "all", "experiments", ",", "for", "all", "three", "models", ",", "training", "is", "performed", "for", "a", "fixed", "number", "of", "200", "epochs", "using", "a", "batch", "size", "of", "32", "."], ["The", "Adam", "optimizer", "-LSB-", "32", "-RSB-", "is", "used", "through", "the", "learning", "process", "with", "the", "following", "values", "for", "its", "parameters\u2014", "-LRB-", "\\", "-LRB-", "learning", "rate=0.001", ",", "\\beta", "1=0.9", ",", "\\beta", "2=0.999", ",", "eps=1e-08", ",", "weight", "decay", "rate=0", ",", "amsgrad=False\\", "-RRB-", "-RRB-"]], "ner": [[], [[27, 28, "a"], [48, 49, "p"], [49, 49, "v"], [52, 52, "v"], [55, 55, "v"], [57, 57, "p"], [57, 57, "v"], [59, 61, "p"], [49, 49, "v"], [52, 52, "v"], [55, 55, "v"], [61, 61, "v"], [63, 63, "p"], [63, 63, "v"]]], "relations": [[], []], "predicted_ner": [[[6, 6, "v"], [17, 17, "v"], [18, 18, "p"], [21, 22, "p"], [24, 24, "v"]], [[27, 27, "a"], [57, 57, "v"]]], "predicted_relations": [[], [[48, 49, 27, 28, "USED-FOR"], [49, 49, 48, 49, "USED-FOR"], [49, 49, 59, 61, "USED-FOR"], [52, 52, 48, 49, "USED-FOR"], [52, 52, 59, 61, "USED-FOR"], [55, 55, 48, 49, "USED-FOR"], [55, 55, 59, 61, "USED-FOR"], [55, 55, 63, 63, "USED-FOR"], [57, 57, 48, 49, "USED-FOR"], [57, 57, 57, 57, "USED-FOR"], [57, 57, 59, 61, "USED-FOR"], [59, 61, 27, 28, "USED-FOR"], [49, 49, 48, 49, "USED-FOR"], [49, 49, 59, 61, "USED-FOR"], [52, 52, 48, 49, "USED-FOR"], [52, 52, 59, 61, "USED-FOR"], [55, 55, 48, 49, "USED-FOR"], [55, 55, 59, 61, "USED-FOR"], [55, 55, 63, 63, "USED-FOR"], [61, 61, 57, 57, "USED-FOR"], [61, 61, 59, 61, "USED-FOR"], [61, 61, 63, 63, "USED-FOR"], [63, 63, 59, 61, "USED-FOR"], [63, 63, 63, 63, "USED-FOR"]]]}
{"doc_key": "1805.01089-30736c6c-7538-4dcc-bc91-f4edd38eba4d", "sentences": [["We", "limit", "the", "vocabulary", "to", "50,000", "most", "frequent", "words", "appearing", "in", "the", "training", "set", "."], ["We", "set", "the", "word", "embedding", "and", "the", "hidden", "size", "to", "256", ",", "512", ",", "and", "512", "for", "Toys", ",", "Sports", ",", "and", "Movies", "datasets", ",", "respectively", "."], ["The", "word", "embedding", "is", "random", "initialized", "and", "learned", "from", "scratch", "."], ["The", "encoder", "is", "a", "single-layer", "bidirectional", "LSTM", ",", "the", "decoder", "is", "a", "single-layer", "unidirectional", "LSTM", ",", "and", "the", "classifier", "is", "a", "two", "layer", "feed-forward", "network", "with", "a", "512", "hidden", "dimension", "."], ["The", "batch", "size", "is", "64", ",", "and", "we", "use", "dropout", "with", "probability", "\\", "-LRB-", "p", "=", "0.2", ",", "\\", "0.05", ",", "\\", "0.0\\", "-RRB-", "for", "Toys", ",", "Sports", ",", "and", "Movies", "datasets", ",", "respectively", "."]], "ner": [[], [[18, 19, "a"], [22, 23, "p"], [25, 25, "v"], [27, 27, "v"], [30, 30, "v"], [27, 27, "v"], [30, 30, "v"]], [[43, 44, "a"]], [[80, 80, "v"], [80, 80, "v"], [54, 54, "a"], [62, 62, "a"], [71, 71, "a"]], [[85, 86, "a"], [93, 93, "a"], [95, 95, "p"], [100, 100, "v"], [103, 103, "v"], [106, 106, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "v"]], [[22, 23, "p"], [25, 25, "v"], [27, 27, "v"], [30, 30, "v"]], [], [[59, 59, "a"], [67, 67, "a"], [74, 74, "v"], [75, 75, "p"], [76, 77, "a"], [80, 80, "v"]], [[85, 86, "p"], [88, 88, "v"], [93, 93, "a"], [100, 100, "v"], [103, 103, "v"], [106, 106, "v"]]], "predicted_relations": [[], [[22, 23, 18, 19, "USED-FOR"]], [], [], []]}
{"doc_key": "1811.05688-c82c6421-377c-4f08-9a0b-9e7c4fdc6a94", "sentences": [["Our", "implementation", "of", "all", "proposed", "architecture", "is", "based", "on", "Pytorch", "library", "-LSB-", "22", "-RSB-", "."], ["Mini-batch", "stochastic", "gradient", "descent", "was", "used", "as", "optimization", "algorithm", "for", "all", "our", "architectures", "."], ["Detailed", "settings", "like", "learning", "rates", "and", "loss", "functions", "can", "be", "found", "in", "the", "corresponding", "sub-sections", "."], ["One", "special", "note", ",", "however", ",", "for", "the", "LSTM", "and", "CRF", "variants", ":", "due", "to", "the", "exploding", "and", "vanishing", "gradient", "problem", "-LSB-", "2", "-RSB-", ",", "these", "models", "can", "not", "learn", "if", "we", "simply", "input", "the", "whole", "songs", "."], ["Hence", ",", "during", "training", ",", "we", "chop", "songs", "further", "into", "some", "sequences", "of", "notes", "that", "contain", "complete", "phrases", "only", ",", "i.e.", ",", "no", "phrase", "will", "be", "broken", "into", "two", "piece", "and", "shared", "by", "two", "adjacent", "sequences", "."], ["For", "LSTM", "variants", ",", "each", "sequence", "of", "notes", "contains", "5", "phrases", "precisely", "."], ["For", "CRF", "variants", ",", "each", "sequence", "of", "notes", "contains", "at", "least", "80", "notes", "and", "at", "least", "two", ",", "but", "an", "unknown", "number", "of", "complete", "phrases", "."], ["All", "sequences", "have", "less", "than", "120", "notes", ",", "the", "upper-bound", "to", "which", "we", "pad", "our", "sequence", "length", "."], ["We", "input", "the", "whole", "song", "only", "at", "validation", "time", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[9, 10, "a"]], [[15, 18, "a"]], [], [[78, 78, "p"], [53, 53, "a"], [55, 55, "a"]], [[86, 86, "c"]], [[121, 121, "a"]], [[134, 134, "a"]], [[174, 175, "p"]], [[178, 178, "p"], [180, 181, "v"], [180, 181, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[15, 18, "a"]], [], [[45, 45, "v"], [53, 53, "a"], [55, 55, "a"]], [[111, 111, "v"], [116, 116, "v"]], [[121, 121, "a"], [129, 129, "v"]], [[134, 134, "a"], [144, 144, "v"], [149, 149, "v"]], [[164, 164, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [[180, 181, 178, 178, "USED-FOR"], [180, 181, 178, 178, "USED-FOR"]], []]}
{"doc_key": "1811.05320-69e33a5b-1997-4d51-a9a7-8d72e85107f0", "sentences": [["The", "hyperparameters", "of", "the", "T-GCN", "model", "mainly", "include", ":", "learning", "rate", ",", "batch", "size", ",", "training", "epoch", ",", "and", "the", "number", "of", "hidden", "layers", "."], ["In", "the", "experiment", ",", "we", "manually", "adjust", "and", "set", "the", "learning", "rate", "to", "0.001", ",", "the", "batch", "size", "to", "64", ",", "and", "the", "training", "epoch", "to", "3000", "."]], "ner": [[[4, 5, "a"], [9, 10, "p"], [12, 13, "p"], [15, 16, "p"], [20, 23, "p"]], [[35, 36, "p"], [38, 38, "v"], [41, 42, "p"], [44, 44, "v"], [48, 49, "p"], [51, 51, "v"]]], "relations": [[], []], "predicted_ner": [[[4, 5, "a"], [9, 10, "p"], [12, 13, "p"], [15, 16, "p"], [22, 23, "p"]], [[35, 36, "p"], [38, 38, "v"], [41, 42, "p"], [44, 44, "v"], [48, 49, "p"], [51, 51, "v"]]], "predicted_relations": [[[9, 10, 4, 5, "USED-FOR"], [12, 13, 4, 5, "USED-FOR"], [15, 16, 4, 5, "USED-FOR"], [20, 23, 4, 5, "USED-FOR"]], [[44, 44, 48, 49, "USED-FOR"], [51, 51, 48, 49, "USED-FOR"]]]}
{"doc_key": "1803.02188-a33f795f-d771-47fd-83b9-370c2e3ce22b", "sentences": [["Training", "Databases", "for", "Faces", "."], ["We", "train", "our", "system", "using", "the", "3DDFA", "data", "of", "-LSB-", "95", "-RSB-", "."], ["The", "3DDFA", "data", "provides", "projection", "and", "3DMM", "model", "parameters", "for", "the", "Basel", "-LSB-", "60", "-RSB-", "+", "FaceWarehouse", "-LSB-", "12", "-RSB-", "model", "for", "each", "image", "of", "the", "300W", "database", "."], ["We", "use", "the", "topology", "defined", "by", "this", "model", "to", "define", "our", "UV", "space", "and", "rasterize", "the", "images", "to", "obtain", "per-pixel", "ground", "truth", "UV", "coordinates", "."], ["Our", "training", "set", "consists", "of", "the", "LFPW", "trainset", ",", "Helen", "trainset", "and", "AFW", ",", "thus", "3148", "images", "that", "are", "captured", "under", "completely", "unconstrained", "conditions", "and", "exhibit", "large", "variations", "in", "pose", ",", "expression", ",", "illumination", ",", "age", ",", "etc", "."], ["Many", "of", "these", "images", "contain", "multiple", "faces", ",", "some", "of", "which", "are", "not", "annotated", "."], ["We", "deal", "with", "this", "issue", "by", "employing", "the", "out-of-the-box", "DPM", "face", "detector", "of", "Mathias", "et", "al", "."], ["-LSB-", "56", "-RSB-", "to", "obtain", "the", "regions", "that", "contain", "a", "face", "for", "all", "of", "the", "images", "."], ["The", "detected", "regions", "that", "do", "not", "overlap", "with", "the", "ground", "truth", "landmarks", "do", "not", "contribute", "to", "the", "loss", "."], ["For", "training", "and", "testing", ",", "we", "have", "rescaled", "the", "images", "such", "that", "their", "largest", "side", "is", "800", "pixels", "."]], "ner": [[], [[11, 12, "a"]], [[19, 20, "a"]], [], [[78, 79, "a"], [81, 82, "a"], [84, 84, "a"]], [], [[135, 137, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[8, 8, "a"]], [[34, 34, "a"], [44, 44, "v"]], [], [[81, 82, "a"], [84, 84, "a"], [87, 87, "v"]], [], [], [], [], [[195, 195, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1803.02188-7a66aaa2-dc0c-43a1-8997-79c9611a4070", "sentences": [["We", "have", "used", "two", "different", "network", "architectures", "for", "our", "experiments", "."], ["In", "particular", ",", "in", "order", "to", "be", "directly", "comparable", "to", "the", "DeepLab-v2", "network", "in", "semantic", "segmentation", "experiments", "we", "first", "used", "a", "ResNet101", "-LSB-", "33", "-RSB-", "architecture", "with", "dilated", "convolutions", "-LRB-", "atrous", "-RRB-", "-LSB-", "15", "-RSB-", ",", "-LSB-", "53", "-RSB-", ",", "such", "that", "the", "stride", "of", "the", "CNN", "is", "8", "and", "-LRB-", "b", "-RRB-", "an", "Hourglass-type", "network", "-LSB-", "57", "-RSB-", "."], ["We", "use", "bilinear", "interpolation", "to", "upscale", "both", "the", "\\", "-LRB-", "\\hat", "-LCB-", "q", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\hat", "-LCB-", "r", "-RCB-", "\\", "-RRB-", "branches", "before", "the", "losses", "."], ["The", "losses", "are", "applied", "at", "the", "input", "image", "scale", "and", "back-propagated", "through", "interpolation", "."], ["We", "apply", "a", "weight", "to", "the", "smooth", "\\", "-LRB-", "L1\\", "-RRB-", "loss", "layers", "to", "balance", "their", "contribution", "."], ["In", "our", "experiments", ",", "we", "have", "used", "a", "weight", "of", "40", "for", "quantized", "-LRB-", "\\", "-LRB-", "d=0.1\\", "-RRB-", "-RRB-", "and", "a", "weight", "of", "70", "for", "non-quantized", "regression", ",", "which", "are", "determined", "by", "a", "coarse", "cross", "validation", "."]], "ner": [[], [[32, 32, "a"], [65, 66, "a"]], [[73, 74, "a"]], [], [[118, 118, "p"]], [[141, 141, "p"], [154, 154, "p"], [143, 143, "v"], [156, 156, "v"], [158, 159, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "v"]], [[22, 23, "a"], [32, 32, "a"], [57, 57, "a"], [59, 59, "v"], [65, 66, "a"]], [], [], [], [[143, 143, "v"], [149, 149, "v"], [156, 156, "v"]]], "predicted_relations": [[], [], [], [], [], [[143, 143, 141, 141, "USED-FOR"], [143, 143, 154, 154, "USED-FOR"], [156, 156, 141, 141, "USED-FOR"], [156, 156, 154, 154, "USED-FOR"], [158, 159, 156, 156, "USED-FOR"]]]}
{"doc_key": "1803.02188-67e58620-6f93-42b1-92be-c070bc9c841e", "sentences": [["For", "the", "ResNet", "based", "network", ",", "we", "use", "an", "initialization", "with", "a", "network", "pre-trained", "for", "the", "MS", "COCO", "segmentation", "task", "-LSB-", "49", "-RSB-", "."], ["The", "new", "layers", "are", "initialized", "with", "random", "weights", "drawn", "from", "Gaussian", "distributions", "."], ["Large", "weights", "of", "the", "regression", "losses", "can", "be", "problematic", "at", "initialization", "even", "with", "moderate", "learning", "rates", "."], ["To", "cope", "with", "this", ",", "we", "use", "initial", "training", "with", "a", "lower", "learning", "rate", "for", "a", "warm", "start", "for", "a", "few", "iterations", "."], ["We", "then", "use", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "with", "a", "polynomial", "decay", "policy", "for", "\\", "-LRB-", "20k\\", "-RRB-", "iterations", "with", "a", "batch", "size", "of", "10", "images", "."]], "ner": [[[2, 4, "a"], [16, 19, "a"]], [[34, 35, "a"]], [[41, 42, "a"]], [[66, 67, "p"], [61, 62, "a"], [75, 75, "p"]], [[82, 83, "p"], [105, 106, "v"], [92, 93, "p"], [99, 99, "p"], [102, 103, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [], [[51, 52, "p"]], [], [[82, 83, "p"], [87, 87, "v"], [97, 97, "v"], [102, 103, "p"], [105, 105, "v"]]], "predicted_relations": [[], [], [], [[66, 67, 61, 62, "USED-FOR"], [75, 75, 61, 62, "USED-FOR"]], []]}
{"doc_key": "1803.02188-617c8c70-15f8-4d51-a0df-35b663956fc7", "sentences": [["For", "the", "hourglass", "architecture", ",", "we", "adopt", "-LSB-", "57", "-RSB-", "with", "inception-v2", "module", "-LRB-", "a", "Figure", "describing", "the", "network", "can", "be", "found", "in", "the", "Appendix", "-RRB-", "."], ["Each", "deconvolution", "layer", "involved", "is", "using", "a", "dilated", "convolution", "following", "by", "a", "\\", "-LRB-", "3\\times", "3\\", "-RRB-", "convolution", "layer", "with", "stride", "1", "and", "same", "output", "channels", "as", "input", "channels", "."]], "ner": [[[2, 3, "a"]], [[28, 29, "p"], [34, 35, "v"], [47, 48, "c"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [11, 11, "a"]], [[41, 42, "v"], [48, 48, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1803.02188-bd938005-1f20-4959-98cb-289d91dea789", "sentences": [["For", "the", "DenseReg", "cascade", "architecture", "-LRB-", "i.e.", ",", "end-to-end", "trainable", "dense", "shape", "regression", "and", "articulated", "pose", "estimation", "by", "means", "of", "landmark", "localisation", "-RRB-", "we", "used", "a", "stack", "of", "two", "hourglasses", "."], ["The", "first", "hourglass", "network", "is", "the", "one", "described", "above", "."], ["The", "second", "hourglass", "network", "is", "regressing", "to", "a", "heatmap", "representation", "of", "facial", "landmarks/body", "joints", "-LRB-", "68-channel", "heatmap", "for", "the", "landmark", "localisation", "experiments", "and", "16-channel", "heatmap", "of", "the", "body", "pose", "estimation", "experiments", "-RRB-", "."], ["We", "apply", "\\", "-LRB-", "L2\\", "-RRB-", "loss", "to", "the", "heatmap", "regression", "."], ["Weights", "are", "applied", "to", "balance", "losses", "of", "both", "first", "and", "second", "hourglasses", "to", "have", "equal", "contribution", "."], ["During", "training", ",", "we", "are", "randomly", "scaling", "with", "ratio", "between", "0.75", "and", "1.25", ",", "randomly", "rotating", "with", "angle", "-30", "to", "30", "degree", ",", "and", "randomly", "cropping", "images", "of", "size", "\\", "-LRB-", "321\\times", "321\\", "-RRB-", "to", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "."]], "ner": [[[2, 4, "a"]], [[33, 34, "a"]], [[43, 44, "a"]], [], [], [[111, 111, "p"], [113, 113, "v"], [115, 115, "v"], [120, 120, "p"], [121, 121, "v"], [123, 123, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 3, "a"], [28, 28, "v"]], [[33, 34, "a"], [37, 37, "v"]], [[56, 56, "v"], [64, 64, "v"]], [[78, 80, "a"]], [], [[113, 113, "v"], [115, 115, "v"], [123, 124, "v"], [135, 135, "v"], [140, 141, "v"]]], "predicted_relations": [[], [], [], [], [], [[113, 113, 120, 120, "USED-FOR"], [115, 115, 111, 111, "USED-FOR"], [115, 115, 120, 120, "USED-FOR"], [121, 121, 111, 111, "USED-FOR"], [121, 121, 120, 120, "USED-FOR"], [123, 123, 120, 120, "USED-FOR"]]]}
{"doc_key": "1809.09767-8559aaa9-1f07-4c22-a6b5-f5fda53d2c31", "sentences": [["The", "following", "apply", "to", "all", "three", "types", "of", "our", "models", "."], ["Images", ",", "unless", "mentioned", "that", "left", "and", "right", "viewpoint", "images", "were", "used", "from", "the", "RobotCar", "dataset", ",", "were", "trained", "on", "rear", "views", "only", "."], ["And", "unless", "stated", "otherwise", ",", "images", "in", "our", "trials", "were", "scaled", "to", "\\", "-LRB-", "286\\times", "286\\", "-RRB-", "size", "and", "randomly", "cropped", "to", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "for", "training", "."], ["If", "a", "\\", "-LRB-", "512\\times", "512\\", "-RRB-", "resolution", "is", "used", ",", "training", "crops", "are", "of", "size", "\\", "-LRB-", "384\\times", "384\\", "-RRB-", "due", "to", "memory", "constraints", "."], ["Memory", "also", "restricts", "training", "on", "resolutions", "higher", "than", "\\", "-LRB-", "512\\times", "512\\", "-RRB-", "."], ["Inference", "is", "always", "on", "the", "pre-crop", "size", "because", "our", "fully-convolutional", "architecture", "allows", "for", "arbitrary", "input", "sizes", "."], ["Batches", "are", "not", "used", ",", "and", "random", "image", "flipping", "-LRB-", "left-right", "-RRB-", "is", "enabled", "."], ["Training", "is", "run", "for", "40", "epochs", "."], ["Learning", "rates", "begin", "at", "\\", "-LRB-", "2\\text", "-LCB-", "e-", "-RCB-", "4\\", "-RRB-", "for", "generators", "and", "\\", "-LRB-", "1\\text", "-LCB-", "e-", "-RCB-", "4\\", "-RRB-", "for", "discriminators", ",", "are", "constant", "for", "the", "first", "half", "of", "training", "and", "decreasing", "linearly", "to", "zero", "during", "the", "second", "half", "."], ["The", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "from", "equation", "-LRB-", "REF", "-RRB-", "is", "set", "to", "10.0", ",", "as", "in", "-LSB-", "27", "-RSB-", "."]], "ner": [[], [[25, 26, "a"]], [[63, 63, "c"], [63, 63, "c"]], [[76, 76, "c"], [76, 76, "c"]], [[94, 94, "c"], [94, 94, "c"]], [], [], [], [[177, 177, "c"], [177, 177, "c"], [168, 168, "p"]], [[202, 202, "v"], [191, 191, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"]], [[25, 26, "a"]], [[50, 50, "v"], [60, 60, "v"]], [[70, 70, "v"], [84, 84, "v"]], [[102, 102, "v"]], [[114, 115, "a"]], [], [[141, 141, "v"], [142, 142, "p"]], [[144, 145, "p"], [150, 154, "v"], [161, 165, "v"], [182, 182, "v"]], [[202, 202, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1809.09767-99559f90-683b-41ad-8246-8b370ab08854", "sentences": [["DenseVLAD", "uses", "the", "\\", "-LRB-", "k=128\\", "-RRB-", "pretrained", "cluster", "centers", "provided", "by", "-LSB-", "24", "-RSB-", "."], ["The", "VLAD", "vectors", "are", "projected", "down", "to", "4096", "dimensions", "via", "PCA", "prior", "to", "comparisons", "."], ["We", "also", "keep", "the", "default", "SIFT", "extraction", "scales", "used", "in", "DenseVLAD", ",", "at", "\\", "-LRB-", "n", "\\in", "\\lbrace", "4", ",", "6", ",", "8", ",", "10\\rbrace", "\\", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[0, 0, "a"], [5, 5, "p"], [5, 5, "v"]], [[26, 26, "a"]], [[41, 41, "a"], [46, 46, "p"], [49, 49, "v"], [51, 51, "v"], [53, 53, "v"], [55, 55, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[0, 0, "a"], [5, 5, "v"]], [[17, 17, "a"], [23, 23, "v"], [26, 26, "a"]], [[41, 41, "a"], [48, 55, "v"]], []], "predicted_relations": [[[5, 5, 0, 0, "USED-FOR"], [5, 5, 5, 5, "USED-FOR"], [5, 5, 5, 5, "USED-FOR"]], [], [[46, 46, 41, 41, "USED-FOR"], [49, 49, 46, 46, "USED-FOR"], [51, 51, 46, 46, "USED-FOR"], [53, 53, 46, 46, "USED-FOR"]], []]}
{"doc_key": "1802.04200-a00d0998-d47d-478f-a0f3-6af69c8241b9", "sentences": [["We", "train", "our", "models", "with", "Adam", "-LSB-", "15", "-RSB-", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "and", "a", "mini-batch", "size", "of", "64", "for", "BTEC", ",", "and", "32", "for", "LibriSpeech", "-LRB-", "because", "of", "memory", "constraints", "-RRB-", "."], ["We", "use", "variational", "dropout", "-LSB-", "16", "-RSB-", ",", "i.e.", ",", "the", "same", "dropout", "mask", "is", "applied", "to", "all", "elements", "in", "a", "batch", "at", "all", "time", "steps", ",", "with", "a", "rate", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "for", "LibriSpeech", "and", "\\", "-LRB-", "0.4\\", "-RRB-", "for", "BTEC", "."], ["In", "the", "MT", "tasks", ",", "we", "also", "drop", "source", "and", "target", "symbols", "at", "random", ",", "with", "probability", "\\", "-LRB-", "0.2\\", "-RRB-", "."], ["Dropout", "is", "not", "applied", "on", "recurrent", "connections", "-LSB-", "17", "-RSB-", "."]], "ner": [[[5, 5, "a"], [12, 13, "p"], [17, 17, "v"], [13, 13, "p"], [32, 32, "c"], [27, 27, "c"]], [[42, 43, "a"], [69, 69, "p"], [73, 73, "v"], [76, 76, "c"], [80, 80, "v"], [83, 83, "c"], [73, 73, "v"]], [[104, 104, "v"], [101, 101, "p"], [104, 104, "v"], [87, 88, "c"]], []], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [12, 13, "p"], [17, 17, "v"], [22, 23, "p"], [25, 25, "v"], [26, 27, "c"], [27, 27, "a"], [30, 30, "v"], [32, 32, "a"]], [[42, 43, "a"], [52, 53, "p"], [73, 73, "v"], [76, 76, "a"], [80, 80, "v"], [83, 83, "a"]], [[104, 104, "v"]], [[107, 107, "a"]]], "predicted_relations": [[[12, 13, 5, 5, "USED-FOR"], [13, 13, 5, 5, "USED-FOR"]], [[69, 69, 42, 43, "USED-FOR"], [76, 76, 73, 73, "USED-FOR"], [76, 76, 80, 80, "USED-FOR"], [76, 76, 73, 73, "USED-FOR"], [83, 83, 73, 73, "USED-FOR"], [83, 83, 80, 80, "USED-FOR"], [83, 83, 73, 73, "USED-FOR"]], [[104, 104, 101, 101, "USED-FOR"], [104, 104, 101, 101, "USED-FOR"], [87, 88, 104, 104, "USED-FOR"], [87, 88, 104, 104, "USED-FOR"]], []]}
{"doc_key": "1802.04200-01c8a36d-29e2-4b79-9a39-4244d29b9654", "sentences": [["We", "train", "all", "our", "models", "on", "LibriSpeech", "train", "augmented", "with", "the", "Google", "Translate", "references", ",", "i.e.", ",", "the", "source", "side", "of", "the", "corpus", "-LRB-", "speech", "-RRB-", "is", "duplicated", ",", "and", "the", "target", "side", "-LRB-", "translations", "-RRB-", "is", "a", "concatenation", "of", "the", "aligned", "references", "with", "the", "Google", "Translate", "references", "."], ["Because", "of", "GPU", "memory", "limits", ",", "we", "set", "the", "maximum", "length", "to", "1400", "frames", "for", "LibriSpeech", "input", ",", "and", "300", "characters", "for", "its", "output", "."], ["This", "covers", "about", "\\", "-LRB-", "90\\", "%", "\\", "-RRB-", "of", "the", "training", "corpus", "."], ["Longer", "sequences", "are", "kept", "but", "truncated", "to", "the", "maximum", "size", "."], ["We", "evaluate", "our", "models", "on", "the", "dev", "set", "every", "1000", "mini-batch", "updates", "using", "BLEU", "for", "AST", "and", "MT", ",", "and", "WER", "for", "ASR", ",", "and", "keep", "the", "best", "performing", "checkpoint", "for", "final", "evaluation", "on", "the", "test", "set", "."]], "ner": [[[6, 7, "a"], [11, 13, "a"], [45, 47, "a"]], [[58, 59, "a"], [58, 59, "p"], [61, 62, "v"], [64, 65, "c"], [68, 69, "v"], [72, 72, "c"]], [], [], [[112, 112, "a"], [119, 119, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 7, "a"]], [[61, 61, "v"], [64, 64, "a"], [68, 68, "v"]], [[79, 80, "v"]], [], [[108, 108, "v"], [112, 112, "a"]]], "predicted_relations": [[], [[58, 59, 58, 59, "USED-FOR"], [61, 62, 58, 59, "USED-FOR"]], [], [], []]}
{"doc_key": "1804.00874-96f6a4de-323d-4904-9400-6c2214b0e83a", "sentences": [["The", "network", "is", "trained", "on", "the", "SceneNet", "RGB-D", "dataset", "-LSB-", "18", "-RSB-", "which", "is", "composed", "of", "photorealistic", "renderings", "of", "randomised", "indoor", "scenes", "."], ["It", "provides", "colour", "and", "depth", "images", "as", "well", "as", "semantic", "labeling", "and", "poses", ",", "out", "of", "which", "we", "only", "make", "use", "of", "the", "two", "former", "ones", "."], ["We", "make", "use", "of", "the", "ADAM", "optimiser", "-LSB-", "14", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "train", "the", "network", "for", "6", "epochs", "while", "reducing", "the", "learning-rate", "to", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[6, 8, "a"]], [], [[55, 56, "a"], [62, 64, "p"]], [[85, 85, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 8, "a"]], [[46, 46, "v"]], [[55, 55, "a"], [63, 64, "p"], [68, 70, "v"]], [[78, 78, "a"], [80, 80, "v"], [81, 81, "p"], [85, 85, "p"], [89, 92, "v"]]], "predicted_relations": [[], [], [[62, 64, 55, 56, "USED-FOR"]], []]}
{"doc_key": "1804.08262-94bf3c7a-d01e-4a44-a733-f623af8daeda", "sentences": [["As", "described", "in", "sec", ":", "neural-transducers", ",", "we", "used", "encoder-decoder", "architectures", "with", "global", "attention", "."], ["Specifically", ",", "both", "the", "encoder", "and", "decoder", "consisted", "of", "2-layer", "LSTMs", "."], ["The", "encoder", "was", "bidirectional", "and", "output", "from", "the", "forward", "and", "backward", "LSTMs", "was", "concatenated", "."], ["Both", "encoder", "and", "decoder", "had", "100", "hidden", "units", "and", "all", "character", "embeddings", "were", "300", "hidden", "units", "."], ["Networks", "were", "trained", "using", "Adadelta", "with", "a", "base", "learning", "rate", "of", "1.0", "."], ["Minibatches", "of", "size", "20", "were", "used", "."], ["Dropout", "between", "layers", "was", "set", "at", "0.3", "."]], "ner": [[[9, 13, "a"]], [[25, 25, "p"], [24, 24, "v"]], [[38, 38, "p"], [30, 30, "v"]], [[48, 49, "p"], [56, 57, "p"], [47, 47, "v"], [55, 55, "v"], [52, 53, "c"]], [[63, 63, "p"], [66, 70, "v"]], [[74, 75, "v"]], [[85, 85, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[25, 25, "a"]], [[38, 38, "a"]], [[47, 47, "v"], [48, 49, "p"], [55, 55, "v"]], [[63, 63, "a"], [70, 70, "v"]], [[75, 75, "v"]], [[79, 79, "p"], [85, 85, "v"]]], "predicted_relations": [[], [], [], [[52, 53, 55, 55, "USED-FOR"]], [], [], []]}
{"doc_key": "1804.00495-039bb374-90de-409e-a07e-32188c06b8bf", "sentences": [["The", "model", "parameters", "hat", "must", "be", "learned", "from", "the", "data", "are", "\\", "-LRB-", "\\theta", "=\\lbrace", "w", ",", "C_", "-LCB-", "\\phi", "-RCB-", ",", "\\beta", ",", "\\alpha", ",", "\\eta", "\\rbrace", "\\", "-RRB-", "."], ["All", "of", "these", "parameters", "have", "concrete", "interpretations", ",", "and", ",", "therefore", ",", "we", "must", "specify", "some", "constraints", "on", "the", "model", "values", "to", "ensure", "the", "result", "is", "reasonable", "."], ["We", "specify", "the", "following", "constraints", "and", "explain", "their", "interpretations", "below", ":", "\\", "-LRB-", "\\begin", "-LCB-", "aligned", "-RCB-", "&", "-LRB-", "1", "-RRB-", "w_1=-2.5", ",", "\\quad", "-LRB-", "2", "-RRB-", "w_2\\le", "-0.5", ",", "\\quad", "-LRB-", "3", "-RRB-", "w_7=w_8\\ge", "0", ",", "\\\\", "&", "-LRB-", "4", "-RRB-", "w_", "-LCB-", "11", "-RCB-", "=w_", "-LCB-", "12", "-RCB-", "\\ge", "0", ",", "\\quad", "-LRB-", "5", "-RRB-", "w_", "-LCB-", "13", "-RCB-", "\\le", "0", ",", "\\quad", "-LRB-", "6", "-RRB-", "w_", "-LCB-", "14", "-RCB-", "\\le", "0", ",", "\\\\", "&", "-LRB-", "7", "-RRB-", "w_", "-LCB-", "17", "-RCB-", "\\le", "0", ",", "\\quad", "-LRB-", "8", "-RRB-", "w_", "-LCB-", "18", "-RCB-", "\\le", "0", ",", "\\quad", "-LRB-", "9", "-RRB-", "2w_2+w_7+w_", "-LCB-", "11", "-RCB-", "\\le", "w_", "-LCB-", "14", "-RCB-", "+w_", "-LCB-", "18", "-RCB-", ",", "\\\\", "&", "-LRB-", "10", "-RRB-", "C_", "-LCB-", "\\phi", "-RCB-", "\\ge", "0", ",", "\\quad", "-LRB-", "11", "-RRB-", "\\beta", "\\ge", "0", ",", "\\quad", "-LRB-", "12", "-RRB-", "\\alpha", "\\ge", "0", ",", "\\quad", "-LRB-", "13", "-RRB-", "\\eta", "\\ge", "0.\\end", "-LCB-", "aligned", "-RCB-", "\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1804.00495-b7830dd5-94a4-41f2-a70c-cb247a468482", "sentences": [["We", "select", "the", "discount", "factor", "\\", "-LRB-", "\\gamma", "=0.99\\", "-RRB-", "for", "the", "MDP", "."], ["This", "parameter", "determines", "the", "effective", "time", "horizon", "."], ["A", "samll", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "would", "result", "in", "a", "greedy", "policy", ",", "which", "is", "undesirable", "."], ["We", "solve", "this", "MDP", "using", "Gaussian", "Process", "Dynamic", "Programming", "-LSB-", "13", "-RSB-", "."]], "ner": [[[3, 4, "a"], [7, 7, "p"], [8, 8, "v"]], [], [[26, 26, "p"]], [[45, 48, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "p"], [8, 8, "v"]], [], [[26, 26, "p"]], [[45, 48, "a"]]], "predicted_relations": [[[8, 8, 7, 7, "USED-FOR"]], [], [], []]}
{"doc_key": "1802.05203-7731e586-1e4e-49e7-bce7-e68f52c5404a", "sentences": [["We", "selected", "the", "number", "of", "epochs", "for", "stopping", "training", "by", "contrasting", "training", "loss", "and", "validation", "loss", "over", "epochs", "."], ["We", "split", "the", "public", "training", "dataset", "into", "a", "training", "set", "and", "a", "validation", "set", "by", "randomly", "picking", "80", "%", "and", "the", "remaining", "20", "%", "cases", "from", "each", "scanner", "respectively", "."], ["Thus", "in", "total", ",", "the", "models", "were", "trained", "on", "48", "cases", "and", "validated", "on", "12", "cases", "."], ["Figure", "REF", "shows", "the", "curves", "of", "training", "and", "validation", "loss", "over", "100", "epochs", "."], ["It", "could", "be", "observed", "that", "the", "validation", "loss", "did", "not", "show", "a", "descending", "trend", "at", "around", "50", "epochs", "."], ["The", "reason", "to", "choose", "50", "epochs", "rather", "than", "a", "higher", "one", "is", "1", "-RRB-", "to", "avoid", "over", "fitting", "on", "the", "training", "data", ",", "and", "2", "-RRB-", "keep", "low", "computational", "cost", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[3, 5, "p"], [6, 8, "c"]], [[23, 24, "a"], [31, 32, "a"]], [], [[72, 75, "a"]], [[96, 96, "v"]], [[103, 103, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[36, 37, "v"], [41, 42, "v"]], [[58, 58, "v"], [63, 63, "v"]], [[77, 77, "v"], [78, 78, "p"]], [[86, 87, "a"], [96, 96, "v"], [97, 97, "p"]], [[103, 103, "v"], [104, 104, "p"], [109, 109, "v"]], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1802.05203-932e2201-97b2-439b-8bff-76b0fa8e4d1c", "sentences": [["The", "size", "of", "batch", "and", "learning", "rate", "have", "a", "large", "influence", "on", "the", "stability", "of", "the", "training", "process", "."], ["To", "our", "empirical", "observation", ",", "if", "the", "learning", "rate", "was", "set", "to", "values", "bigger", "than", "10\\", "-LRB-", "^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "the", "training", "loss", "would", "be", "suddenly", "reaching", "to", "nearly", "0", "-LRB-", "i.e.", ",", "the", "worst", "performance", "-RRB-", "at", "some", "beginning", "epoch", "and", "would", "remain", "not", "updating", "the", "training", "loss", "."], ["Both", "of", "the", "batch", "size", "and", "learning", "rate", "directly", "influence", "the", "magnitude", "of", "the", "gradient", "and", "sometimes", "will", "lead", "to", "a", "gradient", "exposure", "issue", "."], ["Therefore", "the", "batch", "size", "was", "set", "to", "30", "and", "learning", "rate", "was", "set", "to", "0.0002", "throughout", "all", "of", "the", "experiments", "."]], "ner": [[[5, 6, "a"]], [[26, 27, "a"]], [[76, 77, "a"], [79, 80, "a"]], [[100, 101, "a"], [107, 108, "a"], [112, 112, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 6, "p"]], [[26, 27, "p"], [52, 52, "v"]], [[79, 80, "p"]], [[100, 101, "p"], [105, 105, "v"], [107, 108, "p"], [112, 112, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1802.06488-1debd8b3-d9ba-43e4-8fae-f5e1daf56bb7", "sentences": [["The", "proposed", "Tiny", "SSD", "network", "was", "trained", "for", "220,000", "iterations", "in", "the", "Caffe", "framework", "with", "training", "batch", "size", "of", "24", "."], ["RMSProp", "was", "utilized", "as", "the", "training", "policy", "with", "base", "learning", "rate", "set", "to", "0.00001", "and", "\\", "-LRB-", "\\gamma", "=", "0.5\\", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[2, 4, "a"], [12, 13, "a"]], [[21, 21, "a"], [29, 31, "p"], [40, 40, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[2, 4, "a"], [8, 8, "v"], [12, 13, "a"], [15, 17, "p"], [19, 19, "v"]], [[21, 21, "a"], [29, 31, "p"], [34, 34, "v"], [40, 40, "v"]], []], "predicted_relations": [[], [[29, 31, 21, 21, "USED-FOR"]], []]}
{"doc_key": "1810.10254-23cdd525-d04f-45a4-b0c0-4908e0d4ab80", "sentences": [["In", "this", "section", ",", "we", "present", "the", "experimental", "settings", "for", "pointer-generator", "network", "and", "language", "model", "."], ["Our", "experiment", ",", "our", "pointer-generator", "model", "has", "500-dimensional", "hidden", "states", "and", "word", "embeddings", "."], ["We", "use", "50k", "words", "as", "our", "vocabulary", "for", "source", "and", "target", "."], ["We", "evaluate", "our", "pointer-generator", "performance", "using", "BLEUBLEU", "is", "computed", "using", "multi_bleu.perl", "from", "MOSES", "package", "score", "."], ["We", "take", "the", "best", "model", "as", "our", "generator", "and", "during", "the", "decoding", "stage", ",", "we", "generate", "1-best", "and", "3-best", "using", "beam", "search", "with", "a", "beam", "size", "of", "5", "."], ["For", "the", "input", ",", "we", "build", "a", "parallel", "monolingual", "corpus", "by", "translating", "the", "mixed", "language", "sequence", "using", "Google", "NMTGoogle", "NMT", "Translate", "API", "to", "English", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\ell", "_1", "-RCB-", "\\", "-RRB-", "-RRB-", "and", "Mandarin", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\ell", "_2", "-RCB-", "\\", "-RRB-", "-RRB-", "sequences", "."], ["Then", ",", "we", "concatenate", "the", "translated", "English", "and", "Mandarin", "sequences", "and", "assign", "code-switching", "sequences", "as", "the", "labels", "-LRB-", "\\", "-LRB-", "y^", "-LCB-", "cs", "-RCB-", "\\", "-RRB-", "-RRB-", "."]], "ner": [[[10, 11, "a"]], [[24, 25, "p"], [23, 23, "v"], [27, 28, "p"]], [[32, 33, "v"]], [], [[78, 79, "a"], [82, 83, "p"], [85, 85, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[10, 11, "a"]], [[20, 21, "a"], [23, 23, "v"]], [[32, 32, "v"]], [[48, 48, "a"]], [[76, 76, "v"], [78, 79, "a"], [82, 83, "p"], [85, 85, "v"]], [], []], "predicted_relations": [[], [], [], [], [[82, 83, 78, 79, "USED-FOR"], [85, 85, 82, 83, "USED-FOR"]], [], []]}
{"doc_key": "1809.00903-bcb7cc74-e7ec-44b6-91c2-fd0633316b89", "sentences": [["In", "our", "experiments", ",", "we", "use", "the", "FCN8s", "-LSB-", "21", "-RSB-", "as", "the", "semantic", "segmentation", "model", "."], ["The", "backbone", "is", "VGG16", "-LSB-", "32", "-RSB-", "which", "is", "pretrained", "on", "the", "ImageNet", "dataset", "-LSB-", "7", "-RSB-", "."], ["We", "apply", "the", "PatchGAN", "-LSB-", "17", "-RSB-", "as", "the", "discriminator", ",", "in", "which", "the", "discriminator", "tries", "to", "classify", "whether", "overlapping", "image", "patches", "are", "real", "or", "fake", "."], ["Similar", "to", "EBGAN", "-LSB-", "40", "-RSB-", ",", "we", "add", "the", "Gaussian", "noise", "to", "the", "generator", "."], ["During", "training", ",", "Adam", "-LSB-", "15", "-RSB-", "optimization", "is", "applied", "with", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=0.9", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=0.999", "."], ["For", "the", "Conservative", "Loss", ",", "we", "apply", "\\", "-LRB-", "a", "=", "\\mathrm", "-LCB-", "e", "-RCB-", "\\", "-RRB-", "and", "the", "balanced", "weight", "\\", "-LRB-", "\\lambda", "=", "5\\", "-RRB-", "."], ["The", "ablation", "study", "will", "give", "more", "detailed", "explanations", "."], ["Due", "to", "the", "GPU", "memory", "limitation", ",", "the", "images", "used", "in", "our", "experiments", "are", "resized", "and", "cropped", "to", "1024\\", "-LRB-", "\\times", "\\", "-RRB-", "512", "and", "the", "batch", "size", "is", "1", "."], ["More", "experimental", "settings", "will", "be", "available", "in", "the", "supplementary", "material", "."]], "ner": [[[7, 7, "a"]], [[20, 20, "a"], [29, 30, "a"]], [[38, 38, "a"]], [[64, 64, "a"]], [[81, 81, "a"], [94, 94, "v"], [101, 101, "v"]], [[105, 106, "a"], [112, 112, "p"], [128, 128, "v"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"]], [[20, 20, "a"], [29, 30, "a"]], [[38, 38, "a"]], [[64, 64, "a"]], [[81, 81, "a"], [94, 94, "v"], [101, 101, "v"]], [[126, 128, "p"], [128, 128, "v"]], [], [[163, 163, "v"], [166, 167, "p"], [169, 169, "v"]], []], "predicted_relations": [[], [], [], [], [], [[112, 112, 105, 106, "USED-FOR"]], [], [], []]}
{"doc_key": "1811.09885-fa242e30-0d2e-4a7f-a67d-0a9e7b6ac6e8", "sentences": [["Definition", "4.4", "Let", "\\", "-LRB-", "n\\in", "\\mathbb", "-LCB-", "N", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "u", ",", "v\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "n", "-RCB-", "\\", "-RRB-", "be", "two", "probability", "distributions", ",", "i.e", "."], ["\\", "-LRB-", "0\\le", "u_i", ",", "v_i\\le", "1\\", "-RRB-", "for", "all", "\\", "-LRB-", "i=1,2", ",", "\\dots", ",", "n\\", "-RRB-", "and", "\\", "-LRB-", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^n", "u_i=\\sum", "_", "-LCB-", "i=1", "-RCB-", "^n", "v_i=1\\", "-RRB-", "."], ["The", "cross", "entropy", "between", "\\", "-LRB-", "u\\", "-RRB-", "and", "\\", "-LRB-", "v\\", "-RRB-", "is", "defined", "as", ":", "\\", "-LRB-", "H", "-LRB-", "u", ",", "v", "-RRB-", ":", "=", "-u^T\\log", "-LRB-", "v", "-RRB-", ".\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[[29, 29, "v"]], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1811.09885-0a437231-a1fc-4c6c-932e-b168c0799c84", "sentences": [["Let", "\\", "-LRB-", "\\mathcal", "-LCB-", "D", "-RCB-", "\\", "-RRB-", "be", "a", "dataset", "with", "\\", "-LRB-", "C\\", "-RRB-", "classes", "of", "images", "."], ["Given", "an", "input", "image", "\\", "-LRB-", "x^0\\in", "\\mathcal", "-LCB-", "D", "-RCB-", "\\", "-RRB-", "to", "the", "network", "defined", "in", "Figure", "REF", ",", "let", "\\", "-LRB-", "y\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^C\\", "-RRB-", "be", "the", "one-hot", "encoding", "label", "vector", "associated", "with", "\\", "-LRB-", "x^0\\", "-RRB-", "-LRB-", "i.e", "."], ["\\", "-LRB-", "y_i=1\\", "-RRB-", "if", "\\", "-LRB-", "x^0\\", "-RRB-", "is", "of", "Class", "\\", "-LRB-", "i\\", "-RRB-", ",", "and", "\\", "-LRB-", "y_i=0\\", "-RRB-", "otherwise", "-RRB-", ",", "and", "let", "\\", "-LRB-", "x^N\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^C\\", "-RRB-", "be", "the", "output", "of", "the", "network", "."], ["The", "label", "vector", "\\", "-LRB-", "y\\", "-RRB-", "can", "be", "considered", "as", "the", "true", "distribution", "of", "\\", "-LRB-", "x^0\\", "-RRB-", "over", "the", "\\", "-LRB-", "C\\", "-RRB-", "possible", "classes", "."], ["To", "obtain", "a", "predicted", "distribution", "of", "\\", "-LRB-", "x^0\\", "-RRB-", "from", "the", "network", "and", "compare", "it", "with", "\\", "-LRB-", "y\\", "-RRB-", ",", "we", "apply", "the", "softmax", "normalization", "function", "to", "the", "output", "\\", "-LRB-", "x^N\\", "-RRB-", "of", "the", "network", ",", "so", "that", "the", "loss", "to", "be", "minimized", "for", "each", "input", "\\", "-LRB-", "x^0\\in", "\\mathcal", "-LCB-", "D", "-RCB-", "\\", "-RRB-", "is", "\\", "-LRB-", "H", "-LRB-", "y", ",", "S", "-LRB-", "x^N", "-RRB-", "-RRB-", "\\", "-RRB-", "."]], "ner": [[[11, 11, "a"]], [[36, 36, "a"]], [[108, 108, "a"]], [[122, 123, "p"]], [[150, 150, "a"], [175, 175, "a"], [163, 165, "a"], [180, 180, "a"], [141, 142, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [], [], [], [[163, 165, "a"]]], "predicted_relations": [[], [], [], [], [[141, 142, 150, 150, "USED-FOR"]]]}
{"doc_key": "1811.09885-0638332d-e646-47cf-911d-997be030d5bc", "sentences": [["Definition", "4.5", "Let", "\\", "-LRB-", "n\\in", "\\mathbb", "-LCB-", "N", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "u\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "n", "-RCB-", "\\", "-RRB-", "."], ["The", "softmax", "normalization", "of", "\\", "-LRB-", "u\\", "-RRB-", "is", "a", "vector", "in", "\\", "-LRB-", "\\mathbb", "-LCB-", "R", "-RCB-", "^n\\", "-RRB-", "such", "that", ":", "\\", "-LRB-", "S", "-LRB-", "u", "-RRB-", "_i", ":", "=", "\\dfrac", "-LCB-", "\\exp", "-LRB-", "u_i", "-RRB-", "-RCB-", "-LCB-", "\\sum", "_", "-LCB-", "j=1", "-RCB-", "^n\\exp", "-LRB-", "u_j", "-RRB-", "-RCB-", ",", "\\quad", "i=1,2", ",", "\\dots", ",", "n.\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[], [[28, 29, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1812.00500-c5ccb290-b6e5-4a71-89b5-cfac8659e397", "sentences": [["As", "explained", "in", "Sec", "."], ["REF", ",", "we", "first", "train", "our", "network", "on", "each", "individual", "task", "to", "find", "the", "layers", "fit", "for", "each", "task", "along", "with", "other", "training", "parameters", "."], ["The", "results", "are", ":", "\\", "-LRB-", "l_\\mathrm", "-LCB-", "R", "-RCB-", "=3\\", "-RRB-", "-LRB-", "image", "caption", "retrieval", "-RRB-", ",", "\\", "-LRB-", "l_\\mathrm", "-LCB-", "Q", "-RCB-", "=5\\", "-RRB-", "-LRB-", "VQA", "-RRB-", ",", "and", "\\", "-LRB-", "l_\\mathrm", "-LCB-", "G", "-RCB-", "=2\\", "-RRB-", "-LRB-", "visual", "grounding", "-RRB-", "."], ["The", "training", "parameters", "were", "determined", "accordingly", ";", "see", "the", "supplementary", "material", "for", "details", "."], ["We", "freeze", "all", "these", "parameters", "throughout", "all", "the", "experiments", "."]], "ner": [[], [[11, 11, "a"], [27, 28, "a"]], [[40, 40, "v"], [54, 54, "v"], [67, 67, "v"]], [[75, 76, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[11, 11, "a"]], [], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1812.00500-13fdcaca-e1a2-455b-b849-30f671e6c7e3", "sentences": [["We", "note", "here", "the", "training", "method", "used", "in", "all", "the", "experiments", "."], ["We", "used", "the", "Adam", "optimizer", "with", "the", "parameters", "\\", "-LRB-", "\\alpha", "=", "0.001\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.99\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\alpha", "\\text", "-LCB-", "decay", "-RCB-", "=", "0.5\\", "-RRB-", "."], ["We", "employed", "a", "simple", "training", "schedule", ";", "we", "halve", "the", "learning", "rate", "by", "\u201c", "\\", "-LRB-", "\\alpha", "\\text", "-LCB-", "decay", "-RCB-", "\\", "-RRB-", "\u201d", "after", "each", "\u201c", "#", "step", "\u201d", "or", "step", "size", ",", "which", "are", "determined", "above", "."], ["All", "the", "weights", "in", "our", "network", "were", "initialized", "by", "the", "method", "of", "Glorot", "et", "al", "."], ["-LSB-", "11", "-RSB-", "."], ["Dropout", "is", "applied", "with", "probability", "of", "0.3", "and", "0.1", "over", "FC", "layers", "and", "LSTM", ",", "respectively", "."], ["The", "dimension", "\\", "-LRB-", "d\\", "-RRB-", "of", "the", "feature", "space", "is", "set", "to", "1024", "."]], "ner": [[], [[15, 16, "a"], [22, 22, "p"], [46, 46, "p"], [24, 24, "v"], [32, 32, "v"], [40, 40, "v"], [52, 52, "v"]], [[71, 71, "p"]], [], [], [[114, 114, "a"], [118, 118, "p"], [120, 120, "v"], [124, 125, "c"], [122, 122, "v"], [127, 127, "c"]], [[132, 132, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [[15, 15, "a"], [22, 22, "p"], [24, 24, "v"], [32, 32, "v"], [40, 40, "v"], [46, 46, "p"], [52, 52, "v"]], [[65, 66, "p"], [71, 71, "p"]], [[99, 99, "a"]], [], [[114, 114, "a"], [120, 120, "v"], [122, 122, "v"], [127, 127, "a"]], [[135, 135, "p"], [144, 144, "v"]]], "predicted_relations": [[], [[22, 22, 15, 16, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1805.10254-707ec049-39fb-47ae-b87e-1516f17e96da", "sentences": [["For", "all", "models", ",", "we", "use", "a", "two-layer", "biLSTM", "as", "encoder", "and", "a", "two-layer", "unidirectional", "LSTM", "as", "decoder", ",", "with", "200-dimensional", "hidden", "states", "in", "each", "layer", "."], ["We", "apply", "dropout", "-LSB-", "11", "-RSB-", "on", "RNN", "cells", "with", "a", "keep", "probability", "of", "0.8", "."], ["We", "use", "Adam", "-LSB-", "17", "-RSB-", "with", "an", "initial", "learning", "rate", "of", "0.001", "to", "optimize", "the", "cross-entropy", "loss", "."], ["Gradient", "clipping", "is", "also", "applied", "with", "the", "maximum", "norm", "of", "2", "."], ["The", "input", "and", "output", "vocabulary", "sizes", "are", "both", "50k", "."]], "ner": [[[8, 8, "a"], [14, 15, "a"]], [[29, 29, "a"]], [[45, 45, "a"]], [[69, 70, "p"], [72, 72, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [15, 15, "a"], [20, 20, "v"], [21, 22, "p"]], [[29, 29, "a"], [34, 35, "a"], [38, 39, "p"], [41, 41, "v"]], [[45, 45, "a"], [52, 53, "p"], [55, 55, "v"], [59, 60, "a"]], [[62, 63, "a"], [69, 70, "p"], [72, 72, "v"]], [[82, 82, "v"]]], "predicted_relations": [[], [], [], [[72, 72, 69, 70, "USED-FOR"]], []]}
{"doc_key": "1805.10254-17100cf3-0181-4d07-baed-ee6f1d3194a0", "sentences": [["Adding", "Pre-training", "."], ["We", "pre-train", "a", "two-layer", "seq2seq", "model", "with", "OP", "as", "input", "and", "target", "argument", "as", "output", "from", "our", "training", "set", "."], ["After", "20", "epochs", "-LRB-", "before", "converging", "-RRB-", ",", "parameters", "for", "the", "first", "layer", "are", "used", "to", "initialize", "the", "first", "layer", "of", "all", "comparison", "models", "and", "our", "models", "-LRB-", "except", "for", "the", "keyphrase", "decoder", "-RRB-", "."], ["Experimental", "results", "show", "that", "pre-training", "boosts", "all", "methods", "by", "roughly", "2", "METEOR", "-LSB-", "9", "-RSB-", "points", "."], ["We", "describe", "more", "detailed", "results", "in", "the", "supplementary", "material", "."]], "ner": [[], [[6, 8, "a"], [10, 10, "a"], [14, 15, "a"]], [[24, 25, "a"]], [[69, 69, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[7, 8, "a"]], [[24, 24, "v"], [25, 25, "p"]], [[68, 68, "v"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1801.02209-4190ad8d-6f5c-4030-9c84-2b89773ba2b3", "sentences": [["We", "normalize", "each", "channel", "of", "the", "input", "frame", "to", "\\", "-LRB-", "-LSB-", "0", ",", "1", "-RSB-", "\\", "-RRB-", "before", "feeding", "it", "into", "the", "neural", "network", "."], ["Each", "of", "the", "training", "procedures", "includes", "a", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "and", "a", "discounted", "factor", "\\", "-LRB-", "\\gamma", "=0.95\\", "-RRB-", "."]], "ner": [[], [[33, 34, "a"], [46, 47, "p"], [51, 51, "v"]]], "relations": [[], []], "predicted_ner": [[], [[33, 34, "p"], [38, 41, "v"], [50, 50, "p"]]], "predicted_relations": [[], [[51, 51, 46, 47, "USED-FOR"]]]}
{"doc_key": "1801.02209-c89de064-4ef9-4351-a6cf-6f1bd47e2aa1", "sentences": [["DDPG", ":", "We", "stack", "\\", "-LRB-", "k=5\\", "-RRB-", "recent", "frames", "and", "use", "learning", "rate", "\\", "-LRB-", "10^4\\", "-RRB-", "with", "batch", "size", "128", "."], ["We", "choose", "\\", "-LRB-", "\\alpha", "_\\textrm", "-LCB-", "DDPG", "-RCB-", "=100\\", "-RRB-", "for", "all", "the", "settings", "except", "for", "the", "case", "with", "input", "signal", "of", "\u201c", "RGB+Depth", "\u201d", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "large", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "where", "we", "choose", "\\", "-LRB-", "\\alpha", "_\\textrm", "-LCB-", "DDPG", "-RCB-", "=10\\", "-RRB-", "."], ["We", "use", "an", "entropy", "bonus", "term", "with", "coefficient", "0.001", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "small", "-RCB-", "-RCB-", "\\", "-RRB-", "and", "0.01", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "large", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "exponential", "average", "to", "update", "the", "target", "network", "with", "rate", "0.001", "."], ["A", "training", "update", "is", "performed", "every", "10", "time", "steps", "."], ["The", "replay", "buffer", "size", "is", "\\", "-LRB-", "7\\times", "10^5\\", "-RRB-", "."], ["We", "run", "training", "for", "80000", "episodes", "in", "all", "."], ["We", "use", "a", "linear", "exploration", "strategy", "in", "the", "first", "30000", "episodes", "."]], "ner": [[[0, 0, "a"], [6, 6, "p"], [6, 6, "v"], [12, 13, "p"], [16, 16, "v"], [19, 20, "p"], [21, 21, "v"], [16, 16, "v"], [16, 16, "v"]], [[30, 30, "a"], [74, 74, "a"], [32, 32, "v"], [76, 76, "v"], [76, 76, "v"]], [[87, 87, "v"], [105, 105, "v"], [87, 87, "v"]], [[134, 134, "v"], [134, 134, "v"]], [[142, 142, "v"], [142, 142, "v"], [143, 144, "c"]], [[154, 154, "v"], [154, 154, "v"], [154, 154, "v"], [147, 149, "p"]], [[161, 161, "v"]], [[175, 175, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [6, 6, "v"], [12, 13, "p"], [16, 16, "v"], [19, 20, "p"], [21, 21, "v"]], [[27, 31, "p"], [32, 32, "v"], [71, 75, "p"], [76, 76, "v"]], [[82, 84, "a"], [87, 87, "v"], [105, 105, "v"]], [[125, 126, "a"], [134, 134, "v"]], [[142, 142, "v"]], [[147, 149, "p"], [154, 154, "v"]], [[161, 161, "v"]], [[175, 175, "v"]]], "predicted_relations": [[[6, 6, 6, 6, "USED-FOR"], [6, 6, 6, 6, "USED-FOR"], [6, 6, 12, 13, "USED-FOR"], [12, 13, 0, 0, "USED-FOR"], [16, 16, 6, 6, "USED-FOR"], [16, 16, 12, 13, "USED-FOR"], [21, 21, 6, 6, "USED-FOR"], [16, 16, 6, 6, "USED-FOR"], [16, 16, 12, 13, "USED-FOR"], [16, 16, 6, 6, "USED-FOR"], [16, 16, 12, 13, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1801.02209-489fac4d-f09f-4a7f-9157-8e84d8107756", "sentences": [["A3C", ":", "We", "clip", "the", "reward", "to", "the", "range", "\\", "-LRB-", "-LSB-", "-1,1", "-RSB-", "\\", "-RRB-", "and", "use", "a", "learning", "rate", "\\", "-LRB-", "1e-3\\", "-RRB-", "with", "batch", "size", "64", "."], ["We", "launch", "120", "processes", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "small", "-RCB-", "-RCB-", "\\", "-RRB-", "and", "200", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "large", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["During", "training", "we", "estimate", "the", "discounted", "accumulative", "rewards", "and", "back-propagate", "through", "time", "for", "every", "30", "time", "steps", "unrolled", "."], ["We", "perform", "a", "gradient", "clipping", "of", "1.0", "and", "decay", "the", "learning", "rate", "by", "a", "factor", "of", "1.5", "when", "the", "difference", "of", "KL-divergence", "becomes", "larger", "than", "0.01", "."], ["For", "training", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "small", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "we", "use", "a", "entropy", "bonus", "term", "with", "coefficient", "0.1", ";", "while", "on", "\\", "-LRB-", "\\mathcal", "-LCB-", "E", "-RCB-", "_", "-LCB-", "\\textrm", "-LCB-", "large", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "the", "coefficient", "is", "0.05", "."], ["\\", "-LRB-", "\\alpha", "_", "-LCB-", "\\textrm", "-LCB-", "A3C", "-RCB-", "-RCB-", "\\", "-RRB-", "is", "1.0", "."], ["We", "perform", "\\", "-LRB-", "10^5\\", "-RRB-", "training", "updates", "and", "keep", "the", "best", "model", "with", "the", "highest", "training", "success", "rate", "."]], "ner": [[[0, 0, "a"], [19, 20, "p"], [23, 23, "v"], [26, 27, "p"], [28, 28, "v"]], [], [[74, 76, "a"], [78, 80, "a"]], [[98, 99, "p"], [91, 92, "p"], [94, 94, "v"], [104, 104, "v"], [105, 113, "c"], [94, 94, "v"], [91, 92, "a"], [94, 94, "v"]], [[137, 139, "p"], [142, 142, "v"], [165, 165, "v"]], [[174, 174, "a"], [180, 180, "v"], [180, 180, "v"], [180, 180, "v"]], [[188, 189, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [12, 13, "v"], [19, 20, "p"], [23, 23, "v"], [26, 27, "p"], [28, 28, "v"]], [[32, 32, "v"], [51, 51, "v"]], [[83, 83, "v"]], [[91, 92, "p"], [94, 94, "v"], [98, 99, "p"], [104, 104, "v"], [109, 109, "p"], [113, 113, "v"]], [[137, 139, "a"], [142, 142, "v"], [165, 165, "v"]], [[169, 176, "p"], [180, 180, "v"]], [[186, 186, "v"]]], "predicted_relations": [[[19, 20, 0, 0, "USED-FOR"], [23, 23, 19, 20, "USED-FOR"]], [], [], [[98, 99, 91, 92, "USED-FOR"], [91, 92, 91, 92, "USED-FOR"], [94, 94, 98, 99, "USED-FOR"], [105, 113, 94, 94, "USED-FOR"], [105, 113, 104, 104, "USED-FOR"], [105, 113, 94, 94, "USED-FOR"], [105, 113, 94, 94, "USED-FOR"], [94, 94, 98, 99, "USED-FOR"], [94, 94, 98, 99, "USED-FOR"]], [], [], []]}
{"doc_key": "1802.04431-b9bb45ff-aca9-49ee-a4b0-7a16b380597e", "sentences": [["Each", "model", "is", "shallow", "with", "only", "two", "hidden", "layers", "and", "80", "units", "in", "each", "layer", "."], ["We", "found", "this", "architecture", "provided", "enough", "capacity", "to", "predict", "individual", "channels", "well", ",", "and", "adding", "additional", "capacity", "provided", "little", "to", "no", "prediction", "benefits", "while", "increasing", "model", "sizes", "and", "training", "times", "."], ["All", "channels", "do", "not", "necessarily", "require", "this", "amount", "of", "capacity", "and", "future", "improvements", "could", "include", "automated", "selection", "of", "appropriate", "model", "capacity", "based", "on", "channel", "complexity", "."], ["Similarly", ",", "a", "sequence", "length", "\\", "-LRB-", "l_s", "=", "250\\", "-RRB-", "provided", "a", "balance", "between", "performance", "and", "training", "times", "."], ["The", "difference", "in", "input", "dimensions", "for", "SMAP", "and", "MSL", "results", "from", "the", "missions", "each", "having", "different", "sets", "of", "command", "modules", "."], ["Early", "stopping", "was", "used", "to", "prevent", "overfitting", "during", "model", "training", ",", "and", "not", "all", "models", "were", "trained", "for", "the", "full", "35", "iterations", "."]], "ner": [[[1, 1, "a"], [7, 8, "p"], [11, 14, "p"], [10, 10, "v"]], [[41, 41, "a"]], [[66, 66, "a"]], [[76, 77, "a"]], [], [[122, 122, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [7, 8, "p"], [10, 10, "v"]], [], [], [[82, 82, "v"]], [[101, 101, "a"]], [[114, 115, "a"], [134, 134, "v"]]], "predicted_relations": [[[7, 8, 1, 1, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1802.04431-75ed3f9a-2642-4cea-b63a-e14b91b17798", "sentences": [["If", "\\", "-LRB-", "L", "\\ge", "1", "-", "\\epsilon", "_", "-LCB-", "norm", "-RCB-", "\\", "-RRB-", "values", "are", "classified", "as", "anomalous", "."], ["In", "the", "next", "section", ",", "results", "generated", "using", "\\", "-LRB-", "l_", "-LCB-", "short", "-RCB-", "=", "10\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "norm", "-RCB-", "=", "\\lbrace", "0.01", ",", "0.0001\\rbrace", "\\", "-RRB-", "are", "compared", "to", "the", "approach", "in", "Section", "REF", "."], ["The", "effects", "of", "pruning", "-LRB-", "detailed", "in", "Section", "REF", "-RRB-", "on", "this", "approach", "are", "also", "tested", "."]], "ner": [[], [[56, 56, "a"], [35, 35, "v"], [47, 47, "v"], [49, 49, "v"]], [[73, 73, "a"], [64, 64, "a"]]], "relations": [[], [], []], "predicted_ner": [[], [[35, 35, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1812.02395-1feffdb9-3481-4410-b26f-6e673f0b8fbd", "sentences": [["where", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "is", "the", "learning", "rate", "and", "\\", "-LRB-", "M\\", "-RRB-", "is", "the", "mini-batch", "size", "."], ["The", "specific", "gradients", "of", "the", "parameters", "are", "omitted", "due", "to", "space", "limitations", "-LRB-", "see", "the", "Appendix", "-RRB-", "."], ["In", "the", "training", "phase", ",", "the", "dynamic", "pooling", "is", "simply", "passed", "through", "the", "gradient", "to", "the", "unit", "selected", "as", "maximum", ",", "analogous", "to", "ordinary", "max-pooling", "."], ["In", "the", "mini-batch", "gradient", "descent", ",", "the", "learning", "rate", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "is", "controlled", "using", "the", "Adam", "optimizer", "with", "the", "hyperparameters", "recommended", "in", "-LSB-", "28", "-RSB-", ",", "and", "the", "mini-batches", "are", "set", "as", "\\", "-LRB-", "M=16\\", "-RRB-", "examples", "."], ["We", "used", "the", "same", "procedure", "for", "all", "the", "models", "we", "compared", "in", "our", "experiments", "."], ["The", "detailed", "settings", "of", "the", "hyperparameters", "\\", "-LRB-", "K\\", "-RRB-", ",", "\\", "-LRB-", "T_k\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", ",", "\\", "-LRB-", "\\mu", "\\", "-RRB-", ",", "\\", "-LRB-", "l_0\\", "-RRB-", ",", "and", "\\", "-LRB-", "l\\", "-RRB-", "are", "described", "for", "each", "experimental", "task", "in", "Section", "."]], "ner": [[[8, 9, "p"], [17, 18, "p"], [13, 13, "v"]], [], [[44, 45, "a"]], [[82, 83, "a"], [71, 72, "p"], [101, 101, "v"], [66, 68, "a"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 9, "p"], [13, 13, "p"], [17, 18, "p"]], [], [[44, 45, "a"], [62, 62, "a"]], [[66, 68, "a"], [71, 72, "p"], [82, 82, "a"], [101, 101, "v"]], [], [[138, 138, "p"], [144, 144, "p"]]], "predicted_relations": [[[13, 13, 8, 9, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "1812.02619-afc96ba0-9d7f-40fc-9a2a-9721af1c758a", "sentences": [["We", "optimize", "Tube-CNN", "and", "TPN", "with", "the", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "algorithm", "with", "momentum", "0.9", "and", "weight", "decay", "0.0005", "on", "mini-batches", "-LSB-", "17", "-RSB-", "."], ["The", "classification", "and", "regression", "are", "trained", "with", "the", "cross-entropy", "loss", "and", "smooth", "L1", "loss", "-LSB-", "9", "-RSB-", ",", "respectively", "."], ["We", "fix", "tube", "length", "\\", "-LRB-", "T=10\\", "-RRB-", "for", "all", "tube", "models", "."], ["This", "design", "choice", "is", "analyzed", "in", "Section", "REF", "."]], "ner": [[[15, 15, "p"], [16, 16, "v"], [18, 19, "p"], [20, 20, "v"]], [], [[53, 53, "p"], [53, 53, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [7, 13, "a"], [15, 15, "p"], [16, 16, "v"], [18, 19, "p"], [20, 20, "v"], [22, 22, "a"]], [[35, 36, "a"], [38, 40, "a"]], [[53, 53, "v"], [55, 58, "c"]], []], "predicted_relations": [[[20, 20, 15, 15, "USED-FOR"], [20, 20, 18, 19, "USED-FOR"]], [], [[53, 53, 53, 53, "USED-FOR"], [53, 53, 53, 53, "USED-FOR"]], []]}
{"doc_key": "1808.00327-4e942a4c-aee9-41da-a4f5-59e68aa85948", "sentences": [["We", "apply", "the", "PatchGAN", "-LSB-", "13", "-RSB-", "to", "the", "discriminators", ",", "in", "which", "the", "discriminator", "tries", "to", "classify", "whether", "overlapping", "image", "patches", "are", "real", "or", "fake", "."], ["Similar", "to", "EBGAN", "-LSB-", "39", "-RSB-", ",", "we", "add", "the", "gaussian", "noise", "to", "the", "shared", "layers", "and", "generator", "."], ["During", "training", ",", "Adam", "-LSB-", "12", "-RSB-", "optimization", "is", "applied", "with", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=0.5", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=0.999", "."], ["We", "train", "the", "model", "on", "a", "single", "Titan", "X", "GPU", "with", "learning", "rate=0.0001", "."], ["Each", "mini-batch", "contains", "three", "frontal", "view", "images", ",", "three", "homography", "view", "images", "and", "three", "bird", "view", "images", "."], ["For", "the", "weighted", "factor", "\\", "-LRB-", "\\lambda", "_1\\", "-RRB-", ",", "we", "apply", "\\", "-LRB-", "\\lambda", "_1", "=", "10\\", "-RRB-", ",", "which", "is", "chosen", "by", "using", "a", "cross-validation", "method", "."]], "ner": [[[3, 3, "a"]], [[29, 29, "a"]], [[49, 49, "a"], [62, 62, "v"], [69, 69, "v"]], [[82, 83, "a"], [82, 83, "p"], [83, 83, "v"]], [], [[105, 106, "a"], [120, 120, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[29, 29, "a"]], [[49, 49, "a"]], [], [[88, 88, "v"], [93, 93, "v"], [98, 98, "v"]], [[109, 110, "p"], [117, 118, "p"], [120, 120, "v"], [129, 129, "a"]]], "predicted_relations": [[], [], [], [[82, 83, 82, 83, "USED-FOR"], [83, 83, 82, 83, "USED-FOR"]], [], []]}
{"doc_key": "1805.08206-f0fdb2b3-49ee-4331-9667-3fca30b12b15", "sentences": [["VGG-16", ":", "For", "the", "first", "three", "datasets", "-LRB-", "CIFAR10", ",", "CIFAR100", ",", "and", "SVHN", "-RRB-", ",", "we", "used", "an", "architecture", "inspired", "by", "the", "VGG-16", "architecture", "-LSB-", "24", "-RSB-", "."], ["We", "adapted", "the", "VGG-16", "architecture", "to", "the", "small", "images", "size", "and", "a", "relatively", "small", "dataset", "size", "based", "on", "-LSB-", "18", "-RSB-", "."], ["We", "trained", "the", "model", "for", "250", "epochs", "using", "SGD", "with", "a", "momentum", "value", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["We", "used", "an", "initial", "learning", "rate", "of", "0.1", ",", "a", "learning", "rate", "multiplicative", "drop", "of", "0.5", "every", "20", "epochs", ",", "and", "a", "batch", "size", "of", "128", "."], ["A", "standard", "data", "augmentation", "was", "used", "including", "horizontal", "flips", ",", "rotations", ",", "and", "shifts", "."], ["In", "this", "learning", "regime", ",", "we", "reached", "a", "validation", "error", "of", "6.4", "%", "for", "CIFAR-10", ",", "29.2", "%", "for", "CIFAR-100", "and", "3.54", "%", "for", "SVHN", "."]], "ner": [[[0, 0, "a"], [23, 23, "a"]], [[32, 32, "a"]], [[62, 62, "p"], [67, 67, "v"], [59, 59, "a"]], [[73, 75, "p"], [77, 77, "v"], [80, 83, "p"], [85, 85, "v"], [92, 93, "p"], [95, 95, "v"]], [[99, 100, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [5, 5, "v"], [8, 8, "a"], [10, 10, "a"], [13, 13, "a"], [23, 23, "a"]], [[32, 32, "a"]], [[56, 56, "v"], [57, 57, "p"], [59, 59, "a"], [62, 63, "p"], [67, 67, "v"]], [[74, 75, "p"], [77, 77, "v"], [80, 81, "p"], [85, 85, "v"], [87, 87, "v"], [88, 88, "p"], [92, 93, "p"], [95, 95, "v"]], [], [[123, 124, "v"], [125, 126, "c"], [126, 126, "a"], [128, 129, "v"], [131, 131, "a"], [133, 134, "v"], [135, 136, "c"], [136, 136, "a"]]], "predicted_relations": [[], [], [[62, 62, 59, 59, "USED-FOR"]], [], [], []]}
{"doc_key": "1805.08206-1085d894-68cd-4634-88a6-7d6807e85feb", "sentences": [["Resnet-18", ":", "For", "ImageNet", "dataset", ",", "we", "used", "the", "Resnet-18", "architecture", "-LSB-", "12", "-RSB-", ";", "we", "trained", "the", "model", "using", "SGD", "with", "a", "batch", "size", "of", "256", "and", "momentum", "of", "0.9", "for", "90", "epochs", "."], ["We", "used", "a", "learning", "rate", "of", "0.1", ",", "with", "a", "learning", "rate", "multiplicative", "decay", "of", "0.1", "every", "30", "epochs", "."], ["The", "model", "reached", "a", "-LRB-", "single", "center", "crop", "-RRB-", "top", "1", "validation", "accuracy", "of", "69.6", "%", "and", "top", "5", "validation", "accuracy", "of", "89.1", "%", "."]], "ner": [[[0, 0, "a"], [9, 9, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "p"], [30, 30, "v"], [33, 33, "p"], [32, 32, "v"], [3, 4, "a"]], [[53, 53, "p"], [38, 39, "p"], [45, 46, "p"], [41, 41, "v"], [50, 50, "v"], [45, 48, "p"], [41, 41, "v"], [50, 50, "v"], [51, 53, "c"]], []], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"], [3, 3, "a"], [9, 9, "a"], [20, 20, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "p"], [30, 30, "v"], [32, 32, "v"], [33, 33, "p"]], [[38, 39, "p"], [41, 41, "v"], [45, 46, "p"], [50, 50, "v"], [52, 52, "v"], [53, 53, "p"]], [[65, 65, "v"], [69, 70, "v"], [73, 73, "v"], [77, 78, "v"]]], "predicted_relations": [[[23, 24, 0, 0, "USED-FOR"], [23, 24, 9, 9, "USED-FOR"], [26, 26, 33, 33, "USED-FOR"], [28, 28, 0, 0, "USED-FOR"], [28, 28, 9, 9, "USED-FOR"], [30, 30, 33, 33, "USED-FOR"], [32, 32, 28, 28, "USED-FOR"], [32, 32, 33, 33, "USED-FOR"]], [[41, 41, 53, 53, "USED-FOR"], [41, 41, 45, 46, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [41, 41, 53, 53, "USED-FOR"], [41, 41, 45, 46, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [51, 53, 50, 50, "USED-FOR"], [51, 53, 50, 50, "USED-FOR"]], []]}
{"doc_key": "1805.08206-541bfd01-7ced-40e7-a5b2-2b5356b11abc", "sentences": [["NN-distance", ":", "We", "implemented", "the", "NN-distance", "method", "using", "\\", "-LRB-", "k=500\\", "-RRB-", "for", "the", "nearest", "neighbors", "parameter", "."], ["We", "did", "n't", "implemented", "the", "two", "proposed", "extensions", "-LRB-", "embedding", "regularization", ",", "and", "adversarial", "training", "-RRB-", ",", "this", "add-on", "will", "degrade", "the", "performance", "of", "\\", "-LRB-", "f\\", "-RRB-", "for", "better", "uncertainty", "estimation", ",", "which", "we", "are", "not", "interested", "in", "."], ["Moreover", ",", "running", "the", "NN-distance", "with", "this", "add-on", "will", "require", "to", "add", "it", "to", "all", "other", "methods", "to", "manage", "a", "proper", "comparison", "."]], "ner": [[[0, 0, "a"], [5, 5, "a"], [14, 16, "p"], [10, 10, "v"]], [], [[62, 62, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"], [5, 6, "a"], [10, 10, "v"]], [[23, 23, "v"]], [[62, 62, "a"]]], "predicted_relations": [[[14, 16, 0, 0, "USED-FOR"], [14, 16, 5, 5, "USED-FOR"], [10, 10, 14, 16, "USED-FOR"]], [], []]}
{"doc_key": "1805.08193-8e550c07-9523-4be8-baeb-a5268a4b0810", "sentences": [["The", "learning", "rate", "is", "initialized", "as", "0.1", ",", "and", "decreases", "with", "the", "operation", "\\", "-LRB-", "\\emph", "-LCB-", "tf.train.exponential\\_decay", "-RCB-", "\\", "-RRB-", "with", "the", "staircase", "in", "tensorflow", "."], ["The", "corresponding", "decay", "factor", "is", "set", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["The", "learning", "rate", "for", "generator", "and", "discriminator", "is", "fixed", "with", "\\", "-LRB-", "3e-4\\", "-RRB-", "."]], "ner": [[[6, 6, "v"], [1, 2, "a"], [1, 2, "a"]], [[29, 30, "p"], [35, 35, "v"]], [[39, 40, "a"], [39, 40, "a"], [42, 42, "p"], [50, 50, "v"], [44, 44, "p"], [50, 50, "v"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "p"], [6, 6, "v"]], [[29, 30, "p"], [35, 35, "v"]], [[39, 40, "p"], [50, 50, "v"]]], "predicted_relations": [[], [], [[42, 42, 39, 40, "USED-FOR"], [42, 42, 39, 40, "USED-FOR"], [50, 50, 44, 44, "USED-FOR"], [44, 44, 39, 40, "USED-FOR"], [44, 44, 39, 40, "USED-FOR"], [50, 50, 44, 44, "USED-FOR"]]]}
{"doc_key": "1801.06769-cfdf3c8f-ee66-4f44-9809-0805005e37ae", "sentences": [["For", "the", "SRR-net", ",", "we", "simply", "set", "the", "depth", "of", "the", "network", "to", "20", "."], ["We", "spend", "about", "8", "hours", "on", "training", "the", "SRR-net", "by", "using", "the", "Caffe", "-LSB-", "22", "-RSB-", "and", "use", "Adam", "with", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "and", "mini-batch", "size", "of", "64", "."], ["For", "DJRHR-net", ",", "we", "remove", "the", "batch", "normalization", "and", "pooling", "layer", "to", "get", "better", "regression", "effect", "."], ["Besides", ",", "we", "set", "the", "growth", "rate", "\\", "-LRB-", "K\\", "-RRB-", "to", "12", ",", "the", "number", "of", "the", "denseblocks", "\\", "-LRB-", "L\\", "-RRB-", "is", "3", "."], ["We", "use", "the", "pytorch", "to", "construct", "the", "network", "and", "use", "Adam", "with", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "mini-batch", "size", "of", "10", "."], ["We", "start", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "and", "the", "learning", "rate", "decay", "of", "0.95", "."]], "ner": [[[2, 2, "a"], [8, 8, "p"], [13, 13, "v"]], [[23, 23, "a"], [27, 27, "a"], [33, 33, "a"], [35, 36, "p"], [47, 48, "p"], [50, 50, "v"], [33, 33, "a"], [35, 36, "p"], [47, 48, "p"], [40, 40, "v"]], [[53, 53, "a"]], [[74, 75, "p"], [81, 81, "v"], [93, 93, "v"]], [[105, 105, "a"], [107, 108, "p"], [119, 120, "p"], [98, 98, "a"], [105, 105, "a"], [107, 108, "p"], [119, 120, "p"], [112, 112, "v"], [122, 122, "v"]], [[135, 135, "v"], [133, 133, "v"], [128, 129, "p"], [141, 142, "p"], [141, 143, "p"], [145, 145, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [13, 13, "v"]], [[18, 18, "v"], [23, 23, "a"], [27, 27, "a"], [33, 33, "a"], [35, 36, "p"], [40, 43, "v"], [47, 48, "p"], [50, 50, "v"]], [[53, 53, "a"]], [[74, 75, "p"], [78, 78, "p"], [81, 81, "v"], [90, 90, "p"], [93, 93, "v"]], [[98, 98, "a"], [105, 105, "a"], [107, 108, "p"], [112, 115, "v"], [119, 120, "c"], [122, 122, "v"]], [[128, 129, "p"], [133, 136, "v"], [141, 143, "p"], [145, 145, "v"]]], "predicted_relations": [[[8, 8, 2, 2, "USED-FOR"], [13, 13, 8, 8, "USED-FOR"]], [[35, 36, 23, 23, "USED-FOR"], [35, 36, 27, 27, "USED-FOR"], [35, 36, 33, 33, "USED-FOR"], [35, 36, 33, 33, "USED-FOR"], [47, 48, 33, 33, "USED-FOR"], [47, 48, 33, 33, "USED-FOR"], [35, 36, 23, 23, "USED-FOR"], [35, 36, 27, 27, "USED-FOR"], [35, 36, 33, 33, "USED-FOR"], [35, 36, 33, 33, "USED-FOR"], [47, 48, 33, 33, "USED-FOR"], [47, 48, 33, 33, "USED-FOR"], [40, 40, 35, 36, "USED-FOR"], [40, 40, 35, 36, "USED-FOR"]], [], [[81, 81, 74, 75, "USED-FOR"]], [[107, 108, 105, 105, "USED-FOR"], [107, 108, 98, 98, "USED-FOR"], [107, 108, 105, 105, "USED-FOR"], [119, 120, 105, 105, "USED-FOR"], [119, 120, 105, 105, "USED-FOR"], [107, 108, 105, 105, "USED-FOR"], [107, 108, 98, 98, "USED-FOR"], [107, 108, 105, 105, "USED-FOR"], [119, 120, 105, 105, "USED-FOR"], [119, 120, 105, 105, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"], [112, 112, 107, 108, "USED-FOR"]], [[135, 135, 128, 129, "USED-FOR"], [135, 135, 141, 142, "USED-FOR"], [133, 133, 128, 129, "USED-FOR"]]]}
{"doc_key": "1808.06161-a5181b7d-55bd-473c-9243-9b541a775b32", "sentences": [["The", "token", "embeddings", "were", "pre-trained", "on", "a", "large", "corpus", "combining", "Wikipedia", ",", "PubMed", ",", "and", "PMC", "texts", "-LSB-", "27", "-RSB-", "using", "the", "word2vec", "toolThe", "word", "vectors", "can", "be", "downloaded", "at", "http", ":", "//bio.nlplab.org/", "-LRB-", "denoted", "as", "\u201c", "Word2vec-wiki+P.M.", "\u201d", "-RRB-", "."], ["They", "are", "fixed", "during", "the", "training", "phase", "to", "avoid", "over-fitting", "."], ["We", "also", "tried", "other", "types", "of", "word", "embeddings", ",", "such", "as", "the", "word2vec", "embeddings", "pre-trained", "on", "the", "Google", "News", "datasethttps", ":", "//code.google.com/archive/p/word2vec/", "-LRB-", "denoted", "as", "\u201c", "Word2vec-News", "\u201d", "-RRB-", ",", "word2vec", "embeddings", "pre-trained", "on", "the", "Wikipedia", "corpushttps", ":", "//github.com/jind11/word2vec-on-wikipedia", "-LRB-", "denoted", "as", "\u201c", "Word2vec-wiki", "\u201d", "-RRB-", ",", "GloVe", "embeddings", "pre-trained", "on", "the", "corpus", "of", "Wikipedia", "2014", "+", "Gigaword", "5http", ":", "//nlp.stanford.edu/data/glove.6B.zip", "-LRB-", "denoted", "as", "\u201c", "Glove-wiki", "\u201d", "-RRB-", ",", "fastText", "embeddings", "pre-trained", "on", "Wikipediahttps", ":", "//github.com/facebookresearch/fastText/blob/master/", "pretrained-vectors.md", "-LRB-", "denoted", "as", "\u201c", "FastText-wiki", "\u201d", "-RRB-", ",", "and", "fastText", "embeddings", "initialized", "with", "the", "standard", "GloVe", "Common", "Crawl", "embeddings", "and", "then", "fine-tuned", "on", "PubMed", "abstracts", "plus", "MIMIC-III", "notes", "-LRB-", "denoted", "as", "\u201c", "FastText-P.M.+MIMIC", "\u201d", "-RRB-", "."], ["The", "comparison", "results", "are", "summarized", "in", "the", "next", "section", "."]], "ner": [[[37, 37, "a"]], [], [[78, 78, "a"], [95, 95, "a"], [117, 117, "a"], [133, 133, "a"], [161, 161, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [], [[78, 78, "a"], [95, 95, "a"], [117, 117, "a"], [133, 133, "a"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1808.06161-ca00213b-587b-4ef3-b5da-8c1d945c980e", "sentences": [["The", "model", "is", "trained", "using", "the", "Adam", "optimization", "method", "-LSB-", "15", "-RSB-", "."], ["The", "learning", "rate", "is", "initially", "set", "as", "0.003", "and", "decayed", "by", "0.9", "after", "each", "epoch", "."], ["For", "regularization", ",", "dropout", "-LSB-", "30", "-RSB-", "is", "applied", "to", "each", "layer", "."], ["For", "the", "version", "of", "dropout", "used", "in", "practice", "-LRB-", "e.g.", ",", "the", "dropout", "function", "implemented", "in", "the", "TensorFlow", "and", "Pytorch", "libraries", "-RRB-", ",", "the", "model", "ensemble", "generated", "by", "dropout", "in", "the", "training", "phase", "is", "approximated", "by", "a", "single", "model", "with", "scaled", "weights", "in", "the", "inference", "phase", ",", "resulting", "in", "a", "gap", "between", "training", "and", "inference", "."], ["To", "reduce", "this", "gap", ",", "we", "adopted", "the", "dropout", "with", "expectation-linear", "regularization", "introduced", "by", "-LSB-", "24", "-RSB-", "to", "explicitly", "control", "the", "inference", "gap", "and", "thus", "improve", "the", "generalization", "performance", "."]], "ner": [[[6, 8, "a"]], [[14, 15, "p"], [20, 20, "v"]], [[32, 32, "a"]], [[46, 46, "a"], [54, 54, "a"], [70, 70, "a"]], [[106, 106, "a"], [106, 109, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[14, 15, "p"], [20, 20, "v"], [24, 24, "v"]], [[32, 32, "a"]], [[46, 46, "a"], [61, 61, "a"], [70, 70, "a"]], [[106, 106, "a"], [108, 109, "a"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1801.08322-2afac768-df8d-45e2-b3ee-12240e7166fd", "sentences": [["We", "built", "our", "models", "using", "Keras", "-LSB-", "43", "-RSB-", "with", "a", "TensorFlow", "backend", "-LSB-", "44", "-RSB-", "."], ["In", "order", "to", "find", "the", "best", "models", "'", "structure", ",", "we", "evaluated", "a", "different", "number", "of", "gated", "layers", "from", "one", "to", "four", "."], ["A", "smaller", "model", "with", "only", "one", "LSTM", "or", "GRU", "layer", "was", "not", "performing", "well", "on", "this", "task", "."], ["Experiments", "with", "a", "larger", "number", "of", "gated", "layers", "and", "dense", "layers", "also", "failed", "to", "give", "improvements", "in", "performance", "."], ["This", "might", "be", "due", "to", "overfitting", "problem", "."], ["We", "got", "the", "best", "classification", "results", "using", "2", "gated", "layers", "for", "both", "LSTM", "and", "GRU", "models", "."], ["Therefore", ",", "our", "LSTM", "and", "BLSTM", "models", "consist", "of", "two", "LSTM", "layer", "with", "\\", "-LRB-", "\\tanh", "\\", "-RRB-", "function", "-LSB-", "45", "-RSB-", "as", "activation", "."], ["For", "each", "heartbeat", ",", "the", "outputs", "of", "LSTM", "or", "BLSTM", "layers", "were", "given", "to", "the", "dense", "layer", "and", "the", "outputs", "of", "this", "layer", "were", "given", "to", "the", "softmax", "layer", "for", "classification", "-LRB-", "refer", "to", "Section", "-RRB-", "."]], "ner": [[[5, 5, "a"], [11, 11, "a"]], [[31, 34, "p"], [31, 34, "p"]], [[46, 46, "a"], [48, 48, "a"]], [[62, 65, "p"], [62, 65, "p"]], [], [[97, 97, "a"], [92, 92, "v"], [99, 99, "a"], [92, 92, "v"]], [[105, 105, "a"], [112, 112, "a"]], [[134, 134, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"]], [[36, 36, "v"], [38, 38, "v"]], [[45, 45, "v"], [46, 46, "a"], [48, 48, "a"]], [], [], [[92, 92, "v"], [97, 97, "a"], [99, 99, "a"]], [[105, 105, "a"], [107, 107, "a"], [111, 111, "v"], [112, 112, "a"]], [[134, 134, "a"], [136, 136, "a"], [154, 154, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1801.08322-32aa16aa-34fc-42ee-9ea2-071b2812c090", "sentences": [["We", "trained", "all", "these", "models", "using", "the", "training", "portion", "of", "the", "dataset", "and", "development", "portion", "of", "the", "data", "was", "used", "for", "hyper-parameter", "selection", "."], ["We", "started", "training", "the", "network", "with", "a", "learning", "rate", "of", "0.002", "and", "learning", "rate", "was", "halved", "after", "every", "5", "epochs", "if", "the", "classification", "rate", "of", "the", "model", "did", "not", "improve", "on", "the", "validation", "set", "."], ["This", "process", "continued", "until", "the", "learning", "rate", "reached", "below", "0.00001", "or", "until", "the", "maximum", "epochs", "i.e.", ",", "100", "were", "reached", "."], ["We", "used", "batch", "normalization", "after", "the", "dense", "layer", "for", "normalization", "of", "learned", "distribution", "to", "improve", "the", "training", "efficiency", "-LSB-", "46", "-RSB-", "."], ["In", "order", "to", "accommodate", "the", "effect", "of", "initialization", ",", "we", "repeated", "each", "hyperparameter", "combination", "for", "three", "times", "and", "used", "the", "averaged", "prediction", "for", "validation", "and", "testing", "."]], "ner": [[[7, 11, "a"], [13, 17, "a"]], [[28, 28, "a"], [31, 32, "p"], [36, 37, "p"], [34, 34, "v"]], [[64, 65, "p"], [68, 68, "v"], [72, 73, "p"], [76, 76, "v"]], [[82, 83, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[31, 32, "p"], [34, 34, "v"], [36, 37, "p"], [42, 42, "v"], [43, 43, "p"]], [[64, 65, "p"], [68, 68, "v"], [76, 76, "v"]], [[82, 83, "a"]], [[117, 117, "v"]]], "predicted_relations": [[], [[31, 32, 28, 28, "USED-FOR"], [36, 37, 28, 28, "USED-FOR"]], [[68, 68, 72, 73, "USED-FOR"], [76, 76, 72, 73, "USED-FOR"]], [], []]}
{"doc_key": "2108.10274-d42e437d-bbca-4d96-be0c-ae00479914a8", "sentences": [["We", "use", "BiLSTMs", "with", "one", "hidden", "layer", "of", "100", "dimensions", ",", "100-dimensional", "randomly", "initialised", "word", "embeddings", ",", "a", "label", "embedding", "size", "of", "100", "."], ["We", "train", "our", "models", "with", "RMSProp", ",", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "a", "batch", "size", "of", "128", ",", "and", "early", "stopping", "on", "the", "validation", "set", "of", "the", "main", "task", "with", "a", "patience", "of", "3", "."]], "ner": [[[2, 2, "a"], [5, 6, "p"], [8, 8, "v"], [11, 11, "v"], [22, 22, "v"], [9, 9, "c"], [14, 15, "p"], [11, 11, "v"], [12, 13, "c"], [18, 20, "p"], [8, 8, "v"], [11, 11, "v"], [22, 22, "v"]], [[29, 29, "a"], [32, 33, "p"], [37, 37, "v"], [41, 42, "p"], [44, 44, "v"], [59, 59, "p"], [61, 61, "v"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [5, 6, "p"], [8, 8, "v"], [9, 9, "p"], [11, 11, "v"], [22, 22, "v"]], [[27, 27, "a"], [29, 29, "a"], [32, 33, "p"], [37, 37, "v"], [41, 42, "p"], [44, 44, "v"], [47, 48, "a"], [61, 61, "v"]]], "predicted_relations": [[[5, 6, 2, 2, "USED-FOR"], [22, 22, 18, 20, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"], [14, 15, 2, 2, "USED-FOR"], [12, 13, 8, 8, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 22, 22, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 8, 8, "USED-FOR"], [12, 13, 11, 11, "USED-FOR"], [12, 13, 22, 22, "USED-FOR"], [18, 20, 2, 2, "USED-FOR"], [22, 22, 18, 20, "USED-FOR"]], [[32, 33, 29, 29, "USED-FOR"], [41, 42, 29, 29, "USED-FOR"]]]}
{"doc_key": "1809.02306-9c0af8be-9fcc-454d-8ab4-8a1197b86205", "sentences": [["We", "preprocessed", "monolingual", "data", "and", "generated", "mini-batches", "for", "each", "language", "."], ["For", "each", "iteration", ",", "our", "model", "alternately", "read", "mini-batches", "of", "each", "language", ",", "and", "updated", "its", "parameters", "every", "time", "it", "read", "one", "mini-batch", "."], ["We", "trained", "our", "model", "for", "10", "epochs", "with", "the", "mini-batch", "size", "64", "."], ["The", "size", "of", "word", "embedding", "was", "set", "as", "300", ",", "and", "the", "size", "of", "LSTM", "hidden", "states", "was", "also", "set", "as", "300", "for", "the", "forward", "and", "backward", "LSTMs", ",", "respectively", "."], ["Dropout", "-LSB-", "21", "-RSB-", "is", "applied", "to", "the", "hidden", "state", "with", "its", "rate", "0.3", "."], ["We", "used", "SGD", "-LSB-", "5", "-RSB-", "as", "an", "optimizer", "with", "the", "learning", "rate", "1.0", "."], ["Our", "parameters", ",", "which", "include", "word", "embeddings", ",", "were", "uniformly", "initialized", "in", "-LSB-", "-0.1", ",", "0.1", "-RSB-", ",", "and", "gradient", "clipping", "-LSB-", "17", "-RSB-", "was", "used", "with", "the", "clipping", "value", "5.0", "."], ["We", "included", "in", "the", "vocabulary", "the", "words", "that", "were", "used", "at", "least", "a", "certain", "number", "of", "times", "."], ["For", "the", "News", "Crawl", "corpus", ",", "we", "set", "the", "threshold", "as", "3", ",", "5", ",", "5", ",", "5", ",5", ",", "10", ",", "and", "20", "for", "50k", ",", "100k", ",", "150k", ",", "200k", ",", "250k", ",", "300k", "and", "1m", "sentences", "."], ["For", "the", "Europarl", "corpus", ",", "we", "set", "the", "value", "as", "10", "."], ["We", "fed", "10000", "frequent", "words", "into", "the", "discriminator", "in", "-LSB-", "7", "-RSB-", "MUSE", "."]], "ner": [[], [], [[46, 46, "v"], [40, 40, "v"]], [[56, 56, "v"], [69, 69, "v"], [62, 64, "a"], [56, 56, "v"], [69, 69, "v"]], [[79, 79, "a"], [92, 92, "v"], [92, 92, "v"]], [[96, 96, "a"], [107, 107, "v"], [98, 98, "v"]], [[139, 139, "v"], [139, 139, "v"]], [], [[170, 170, "v"], [172, 172, "v"], [174, 174, "v"], [176, 176, "v"], [177, 177, "v"], [179, 179, "v"], [182, 182, "v"], [196, 197, "c"]], [[209, 209, "v"]], [[213, 213, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[16, 16, "a"], [32, 32, "v"]], [[38, 38, "a"], [40, 40, "v"], [41, 41, "p"], [44, 44, "p"], [46, 46, "v"]], [[56, 56, "v"], [62, 62, "a"], [69, 69, "v"], [75, 75, "a"]], [[79, 79, "a"], [87, 88, "p"], [92, 92, "v"]], [[96, 96, "a"], [105, 106, "p"], [107, 107, "v"]], [[122, 122, "v"], [124, 124, "v"], [128, 129, "a"], [137, 138, "p"], [139, 139, "v"]], [], [[161, 163, "a"], [170, 170, "v"], [179, 179, "v"], [182, 182, "v"], [184, 184, "v"], [186, 186, "v"], [188, 188, "v"], [190, 190, "v"], [192, 192, "v"], [194, 194, "v"], [196, 196, "v"]], [[201, 202, "a"], [209, 209, "v"]], [[213, 213, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1811.04551-6bc68c3a-428a-4741-bbd9-259dc0f60094", "sentences": [["We", "use", "the", "convolutional", "and", "deconvolutional", "networks", "from", "-LSB-", "22", "-RSB-", ",", "a", "GRU", "-LSB-", "9", "-RSB-", "with", "200", "units", "as", "deterministic", "path", "in", "the", "dynamics", "model", ",", "and", "implement", "all", "other", "functions", "as", "two", "fully", "connected", "layers", "of", "size", "200", "with", "ReLU", "activations", "-LSB-", "43", "-RSB-", "."], ["Distributions", "in", "latent", "space", "are", "30-dimensional", "diagonal", "Gaussians", "with", "predicted", "mean", "and", "standard", "deviation", "."]], "ner": [[[3, 6, "a"], [13, 13, "a"], [19, 19, "p"], [18, 18, "v"], [40, 40, "v"], [35, 37, "a"], [39, 39, "p"], [18, 18, "v"], [40, 40, "v"], [42, 42, "v"]], [[54, 55, "a"], [53, 53, "v"]]], "relations": [[], []], "predicted_ner": [[[5, 6, "a"], [13, 13, "a"], [18, 18, "v"], [34, 34, "v"], [40, 40, "v"], [42, 43, "a"]], [[53, 53, "v"]]], "predicted_relations": [[[19, 19, 13, 13, "USED-FOR"], [18, 18, 19, 19, "USED-FOR"], [40, 40, 39, 39, "USED-FOR"], [39, 39, 13, 13, "USED-FOR"], [39, 39, 35, 37, "USED-FOR"], [18, 18, 19, 19, "USED-FOR"], [40, 40, 39, 39, "USED-FOR"]], []]}
{"doc_key": "1811.04551-cea088a4-96a2-4a43-81ab-6378374ee7e7", "sentences": [["We", "pre-process", "images", "by", "reducing", "the", "bit", "depth", "to", "5", "bits", "as", "in", "-LSB-", "31", "-RSB-", "."], ["The", "model", "is", "trained", "using", "the", "Adam", "optimizer", "-LSB-", "30", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "gradient", "clipping", "norm", "of", "1000", "on", "batches", "of", "\\", "-LRB-", "B=50\\", "-RRB-", "sequence", "chunks", "of", "length", "\\", "-LRB-", "L=50\\", "-RRB-", "."], ["We", "do", "not", "scale", "the", "KL", "divergence", "terms", "relatively", "to", "the", "reconstruction", "terms", "but", "grant", "the", "model", "3", "free", "nats", "by", "clipping", "the", "divergence", "loss", "below", "this", "value", "."], ["In", "a", "previous", "version", "of", "the", "agent", ",", "we", "used", "latent", "overshooting", "and", "an", "additional", "fixed", "global", "prior", ",", "but", "we", "found", "this", "to", "not", "be", "necessary", "."]], "ner": [[], [[23, 24, "a"], [30, 31, "p"], [44, 44, "p"], [53, 55, "p"], [57, 57, "v"], [37, 37, "v"]], [[79, 80, "a"], [92, 93, "p"], [91, 91, "v"]], [[113, 114, "a"], [117, 120, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[9, 9, "v"]], [[18, 18, "a"], [23, 23, "a"], [30, 31, "p"], [35, 38, "v"], [53, 55, "p"], [57, 57, "v"], [63, 63, "v"], [71, 71, "v"]], [[91, 91, "v"], [97, 98, "a"]], []], "predicted_relations": [[], [[30, 31, 23, 24, "USED-FOR"], [44, 44, 23, 24, "USED-FOR"], [53, 55, 23, 24, "USED-FOR"], [57, 57, 53, 55, "USED-FOR"], [37, 37, 30, 31, "USED-FOR"], [37, 37, 44, 44, "USED-FOR"]], [[92, 93, 79, 80, "USED-FOR"], [91, 91, 92, 93, "USED-FOR"]], []]}
{"doc_key": "1811.04551-82c4870b-ece3-4c76-9252-5761cc099098", "sentences": [["For", "planning", ",", "we", "use", "CEM", "with", "horizon", "length", "\\", "-LRB-", "H=12\\", "-RRB-", ",", "optimization", "iterations", "\\", "-LRB-", "I=10\\", "-RRB-", ",", "candidate", "samples", "\\", "-LRB-", "J=1000\\", "-RRB-", ",", "and", "refitting", "to", "the", "best", "\\", "-LRB-", "K=100\\", "-RRB-", "."], ["We", "start", "from", "\\", "-LRB-", "S=5\\", "-RRB-", "seed", "episodes", "with", "random", "actions", "and", "collect", "another", "episode", "every", "\\", "-LRB-", "C=100\\", "-RRB-", "update", "steps", "under", "\\", "-LRB-", "\\epsilon", "\\sim", "-LRB-", "0,0.3", "-RRB-", "\\", "-RRB-", "action", "noise", "."], ["The", "action", "repeat", "differs", "between", "domains", ":", "cartpole", "-LRB-", "\\", "-LRB-", "R=8\\", "-RRB-", "-RRB-", ",", "reacher", "-LRB-", "\\", "-LRB-", "R=4\\", "-RRB-", "-RRB-", ",", "cheetah", "-LRB-", "\\", "-LRB-", "R=4\\", "-RRB-", "-RRB-", ",", "finger", "-LRB-", "\\", "-LRB-", "R=2\\", "-RRB-", "-RRB-", ",", "cup", "-LRB-", "\\", "-LRB-", "R=4\\", "-RRB-", "-RRB-", ",", "walker", "-LRB-", "\\", "-LRB-", "R=2\\", "-RRB-", "-RRB-", "."], ["We", "found", "important", "hyper", "parameters", "to", "be", "the", "action", "repeat", ",", "the", "KL-divergence", "scales", "\\", "-LRB-", "\\beta", "\\", "-RRB-", ",", "and", "the", "learning", "rate", "."]], "ner": [[[5, 5, "a"], [7, 8, "p"], [11, 11, "v"], [14, 15, "p"], [18, 18, "v"], [21, 22, "p"], [25, 25, "v"], [29, 32, "p"], [35, 35, "v"], [35, 35, "v"]], [[57, 57, "v"], [45, 46, "p"], [43, 43, "v"], [59, 60, "p"], [57, 57, "v"], [71, 72, "p"]], [[75, 76, "p"], [85, 85, "v"], [81, 81, "c"], [93, 93, "v"], [101, 101, "v"], [117, 117, "v"], [89, 89, "c"], [93, 93, "v"], [101, 101, "v"], [117, 117, "v"], [97, 97, "c"], [109, 109, "v"], [125, 125, "v"], [105, 105, "c"], [93, 93, "v"], [101, 101, "v"], [117, 117, "v"], [113, 113, "c"], [109, 109, "v"], [125, 125, "v"], [121, 121, "c"]], [[137, 138, "p"], [141, 142, "p"], [151, 152, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"], [7, 8, "p"], [11, 11, "v"], [18, 18, "v"], [25, 25, "v"], [35, 35, "v"]], [[43, 43, "v"], [57, 57, "v"], [67, 67, "v"]], [[81, 81, "a"], [85, 85, "v"], [89, 89, "a"], [97, 97, "a"], [105, 105, "a"], [113, 113, "a"], [121, 121, "a"]], [[145, 145, "p"]]], "predicted_relations": [[[7, 8, 5, 5, "USED-FOR"], [11, 11, 7, 8, "USED-FOR"], [11, 11, 14, 15, "USED-FOR"], [14, 15, 5, 5, "USED-FOR"], [18, 18, 7, 8, "USED-FOR"], [18, 18, 14, 15, "USED-FOR"], [18, 18, 21, 22, "USED-FOR"], [21, 22, 5, 5, "USED-FOR"], [25, 25, 7, 8, "USED-FOR"], [25, 25, 14, 15, "USED-FOR"], [25, 25, 21, 22, "USED-FOR"], [29, 32, 5, 5, "USED-FOR"], [35, 35, 21, 22, "USED-FOR"], [35, 35, 29, 32, "USED-FOR"], [35, 35, 21, 22, "USED-FOR"], [35, 35, 29, 32, "USED-FOR"]], [[57, 57, 45, 46, "USED-FOR"], [57, 57, 59, 60, "USED-FOR"], [43, 43, 45, 46, "USED-FOR"], [57, 57, 45, 46, "USED-FOR"], [57, 57, 59, 60, "USED-FOR"]], [[85, 85, 75, 76, "USED-FOR"], [81, 81, 85, 85, "USED-FOR"], [81, 81, 93, 93, "USED-FOR"], [81, 81, 101, 101, "USED-FOR"], [81, 81, 117, 117, "USED-FOR"], [81, 81, 93, 93, "USED-FOR"], [81, 81, 101, 101, "USED-FOR"], [81, 81, 117, 117, "USED-FOR"], [81, 81, 109, 109, "USED-FOR"], [81, 81, 125, 125, "USED-FOR"], [81, 81, 93, 93, "USED-FOR"], [81, 81, 101, 101, "USED-FOR"], [81, 81, 117, 117, "USED-FOR"], [81, 81, 109, 109, "USED-FOR"], [81, 81, 125, 125, "USED-FOR"], [93, 93, 75, 76, "USED-FOR"], [89, 89, 85, 85, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 117, 117, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 117, 117, "USED-FOR"], [89, 89, 109, 109, "USED-FOR"], [89, 89, 125, 125, "USED-FOR"], [89, 89, 93, 93, "USED-FOR"], [89, 89, 101, 101, "USED-FOR"], [89, 89, 117, 117, "USED-FOR"], [89, 89, 109, 109, "USED-FOR"], [89, 89, 125, 125, "USED-FOR"], [93, 93, 75, 76, "USED-FOR"], [97, 97, 85, 85, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [97, 97, 101, 101, "USED-FOR"], [97, 97, 117, 117, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [97, 97, 101, 101, "USED-FOR"], [97, 97, 117, 117, "USED-FOR"], [97, 97, 109, 109, "USED-FOR"], [97, 97, 125, 125, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [97, 97, 101, 101, "USED-FOR"], [97, 97, 117, 117, "USED-FOR"], [97, 97, 109, 109, "USED-FOR"], [97, 97, 125, 125, "USED-FOR"], [105, 105, 85, 85, "USED-FOR"], [105, 105, 93, 93, "USED-FOR"], [105, 105, 101, 101, "USED-FOR"], [105, 105, 117, 117, "USED-FOR"], [105, 105, 93, 93, "USED-FOR"], [105, 105, 101, 101, "USED-FOR"], [105, 105, 117, 117, "USED-FOR"], [105, 105, 109, 109, "USED-FOR"], [105, 105, 125, 125, "USED-FOR"], [105, 105, 93, 93, "USED-FOR"], [105, 105, 101, 101, "USED-FOR"], [105, 105, 117, 117, "USED-FOR"], [105, 105, 109, 109, "USED-FOR"], [105, 105, 125, 125, "USED-FOR"], [93, 93, 75, 76, "USED-FOR"], [121, 121, 93, 93, "USED-FOR"], [121, 121, 101, 101, "USED-FOR"], [121, 121, 117, 117, "USED-FOR"], [121, 121, 93, 93, "USED-FOR"], [121, 121, 101, 101, "USED-FOR"], [121, 121, 117, 117, "USED-FOR"], [121, 121, 109, 109, "USED-FOR"], [121, 121, 125, 125, "USED-FOR"], [121, 121, 93, 93, "USED-FOR"], [121, 121, 101, 101, "USED-FOR"], [121, 121, 117, 117, "USED-FOR"], [121, 121, 109, 109, "USED-FOR"], [121, 121, 125, 125, "USED-FOR"]], []]}
{"doc_key": "1805.05593-2835f32f-2cab-4909-9f29-4a7772f2adfe", "sentences": [["We", "employed", "pre-trained", "word", "embeddings", "trained", "by", "using", "the", "word2vec", "tool", "-LSB-", "12", "-RSB-", "on", "the", "2014", "MEDLINE/PubMed", "baseline", "distribution", "."], ["The", "vocabulary", "size", "was", "215,840", "."], ["The", "embedding", "of", "the", "drugs", ",", "i.e.", ",", "DRUG1", "and", "DRUG2", "were", "initialized", "with", "the", "pre-trained", "embedding", "of", "the", "word", "drug", "."], ["The", "embeddings", "of", "training", "words", "that", "did", "not", "appear", "in", "the", "pre-trained", "embeddings", "were", "initialized", "with", "the", "average", "of", "all", "pre-trained", "word", "embeddings", "."], ["Words", "that", "appeared", "only", "once", "in", "the", "training", "data", "were", "replaced", "with", "an", "UNK", "word", "during", "training", ",", "and", "the", "embedding", "of", "words", "in", "the", "test", "data", "set", "that", "did", "not", "appear", "in", "both", "training", "and", "pre-trained", "embeddings", "were", "set", "to", "the", "embedding", "of", "the", "UNK", "word", "."], ["Word", "position", "embeddings", "are", "initialized", "with", "random", "values", "drawn", "from", "a", "uniform", "distribution", "."]], "ner": [[[9, 10, "a"], [2, 4, "a"]], [], [], [[69, 71, "a"]], [], [[127, 133, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[25, 25, "v"]], [], [], [], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1809.03036-1a4fa01e-84c0-4bef-8554-278409277c4e", "sentences": [["For", "our", "short-term", "model", ",", "the", "VGRU-r1", "-LRB-", "MA", "-RRB-", ",", "we", "trained", "on", "all", "action", "classes", "using", "our", "proposed", "multi-objective", "cost", ",", "calculating", "gradients", "over", "mini-batches", "of", "32", "samples", "-LRB-", "clipping", "gradient", "norms", "to", "5", "-RRB-", "and", "optimizing", "parameters", "over", "\\", "-LRB-", "100,000\\", "-RRB-", "iterations", "RMSprop", "-LSB-", "27", "-RSB-", "with", "initial", "learning", "rate", "\\", "-LRB-", "\\lambda", "=", "0.0001\\", "-RRB-", "and", "decayed", "by", "\\", "-LRB-", "0.8\\", "-RRB-", "every", "5000", "iterations", "until", "60,000", "iterations", "."], ["Drop-out", "-LSB-", "29", "-RSB-", ",", "-LSB-", "19", "-RSB-", ",", "with", "probability", "of", "0.3", ",", "was", "applied", "only", "to", "the", "Body-RNN", ",", "which", "was", "further", "modified", "to", "use", "skip", "connections", "that", "connect", "input", "units", "to", "output", "units", ",", "as", "in", "-LSB-", "16", "-RSB-", "."], ["The", "model", "was", "given", "50", "seed", "frames", "and", "tasked", "with", "predicting", "the", "next", "10", "subsequent", "frames", "-LRB-", "400", "milliseconds", "-RRB-", "."], ["When", "training", "for", "this", ",", "the", "VTLN-RNN", "is", "unrolled", "backwards", "while", "the", "Body-RNN", "is", "unrolled", "forwards", ",", "in", "time", ",", "over", "60", "steps", "."], ["-LRB-", "Note", ":", "MA", "stands", "for", "multi-action", ",", "SA", "for", "single-action", ".", "-RRB-"]], "ner": [[[51, 53, "p"], [58, 58, "v"], [46, 46, "a"]], [[74, 74, "a"], [84, 84, "p"], [86, 86, "v"]], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [20, 21, "a"], [28, 28, "v"], [35, 35, "v"], [43, 43, "v"], [46, 46, "a"], [52, 53, "p"], [58, 58, "v"], [65, 65, "v"], [68, 68, "v"], [71, 71, "v"]], [[86, 86, "v"], [93, 93, "a"]], [[121, 121, "v"], [130, 130, "v"], [134, 134, "v"]], [[144, 144, "a"], [150, 150, "a"], [159, 159, "v"]], []], "predicted_relations": [[[51, 53, 46, 46, "USED-FOR"], [58, 58, 51, 53, "USED-FOR"]], [[84, 84, 74, 74, "USED-FOR"]], [], [], []]}
{"doc_key": "1809.03036-1e4a12a2-7927-44f3-8ea5-5e277b4c620c", "sentences": [["For", "our", "long-term", "models", ",", "which", "were", "trained", "on", "single-action", "data", ",", "parameter", "optimization", "was", "carried", "out", "with", "RMSprop", "-LRB-", "\\", "-LRB-", "\\lambda", "=", "0.0002\\", "-RRB-", ",", "decayed", "by", "\\", "-LRB-", "0.6\\", "-RRB-", "every", "2000", "iterations", "-RRB-", "over", "\\", "-LRB-", "10,000\\", "-RRB-", "iterations", "with", "mini-batches", "of", "32", ",", "using", ",", "again", ",", "our", "proposed", "cost", "function", "."], ["Models", "were", "fed", "in", "50", "seed", "frames", "and", "made", "to", "predict", "the", "next", "100", "frames", "-LRB-", "4", "sec", "-RRB-", ",", "which", "meant", "that", "the", "VTLN-RNN", "was", "unrolled", "backwards", "and", "the", "Body-RNN", "forwards", "150", "steps", "."], ["The", "input", "vector", "to", "the", "Body-RNN", "consisted", "of", "joint", "angles", "appended", "with", "motion", "derivatives", "."], ["VGRU-d", "refers", "to", "our", "proposed", "VTLN-RNN", "architecture", "where", "the", "VTLN-RNN", "and", "Body-RNN", "both", "contain", "only", "a", "single", "layer", "of", "512", "GRU", "cells", "."], ["GRU-d", "refers", "to", "a", "2-layer", "GRU", "model", "-LRB-", "512", "units", "in", "each", "-RRB-", "."], ["Both", "VGRU-d", "and", "GRU-d", "models", "are", "trained", "with", "our", "proposed", "loss", "and", "make", "use", "of", "inputs", "augmented", "with", "motion", "derivatives", "."], ["VGRU-ac", "refers", "to", "our", "VTLN-RNN", "architecture", "trained", "with", "auto-conditioning", "-LSB-", "30", "-RSB-", ",", "using", "the", "recommended", "length", "of", "5", ",", "serving", "as", "a", "baseline", "."], ["For", "all", "models", "-LRB-", "short", "and", "long-term", "-RRB-", ",", "hyper-parameters", "were", "tuned", "on", "a", "separate", "validation", "set", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[18, 18, "a"], [22, 22, "p"], [24, 24, "v"], [27, 28, "p"], [31, 31, "v"], [35, 35, "p"], [42, 42, "p"], [34, 34, "v"], [44, 44, "a"], [46, 46, "v"], [54, 55, "a"]], [[81, 81, "a"], [83, 83, "p"], [84, 84, "v"], [87, 87, "p"], [88, 90, "v"], [81, 81, "p"], [87, 87, "p"], [81, 81, "p"]], [[97, 97, "p"], [97, 97, "p"]], [[112, 112, "a"], [116, 116, "a"], [118, 118, "p"], [107, 107, "a"], [112, 112, "p"], [116, 116, "p"], [123, 128, "v"], [118, 118, "p"], [123, 128, "v"], [126, 126, "v"], [112, 112, "p"], [116, 116, "p"]], [[130, 130, "a"], [134, 134, "v"], [139, 139, "p"], [138, 138, "v"]], [[145, 145, "a"], [159, 159, "p"], [160, 163, "v"], [147, 147, "a"], [159, 159, "p"], [160, 163, "v"]], [[169, 169, "a"], [169, 169, "p"], [165, 165, "a"], [169, 169, "p"], [173, 173, "v"], [181, 183, "c"]], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[18, 18, "a"], [24, 24, "v"], [31, 31, "v"], [34, 34, "v"], [40, 40, "v"], [44, 44, "p"], [46, 46, "v"]], [[61, 61, "v"], [70, 70, "v"], [73, 73, "v"], [81, 81, "a"], [87, 87, "a"], [89, 89, "v"]], [[97, 97, "a"]], [[107, 107, "a"], [112, 112, "a"], [116, 116, "a"], [118, 118, "a"], [126, 126, "v"], [127, 127, "a"]], [[130, 130, "a"], [134, 134, "v"], [138, 138, "v"]], [[145, 145, "a"], [147, 147, "a"], [154, 154, "a"]], [[165, 165, "a"], [169, 169, "a"], [183, 183, "v"]], [], []], "predicted_relations": [[[22, 22, 18, 18, "USED-FOR"], [24, 24, 22, 22, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 35, 35, "USED-FOR"], [27, 28, 18, 18, "USED-FOR"], [31, 31, 27, 28, "USED-FOR"], [31, 31, 35, 35, "USED-FOR"], [31, 31, 42, 42, "USED-FOR"], [35, 35, 18, 18, "USED-FOR"], [42, 42, 18, 18, "USED-FOR"], [34, 34, 22, 22, "USED-FOR"], [34, 34, 27, 28, "USED-FOR"], [34, 34, 35, 35, "USED-FOR"], [34, 34, 42, 42, "USED-FOR"]], [[83, 83, 81, 81, "USED-FOR"], [84, 84, 83, 83, "USED-FOR"], [84, 84, 87, 87, "USED-FOR"], [84, 84, 81, 81, "USED-FOR"], [84, 84, 87, 87, "USED-FOR"], [84, 84, 81, 81, "USED-FOR"], [87, 87, 81, 81, "USED-FOR"], [88, 90, 83, 83, "USED-FOR"], [88, 90, 87, 87, "USED-FOR"], [88, 90, 81, 81, "USED-FOR"], [88, 90, 87, 87, "USED-FOR"], [88, 90, 81, 81, "USED-FOR"], [81, 81, 81, 81, "USED-FOR"], [87, 87, 81, 81, "USED-FOR"], [81, 81, 81, 81, "USED-FOR"]], [], [[118, 118, 112, 112, "USED-FOR"], [118, 118, 116, 116, "USED-FOR"], [118, 118, 107, 107, "USED-FOR"], [112, 112, 112, 112, "USED-FOR"], [112, 112, 116, 116, "USED-FOR"], [112, 112, 107, 107, "USED-FOR"], [116, 116, 112, 112, "USED-FOR"], [116, 116, 116, 116, "USED-FOR"], [116, 116, 107, 107, "USED-FOR"], [123, 128, 118, 118, "USED-FOR"], [123, 128, 118, 118, "USED-FOR"], [118, 118, 112, 112, "USED-FOR"], [118, 118, 116, 116, "USED-FOR"], [118, 118, 107, 107, "USED-FOR"], [123, 128, 118, 118, "USED-FOR"], [123, 128, 118, 118, "USED-FOR"], [126, 126, 118, 118, "USED-FOR"], [126, 126, 116, 116, "USED-FOR"], [126, 126, 118, 118, "USED-FOR"], [126, 126, 116, 116, "USED-FOR"], [112, 112, 112, 112, "USED-FOR"], [112, 112, 116, 116, "USED-FOR"], [112, 112, 107, 107, "USED-FOR"], [116, 116, 112, 112, "USED-FOR"], [116, 116, 116, 116, "USED-FOR"], [116, 116, 107, 107, "USED-FOR"]], [[139, 139, 130, 130, "USED-FOR"]], [[160, 163, 159, 159, "USED-FOR"], [160, 163, 159, 159, "USED-FOR"], [160, 163, 159, 159, "USED-FOR"], [160, 163, 159, 159, "USED-FOR"]], [[169, 169, 169, 169, "USED-FOR"], [169, 169, 165, 165, "USED-FOR"], [169, 169, 169, 169, "USED-FOR"], [169, 169, 165, 165, "USED-FOR"], [173, 173, 169, 169, "USED-FOR"], [173, 173, 169, 169, "USED-FOR"]], [], []]}
{"doc_key": "1809.02940-ea461131-6e58-4976-92a5-d227286f6b18", "sentences": [["R-FCN", ":", "ResNet-101", "-LSB-", "24", "-RSB-", "is", "adopted", "as", "the", "backone", "of", "R-FCN", ",", "and", "online", "hard", "example", "mining", "-LRB-", "OHEM", "-RRB-", "-LSB-", "25", "-RSB-", "is", "used", "to", "train", "R-FCN", "."], ["The", "learning", "rate", "is", "\\", "-LRB-", "0.0003\\", "-RRB-", "and", "the", "momentum", "is", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["A", "number", "of", "eye", "regions", "are", "segmented", "by", "R-FCN", ",", "which", "are", "further", "resized", "into", "\\", "-LRB-", "224\\times", "224\\times", "3\\", "-RRB-", "."]], "ner": [[[2, 2, "a"], [0, 0, "a"], [12, 12, "a"], [29, 29, "a"]], [[32, 33, "p"], [37, 37, "v"], [41, 41, "p"], [45, 45, "v"]], [[56, 56, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 0, "a"], [2, 2, "a"], [12, 12, "a"], [15, 21, "a"], [29, 29, "a"]], [[32, 33, "p"], [37, 37, "v"], [41, 41, "p"], [45, 45, "v"]], [[56, 56, "a"], [67, 67, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1809.02940-cbae4dd4-a63d-46d3-94f3-ec3b3a27ec71", "sentences": [["CNN", ":", "The", "network", "architecture", "consists", "of", "five", "convolutional", "layers", "and", "three", "pooling", "layers", ",", "followed", "by", "three", "fully", "connected", "layers", ",", "as", "shown", "in", "Figure", "REF", "."], ["Each", "convolutional", "layer", "is", "followed", "by", "a", "Relu", "layer", "-LSB-", "26", "-RSB-", ",", "an", "effective", "activation", "function", "to", "improve", "the", "performance", "of", "the", "CNNs", "."], ["In", "addition", ",", "the", "dropout", "strategy", "-LSB-", "27", "-RSB-", "is", "used", "in", "the", "first", "two", "fully", "connected", "layers", "in", "order", "to", "prevent", "overfitting", "."], ["The", "network", "training", "is", "performed", "by", "the", "stochastic", "gradient", "descent", "method", "-LSB-", "28", "-RSB-", "."], ["\\", "-LRB-", "L_2\\", "-RRB-", "regularization", "with", "the", "weight", "decay", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "is", "used", "in", "the", "network", "training", "."], ["The", "dropout", "ratio", "is", "set", "as", "0.5", "."], ["The", "batch", "size", "is", "set", "as", "32", "."], ["The", "learning", "rate", "is", "initially", "set", "as", "0.01", "and", "the", "training", "is", "stopped", "after", "5000", "iterations", "."]], "ner": [[[0, 0, "a"]], [[35, 36, "p"]], [[57, 58, "p"]], [[84, 87, "a"]], [[99, 100, "p"]], [[123, 123, "v"], [118, 119, "c"]], [[126, 127, "p"], [131, 131, "v"]], [[134, 135, "p"], [140, 140, "v"], [147, 147, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [7, 7, "v"], [11, 11, "v"], [17, 17, "v"]], [[35, 35, "a"], [51, 51, "a"]], [[67, 67, "v"]], [[84, 87, "a"]], [[94, 94, "a"], [96, 96, "a"], [99, 100, "p"], [104, 106, "v"]], [[118, 119, "p"], [123, 123, "v"]], [[126, 127, "p"], [131, 131, "v"]], [[134, 135, "p"], [140, 140, "v"], [147, 147, "v"]]], "predicted_relations": [[], [], [], [], [], [[118, 119, 123, 123, "USED-FOR"]], [], []]}
{"doc_key": "1810.12715-096a6877-68a2-40c1-bed7-c67a42c10f7f", "sentences": [["For", "IBP", ",", "across", "all", "datasets", ",", "the", "networks", "were", "trained", "using", "the", "Adam", "-LSB-", "30", "-RSB-", "algorithm", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["We", "linearly", "ramp-down", "the", "value", "of", "\\", "-LRB-", "\\kappa", "\\", "-RRB-", "between", "1", "and", "\\", "-LRB-", "\\kappa", "_\\textrm", "-LCB-", "final", "-RCB-", "\\", "-RRB-", "after", "a", "fixed", "warm-up", "period", "-LRB-", "\\", "-LRB-", "\\kappa", "_\\textrm", "-LCB-", "final", "-RCB-", "\\", "-RRB-", "is", "set", "to", "both", "0", "or", "0.5", "and", "the", "best", "result", "is", "used", "-RRB-", "."], ["Simultaneously", ",", "we", "lineary", "ramp-up", "the", "value", "of", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "between", "0", "and", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "\\textrm", "-LCB-", "train", "-RCB-", "-RCB-", "\\", "-RRB-", "-LRB-", "for", "Cifar-10", "and", "Svhn", ",", "we", "use", "a", "value", "of", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "\\textrm", "-LCB-", "train", "-RCB-", "-RCB-", "\\", "-RRB-", "that", "is", "10", "%", "higher", "than", "the", "desired", "robustness", "radius", "-RRB-", "."], ["Mnist", "is", "trained", "on", "a", "single", "Nvidia", "V100", "GPU", "."], ["Cifar-10", ",", "Svhn", "and", "ImageNet", "are", "trained", "on", "32", "tensor", "processing", "units", "-LRB-", "TPU", "-RRB-", "-LSB-", "31", "-RSB-", "with", "2", "workers", "with", "16", "TPU", "cores", "each", "."]], "ner": [[[13, 13, "a"], [20, 22, "p"]], [[41, 41, "p"], [49, 49, "p"], [64, 64, "p"], [45, 45, "v"], [75, 75, "v"], [77, 77, "v"]], [[96, 96, "p"], [104, 104, "p"], [127, 127, "p"], [100, 100, "v"]], [], [[172, 172, "a"], [182, 182, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [13, 13, "a"], [21, 22, "p"], [26, 29, "v"]], [[41, 41, "p"], [45, 45, "v"], [75, 75, "v"], [77, 77, "v"]], [[100, 100, "v"], [104, 111, "p"], [116, 116, "a"], [118, 118, "a"], [127, 134, "p"], [139, 140, "v"]], [[149, 149, "a"]], [[159, 159, "a"], [161, 161, "a"], [163, 163, "a"], [167, 167, "v"], [178, 178, "v"], [181, 181, "v"]]], "predicted_relations": [[[20, 22, 13, 13, "USED-FOR"]], [[45, 45, 41, 41, "USED-FOR"], [45, 45, 49, 49, "USED-FOR"], [75, 75, 64, 64, "USED-FOR"]], [[100, 100, 96, 96, "USED-FOR"], [100, 100, 104, 104, "USED-FOR"]], [], []]}
{"doc_key": "1810.12715-30c00573-b655-4361-9f5d-f7fcdc4f0c8a", "sentences": [["The", "networks", "trained", "using", "-LSB-", "24", "-RSB-", "were", "trained", "using", "the", "schedule", "and", "learning", "rate", "proposed", "by", "the", "authors", "."], ["For", "-LSB-", "8", "-RSB-", ",", "we", "used", "a", "learning", "rate", "schedule", "identical", "to", "IBP", "and", ",", "for", "the", "inner", "optimization", ",", "adversarial", "examples", "are", "generated", "by", "7", "steps", "of", "PGD", "with", "Adam", "-LSB-", "30", "-RSB-", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-1", "-RCB-", "\\", "-RRB-", "."], ["Note", "that", "our", "reported", "results", "for", "these", "two", "methods", "closely", "match", "or", "beat", "published", "results", ",", "giving", "us", "confidence", "that", "we", "performed", "a", "fair", "comparison", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[13, 14, "p"]], [[33, 33, "a"], [51, 51, "a"], [28, 29, "p"], [57, 58, "p"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[13, 14, "p"]], [[28, 29, "p"], [33, 33, "a"], [46, 46, "v"], [51, 51, "a"], [57, 58, "p"], [62, 64, "v"]], [[76, 76, "v"]], []], "predicted_relations": [[], [[28, 29, 33, 33, "USED-FOR"], [57, 58, 33, 33, "USED-FOR"], [57, 58, 51, 51, "USED-FOR"]], [], []]}
{"doc_key": "1810.12546-437e9436-8e3b-4d15-8cf0-183df71e2f91", "sentences": [["DeepRNNSearch", "-LRB-", "GRU", "-RRB-", ":", "a", "deep", "GRU-equipped", "RNNSearch", "model", "-LSB-", "36", "-RSB-", "with", "5", "layers", "."], ["We", "set", "the", "dimension", "of", "word", "embedding", "and", "hidden", "state", "to", "620", "and", "1000", "respectively", "."], ["Transformer", ":", "a", "purely", "attentional", "translator", "-LSB-", "30", "-RSB-", "."], ["We", "set", "the", "dimension", "of", "word", "embedding", "and", "filter", "size", "to", "512", "and", "2048", "respectively", "."], ["The", "model", "was", "trained", "with", "a", "minibatch", "size", "of", "256", "."]], "ner": [[], [[20, 23, "p"], [28, 28, "v"], [30, 30, "v"], [20, 23, "p"]], [[33, 33, "a"]], [[46, 49, "p"], [46, 49, "p"], [54, 54, "v"], [51, 52, "p"], [56, 56, "v"]], [[65, 66, "p"], [68, 68, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 3, "a"], [8, 9, "a"], [14, 14, "v"], [15, 15, "p"]], [[25, 26, "p"], [28, 28, "v"], [30, 30, "v"]], [[33, 33, "a"]], [[54, 54, "v"], [56, 56, "v"]], [[68, 68, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1810.12546-2f83c96b-57aa-4f11-bd47-13b5e1f3f54b", "sentences": [["Our", "model", "with", "the", "CA", "structure", ",", "using", "only", "63.1M", "parameters", ",", "processes", "3993", "words", "per", "second", "during", "training", "and", "generates", "186", "words", "per", "second", "during", "decoding", ",", "which", "yields", "substantial", "speed", "improvements", "over", "the", "GRU-", "and", "LSTM-equipped", "RNNSearch", "."], ["This", "is", "due", "to", "the", "light", "matrix", "computation", "in", "recurrent", "units", "of", "ATR", "."], ["Notice", "that", "the", "speed", "increase", "of", "ATR", "over", "GRU", "and", "LSTM", "does", "not", "reach", "3x", "."], ["This", "is", "because", "at", "each", "decoding", "step", ",", "there", "are", "mainly", "two", "types", "of", "computation", ":", "recurrent", "unit", "and", "softmax", "layer", "."], ["The", "latter", "consumes", "the", "most", "calculation", ",", "which", ",", "however", ",", "is", "the", "same", "for", "different", "models", "-LRB-", "LSTM/GRU/ATR", "-RRB-", "."]], "ner": [[[4, 5, "a"], [35, 38, "a"]], [[52, 52, "a"]], [[60, 60, "a"]], [[86, 87, "a"], [89, 90, "a"]], [[110, 110, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [4, 4, "a"], [9, 9, "v"], [13, 13, "v"], [21, 21, "v"], [38, 38, "a"]], [], [[62, 62, "a"], [64, 64, "a"], [68, 68, "v"]], [[81, 81, "v"], [89, 89, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1810.12557-02bee1a7-a444-4371-89e6-edd51b5bf8aa", "sentences": [["Maximum", "input", "length", "-LRB-", "max_length", "-RRB-", ":", "specifies", "the", "maximum", "length", "of", "a", "sentence", "in", "tokens", "-LRB-", "sub-words", "in", "our", "case", "-RRB-", "."], ["Sentences", "longer", "than", "max_length", "are", "either", "excluded", "from", "the", "training", "-LRB-", "T2T", "-RRB-", "or", "cut", "to", "match", "the", "max_length", "-LRB-", "RNN", "-RRB-", "."], ["Lowering", "max_length", "allows", "us", "to", "use", "a", "higher", "batch", "size", "and/or", "bigger", "model", "but", "biases", "the", "translation", "towards", "shorter", "sentences", "."], ["Since", "\\", "-LRB-", "99\\", "%", "\\", "-RRB-", "of", "the", "training", "sentences", "are", "not", "longer", "than", "70", ",", "we", "set", "max_length", "to", "70", "."], ["Batch", "size", "-LRB-", "batch_size", "-RRB-", "For", "T2T", "batch_size", "is", "the", "approximate", "number", "of", "tokens", "-LRB-", "subwords", "-RRB-", "consumed", "in", "one", "training", "step", ",", "while", "for", "ConvS2S", "and", "RNN", "batch_size", "is", "the", "number", "of", "sentence", "pairs", "consumed", "in", "one", "training", "step", "."], ["Hence", "for", "consistency", "we", "define", "batch_size", "as", "the", "approximate", "average", "number", "of", "tokens", "consumed", "in", "one", "training", "step", "."], ["In", "fact", "the", "number", "of", "tokens", "in", "a", "sentence", "is", "the", "maximum", "of", "source", "and", "target", "subwords", "from", "the", "pair", "of", "training", "sentences", "."], ["During", "training", "this", "allows", "us", "to", "put", "as", "many", "training", "tokens", "per", "batch", "as", "possible", "while", "ensuring", "that", "batches", "with", "long", "sentences", "still", "fit", "in", "GPU", "memory", "."], ["In", "contrast", ",", "if", "we", "fixed", "the", "number", "of", "sentence", "pairs", "in", "a", "training", "batch", ",", "the", "model", "can", "run", "out", "of", "memory", "if", "a", "batch", "has", "many", "long", "sentences", "."], ["Training", "epoch", "is", "one", "complete", "pass", "through", "the", "whole", "training", "set", "."], ["The", "number", "of", "training", "steps", "can", "be", "converted", "to", "epochs", "by", "multiplying", "by", "the", "batch", "size", "and", "dividing", "by", "the", "number", "of", "subwords", "in", "the", "training", "data", "."], ["Model", "size", "is", "number", "of", "trainable", "parameters", "of", "each", "model", "."], ["Because", "of", "the", "difference", "in", "model", "structures", ",", "it", "is", "almost", "certain", "that", "two", "models", "with", "the", "same", "model", "size", "will", "not", "have", "the", "same", "training", "time", "."]], "ner": [[[0, 2, "a"], [4, 4, "p"]], [[26, 26, "p"], [41, 41, "p"]], [[47, 47, "p"]], [[86, 86, "p"], [82, 82, "v"], [88, 88, "v"]], [[90, 91, "a"], [93, 93, "p"], [97, 97, "p"], [118, 118, "p"]], [[136, 136, "p"], [139, 148, "v"]], [], [], [], [[233, 234, "a"]], [], [[273, 274, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[34, 34, "a"], [43, 43, "a"]], [], [[70, 71, "v"], [82, 82, "v"], [88, 88, "v"]], [[96, 96, "a"], [109, 109, "v"], [115, 115, "a"], [117, 117, "a"], [127, 127, "v"]], [[146, 146, "v"]], [], [], [], [[236, 236, "v"]], [], [], [[297, 297, "v"]]], "predicted_relations": [[[4, 4, 0, 2, "USED-FOR"]], [], [], [[82, 82, 86, 86, "USED-FOR"], [88, 88, 86, 86, "USED-FOR"]], [[93, 93, 90, 91, "USED-FOR"], [97, 97, 90, 91, "USED-FOR"]], [], [], [], [], [], [], [], []]}
{"doc_key": "1810.12443-f90d5a3f-c3b2-47cb-885b-02834f18b91c", "sentences": [["Initialization", "."], ["The", "size", "of", "the", "dimensions", "of", "character", "embeddings", "is", "32", "which", "are", "randomly", "initialized", "using", "a", "uniform", "distribution", "."], ["We", "adopt", "the", "same", "initialization", "method", "for", "randomly", "initialized", "word", "embeddings", "that", "are", "updated", "during", "training", "."], ["For", "IntNet", ",", "the", "filter", "size", "of", "the", "initial", "convolution", "is", "32", "and", "that", "of", "other", "convolutions", "is", "16", "."], ["We", "have", "used", "filters", "of", "size", "\\", "-LRB-", "-LSB-", "3", ",", "4", ",", "5", "-RSB-", "\\", "-RRB-", "for", "all", "the", "kernels", "."], ["The", "number", "of", "convolutional", "layers", "are", "5", "and", "9", "for", "IntNet-5", "and", "IntNet-9", ",", "respectively", ",", "and", "we", "have", "adopted", "the", "same", "weight", "initialization", "as", "that", "of", "ResNet", "."], ["We", "use", "pre-trained", "word", "embeddings", "for", "initialization", ",", "GloVe", "-LSB-", "17", "-RSB-", "100-dimension", "word", "embeddings", "for", "English", ",", "and", "fastText", "-LSB-", "0", "-RSB-", "300-dimension", "word", "embeddings", "for", "Spanish", ",", "Dutch", ",", "and", "German", "."], ["The", "state", "size", "of", "the", "bi-directional", "LSTMs", "is", "set", "to", "256", "."], ["We", "adopt", "standard", "BIOES", "tagging", "scheme", "for", "NER", "and", "Chunking", "."]], "ner": [[], [[11, 11, "v"], [18, 19, "a"]], [], [[39, 39, "a"], [42, 43, "p"], [49, 49, "v"], [46, 47, "c"], [56, 56, "v"], [53, 54, "c"]], [[71, 71, "v"]], [[90, 90, "a"], [92, 92, "a"], [81, 84, "p"], [86, 86, "v"], [90, 90, "v"], [90, 90, "c"], [88, 88, "v"], [92, 92, "v"], [92, 92, "c"], [102, 103, "a"]], [[117, 117, "a"], [128, 128, "a"], [111, 113, "a"]], [[148, 149, "a"], [144, 145, "p"], [153, 153, "v"]], [[158, 160, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[11, 11, "v"]], [], [[39, 39, "a"], [49, 49, "v"], [56, 56, "v"]], [], [[86, 86, "v"], [88, 88, "v"], [90, 90, "a"], [92, 92, "a"], [107, 107, "a"]], [[117, 117, "a"], [128, 128, "a"]], [[149, 149, "a"], [153, 153, "v"]], []], "predicted_relations": [[], [], [], [[42, 43, 39, 39, "USED-FOR"], [46, 47, 56, 56, "USED-FOR"], [53, 54, 56, 56, "USED-FOR"]], [], [[81, 84, 90, 90, "USED-FOR"], [90, 90, 86, 86, "USED-FOR"], [90, 90, 90, 90, "USED-FOR"], [90, 90, 88, 88, "USED-FOR"], [90, 90, 92, 92, "USED-FOR"], [92, 92, 90, 90, "USED-FOR"], [92, 92, 92, 92, "USED-FOR"]], [], [[144, 145, 148, 149, "USED-FOR"]], []]}
{"doc_key": "1809.10966-0027605e-a74d-4586-90ce-1dfe75002c20", "sentences": [["We", "finetuned", "our", "models", "on", "\\", "-LRB-", "S=3\\", "-RRB-", "source", "domains", "and", "tested", "on", "the", "remaining", "target", "."], ["We", "splitted", "our", "training", "sets", "in", "90", "%", "train", "and", "10", "%", "validation", ",", "and", "used", "the", "best", "performing", "model", "on", "the", "validation", "set", "for", "the", "final", "test", ",", "following", "the", "validation", "strategy", "described", "in", "Section", "."], ["For", "preprocessing", ",", "we", "used", "random", "zooming", "with", "rescaling", ",", "horizontal", "flipping", ",", "brightness/contrast/saturation/hue", "perturbations", "and", "normalization", "using", "ImageNet", "'s", "statistics", "."], ["We", "used", "a", "batch", "size", "of", "96", "-LRB-", "32", "images", "per", "source", "domain", "-RRB-", "and", "trained", "using", "SGD", "with", "momentum", "set", "at", "0.9", "and", "initial", "learning", "rate", "at", "0.01", "and", "0.007", "for", "ResNet", "'s", "and", "AlexNet", "'s", "experiments", "respectively", "."], ["We", "considered", "an", "epoch", "as", "the", "minimum", "number", "of", "steps", "necessary", "to", "iterate", "over", "the", "largest", "source", "domain", "and", "we", "trained", "our", "models", "for", "30", "epochs", ",", "scaling", "the", "learning", "rate", "by", "a", "factor", "of", "0.2", "every", "10", "epochs", "."], ["We", "used", "the", "same", "setup", "to", "train", "our", "ResNet-18", "Deep", "All", "baselines", "."], ["We", "repeated", "each", "experiment", "5", "times", ",", "averaging", "the", "results", "."]], "ner": [[], [], [[56, 56, "a"]], [[94, 94, "a"], [96, 96, "p"], [99, 99, "v"], [101, 103, "p"], [105, 105, "v"], [107, 107, "v"], [112, 114, "c"], [80, 81, "a"]], [[152, 152, "v"], [120, 120, "a"]], [[165, 167, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"]], [[24, 25, "v"], [28, 29, "v"]], [[73, 73, "a"]], [[80, 81, "p"], [83, 83, "v"], [85, 85, "v"], [94, 94, "a"], [99, 99, "v"], [102, 103, "p"], [105, 105, "v"], [107, 107, "v"], [109, 109, "a"], [112, 112, "a"]], [[141, 141, "v"], [142, 142, "p"], [146, 147, "p"], [152, 152, "v"], [154, 154, "v"], [155, 155, "p"]], [[165, 166, "a"]], [[174, 174, "v"]]], "predicted_relations": [[], [], [], [[96, 96, 94, 94, "USED-FOR"], [96, 96, 80, 81, "USED-FOR"], [99, 99, 101, 103, "USED-FOR"], [101, 103, 94, 94, "USED-FOR"], [107, 107, 101, 103, "USED-FOR"], [112, 114, 105, 105, "USED-FOR"], [112, 114, 107, 107, "USED-FOR"]], [], [], []]}
{"doc_key": "1811.05163-1fbbc7c2-ee5a-4f67-94be-76551b53c524", "sentences": [["In", "our", "experiments", ",", "the", "software", "tools", "are", "Matconvnet", "-LSB-", "16", "-RSB-", ",", "CUDA", "8.0", ",", "CUDNN", "V5.1", ",", "MATLAB", "2014", "and", "Visual", "Studio", "2012", "."], ["The", "hardware", "device", "is", "workstation", "configured", "with", "a", "Intel", "Xeon", "E3-1505", "M", "v5", "CPU", "@", "2.80", "GHz", ",", "a", "NVIDIA", "Titan", "X", "GPU", "and", "128", "GB", "DDR3", "Memory", "."], ["Moreover", ",", "the", "training", "settings", "similar", "to", "-LSB-", "21", "-RSB-", ",", "-LSB-", "23", "-RSB-", "are", "adopted", "and", "summarized", "as", "follows", "."], ["All", "images", "in", "these", "two", "databases", "are", "scaled", "to", "\\", "-LRB-", "128\\times", "128\\", "-RRB-", "pixels", ",", "and", "each", "image", "is", "further", "augmented", "by", "the", "horizontal", "mirror", "and", "randomly", "rotating", "operations", "."], ["The", "randomly", "rotating", "operation", "is", "applied", "to", "randomly", "rotate", "an", "image", "in", "ranges", "\\", "-LRB-", "-LSB-", "-3^", "-LCB-", "\\circ", "-RCB-", ",", "0^", "-LCB-", "\\circ", "-RCB-", "-RSB-", "\\", "-RRB-", "and", "\\", "-LRB-", "-LSB-", "0^", "-LCB-", "\\circ", "-RCB-", ",", "3^", "-LCB-", "\\circ", "-RCB-", "-RSB-", "\\", "-RRB-", "."], ["The", "weights", "in", "each", "layer", "are", "initialized", "based", "on", "a", "normal", "distribution", "\\", "-LRB-", "N", "-LRB-", "0", ",", "0.01", "-RRB-", "\\", "-RRB-", ",", "and", "the", "biases", "are", "initialized", "to", "0", "."], ["The", "\\", "-LRB-", "L_2\\", "-RRB-", "regularization", "weights", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "in", "Eq", "."], ["-LRB-", "REF", "-RRB-", "is", "set", "as", "0.005", "on", "the", "VeRi", "-LSB-", "0", "-RSB-", "database", ",", "while", "for", "the", "larger", "VehicleID", "-LSB-", "2", "-RSB-", "database", ",", "it", "is", "set", "as", "0.001", "."], ["The", "size", "of", "mini-batch", "is", "128", "including", "64", "positive", "and", "64", "negative", "image", "pairs", ",", "and", "both", "positive", "and", "negative", "pairs", "are", "randomly", "selected", "from", "the", "whole", "database", "."], ["The", "momentums", "are", "set", "to", "0.9", "."], ["The", "learning", "rates", "start", "with", "0.01", "and", "are", "gradually", "decreased", "along", "the", "training", "progress", "."], ["That", "is", ",", "if", "the", "objective", "function", "is", "convergent", "at", "a", "stage", ",", "the", "learning", "rates", "are", "reduced", "to", "1/10", "of", "the", "current", "values", ",", "and", "the", "minimum", "learning", "rates", "are", "0.001", "."]], "ner": [[[8, 8, "a"], [13, 14, "a"], [16, 17, "a"], [19, 20, "a"], [22, 24, "a"]], [], [], [], [], [], [[192, 192, "p"]], [[204, 204, "v"], [227, 227, "v"]], [], [], [], [[311, 311, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [16, 16, "a"]], [[41, 42, "v"], [50, 51, "v"]], [], [[80, 80, "v"], [88, 88, "v"]], [], [[168, 168, "v"], [170, 170, "v"], [181, 181, "v"]], [[186, 186, "p"], [192, 192, "p"]], [[204, 204, "v"], [217, 217, "a"], [227, 227, "v"]], [[234, 234, "v"], [236, 236, "v"], [239, 239, "v"]], [[263, 263, "v"]], [[266, 267, "p"], [270, 270, "v"]], [[294, 295, "p"], [299, 299, "v"], [311, 311, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1807.01846-0a0dc225-6d3e-4ecf-86ad-c2700384c186", "sentences": [["To", "compute", "the", "output", "mass", "function", "given", "by", "Eq", "-LRB-", "-RRB-", "in", "the", "binary", "case", "and", "by", "Proposition", "REF", "in", "the", "multi-category", "case", ",", "we", "need", "to", "compute", "the", "weights", "of", "evidence", "."], ["In", "the", "binary", "case", ",", "these", "weights", "depend", "on", "coefficients", "\\", "-LRB-", "\\beta", "_j\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "_j\\", "-RRB-", "for", "\\", "-LRB-", "j=1", ",", "\\ldots", ",", "J\\", "-RRB-", "through", "-LRB-", "REF", "-RRB-", "."], ["A", "learning", "procedure", "-LRB-", "such", "as", "likelihood", "maximization", "-RRB-", "gives", "us", "estimates", "\\", "-LRB-", "\\widehat", "-LCB-", "\\beta", "-RCB-", "_j\\", "-RRB-", "of", "\\", "-LRB-", "\\beta", "_j\\", "-RRB-", "for", "\\", "-LRB-", "j=0", ",", "\\ldots", ",", "J\\", "-RRB-", "."], ["Parameters", "\\", "-LRB-", "\\alpha", "_j\\", "-RRB-", "are", "not", "identifiable", ",", "but", "are", "linked", "to", "\\", "-LRB-", "\\beta", "_0\\", "-RRB-", "by", "Eq", "."], ["-LRB-", "REF", "-RRB-", "."], ["In", "the", "multi-category", "case", ",", "things", "are", "worse", ",", "because", "parameters", "\\", "-LRB-", "\\beta", "_", "-LCB-", "jk", "-RCB-", "\\", "-RRB-", "are", "also", "not", "identifiable", ":", "we", "can", "easily", "check", "that", "adding", "any", "constant", "vector", "\\", "-LRB-", "c=", "-LRB-", "c_0", ",", "\\ldots", ",", "c_J", "-RRB-", "\\", "-RRB-", "to", "each", "vector", "\\", "-LRB-", "\\beta", "_k=", "-LRB-", "\\beta", "_", "-LCB-", "0k", "-RCB-", ",", "\\ldots", ",", "\\beta", "_", "-LCB-", "Jk", "-RCB-", "-RRB-", "\\", "-RRB-", "produces", "the", "same", "normalized", "plausibilities", "-LRB-", "REF", "-RRB-", "."], ["Both", "parameters", "\\", "-LRB-", "\\beta", "_", "-LCB-", "jk", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\alpha", "_", "-LCB-", "jk", "-RCB-", "\\", "-RRB-", "are", ",", "thus", ",", "underdetermined", "in", "that", "case", "."]], "ner": [[[3, 5, "a"]], [[42, 42, "p"]], [[74, 75, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [], [[74, 75, "a"]], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1807.01846-d4be4b4f-3843-4b10-9682-2a3105a092f4", "sentences": [["To", "identify", "the", "model", "parameters", ",", "we", "propose", "to", "apply", "the", "Least", "Commitment", "Principle", "introduced", "in", "Section", "REF", ",", "by", "searching", "for", "the", "parameter", "values", "that", "give", "us", "the", "output", "mass", "functions", "with", "minimal", "information", "content", ",", "the", "information", "content", "of", "a", "mass", "function", "\\", "-LRB-", "m\\", "-RRB-", "being", "taken", "to", "be", "\\", "-LRB-", "I_p", "-LRB-", "m", "-RRB-", "\\", "-RRB-", "defined", "by", "-LRB-", "REF", "-RRB-", ",", "with", "\\", "-LRB-", "p=2\\", "-RRB-", "."], ["-LRB-", "The", "value", "\\", "-LRB-", "p=2\\", "-RRB-", "is", "chosen", "because", "it", "lends", "itself", "to", "easy", "computation", ",", "as", "will", "be", "shown", "below", "-RRB-", "."], ["We", "will", "first", "deal", "with", "the", "binary", "case", "in", "Section", "REF", "and", "proceed", "with", "the", "multi-category", "case", "in", "Section", "REF", "."]], "ner": [[[11, 13, "a"], [34, 35, "a"], [38, 39, "a"], [69, 69, "p"], [69, 69, "v"]], [[77, 77, "p"], [77, 77, "v"]], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[[69, 69, 34, 35, "USED-FOR"], [69, 69, 38, 39, "USED-FOR"], [69, 69, 69, 69, "USED-FOR"], [69, 69, 69, 69, "USED-FOR"]], [[77, 77, 77, 77, "USED-FOR"], [77, 77, 77, 77, "USED-FOR"]], []]}
{"doc_key": "1804.02204-afeda2a9-3718-45ab-bc95-48f36b126ee5", "sentences": [["From", "preliminary", "experiments", "it", "was", "found", "that", "using", "batch", "sizes", "of", "roughly", "25", "hrs", "gave", "a", "good", "balance", "between", "the", "number", "of", "updates", "and", "using", "good", "gradient", "estimate", "."], ["When", "the", "number", "of", "CG", "iterations", "is", "limited", ",", "initialising", "CG", "with", "a", "good", "estimate", "of", "the", "gradient", "is", "desirable", ",", "as", "within", "a", "few", "iterations", "a", "good", "descent", "direction", "can", "be", "found", "."], ["However", "this", "comes", "at", "the", "cost", "of", "fewer", "HF/NG", "updates", "per", "epoch", "as", "larger", "batch", "sizes", "are", "needed", "to", "reduce", "the", "variance", "associated", "with", "the", "gradient", "estimates", "."], ["In", "preliminary", "tests", ",", "it", "was", "found", "that", "increasing", "the", "batch", "sizes", "beyond", "25hrs", "yielded", "no", "significant", "improvements", "."], ["To", "make", "up", "the", "NG/HF", "minibatch", ",", "we", "followed", "Kingsbury", "'s", "approach", "-LSB-", "4", "-RSB-", "and", "sampled", "only", "1", "%", "of", "the", "training", "set", "."]], "ner": [[[8, 9, "a"], [20, 22, "p"], [12, 13, "v"], [8, 9, "p"]], [[33, 34, "a"], [38, 39, "p"], [42, 46, "v"]], [[77, 78, "a"], [71, 72, "a"], [77, 78, "p"]], [[101, 102, "a"], [101, 102, "p"], [104, 104, "v"]], [[119, 121, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 12, "v"]], [[33, 33, "a"], [39, 39, "a"]], [], [], [[114, 114, "a"], [119, 121, "a"], [128, 129, "v"]]], "predicted_relations": [[[20, 22, 8, 9, "USED-FOR"], [12, 13, 20, 22, "USED-FOR"], [8, 9, 8, 9, "USED-FOR"]], [[38, 39, 33, 34, "USED-FOR"]], [[77, 78, 77, 78, "USED-FOR"], [77, 78, 71, 72, "USED-FOR"]], [[101, 102, 101, 102, "USED-FOR"], [104, 104, 101, 102, "USED-FOR"]], []]}
{"doc_key": "1811.06017-ded2c426-f92b-4e40-9fed-4dd01280d060", "sentences": [["Training", "setups", ":", "The", "loss", "function", "is", "the", "mean", "squared", "error", "-LRB-", "MSE", "-RRB-", "and", "is", "optimized", "with", "Adam", "optimizer", "-LSB-", "18", "-RSB-", "with", "learning", "rate=0.001", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=0.9", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=0.999", "."], ["The", "batch", "size", "used", "in", "this", "work", "is", "256", "and", "models", "are", "trained", "for", "1000", "epochs", "."]], "ner": [[[18, 19, "a"], [24, 25, "p"], [25, 25, "v"], [32, 32, "v"], [39, 39, "v"]], []], "relations": [[], []], "predicted_ner": [[[18, 18, "a"]], [[42, 43, "p"], [49, 49, "v"], [55, 55, "v"], [56, 56, "p"]]], "predicted_relations": [[[24, 25, 18, 19, "USED-FOR"], [25, 25, 24, 25, "USED-FOR"], [32, 32, 24, 25, "USED-FOR"]], []]}
{"doc_key": "1805.10163-063e70a8-1b16-4d5b-9b6a-a365f6c4192d", "sentences": [["We", "follow", "the", "setup", "of", "Transformer", "base", "model", "-LSB-", "26", "-RSB-", "."], ["More", "precisely", ",", "the", "number", "of", "layers", "in", "the", "encoder", "and", "decoder", "is", "\\", "-LRB-", "N=6\\", "-RRB-", "."], ["We", "employ", "\\", "-LRB-", "h", "=", "8\\", "-RRB-", "parallel", "attention", "layers", ",", "or", "heads", "."], ["The", "dimensionality", "of", "input", "and", "output", "is", "\\", "-LRB-", "d_", "-LCB-", "model", "-RCB-", "=", "512\\", "-RRB-", ",", "and", "the", "inner-layer", "of", "a", "feed-forward", "networks", "has", "dimensionality", "\\", "-LRB-", "d_", "-LCB-", "ff", "-RCB-", "=2048\\", "-RRB-", "."]], "ner": [[[5, 7, "a"]], [[16, 23, "p"], [27, 27, "v"]], [[36, 36, "v"]], [[46, 50, "p"], [59, 59, "v"], [77, 77, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 7, "a"]], [[27, 27, "v"]], [[34, 36, "v"]], [[59, 59, "v"], [67, 68, "a"], [73, 76, "a"]]], "predicted_relations": [[], [[27, 27, 16, 23, "USED-FOR"]], [], []]}
{"doc_key": "1807.04734-f821c53c-b7c2-4bb4-9b50-1501c54d48e9", "sentences": [["For", "training", ",", "validation", ",", "and", "testing", ",", "we", "used", "630", ",", "70", ",", "and", "20", "windows", "respectively", "."], ["We", "trained", "CRsAE", "using", "mini-batch", "gradient", "descent", "back-propagation", "with", "the", "ADAM", "optimizer", "-LSB-", "10", "-RSB-", "for", "a", "maximum", "of", "60", "epochs", "."], ["In", "cases", "when", "the", "filters", "converged", "early", ",", "and", "the", "validation", "loss", "stopped", "to", "improve", ",", "we", "stopped", "the", "training", "."], ["We", "picked", "the", "learned", "dictionary", "as", "the", "one", "with", "minimum", "validation", "loss", "."], ["The", "number", "of", "training", "parameters", "was", "\\", "-LRB-", "K", "\\times", "C", "=", "45", "\\times", "3", "=", "135\\", "-RRB-", "."], ["The", "parameters", "to", "be", "tuned", "were", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", ",", "\\", "-LRB-", "L\\", "-RRB-", ",", "the", "learning", "rate", "of", "the", "ADAM", "optimizer", ",", "the", "number", "of", "FISTA", "iterations", "\\", "-LRB-", "T\\", "-RRB-", ",", "and", "the", "mini-batch", "size", "\\", "-LRB-", "B\\", "-RRB-", "."], ["Below", ",", "we", "discussed", "how", "we", "selected", "each", "."]], "ner": [[], [[21, 21, "a"], [23, 26, "a"], [29, 30, "a"]], [], [], [], [[102, 102, "p"], [108, 108, "p"], [112, 117, "p"], [120, 123, "p"], [131, 132, "p"], [116, 117, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[10, 10, "v"], [12, 12, "v"], [15, 15, "v"]], [[21, 21, "a"], [23, 26, "a"], [29, 29, "a"], [38, 38, "v"], [39, 39, "p"]], [], [], [[83, 83, "p"], [85, 87, "v"], [89, 91, "v"]], [[102, 102, "p"], [108, 108, "p"], [112, 113, "p"], [116, 116, "a"], [122, 122, "a"], [126, 126, "p"], [131, 132, "p"], [135, 135, "p"]], []], "predicted_relations": [[], [], [], [], [], [[120, 123, 116, 117, "USED-FOR"]], []]}
{"doc_key": "1807.04734-cf6ff6ec-30a9-415d-930f-c136d67c5a53", "sentences": [["Regularization", "parameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "."], ["Let", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "_0\\", "-RRB-", "denote", "the", "initial", "dictionary", "estimate", ":", "\\", "-LRB-", "\\mathbf", "-LCB-", "y", "-RCB-", "_j", "=", "\\mathbf", "-LCB-", "H", "-RCB-", "_", "-LCB-", "0", "-RCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "_j", "+", "\\underbrace", "-LCB-", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "-\\mathbf", "-LCB-", "H", "-RCB-", "_", "-LCB-", "0", "-RCB-", "-RRB-", "\\mathbf", "-LCB-", "x", "-RCB-", "_j", "+", "\\mathbf", "-LCB-", "v", "-RCB-", "_j", "-RCB-", "_", "-LCB-", "\\mathbf", "-LCB-", "n", "-RCB-", "_j", "-RCB-", "\\", "-RRB-", "."], ["The", "observations", "contain", "two", "sources", "of", "noise", ",", "namely", "observation", "noise", ",", "and", "noise", "from", "lack", "of", "knowledge", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "\\", "-RRB-", "."], ["For", "simulated", "data", ",", "we", "can", "compute", "both", "quantities", "explicitly", "."], ["If", "we", "let", "\\", "-LRB-", "\\hat", "-LCB-", "\\sigma", "-RCB-", "_n", "=", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "N", "-RCB-", "\\left|\\left|n_j\\right|\\right|_2\\", "-RRB-", ",", "we", "can", "use", "\\", "-LRB-", "\\lambda", "\\approx", "\\hat", "-LCB-", "\\sigma", "-RCB-", "_n", "\\sqrt", "-LCB-", "2\\log", "-LRB-", "C\\times", "N_e", "-RRB-", "-RCB-", "\\", "-RRB-", "as", "suggested", "in", "-LSB-", "11", "-RSB-", "."], ["For", "real", "data", ",", "we", "can", "estimate", "\\", "-LRB-", "\\left|\\left|\\mathbf", "-LCB-", "v", "-RCB-", "_j\\right|\\right|_2\\", "-RRB-", "from", "\u201c", "silent", "\u201d", "periods", "."], ["Assuming", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "_0\\", "-RRB-", "is", "close", "enough", ",", "an", "assumption", "well-justified", "by", "the", "dictionary", "learning", "literature", "-LSB-", "1", "-RSB-", ",", "we", "propose", "to", "estimate", "the", "cumulative", "noise", "by", "scaling", "this", "estimate", "by", "a", "constant", "factor", "of", "\\", "-LRB-", "1.1\\", "-RRB-", "to", "2", "."], ["In", "principle", ",", "this", "argument", "suggests", "we", "should", "decrease", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "as", "the", "estimate", "of", "the", "dictionary", "improved", "."], ["The", "rate", "at", "which", "this", "occurs", "should", "depend", "on", "the", "rate", "at", "which", "the", "dictionary", "estimate", "improves", "."], ["To", "our", "knowledge", ",", "there", "is", "no", "theory", "characterizing", "this", "."], ["Therefore", ",", "we", "do", "not", "decrease", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "in", "the", "results", "we", "report", "."]], "ner": [[[0, 1, "a"], [4, 4, "p"], [4, 4, "v"]], [], [], [], [[149, 149, "p"], [149, 149, "v"]], [], [], [[253, 253, "p"], [253, 253, "v"]], [], [], [[301, 301, "p"], [301, 301, "v"]]], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 1, "p"], [4, 4, "p"]], [], [[87, 87, "v"]], [], [], [], [[237, 237, "v"], [240, 240, "v"]], [], [], [], []], "predicted_relations": [[[4, 4, 0, 1, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"]], [], [], [], [[149, 149, 149, 149, "USED-FOR"]], [], [], [[253, 253, 253, 253, "USED-FOR"]], [], [], [[301, 301, 301, 301, "USED-FOR"]]]}
{"doc_key": "1807.04734-754c256d-31a3-48a3-a851-4434e9f05e5f", "sentences": [["Picking", "\\", "-LRB-", "L\\", "-RRB-", "and", "the", "learning", "rate", "."], ["\\", "-LRB-", "L\\", "-RRB-", "must", "be", "greater", "than", "the", "maximum", "eigenvalue", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "^\\textrm", "-LCB-", "T", "-RCB-", "\\mathbf", "-LCB-", "H", "-RCB-", "\\", "-RRB-", "-LSB-", "9", "-RSB-", "."], ["We", "used", "an", "existing", "collection", "of", "neural", "action", "potentials", "to", "estimate", "\\", "-LRB-", "L\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "L", "=", "26\\", "-RRB-", "."], ["We", "varied", "the", "learning", "rate", "of", "the", "optimizer", "from", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "to", "\\", "-LRB-", "10^", "-LCB-", "-1", "-RCB-", "\\", "-RRB-", "and", "chose", "the", "one", "associated", "with", "the", "sharpest", "drop", "in", "the", "validation", "loss", "function", "as", "in", "-LSB-", "12", "-RSB-", "."]], "ner": [[[7, 8, "p"]], [], [], [], [[74, 74, "a"], [70, 71, "p"], [105, 106, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 8, "p"]], [], [], [[62, 64, "v"]], [[70, 71, "p"], [87, 90, "v"], [96, 96, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1807.04734-6091c8ef-72a5-4ccf-ac03-76eb46b1727d", "sentences": [["Batch", "size", "\\", "-LRB-", "B\\", "-RRB-", "."], ["We", "chose", "\\", "-LRB-", "B", "=", "16\\", "-RRB-", "."], ["We", "found", "this", "to", "be", "a", "choice", "for", "which", "the", "ADAM", "optimizer", "successfully", "avoided", "local", "optima", "of", "the", "loss", "function", "."]], "ner": [[], [[13, 13, "v"]], [[26, 27, "a"]]], "relations": [[], [], []], "predicted_ner": [[[0, 1, "p"], [4, 4, "p"]], [[11, 11, "p"], [11, 13, "v"]], [[26, 26, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1807.04734-bc4dc52e-f763-4f4d-8fa5-a36469f572eb", "sentences": [["Figure", "REF", "demonstrates", "the", "ability", "of", "CRsAE", "to", "recover", "the", "filters", "used", "in", "the", "simulation", "in", "the", "presence", "of", "noise", "."], ["For", "each", "point", "in", "Figure", "REF", ",", "we", "estimated", "the", "recovery", "error", "by", "averaging", "over", "7", "independent", "simulations", "."], ["We", "note", "that", "we", "only", "used", "700", "examples", "per", "simulation", ",", "which", "took", "\\", "-LRB-", "\\approx", "1\\", "-RRB-", "hour", "on", "a", "GPU", "!"], ["Increasing", "the", "number", "of", "simulations", "and", "the", "number", "of", "training", "examples", "would", "let", "the", "errors", "converge", "to", "values", "much", "closer", "to", "0", "."], ["Figure", "REF", "demonstrates", "that", ",", "for", "one", "of", "the", "best", "simulations", "with", "16", "dB", "SNR", ",", "the", "errors", "do", "converge", "to", "0", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[36, 36, "v"]], [[46, 46, "v"]], [[84, 84, "v"]], [[92, 92, "v"], [98, 99, "v"], [107, 107, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1807.04734-46b7ea81-0f24-45a6-9e99-87f8bc5d5b03", "sentences": [["We", "also", "compared", "the", "dictionary-learning", "performance", "of", "CRsAE", "to", "the", "network", "in", "-LSB-", "4", "-RSB-", "where", "the", "encoder", "consists", "of", "3", "ISTA", "iterations", ",", "and", "the", "decoder", "is", "linear", "and", "unconstrained", "."], ["We", "term", "this", "architecture", "LCSC", "-LRB-", "3", "-RRB-", "."], ["Figure", "REF", "compares", "the", "true", "dictionary", "to", "that", "estimated", "using", "LCSC", "-LRB-", "3", "-RRB-", "when", "the", "SNR", "is", "16", "dB", "."], ["We", "considered", "two", "cases", "for", "CRsAE", "."], ["In", "the", "first", ",", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "_0\\", "-RRB-", "was", "a", "random", "perturbation", "of", "the", "true", "dictionary", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "\\", "-RRB-", "such", "that", "the", "error", "-LRB-", "Eq", "."], ["REF", "-RRB-", "was", "between", "\\", "-LRB-", "0.4\\", "-RRB-", "to", "\\", "-LRB-", "0.5\\", "-RRB-", "."], ["In", "the", "second", ",", "the", "entries", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "H", "-RCB-", "_0\\", "-RRB-", "were", "assumed", "to", "be", "i.i.d", "."], ["Gaussian", "."], ["For", "LCSC", "-LRB-", "3", "-RRB-", ",", "we", "initialized", "the", "dictionary", "as", "in", "the", "first", "case", "for", "CRsAE", "."], ["We", "also", "allowed", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "to", "be", "trainable", "as", "in", "-LSB-", "4", "-RSB-", "."], ["In", "spite", "of", "the", "fact", "LCSC", "-LRB-", "3", "-RRB-", "converged", "to", "a", "solution", "with", "small", "reconstruction", "error", ",", "unlike", "CRsAE", ",", "it", "was", "not", "able", "to", "learn", "the", "true", "filters", "."], ["-LCB-", "FIGURE", "-RCB-", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[[7, 7, "a"]], [], [], [[67, 67, "a"]], [], [], [], [], [[157, 157, "a"]], [[164, 164, "p"]], [[195, 195, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "a"], [20, 20, "v"], [21, 21, "a"]], [], [[59, 60, "v"]], [[64, 64, "v"], [67, 67, "a"]], [], [[110, 110, "v"], [115, 115, "v"]], [], [], [[144, 144, "v"], [157, 157, "a"]], [[164, 164, "p"]], [[195, 195, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "1805.10981-ca5e5164-2e22-4c04-b86c-9c93f9c939dc", "sentences": [["Figure", "REF", "shows", "the", "activation", "patterns", "and", "the", "corresponding", "informative", "time-windows", "of", "the", "components", "with", "the", "maximum", "contribution", "to", "the", "decoding", "of", "each", "class", "in", "the", "LF-CNN", "model", ",", "trained", "on", "the", "pooled", "data", "from", "Experiment", "1", "and", "updated", "using", "the", "pseudo-real", "time", "update", "procedure", "described", "above", "on", "single", "held-out", "subject", "."], ["For", "all", "of", "the", "five", "classes", ",", "our", "model", "extracted", "spatial", "patterns", "whose", "source", "estimates", "showed", "overall", "good", "correspondence", "to", "the", "locations", "and", "lateralizations", "of", "the", "peaks", "of", "the", "evoked", "responses", "-LRB-", "Figure", "REF", "-RRB-", "."]], "ner": [[[26, 27, "a"], [41, 44, "a"]], []], "relations": [[], []], "predicted_ner": [[[26, 27, "a"]], [[56, 56, "v"], [60, 60, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1805.10981-2bf48e8b-dd72-4b2b-b05c-e8f5c1e0c22d", "sentences": [["We", "also", "estimated", "spatial", "properties", "of", "the", "latent", "components", "that", "had", "the", "least", "overall", "contribution", "to", "any", "of", "the", "classes", "."], ["Inspecting", "the", "weights", "of", "the", "output", "-LRB-", "classification", "-RRB-", "layer", "-LRB-", "Figure", "REF", "-RRB-", "further", "allowed", "us", "to", "identify", "5", "components", "which", "provided", "minimum", "contribution", "to", "either", "class", "."], ["Although", "none", "of", "these", "components", "directly", "corresponded", "to", "known", "signatures", "of", "e.g", "."], ["oculomotor", "artifacts", ",", "their", "overall", "limited", "contribution", "to", "either", "class", "may", "suggest", "that", "these", "patterns", "were", "used", "for", "out-projecting", "irrelevant", "activity", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[40, 40, "v"]], [], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1807.06216-0b6e46f2-4f1e-4d0b-91a9-124e483caeb2", "sentences": [["As", "TNRD", "model", "serves", "as", "a", "strong", "baseline", ",", "we", "initialize", "the", "parameters", "\\", "-LRB-", "\\Theta", "\\", "-RRB-", "using", "the", "TNRD", "model", "."], ["We", "tested", "the", "trained", "models", "on", "the", "68", "images", "test", "dataset", "-LSB-", "17", "-RSB-", "."], ["We", "evaluated", "the", "denoising", "performance", "using", "PSNR", "-LSB-", "5", "-RSB-", "and", "SSIM", "-LSB-", "23", "-RSB-", "."]], "ner": [[[1, 2, "a"], [20, 21, "a"]], [[30, 33, "a"]], [[44, 44, "a"], [49, 49, "a"]]], "relations": [[], [], []], "predicted_ner": [[[1, 2, "a"], [20, 21, "a"]], [[30, 30, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "1807.06233-1004042c-048e-4662-b2dd-076e893245ad", "sentences": [["Except", "for", "our", "data", "augmentation", "strategy", ",", "we", "use", "the", "same", "training", "setup", "used", "in", "SSD", "-LRB-", "e.g.", ",", "matching", "strategy", ",", "hard", "negative", "mining", ",", "and", "multi-task", "loss", "function", "-RRB-", "."], ["We", "use", "VGG-16", "pretrained", "model", "on", "ImageNet", "in", "two", "parallel", "CNN", "pipelines", "."], ["The", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "are", "used", "with", "the", "mini-batch", "size", "of", "2", "and", "the", "momentum", "parameter", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["We", "set", "the", "initial", "learning", "rate", "to", "\\", "-LRB-", "0.0005\\", "-RRB-", "."], ["We", "set", "the", "weight", "decay", "parameter", "applied", "to", "L2", "regularization", "term", "to", "\\", "-LRB-", "0.0005\\", "-RRB-", "."]], "ner": [[], [[34, 36, "a"]], [[56, 57, "p"], [62, 63, "p"]], [[79, 79, "v"], [73, 75, "p"]], [[96, 96, "v"], [85, 87, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[34, 34, "a"], [38, 38, "a"], [40, 40, "v"]], [[46, 51, "a"], [56, 57, "p"], [59, 59, "v"], [62, 63, "p"], [67, 67, "v"]], [[74, 75, "p"], [79, 79, "v"]], [[85, 87, "p"], [90, 92, "a"], [96, 96, "v"]]], "predicted_relations": [[], [], [], [[79, 79, 73, 75, "USED-FOR"]], []]}
{"doc_key": "1807.02305-1f74230f-fc71-43e8-a7d2-67abf0716d92", "sentences": [["The", "vocabulary", "is", "collected", "from", "the", "CNN/Daily", "Mail", "training", "data", "."], ["We", "lower-case", "the", "text", "and", "there", "are", "732,304", "unique", "word", "types", "."], ["We", "use", "the", "top", "100,000", "words", "as", "the", "model", "vocabulary", "since", "they", "can", "cover", "98.23", "%", "of", "the", "training", "data", "."], ["The", "size", "of", "word", "embedding", ",", "sentence", "level", "encoder", "GRU", ",", "document", "level", "encoder", "GRU", "are", "set", "to", "50", ",", "256", ",", "and", "256", "respectively", "."], ["We", "set", "the", "sentence", "extractor", "GRU", "hidden", "size", "to", "256", "."]], "ner": [[[6, 9, "a"]], [], [], [[47, 48, "a"], [45, 45, "p"], [62, 62, "v"], [50, 53, "a"], [45, 45, "p"], [64, 64, "v"], [67, 67, "v"], [55, 58, "a"], [45, 45, "p"], [64, 64, "v"], [67, 67, "v"], [64, 64, "v"], [67, 67, "v"]], [[77, 77, "p"], [77, 77, "p"], [79, 79, "v"], [77, 77, "p"], [79, 79, "v"], [73, 75, "a"], [76, 77, "p"], [79, 79, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[18, 18, "v"]], [[27, 27, "v"], [37, 38, "v"]], [[62, 62, "v"], [64, 64, "v"], [67, 67, "v"]], [[75, 75, "a"], [79, 79, "v"]]], "predicted_relations": [[], [], [], [[45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"], [45, 45, 47, 48, "USED-FOR"]], [[77, 77, 73, 75, "USED-FOR"], [77, 77, 73, 75, "USED-FOR"], [77, 77, 73, 75, "USED-FOR"], [76, 77, 73, 75, "USED-FOR"]]]}
{"doc_key": "1807.02232-b1ebf0d3-e324-4ace-81af-0ebfe320b948", "sentences": [["We", "propose", "the", "model", "to", "work", "for", "various", "resolutions", ",", "so", "we", "train", "the", "model", "with", "materials", "of", "various", "scales", "."], ["The", "images", "are", "cropped", "and", "downsampled", "to", "three", "scales", ",", "namely", "\\", "-LRB-", "1792\\times", "1024\\", "-RRB-", ",", "\\", "-LRB-", "1344\\times", "768\\", "-RRB-", ",", "and", "\\", "-LRB-", "896\\times", "512\\", "-RRB-", "."], ["Using", "these", "images", "with", "different", "scales", ",", "our", "network", "can", "work", "for", "videos", "from", "high", "resolution", "to", "low", "resolution", "."], ["Further", ",", "to", "reduce", "the", "gap", "between", "the", "distribution", "of", "the", "training", "set", "and", "the", "test", "set", ",", "the", "images", "are", "previously", "encoded", "using", "HEVC", "."], ["We", "set", "the", "Quantization", "Parameter", "-LRB-", "QP", "-RRB-", "to", "\\", "-LRB-", "22", ",", "27", ",", "32", ",", "37\\", "-RRB-", "and", "use", "the", "reconstructed", "blocks", "in", "the", "decoding", "process", "to", "form", "the", "training", "pairs", "."], ["We", "randomly", "sample", "about", "3,000,000", "pairs", "to", "train", "the", "model", "."], ["A", "training", "process", "takes", "about", "4", "hours", "on", "an", "NVIDIA", "GTX", "1080", "GPU", "."], ["Adam", "optimizer", "-LSB-", "58", "-RSB-", "is", "used", "for", "training", "."], ["The", "network", "is", "implemented", "using", "TensorFlow", "-LSB-", "59", "-RSB-", "."]], "ner": [[], [], [], [[95, 95, "a"]], [[108, 108, "v"], [110, 110, "v"], [112, 112, "v"], [114, 114, "v"]], [], [], [[156, 157, "a"]], [[171, 171, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [14, 14, "a"]], [[28, 28, "v"], [35, 35, "v"], [41, 41, "v"], [48, 48, "v"]], [[59, 59, "a"]], [], [[114, 114, "v"]], [[135, 135, "v"]], [[147, 147, "v"]], [[156, 156, "a"]], [[167, 167, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "1807.02371-3722de15-3d93-4e78-8560-1a6b6bb51770", "sentences": [["The", "training", "setup", "is", "depicted", "in", "figure", "REF", "."], ["We", "use", "a", "central", "machine", "to", "run", "the", "RL", "algorithm", "which", "communicates", "with", "9", "instances", "of", "the", "game", "split", "over", "2", "machines", "."], ["Each", "of", "the", "agents", "communicates", "via", "TCP", "with", "a", "WRC6", "instance", "through", "a", "dedicated", "API", "specifically", "developed", "for", "this", "work", "."], ["It", "allows", "us", "to", "retrieve", "in-game", "info", ",", "compute", "the", "reward", "and", "send", "control", "back", "to", "the", "game", "."], ["To", "speed", "up", "the", "pipeline", "and", "match", "the", "CNN", "input", "resolution", ",", "some", "costly", "graphics", "effects", "were", "disabled", "and", "we", "used", "a", "narrower", "field", "of", "view", "compared", "to", "the", "in-game", "view", ",", "as", "shown", "in", "figure", "REF", "."], ["The", "game", "'s", "clock", "runs", "at", "30FPS", "and", "the", "physical", "engine", "is", "on", "hold", "as", "it", "waits", "for", "the", "next", "action", "."]], "ner": [[], [], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[17, 18, "a"], [22, 22, "v"], [29, 29, "v"]], [[41, 41, "a"]], [], [[80, 80, "a"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "1807.02371-3454f9f3-4ecd-4681-b67f-2aa7d1fd53f6", "sentences": [["Three", "tracks", "-", "a", "total", "of", "29.6km", "-", "were", "used", "for", "training", "-LRB-", "3", "instances", "of", "each", "-RRB-", "and", "we", "reserved", "two", "tracks", "for", "testing", "the", "generalization", "of", "the", "learning", "which", "is", "discussed", "in", "section", "."], ["The", "agents", "-LRB-", "cars", "-RRB-", "start", "and", "respawn", "-LRB-", "after", "crashes", "-RRB-", "at", "a", "random", "checkpoint", "-LRB-", "always", "at", "0", "km/h", "-RRB-", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[0, 0, "v"], [6, 6, "v"], [13, 13, "v"], [21, 21, "v"]], [[55, 55, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1804.06958-f800e541-9391-49dc-9055-e480275d631d", "sentences": [["Showing", "the", "effectiveness", "of", "the", "proposed", "A-CCNN", ",", "we", "use", "the", "same", "training", "parameters", "as", "in", "-LSB-", "1", "-RSB-", ",", "except", "for", "two", "HPs", ",", "which", "are", "the", "patch", "sizes", "and", "\\", "-LRB-", "\\Sigma", "\\", "-RRB-", "'s", ",", "for", "people", "counting", "and", "density", "estimation", "."], ["These", "two", "HPs", "are", "empiracally", "determined", "on", "the", "traing", "data", "set", "."], ["Similar", "to", "the", "approach", "in", "-LSB-", "1", "-RSB-", ",", "a", "stochastic", "gradient", "decent", "algorithm", "is", "used", "during", "training", "."], ["The", "momentum", ",", "the", "learning", "rate", "and", "the", "weight", "decay", "are", "set", "to", "be", "0.9", ",", "0.0001", "and", "0.001", "respectively", "."], ["After", "25", "epochs", ",", "the", "model", "can", "reach", "a", "local", "optimum", "."]], "ner": [[[6, 6, "a"], [28, 29, "p"]], [[49, 50, "v"], [49, 50, "v"]], [[67, 70, "a"]], [[77, 77, "p"], [90, 90, "v"], [80, 81, "p"], [92, 92, "v"], [84, 85, "p"], [94, 94, "v"]], [[99, 99, "p"], [98, 98, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [22, 22, "v"], [33, 33, "p"]], [[46, 46, "v"]], [[67, 70, "a"]], [[77, 77, "p"], [80, 81, "p"], [84, 85, "p"], [90, 90, "v"], [92, 92, "v"], [94, 94, "v"]], [[98, 98, "v"], [99, 99, "p"]]], "predicted_relations": [[[28, 29, 6, 6, "USED-FOR"]], [], [], [[90, 90, 84, 85, "USED-FOR"], [92, 92, 84, 85, "USED-FOR"], [94, 94, 84, 85, "USED-FOR"]], [[98, 98, 99, 99, "USED-FOR"]]]}
{"doc_key": "1804.06898-fecd5eb7-fce4-4e11-8bbe-9c69b802a839", "sentences": [["Coherence", "models", "We", "train", "and", "test", "the", "LC", "model", "described", "in", "Section", "REF", "on", "the", "synthetic", "dataset", "and", "evaluate", "it", "using", "PRA", "and", "TPRA", "."], ["During", "pre-processing", ",", "words", "are", "lowercased", "and", "initialized", "with", "pre-trained", "word", "embeddings", "-LSB-", "22", "-RSB-", "."], ["Words", "that", "occur", "only", "once", "in", "the", "training", "set", "are", "mapped", "to", "a", "special", "UNK", "embedding", "."], ["All", "network", "weights", "are", "initialized", "to", "values", "drawn", "randomly", "from", "a", "uniform", "distribution", "with", "scale", "\\", "-LRB-", "=0.05\\", "-RRB-", ",", "and", "biases", "are", "initialized", "to", "zeros", "."], ["We", "apply", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "RMSProp", "-LSB-", "17", "-RSB-", "for", "optimization", "."], ["A", "size", "of", "100", "is", "chosen", "for", "the", "hidden", "layers", "-LRB-", "\\", "-LRB-", "d_", "-LCB-", "lstm", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "d_", "-LCB-", "cnn", "-RCB-", "\\", "-RRB-", "-RRB-", ",", "and", "the", "convolutional", "window", "size", "-LRB-", "\\", "-LRB-", "m\\", "-RRB-", "-RRB-", "is", "set", "to", "3", "."], ["Dropout", "-LSB-", "15", "-RSB-", "is", "applied", "for", "regularization", "to", "the", "output", "of", "the", "convolutional", "operation", "with", "probability", "\\", "-LRB-", "0.3\\", "-RRB-", "."], ["The", "network", "is", "trained", "for", "60", "epochs", "and", "performance", "is", "monitored", "on", "the", "development", "sets", "\u2013", "we", "select", "the", "model", "that", "yields", "the", "highest", "PRA", "value.Our", "implementation", "is", "available", "at", "https", ":", "//github.com/Youmna-H/Coherence_AES"]], "ner": [[[7, 8, "a"]], [], [], [], [[88, 89, "p"], [93, 93, "v"], [96, 96, "a"]], [[106, 106, "v"], [135, 137, "p"], [147, 147, "v"]], [[168, 168, "v"], [168, 168, "v"], [149, 149, "a"], [168, 168, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[7, 8, "a"]], [], [], [[75, 75, "v"], [83, 83, "v"]], [[88, 89, "p"], [93, 93, "v"], [96, 96, "a"]], [[106, 106, "v"], [116, 119, "a"], [125, 128, "a"], [135, 137, "p"], [141, 141, "p"], [147, 147, "v"]], [[149, 149, "a"], [168, 168, "v"]], [[176, 176, "v"], [177, 177, "p"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1804.06898-d52196e4-0fb1-4714-af0e-3336360319d4", "sentences": [["We", "use", "as", "a", "baseline", "the", "LC", "model", "that", "is", "based", "on", "the", "multiplication", "of", "the", "clique", "scores", "-LRB-", "similarly", "to", "-LSB-", "9", "-RSB-", "-RRB-", ",", "and", "compare", "the", "results", "-LRB-", "LCmul", "-RRB-", "to", "our", "averaged", "approach", "."], ["As", "another", "baseline", ",", "we", "use", "the", "entity", "grid", "-LRB-", "EGrid", "-RRB-", "-LSB-", "2", "-RSB-", "that", "models", "transitions", "between", "sentences", "based", "on", "sequences", "of", "entity", "mentions", "labeled", "with", "their", "grammatical", "role", "."], ["EGrid", "has", "been", "shown", "to", "give", "competitive", "results", "on", "similar", "coherence", "tasks", "in", "other", "domains", "."], ["Using", "the", "Brown", "Coherence", "Toolkit", "-LSB-", "6", "-RSB-", ",", "https", ":", "//bitbucket.org/melsner/browncoherence", "we", "construct", "the", "entity", "transition", "probabilities", "with", "length", "=", "3", "and", "salience", "=", "2", "."], ["The", "transition", "probabilities", "are", "then", "used", "as", "features", "that", "are", "fed", "as", "input", "to", "an", "SVM", "classifier", "with", "an", "RBF", "kernel", "and", "penalty", "parameter", "\\", "-LRB-", "C", "=", "1.5\\", "-RRB-", "to", "predict", "a", "coherence", "score", "."]], "ner": [[[6, 7, "a"]], [[51, 51, "v"]], [], [[105, 105, "p"], [107, 107, "v"], [109, 109, "p"], [111, 111, "v"]], [[128, 129, "a"], [132, 133, "p"], [141, 141, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 7, "a"], [31, 31, "a"]], [], [[70, 70, "a"]], [[88, 90, "a"], [107, 107, "v"], [111, 111, "v"]], [[139, 139, "p"], [141, 141, "v"]]], "predicted_relations": [[], [], [], [[107, 107, 105, 105, "USED-FOR"], [111, 111, 105, 105, "USED-FOR"], [111, 111, 109, 109, "USED-FOR"]], [[132, 133, 128, 129, "USED-FOR"], [141, 141, 132, 133, "USED-FOR"]]]}
{"doc_key": "1804.06898-84e9bbea-9a50-429f-9626-0a50eaeeb39a", "sentences": [["Combined", "models", "After", "training", "the", "LC", "and", "LSTMT", "&", "N", "models", ",", "we", "concatenate", "their", "output", "vectors", "to", "build", "the", "Baseline", ":", "Vector", "Concatenation", "-LRB-", "VecConcat", "-RRB-", "model", "as", "described", "in", "Section", "REF", ",", "and", "train", "a", "Kernel", "Ridge", "Regression", "model.We", "use", "scikit-learn", "with", "the", "following", "parameters", ":", "alpha=\\", "-LRB-", "0.1\\", "-RRB-", ",", "coef0=1", ",", "degree=3", ",", "gamma=\\", "-LRB-", "0.1\\", "-RRB-", ",", "kernel=", "`", "rbf", "'", "."]], "ner": [[[5, 5, "a"], [7, 9, "a"], [37, 39, "a"], [48, 48, "p"], [50, 50, "v"], [59, 59, "v"], [53, 53, "p"], [50, 50, "v"], [53, 53, "v"], [59, 59, "v"], [55, 55, "p"], [55, 55, "v"], [57, 57, "p"], [50, 50, "v"], [59, 59, "v"], [62, 62, "p"], [64, 64, "v"]]], "relations": [[]], "predicted_ner": [[[5, 5, "a"], [7, 9, "a"], [42, 42, "a"], [50, 50, "v"], [59, 59, "v"]]], "predicted_relations": [[[48, 48, 37, 39, "USED-FOR"], [50, 50, 48, 48, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [50, 50, 55, 55, "USED-FOR"], [50, 50, 57, 57, "USED-FOR"], [50, 50, 62, 62, "USED-FOR"], [59, 59, 53, 53, "USED-FOR"], [59, 59, 55, 55, "USED-FOR"], [59, 59, 57, 57, "USED-FOR"], [59, 59, 62, 62, "USED-FOR"], [53, 53, 37, 39, "USED-FOR"], [50, 50, 48, 48, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [50, 50, 55, 55, "USED-FOR"], [50, 50, 57, 57, "USED-FOR"], [50, 50, 62, 62, "USED-FOR"], [53, 53, 48, 48, "USED-FOR"], [53, 53, 53, 53, "USED-FOR"], [53, 53, 55, 55, "USED-FOR"], [59, 59, 53, 53, "USED-FOR"], [59, 59, 55, 55, "USED-FOR"], [59, 59, 57, 57, "USED-FOR"], [59, 59, 62, 62, "USED-FOR"], [55, 55, 37, 39, "USED-FOR"], [55, 55, 48, 48, "USED-FOR"], [55, 55, 53, 53, "USED-FOR"], [55, 55, 55, 55, "USED-FOR"], [55, 55, 57, 57, "USED-FOR"], [55, 55, 62, 62, "USED-FOR"], [57, 57, 37, 39, "USED-FOR"], [50, 50, 48, 48, "USED-FOR"], [50, 50, 53, 53, "USED-FOR"], [50, 50, 55, 55, "USED-FOR"], [50, 50, 57, 57, "USED-FOR"], [50, 50, 62, 62, "USED-FOR"], [59, 59, 53, 53, "USED-FOR"], [59, 59, 55, 55, "USED-FOR"], [59, 59, 57, 57, "USED-FOR"], [59, 59, 62, 62, "USED-FOR"], [62, 62, 37, 39, "USED-FOR"], [64, 64, 48, 48, "USED-FOR"], [64, 64, 53, 53, "USED-FOR"], [64, 64, 55, 55, "USED-FOR"], [64, 64, 57, 57, "USED-FOR"], [64, 64, 62, 62, "USED-FOR"]]]}
{"doc_key": "1801.00968-9b62af20-b91a-4243-9474-ed472730d411", "sentences": [["We", "implement", "our", "network", "in", "Tensorflow", "on", "an", "NVIDIA", "GeForce", "GTX", "1080Ti", "graphics", "card", "."], ["We", "collect", "1449", "RGB/D", "image", "pairs", "from", "NYU", "data", "set", "-LSB-", "20", "-RSB-", ",", "1000", "RGB/D", "image", "pairs", "for", "training", "and", "449", "RGB/D", "image", "pairs", "for", "testing", "."], ["We", "augment", "the", "training", "data", "by", "clip", ",", "rotation", "and", "mirror", "and", "generate", "180,000", "training", "patch", "pairs", "of", "size", "128\\", "-LRB-", "\\times", "\\", "-RRB-", "128", "."], ["The", "batch", "size", "is", "set", "to", "36", "."], ["The", "network", "is", "trained", "with", "200,000", "steps", "and", "the", "initial", "learning", "rate", "is", "1e-3", ",", "which", "decays", "to", "0.8", "times", "per", "10000", "steps", "."], ["We", "train", "our", "network", "for", "joint", "image", "SR.", "We", "get", "the", "low-resolution", "target", "image", "from", "a", "ground-truth", "image", "using", "nearest-neighbor", "down-sampling", "."], ["When", "our", "JCNP", "model", "is", "trained", "with", "the", "augmented", "RGB/D", "data", "pairs", ",", "it", "can", "be", "directly", "applied", "to", "several", "different", "joint", "image", "SR", "tasks", ",", "including", "depth", "map", "SR", ",", "chromaticity", "map", "SR", "and", "saliency", "map", "SR", "."], ["In", "experiments", ",", "we", "provide", "the", "average", "root", "mean", "squared", "errors", "-LRB-", "RMSEs", "-RRB-", "of", "test", "data", "set", ",", "except", "for", "the", "visual", "results", ",", "to", "evaluate", "the", "results", "."]], "ner": [[[8, 13, "a"], [5, 5, "a"]], [[22, 24, "a"]], [[49, 53, "a"]], [], [], [[120, 121, "a"]], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"]], [[17, 17, "v"], [29, 29, "v"], [36, 36, "v"]], [[56, 56, "v"], [67, 67, "v"]], [[70, 71, "p"], [75, 75, "v"]], [[82, 82, "v"], [87, 88, "p"], [90, 90, "v"], [95, 95, "v"], [98, 98, "v"]], [[104, 104, "a"], [120, 121, "a"]], [[125, 126, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "1803.06554-1dad6e18-eed3-42d8-b5a9-7d684536cd4a", "sentences": [["The", "network", "structure", "for", "YOLO", "is", "basically", "the", "same", "as", "the", "default", "structure", "of", "YOLOv2", "-LSB-", "17", "-RSB-", "except", "the", "last", "layer", "."], ["YOLOv2", "divides", "each", "image", "into", "13", "by", "13", "grids", "."], ["For", "our", "application", ",", "we", "predict", "five", "base", "bounding", "boxes", "for", "each", "grid", "in", "the", "image", "."], ["For", "each", "box", ",", "there", "are", "4", "numbers", "-LRB-", "for", "the", "top", "left", "and", "bottom", "right", "coordinates", "of", "the", "AABB", "-RRB-", ",", "1", "confidence", "score", "and", "5", "class", "scores", "."], ["Therefore", ",", "we", "change", "the", "filter", "size", "to", "\\", "-LRB-", "13", "\\times", "13", "\\times", "50\\", "-RRB-", "-LRB-", "\\", "-LRB-", "5", "\\times", "-LRB-", "4", "+", "1", "+", "5", "-RRB-", "=", "50\\", "-RRB-", "-RRB-", "in", "the", "last", "layer", "."], ["We", "also", "change", "the", "learning", "rate", "to", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "to", "avoid", "divergence", "."], ["We", "use", "a", "batch", "size", "of", "64", ",", "a", "momentum", "of", "0.9", "and", "a", "decay", "of", "0.0005", ",", "which", "are", "the", "same", "as", "those", "in", "the", "original", "YOLOv2", "configuration", "."]], "ner": [[[4, 4, "a"], [14, 14, "a"]], [[23, 23, "a"]], [], [], [], [[121, 122, "p"]], [[139, 140, "p"], [142, 142, "v"], [145, 145, "p"], [147, 147, "v"], [150, 150, "p"], [152, 152, "v"], [163, 163, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [14, 14, "a"]], [[23, 23, "a"], [28, 28, "v"], [30, 30, "v"]], [[39, 39, "v"]], [[56, 56, "v"], [72, 72, "v"], [76, 76, "v"]], [[85, 86, "p"], [90, 90, "v"], [94, 94, "v"], [99, 99, "v"], [102, 106, "v"], [109, 109, "v"]], [[121, 122, "p"], [126, 129, "v"]], [[139, 140, "p"], [142, 142, "v"], [147, 147, "v"], [150, 150, "p"], [152, 152, "v"], [163, 163, "a"]]], "predicted_relations": [[], [], [], [], [], [], [[142, 142, 145, 145, "USED-FOR"], [152, 152, 145, 145, "USED-FOR"], [152, 152, 150, 150, "USED-FOR"]]]}
{"doc_key": "1803.06554-c2628561-d1b0-42da-9644-99734884edfc", "sentences": [["For", "Faster", "R-CNN", ",", "the", "model", "is", "trained", "with", "a", "VGG", "net", "."], ["Most", "parameters", "are", "set", "to", "be", "the", "same", "as", "the", "original", "Faster", "R-CNN", "-LSB-", "18", "-RSB-", "."], ["The", "changes", "are", "as", "follows", ":", "the", "number", "of", "classes", "is", "modified", "to", "five", ";", "the", "number", "of", "outputs", "in", "the", "class", "score", "layer", "is", "modified", "to", "five", ";", "the", "number", "of", "outputs", "in", "the", "bounding", "box", "prediction", "layer", "is", "modified", "to", "20", "-LRB-", "\\", "-LRB-", "4", "\\times", "5\\", "-RRB-", "-RRB-", "."]], "ner": [[[1, 2, "a"], [10, 11, "a"]], [[24, 25, "a"]], [[37, 39, "p"], [43, 43, "v"], [57, 57, "v"], [46, 53, "p"], [43, 43, "v"], [57, 57, "v"], [60, 68, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [10, 11, "a"]], [[25, 25, "a"]], [[43, 43, "v"], [57, 57, "v"], [72, 72, "v"], [76, 76, "v"], [78, 78, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1810.04142-17a77be8-c204-4f92-8a2e-38e45c2d565d", "sentences": [["We", "train", "CMX", "on", "the", "concatenation", "of", "three", "datasets", ":", "-LRB-", "a", "-RRB-", "GY-Mix", "'s", "training", "portion", ",", "-LRB-", "b", "-RRB-", "synthetic", "codemixed", "data", "and", "-LRB-", "c", "-RRB-", "a", "monolingual", "corpus", "that", "covers", "100", "languages", "."], ["Every", "token", "in", "the", "training", "set", "spawns", "a", "training", "instance", "."], ["Our", "training", "set", "consists", "of", "38M", "tokens", "in", "total", ",", "which", "is", "on", "the", "same", "magnitude", "as", "the", "sizes", "of", "training", "data", "reported", "in", "previous", "work", "-LSB-", "13", "-RSB-", ",", "-LSB-", "11", "-RSB-", "."]], "ner": [[[2, 2, "a"], [13, 16, "a"], [21, 23, "a"], [29, 30, "a"], [33, 33, "v"]], [], []], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [7, 7, "v"], [13, 13, "a"], [33, 33, "v"]], [], [[52, 52, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1810.04142-2f53d6a2-eb92-481c-ad2b-fee2b72ce6aa", "sentences": [["We", "use", "mini-batched", "averaged", "stochastic", "gradient", "descent", "-LRB-", "ASGD", "-RRB-", "-LSB-", "6", "-RSB-", "with", "momentum", "-LSB-", "9", "-RSB-", "and", "exponentially", "decaying", "learning", "rates", "to", "learn", "the", "parameters", "of", "the", "network", "."], ["We", "fix", "the", "mini-batch", "size", "to", "256", "and", "the", "momentum", "rate", "to", "0.9", "."], ["We", "tune", "the", "initial", "learning", "rate", "and", "the", "decay", "step", "using", "development", "data", "."]], "ner": [[[14, 14, "a"]], [[34, 35, "p"], [37, 37, "v"], [40, 41, "p"], [43, 43, "v"], [40, 40, "a"]], [[48, 50, "p"], [53, 54, "p"]]], "relations": [[], [], []], "predicted_ner": [[[2, 9, "a"], [14, 14, "a"]], [[34, 35, "p"], [37, 37, "v"], [40, 41, "p"], [43, 43, "v"]], [[49, 50, "p"], [53, 54, "p"]]], "predicted_relations": [[], [[40, 41, 40, 40, "USED-FOR"]], []]}
{"doc_key": "1810.04158-33ce7e80-13b6-4505-88cd-74c303946ad2", "sentences": [["Weights", "are", "initialized", "from", "a", "zero-centered", "Gaussian", "distribution", ",", "with", "a", "standard", "deviation", "of", "\\", "-LRB-", "0.02\\", "-RRB-", ";", "The", "Adam", "optimizer", "-LSB-", "19", "-RSB-", "is", "used", ",", "with", "\\", "-LRB-", "\\beta", "_1", "=", "0.5\\", "-RRB-", ";", "The", "base", "learning", "rate", "is", "initialized", "at", "\\", "-LRB-", "2e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[20, 21, "a"], [34, 34, "v"], [6, 7, "a"], [11, 12, "p"], [16, 16, "v"], [38, 40, "a"]]], "relations": [[]], "predicted_ner": [[[5, 5, "v"], [16, 16, "v"], [20, 20, "a"], [34, 34, "v"], [38, 40, "p"], [46, 49, "v"]]], "predicted_relations": [[[11, 12, 6, 7, "USED-FOR"], [16, 16, 11, 12, "USED-FOR"]]]}
{"doc_key": "1811.11161-dde729dd-2225-4100-9ff7-a6cb149219a6", "sentences": [["For", "the", "model", ",", "we", "initialize", "the", "word", "embeddings", "using", "fasttext", "embedings", "-LSB-", "11", "-RSB-", "."], ["The", "model", "is", "trained", "using", "mini-batch", "SGD", "with", "Adam", "optimizer", "-LSB-", "9", "-RSB-", "with", "standard", "parameters", "to", "minimize", "the", "class", "weighted", "cross-entropy", "loss", "."], ["In", "our", "experiments", ",", "we", "use", "128", "dimensions", "for", "the", "LSTM", "hidden", "states", "and", "256", "dimensions", "for", "the", "hidden", "state", "in", "the", "decoder", "."], ["Similar", "to", "-LSB-", "21", "-RSB-", ",", "we", "pre-train", "an", "LSTM", "encoder", "using", "live", "data", "in", "each", "of", "the", "languages", "and", "use", "this", "model", "to", "initialize", "the", "parameters", "of", "the", "LSTM-based", "encoders", "."], ["All", "model", "setups", "are", "trained", "for", "40", "epochs", "."], ["For", "evaluation", "on", "test", "set", "we", "pick", "the", "best", "model", "based", "on", "performance", "on", "dev", "set", "."], ["For", "evaluation", ",", "we", "only", "select", "those", "slots", "as", "the", "final", "hypothesis", ",", "whose", "\\", "-LRB-", "\\tau", ">", "0.5\\", "-RRB-", "and", "occur", "in", "the", "context", "of", "the", "conversation", "."], ["For", "each", "utterance", ",", "independent", "carryover", "decisions", "are", "taken", "for", "each", "candidate", "slot", "."], ["We", "use", "standard", "definitions", "of", "precision", ",", "recall", "and", "F1", "by", "comparing", "the", "reference", "slots", "with", "the", "model", "hypothesis", "slots", "."], ["If", "an", "entity", "type", "is", "repeated", "in", "the", "current", "turn", "then", "we", "do", "not", "carry", "this", "from", "dialogue", "history", "."]], "ner": [[[10, 11, "a"]], [[21, 25, "a"], [35, 38, "a"]], [[50, 50, "a"], [50, 52, "c"], [54, 54, "v"], [58, 62, "c"]], [[73, 73, "a"], [93, 93, "a"], [71, 74, "a"]], [], [], [[140, 140, "v"]], [], [[167, 174, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[21, 21, "a"], [24, 24, "a"], [35, 38, "a"]], [[46, 46, "v"], [47, 47, "p"], [50, 50, "a"], [54, 54, "v"]], [[73, 73, "a"], [93, 93, "a"]], [[102, 102, "v"], [103, 103, "p"]], [], [[140, 140, "v"]], [], [], []], "predicted_relations": [[], [], [[58, 62, 54, 54, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1811.11165-1210d69a-2a2b-4d52-99c5-264c6e02fb43", "sentences": [["In", "the", "experiments", "on", "Clothing1M", "-LRB-", "Section", "REF", "-RRB-", ",", "we", "used", "two", "GAN", "configurations", ":", "CT-GAN", "for", "AC-GAN/rAC-GAN", "and", "SN-GAN", "for", "cGAN/rcGAN", "."], ["We", "defined", "the", "network", "architectures", "and", "training", "settings", "while", "referring", "to", "the", "source", "code", "provided", "by", "the", "authors", "of", "SN-GAN", "-LSB-", "47", "-RSB-", "-LRB-", "which", "is", "used", "for", "\\", "-LRB-", "64", "\\times", "64\\", "-RRB-", "dog", "and", "cat", "image", "generation", "-RRB-", ".https", ":", "//github.com/pfnet-research/sngan_projection", "The", "reason", "why", "we", "refer", "to", "this", "source", "code", "is", "that", "there", "is", "no", "previous", "study", "attempting", "to", "learn", "a", "generative", "model", "using", "Clothing1M", ",", "to", "the", "best", "of", "our", "knowledge", "."], ["We", "experimentally", "confirm", "that", "its", "settings", "are", "reasonable", "for", "Clothing1M", "with", "no", "hyperparameter", "tuning", "."]], "ner": [[[4, 4, "a"], [16, 16, "a"], [20, 20, "a"], [18, 18, "a"], [22, 22, "a"]], [[90, 90, "a"], [43, 43, "a"], [27, 28, "a"], [30, 31, "a"]], [[108, 108, "a"], [111, 112, "a"]]], "relations": [[], [], []], "predicted_ner": [[[4, 4, "a"], [12, 12, "v"], [13, 13, "a"], [16, 16, "a"], [20, 20, "a"]], [[43, 43, "a"], [54, 54, "v"], [56, 56, "v"], [90, 90, "a"]], [[108, 108, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1806.11534-b469ff7d-c68c-451f-94c3-e146b9b03be5", "sentences": [["We", "use", "Adam", "optimizer", "-LSB-", "42", "-RSB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "of", "\\", "-LRB-", "0.999\\", "-RRB-", "."], ["The", "CNNs", "are", "initialized", "with", "the", "pre-trained", "VGG16", "weights", "on", "ImageNet", "and", "the", "fully", "connected", "layers", "-LRB-", "which", "includes", "the", "weights", "of", "the", "binary", "random", "variables", "\\", "-LRB-", "\\mathbf", "-LCB-", "y", "-RCB-", "\\", "-RRB-", "-RRB-", "are", "initialized", "by", "sampling", "from", "a", "truncated", "normal", "distribution", "-LRB-", "a", "normal", "distribution", "in", "which", "values", "sampled", "more", "than", "2", "standard", "deviations", "from", "the", "mean", "are", "dropped", "and", "re-picked", "-RRB-", "with", "0", "mean", "and", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "standard", "deviation", "."]], "ner": [[[2, 3, "a"], [9, 10, "p"], [29, 29, "v"], [40, 40, "v"], [29, 29, "v"], [40, 40, "v"]], [[50, 50, "a"], [84, 86, "a"], [102, 102, "p"], [110, 110, "p"], [109, 109, "v"], [120, 121, "p"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [9, 10, "p"], [14, 17, "v"], [29, 29, "v"], [40, 40, "v"]], [[44, 44, "a"], [50, 50, "a"], [53, 53, "a"], [97, 97, "v"], [109, 109, "v"], [114, 117, "v"]]], "predicted_relations": [[], [[102, 102, 50, 50, "USED-FOR"], [102, 102, 84, 86, "USED-FOR"], [110, 110, 84, 86, "USED-FOR"], [109, 109, 102, 102, "USED-FOR"], [109, 109, 110, 110, "USED-FOR"], [109, 109, 120, 121, "USED-FOR"], [120, 121, 84, 86, "USED-FOR"]]]}
{"doc_key": "1805.00912-ad6ac2cf-a563-4e58-a3e5-19b2649b1b10", "sentences": [["The", "optimization", "objectives", "for", "classification", "and", "regression", "problems", "are", "cross-entropy", "loss", "and", "mean", "square", "error", "respectively", ",", "which", "we", "minimize", "by", "using", "Adadelta", "-LSB-", "52", "-RSB-", "or", "Adam", "-LSB-", "23", "-RSB-", "optimizer", "."], ["All", "trainable", "weight", "matrices", "are", "initialized", "by", "Glorot", "Initializer", "-LSB-", "11", "-RSB-", ",", "and", "all", "the", "biases", "are", "initialized", "as", "zeros", "."], ["We", "use", "300D", "-LRB-", "except", "200D", "for", "SRL", "task", "-RRB-", "GloVe", "6B", "pre-trained", "vectors", "-LSB-", "35", "-RSB-", "to", "initialize", "the", "word", "embeddings", "."], ["The", "embedding", "for", "a", "word", "in", "the", "training", "set", "but", "not", "in", "GloVe", "is", "randomly", "initialized", "by", "sampling", "from", "uniform", "distribution", "between", "\\", "-LRB-", "-LSB-", "-0.05", ",", "0.05", "-RSB-", "\\", "-RRB-", "."], ["The", "word", "embeddings", "will", "be", "fine-tuned", "during", "the", "training", "phase", "."], ["We", "also", "apply", "Dropout", "with", "keep", "probability", "\\", "-LRB-", "p_", "-LCB-", "kp", "-RCB-", "\\", "-RRB-", ",", "and", "L2", "regularization", "with", "weight", "decay", "factor", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "to", "all", "the", "model", "for", "avoiding", "overfitting", "."], ["The", "unspecified", "activation", "functions", "for", "all", "fully-connected", "layers", "appearing", "in", "models", "are", "set", "to", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "relu", "-RCB-", "\\", "-RRB-", "-LSB-", "12", "-RSB-", "."], ["The", "activation", "function", "\\", "-LRB-", "\\sigma", "_t", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "applied", "to", "token2token", "alignment", "scores", "is", "set", "to", "\\", "-LRB-", "\\log", "-LRB-", "\\operatornamewithlimits", "-LCB-", "sigmoid", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "-RRB-", "\\", "-RRB-", "unless", "otherwise", "specified", "."]], "ner": [[[22, 22, "a"], [27, 27, "a"]], [[40, 41, "a"]], [[65, 68, "a"]], [], [], [[124, 124, "a"], [126, 127, "p"], [138, 139, "a"], [141, 143, "p"], [146, 146, "v"]], [], [[209, 209, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[9, 10, "a"], [22, 22, "a"], [27, 27, "a"]], [], [[57, 57, "v"], [60, 60, "v"]], [[90, 90, "a"], [103, 103, "v"], [105, 105, "v"]], [], [[124, 124, "a"], [138, 139, "a"], [141, 143, "p"], [146, 146, "p"]], [[173, 176, "a"]], [[188, 189, "p"], [197, 197, "a"]]], "predicted_relations": [[], [], [], [], [], [[141, 143, 124, 124, "USED-FOR"]], [], []]}
{"doc_key": "1805.00912-519da975-bfe0-4f68-bdc0-da12262a61e1", "sentences": [["For", "fair", "and", "reliable", "comparisons", "with", "baselines", "and", "prior", "works", ",", "on", "SNLI", "and", "sentence", "classification", "tasks", ",", "we", "follow", "training", "setup", "and", "hyperparameters", "used", "in", "corresponding", "prior", "works", ",", "and", "only", "tune", "the", "dropout", "probability", "for", "different", "baseline", "or", "ablation", "models", ",", "without", "any", "other", "trick", "-LRB-", "e.g.", ",", "learning", "rate", "schedule", ",", "batch/layer", "normalization", ",", "etc", "."], ["-RRB-", ";", "on", "SRL", ",", "we", "directly", "employ", "the", "training", "setup", "and", "the", "well-tuned", "hyperparameters", "used", "in", "the", "prior", "state-of-the-art", "work", "-LSB-", "46", "-RSB-", "based", "on", "multi-head", "self-attention", "mechanism", ",", "without", "tuning", "them", "specifically", "for", "our", "proposed", "model", "."], ["Besides", ",", "for", "the", "language", "model", "based", "transfer", "learning", "for", "SNLI", "and", "MultiNLI", "tasks", ",", "we", "use", "the", "pretrained", "model", "provided", "by", "-LSB-", "36", "-RSB-", "radford2018improving", "."], ["And", ",", "we", "use", "the", "language", "model", "as", "the", "auxiliary", "task", "for", "models", "'", "universality", "with", "the", "coefficient", "of", "\\", "-LRB-", "0.3\\", "-RRB-", ",", "and", "use", "other", "hyper-parameters", "-LRB-", "e.g.", ",", "initial", "learning", "rate", ",", "optimizer", ",", "leaning", "rate", "schedule", ",", "epoch", "number", "-RRB-", "given", "by", "-LSB-", "36", "-RSB-", "radford2018improving", "."]], "ner": [[[12, 12, "a"], [14, 16, "a"], [34, 35, "a"]], [[85, 87, "a"]], [[108, 108, "a"], [116, 117, "a"], [102, 103, "a"]], [[130, 131, "a"], [142, 142, "a"], [146, 146, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[12, 12, "a"], [34, 35, "p"]], [[62, 62, "a"], [96, 96, "a"]], [[108, 108, "a"], [110, 110, "a"]], [[146, 146, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1805.00912-e3bdea96-12ed-4371-9116-736ac852c0f9", "sentences": [["For", "SNLI", "dataset", "-LRB-", "natural", "language", "inference", "-RRB-", ",", "we", "set", "\\", "-LRB-", "p_", "-LCB-", "kp", "-RCB-", "=", "0.65\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "use", "Adadelta", "as", "the", "optimizer", "with", "mini", "batch", "size", "of", "128", "."], ["And", ",", "we", "do", "not", "use", "the", "attention", "dropout", "for", "this", "benchmark", "."], ["Besides", ",", "the", "activation", "function", "for", "fully-connected", "layer", "is", "set", "to", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "elu", "-RCB-", "\\", "-RRB-", "-LSB-", "8", "-RSB-", "."], ["The", "training", "procedure", "is", "completed", "within", "600K", "steps", ",", "approximately", "costing", "12", "hours", "."]], "ner": [[[1, 2, "a"], [35, 35, "a"], [23, 23, "a"]], [], [[74, 74, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"], [18, 18, "v"], [26, 29, "v"], [35, 35, "a"], [40, 42, "p"], [44, 44, "v"]], [[53, 54, "a"]], [], [[88, 88, "v"], [93, 93, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1805.00912-c5e215b9-a214-4890-9fee-3d1e75bcb2b1", "sentences": [["For", "CoNLL-05", "dataset", "-LRB-", "semantic", "role", "labeling", "-RRB-", ",", "we", "use", "the", "same", "hyper-parameters", "provided", "in", "-LSB-", "46", "-RSB-", "rather", "than", "tune", "them", "for", "a", "fair", "comparison", "."], ["The", "keep", "probabilities", "of", "dropout", "for", "fully-connected", "layer", "and", "residual", "connection", "-LSB-", "14", "-RSB-", "are", "set", "to", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "0.8\\", "-RRB-", "respectively", "."], ["The", "attention", "dropout", "with", "keep", "probability", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "is", "applied", "to", "both", "source2token", "and", "token2token", "alignment", "scores", ",", "which", "equals", "to", "setting", "the", "probability", "to", "\\", "-LRB-", "0.81\\", "-RRB-", "in", "MTSA", "."], ["And", ",", "the", "activation", "function", "\\", "-LRB-", "\\sigma", "_t", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "applied", "to", "the", "token2token", "alignment", "scores", "is", "set", "to", "\\", "-LRB-", "\\operatornamewithlimits", "-LCB-", "identity", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "."], ["Besides", ",", "different", "from", "using", "fixed", "positional", "embedding", "in", "-LSB-", "46", "-RSB-", ",", "we", "remove", "it", "and", "only", "use", "the", "forward", "and", "backward", "masks", "in", "MTSA", "to", "encode", "bi-directional", "order", "information", "."], ["The", "training", "will", "finish", "within", "about", "20", "hours", "by", "using", "Adadelta", "optimizer", "."]], "ner": [[[1, 2, "a"]], [[32, 32, "a"], [34, 35, "c"], [52, 52, "v"], [37, 38, "c"], [47, 47, "v"]], [[58, 58, "a"], [65, 65, "v"], [57, 58, "c"]], [[94, 95, "a"]], [[132, 133, "a"]], [[168, 169, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"]], [[32, 32, "a"], [47, 47, "v"], [52, 52, "v"]], [[57, 58, "a"], [65, 65, "v"], [71, 71, "a"], [73, 73, "a"], [86, 86, "v"], [89, 89, "a"]], [[98, 99, "p"], [108, 108, "a"]], [[151, 151, "a"]], [[164, 164, "v"], [168, 168, "a"]]], "predicted_relations": [[], [[34, 35, 52, 52, "USED-FOR"], [34, 35, 47, 47, "USED-FOR"], [37, 38, 52, 52, "USED-FOR"], [37, 38, 47, 47, "USED-FOR"]], [[57, 58, 65, 65, "USED-FOR"]], [], [], []]}
{"doc_key": "1805.00912-18e883b4-047c-48e9-a25a-390c4b41acbe", "sentences": [["For", "CR", ",", "MPQA", "and", "SUBJ", "datasets", ",", "we", "set", "\\", "-LRB-", "p_", "-LCB-", "kp", "-RCB-", "=", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "these", "three", "benchmarks", "."], ["And", "we", "apply", "attention", "dropout", "with", "keep", "probability", "of", "\\", "-LRB-", "0.8\\", "-RRB-", "to", "CR", "and", "MPQA", "."], ["Different", "from", "the", "other", "experiments", "in", "this", "paper", ",", "we", "here", "use", "Adam", "as", "the", "optimizer", "to", "train", "the", "models", ",", "and", "do", "not", "use", "any", "learning", "rate", "decay", "trick", "."], ["The", "training", "procedure", "is", "completed", "within", "1000", "batch", "steps", "."]], "ner": [[[1, 1, "a"], [3, 3, "a"], [5, 5, "a"]], [[49, 49, "a"], [51, 51, "a"], [38, 39, "a"], [41, 42, "p"], [46, 46, "v"]], [[65, 65, "a"]], [[91, 92, "a"], [90, 90, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [17, 17, "v"], [22, 22, "p"], [24, 27, "v"], [32, 32, "v"]], [[38, 39, "a"], [46, 46, "v"], [49, 49, "a"], [51, 51, "a"]], [[65, 65, "a"]], [[90, 90, "v"], [91, 92, "p"]]], "predicted_relations": [[], [[41, 42, 38, 39, "USED-FOR"]], [], []]}
{"doc_key": "1805.00912-91e303d4-b9c0-419d-aa64-594a802698b7", "sentences": [["For", "TREC", "dataset", "-LRB-", "question-type", "classification", "-RRB-", ",", "we", "set", "\\", "-LRB-", "p_", "-LCB-", "kp", "-RCB-", "=", "0.5\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "do", "not", "apply", "the", "attention", "dropout", "."], ["The", "training", "procedure", "is", "completed", "within", "80K", "steps", "by", "using", "Adadelta", "optimizer", "."]], "ner": [[[1, 2, "a"], [35, 36, "a"], [17, 17, "v"]], [[48, 49, "a"]]], "relations": [[], []], "predicted_ner": [[[1, 2, "a"], [17, 17, "v"], [22, 22, "p"], [24, 27, "v"], [35, 36, "a"]], [[44, 44, "v"], [48, 48, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1805.00912-231b1268-2f34-4893-b2c6-3a08a15fe81c", "sentences": [["For", "SST-5", "dataset", "-LRB-", "sentiment", "analysis", "-RRB-", ",", "we", "set", "\\", "-LRB-", "p_", "-LCB-", "kp", "-RCB-", "=", "0.7\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "do", "not", "apply", "the", "attention", "dropout", "."], ["The", "training", "procedure", "is", "completed", "within", "120K", "steps", "by", "using", "Adadelta", "optimizer", "."]], "ner": [[[1, 2, "a"]], [[48, 49, "a"]]], "relations": [[], []], "predicted_ner": [[[1, 2, "a"], [17, 17, "v"], [22, 22, "p"], [24, 27, "v"], [35, 36, "a"]], [[44, 44, "v"], [48, 48, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "1802.09660-ec576c50-2136-4e85-990e-61b2c7cc2b89", "sentences": [["We", "use", "the", "standard", "\\", "-LRB-", "tanh\\", "-RRB-", "for", "activation", "function", "of", "nodes", "in", "the", "networks", "and", "the", "mean", "square", "root", "error", "function", "-LRB-", "MSE", "-RRB-", "for", "the", "subsequent", "gradient", "minimisation", "."], ["The", "artificially", "generated", "training", "sets", "are", "split", "in", "ratios", "of", "0.7", ",", "0.15", "and", "0.15", "for", "training", ",", "internal", "cross", "validation", "and", "generalisation", "testing", ",", "respectively", "."]], "ner": [[[6, 6, "a"]], [[35, 36, "a"], [40, 40, "p"], [42, 42, "v"], [35, 35, "c"], [48, 48, "c"], [44, 44, "v"], [46, 46, "v"], [50, 52, "c"], [44, 44, "v"], [46, 46, "v"], [54, 55, "c"]]], "relations": [[], []], "predicted_ner": [[], [[42, 42, "v"], [44, 44, "v"], [46, 46, "v"]]], "predicted_relations": [[], [[40, 40, 35, 36, "USED-FOR"], [50, 52, 42, 42, "USED-FOR"], [50, 52, 44, 44, "USED-FOR"], [50, 52, 46, 46, "USED-FOR"], [50, 52, 44, 44, "USED-FOR"], [50, 52, 46, 46, "USED-FOR"], [54, 55, 42, 42, "USED-FOR"], [54, 55, 44, 44, "USED-FOR"], [54, 55, 46, 46, "USED-FOR"], [54, 55, 44, 44, "USED-FOR"], [54, 55, 46, 46, "USED-FOR"]]]}
{"doc_key": "1812.01598-42522193-20eb-4939-882b-c6cdb5689f64", "sentences": [["As", "explained", "in", "the", "main", "paper", ",", "we", "use", "Adam", "model", "introduced", "in", "-LSB-", "22", "-RSB-", "for", "total", "body", "motion", "capture", "."], ["The", "model", "parameters", "\\", "-LRB-", "\\Psi", "\\", "-RRB-", "include", "the", "shape", "parameters", "\\", "-LRB-", "\\phi", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "K_\\phi", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "K_\\phi", "=30\\", "-RRB-", "is", "the", "dimension", "of", "shape", "deformation", "space", ",", "the", "pose", "parameters", "\\", "-LRB-", "\\theta", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "J", "\\times", "3", "-RCB-", "\\", "-RRB-", "where", "the", "\\", "-LRB-", "J=62\\", "-RRB-", "is", "the", "number", "of", "joints", "in", "the", "modelThe", "model", "has", "22", "body", "joints", "and", "20", "joints", "for", "each", "hand.", ",", "the", "global", "translation", "parameters", "\\", "-LRB-", "t", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^3\\", "-RRB-", ",", "and", "the", "facial", "expression", "parameter", "\\", "-LRB-", "\\sigma", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "K_\\sigma", "-RCB-", "\\", "-RRB-", "where", "\\", "-LRB-", "K_\\sigma", "=200\\", "-RRB-", "is", "the", "number", "of", "facial", "expression", "bases", "."]], "ner": [[[9, 10, "a"]], [[32, 33, "p"], [64, 65, "p"], [109, 111, "p"], [125, 127, "p"]]], "relations": [[], []], "predicted_ner": [[[9, 10, "a"]], [[98, 98, "v"], [102, 102, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1812.10235-944594a2-6cea-429c-93cb-55063d5dc8a9", "sentences": [["The", "layer", "sizes", "for", "both", "the", "LSTM", "and", "BLSTM", "networks", "in", "our", "model", "are", "chosen", "as", "200", "."], ["Based", "on", "the", "size", "of", "our", "dataset", ",", "the", "number", "of", "hidden", "layers", "is", "chosen", "as", "2", "and", "Adam", "optimization", "is", "used", "as", "in", "-LSB-", "8", "-RSB-", "."], ["The", "size", "of", "word", "embedding", "is", "300", ",", "which", "are", "initialized", "randomly", "at", "the", "beginning", "of", "experiment", "."]], "ner": [[[6, 6, "a"], [1, 2, "p"], [16, 16, "v"], [8, 8, "a"], [1, 2, "p"], [16, 16, "v"]], [[36, 37, "a"], [21, 21, "p"]], [[49, 50, "a"], [47, 47, "p"], [52, 52, "v"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "a"], [8, 9, "a"], [12, 12, "a"], [16, 16, "v"]], [[24, 24, "a"], [34, 34, "v"]], [[52, 52, "v"]]], "predicted_relations": [[[1, 2, 6, 6, "USED-FOR"], [1, 2, 8, 8, "USED-FOR"], [1, 2, 6, 6, "USED-FOR"], [1, 2, 8, 8, "USED-FOR"]], [], [[47, 47, 49, 50, "USED-FOR"], [52, 52, 47, 47, "USED-FOR"]]]}
{"doc_key": "1812.10234-7ca5c2ac-fcb2-45b0-b51c-aa31520fe21a", "sentences": [["Slot", "Filling", ":", "For", "slot", "filling", "task", ",", "the", "pre-trained", "DNN", "model", "\\", "-LRB-", "f_", "-LCB-", "dnn", "-RCB-", "\\", "-RRB-", "has", "the", "same", "set-up", "as", "in", "-LSB-", "11", "-RSB-", ",", "by", "using", "an", "attention", "based", "bi-directional", "LSTM", "."], ["The", "number", "of", "states", "in", "LSTM", "cell", "is", "128", "."], ["The", "randomly", "initialized", "word", "embedding", "size", "is", "also", "128.The", "batch", "size", "is", "16", "and", "the", "dropout", "rate", "for", "non-recurrent", "connection", "is", "0.5", "."]], "ner": [[[10, 11, "a"]], [[39, 44, "p"], [46, 46, "v"], [46, 46, "v"]], [[56, 56, "v"], [51, 53, "p"], [56, 56, "v"], [57, 58, "p"], [60, 60, "v"], [63, 67, "p"], [69, 69, "v"]]], "relations": [[], [], []], "predicted_ner": [[[10, 11, "a"], [35, 36, "a"]], [[43, 44, "a"], [46, 46, "v"]], [[57, 58, "p"], [60, 60, "v"], [63, 64, "p"], [69, 69, "v"]]], "predicted_relations": [[], [[46, 46, 39, 44, "USED-FOR"], [46, 46, 39, 44, "USED-FOR"]], []]}
{"doc_key": "1812.10234-d1a70252-8c3a-4485-bdb4-bd96aac6d00c", "sentences": [["The", "DAT", "model", "\\", "-LRB-", "f_", "-LCB-", "dat", "-RCB-", "\\", "-RRB-", "used", "for", "Slot", "fill", "and", "NER", "tasks", "are", "almost", "the", "same", "except", "the", "batch", "size", "."], ["The", "network", "structure", "chosen", "to", "estimate", "the", "action-value", "function", "\\", "-LRB-", "Q\\", "-RRB-", "is", "an", "LSTM", "structure", "with", "100", "states", "."], ["The", "averaged", "word", "vector", "in", "a", "reinforcement", "learning", "state", "is", "chosen", "as", "a", "trigram", ",", "i.e", "."], ["n=3", "."], ["The", "discount", "factor", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "is", "selected", "as", "0.5", ",", "0.7", "and", "0.9", "for", "difference", "experiments", "."], ["The", "minibatch", "size", "is", "\\", "-LRB-", "K=16\\", "-RRB-", "for", "slot", "filling", "task", "and", "\\", "-LRB-", "K=10\\", "-RRB-", "for", "NER", "in", "order", "to", "keep", "the", "same", "training", "batch", "size", "as", "\\", "-LRB-", "f_", "-LCB-", "dnn", "-RCB-", "\\", "-RRB-", "in", "different", "tasks", ",", "and", "the", "replay", "memory", "size", "is", "pre-defined", "as", "\\", "-LRB-", "\\mu", "=5,000\\", "-RRB-", "."], ["The", "thresholds", "for", "both", "experiment", "are", "set", "as", "\\", "-LRB-", "T_r=0.95\\", "-RRB-", "."]], "ner": [[[1, 2, "a"], [24, 25, "p"], [16, 16, "c"]], [[42, 43, "a"], [46, 46, "p"], [45, 45, "v"]], [[61, 61, "p"]], [[65, 65, "v"]], [[68, 69, "a"], [72, 72, "p"], [82, 82, "v"], [84, 84, "v"], [86, 86, "v"]], [[117, 118, "p"], [97, 97, "v"], [100, 102, "c"], [106, 106, "v"], [109, 109, "c"], [134, 136, "a"], [142, 142, "p"]], [[147, 147, "a"], [156, 156, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"]], [[42, 43, "a"], [45, 45, "v"]], [], [], [[68, 69, "p"], [72, 72, "p"], [82, 82, "v"], [84, 84, "v"], [86, 86, "v"], [87, 89, "c"]], [[92, 93, "p"], [97, 97, "v"], [106, 106, "v"], [122, 125, "a"], [143, 143, "v"]], [[156, 156, "v"]]], "predicted_relations": [[[24, 25, 1, 2, "USED-FOR"]], [[46, 46, 42, 43, "USED-FOR"], [45, 45, 46, 46, "USED-FOR"]], [], [], [], [[100, 102, 97, 97, "USED-FOR"], [100, 102, 106, 106, "USED-FOR"], [109, 109, 97, 97, "USED-FOR"], [109, 109, 106, 106, "USED-FOR"], [142, 142, 134, 136, "USED-FOR"]], []]}
{"doc_key": "1806.01523-ff36f9da-786e-4fba-ac6b-d9c50eac2e5a", "sentences": [["For", "training", "configurations", ",", "we", "trained", "for", "10", "epochs", "using", "AdaDelta", "-LSB-", "26", "-RSB-", "with", "\\", "-LRB-", "\\rho", "=0.95\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=1.\\mathrm", "-LCB-", "e", "-RCB-", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."], ["We", "also", "employed", "early", "stopping", "with", "patience", "set", "to", "3", "."], ["We", "split", "our", "data", "using", "80", "%", "training", ",", "10", "%", "validation", ",", "and", "10", "%", "test", "for", "the", "fully", "supervised", "scenario", "."], ["For", "the", "active", "learning", "scenario", ",", "we", "further", "split", "the", "training", "data", "into", "labeled", "and", "unlabeled", "data", "."], ["We", "used", "two", "kinds", "of", "split", ",", "50:50", "and", "85:15", "."], ["For", "the", "50:50", "scenario", ",", "we", "queried", "100", "sentences", "for", "each", "epoch", "."], ["For", "the", "85:15", "scenario", ",", "we", "used", "a", "smaller", "query", "of", "10", "sentences", "in", "an", "epoch", "to", "keep", "the", "number", "of", "queries", "less", "than", "the", "number", "of", "available", "fully", "supervised", "training", "data", "in", "10", "epochs", "."], ["This", "number", "of", "queried", "sentences", "was", "obtained", "by", "tuning", "on", "the", "validation", "set", "."]], "ner": [[[10, 10, "a"], [17, 17, "p"], [18, 18, "v"], [23, 23, "p"]], [], [], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"], [8, 8, "p"], [10, 10, "a"]], [[37, 38, "a"], [43, 43, "v"]], [[50, 51, "v"], [54, 55, "v"], [59, 60, "v"]], [], [[88, 88, "v"], [93, 93, "v"], [95, 95, "v"]], [[99, 99, "v"], [104, 104, "v"]], [[112, 112, "v"], [121, 121, "v"], [143, 143, "v"]], []], "predicted_relations": [[[17, 17, 10, 10, "USED-FOR"], [18, 18, 17, 17, "USED-FOR"], [18, 18, 23, 23, "USED-FOR"], [23, 23, 10, 10, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "1801.00693-09f55c7c-bf2c-49ef-8752-17cc43b2cd1c", "sentences": [["For", "both", "the", "baseline", "model", "and", "our", "adversarial", "auto-encoder", "model", ",", "we", "used", "\\", "-LRB-", "-LRB-", "a", ",", "b", "-RRB-", "=", "-LRB-", "9,1", "-RRB-", "\\", "-RRB-", "for", "the", "weighted", "classification", "loss", "."], ["The", "CNN", "was", "trained", "using", "an", "RMSProp", "Optimizer", "with", "a", "momentum", "of", "0", "and", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "encoder", "and", "decoder", "of", "the", "ssDAAE", "were", "trained", "with", "the", "same", "optimizer", "with", "same", "learning", "are", "and", "momentum", "as", "the", "CNN", "."], ["We", "found", "setting", "coefficients", "\\", "-LRB-", "-LRB-", "\\alpha", ",", "\\beta", ",", "\\eta", "-RRB-", "=", "-LRB-", "0.1", ",", "1", ",", "0.1", "-RRB-", "\\", "-RRB-", "to", "work", "well", "."], ["When", "training", "the", "discriminator", "training", ",", "the", "same", "optimizer", "and", "learning", "rate", "were", "used", ",", "but", "the", "momentum", "was", "set", "to", "\\", "-LRB-", "0.2\\", "-RRB-", "."]], "ner": [[[28, 30, "a"], [16, 16, "p"], [22, 22, "v"], [18, 18, "p"], [22, 22, "v"], [22, 22, "v"]], [[41, 41, "p"], [46, 46, "p"], [38, 39, "a"], [42, 42, "p"], [44, 44, "v"], [47, 48, "p"]], [[77, 77, "p"], [65, 65, "a"]], [[97, 97, "v"], [99, 99, "v"], [101, 101, "v"], [97, 97, "v"], [101, 101, "v"], [89, 89, "p"], [97, 97, "v"], [101, 101, "v"], [91, 91, "p"], [97, 97, "v"], [99, 99, "v"], [101, 101, "v"], [93, 93, "p"], [97, 97, "v"], [101, 101, "v"]], [[126, 126, "p"], [132, 132, "v"], [132, 132, "v"], [112, 113, "c"], [119, 120, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 9, "a"], [22, 22, "v"], [28, 30, "a"]], [[33, 33, "a"], [38, 38, "a"], [44, 44, "v"], [47, 48, "p"], [52, 55, "v"]], [[65, 65, "a"], [74, 75, "p"], [80, 80, "a"]], [[89, 89, "p"], [91, 91, "p"], [97, 97, "v"], [99, 101, "v"]], [[119, 120, "p"], [132, 132, "v"]]], "predicted_relations": [[[22, 22, 16, 16, "USED-FOR"], [22, 22, 18, 18, "USED-FOR"], [22, 22, 16, 16, "USED-FOR"], [22, 22, 18, 18, "USED-FOR"], [22, 22, 16, 16, "USED-FOR"], [22, 22, 18, 18, "USED-FOR"]], [[41, 41, 38, 39, "USED-FOR"], [46, 46, 38, 39, "USED-FOR"], [42, 42, 38, 39, "USED-FOR"], [44, 44, 46, 46, "USED-FOR"], [44, 44, 42, 42, "USED-FOR"], [47, 48, 38, 39, "USED-FOR"]], [], [[97, 97, 93, 93, "USED-FOR"], [99, 99, 93, 93, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"], [99, 99, 93, 93, "USED-FOR"], [97, 97, 93, 93, "USED-FOR"]], [[132, 132, 126, 126, "USED-FOR"], [132, 132, 126, 126, "USED-FOR"], [112, 113, 132, 132, "USED-FOR"], [112, 113, 132, 132, "USED-FOR"]]]}
{"doc_key": "1809.00582-13ac24ca-3251-4648-9968-62956863988b", "sentences": [["We", "validated", "model", "hyperparameters", "on", "the", "development", "set", "."], ["We", "did", "not", "tune", "the", "dimensions", "of", "word", "embeddings", "and", "LSTM", "hidden", "layers", ";", "we", "used", "the", "same", "value", "of", "600", "reported", "in", "Wiseman", "et", "al", ".", "wiseman2017challenges", "."], ["We", "used", "one-layer", "pointer", "networks", "during", "content", "planning", ",", "and", "two-layer", "LSTMs", "during", "text", "generation", "."], ["Input", "feeding", "-LRB-", "Luong", "et", "al", "."], ["-LSB-", "26", "-RSB-", "-RRB-", "was", "employed", "for", "the", "text", "decoder", "."], ["We", "applied", "dropout", "-LRB-", "Zaremba", "et", "al", "."], ["-LSB-", "44", "-RSB-", "-RRB-", "at", "a", "rate", "of", "\\", "-LRB-", "0.3\\", "-RRB-", "."], ["Models", "were", "trained", "for", "25", "epochs", "with", "the", "Adagrad", "optimizer", "-LRB-", "Duchi", "et", "al", "."], ["-LSB-", "10", "-RSB-", "-RRB-", ";", "the", "initial", "learning", "rate", "was", "\\", "-LRB-", "0.15\\", "-RRB-", ",", "learning", "rate", "decay", "was", "selected", "from", "\\", "-LRB-", "\\lbrace", "0.5", ",", "0.97\\rbrace", "\\", "-RRB-", ",", "and", "batch", "size", "was", "5", "."], ["For", "text", "decoding", ",", "we", "made", "use", "of", "BPTT", "-LSB-", "31", "-RSB-", "and", "set", "the", "truncation", "size", "to", "100", "."], ["We", "set", "the", "beam", "size", "to", "5", "during", "inference", "."], ["All", "models", "are", "implemented", "in", "OpenNMT-py", "-LSB-", "18", "-RSB-", "."]], "ner": [[], [], [], [], [], [[74, 74, "a"]], [[86, 86, "p"], [90, 90, "v"]], [[101, 102, "a"]], [[114, 116, "p"], [120, 120, "v"], [123, 125, "p"], [132, 132, "v"], [134, 134, "v"], [116, 116, "p"], [124, 124, "p"]], [[152, 152, "a"], [159, 160, "p"], [162, 162, "v"]], [[167, 168, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[19, 19, "a"], [29, 29, "v"]], [[41, 42, "a"], [49, 49, "a"]], [], [], [[74, 74, "a"]], [[90, 90, "v"]], [[97, 97, "v"], [98, 98, "p"], [101, 101, "a"]], [[115, 116, "p"], [120, 120, "v"], [123, 125, "p"], [132, 132, "v"], [134, 134, "v"], [139, 140, "p"], [142, 142, "v"]], [[152, 152, "a"], [159, 160, "p"], [162, 162, "v"]], [[167, 168, "p"], [170, 170, "v"]], [[179, 179, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [[120, 120, 123, 125, "USED-FOR"]], [[159, 160, 152, 152, "USED-FOR"], [162, 162, 159, 160, "USED-FOR"]], [], []]}
{"doc_key": "1810.03444-85deea97-4377-40e6-85ff-4e7763537747", "sentences": [["We", "preserve", "most", "of", "the", "training", "settings", "from", "-LSB-", "15", "-RSB-", "to", "enable", "a", "fair", "comparison", "with", "the", "original", "Transformer", "."], ["Specifically", ",", "we", "use", "the", "Adam", "optimizer", "-LSB-", "7", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.98\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\epsilon", "=10^", "-LCB-", "-9", "-RCB-", "\\", "-RRB-", "."], ["We", "follow", "a", "similar", "learning", "rate", "schedule", "with", "\\", "-LRB-", "warmup\\_steps\\", "-RRB-", "of", "16000", ":", "\\", "-LRB-", "LearningRate", "=", "2", "*", "d^", "-LCB-", "-0.5", "-RCB-", "*", "\\min", "-LRB-", "step\\_num^", "-LCB-", "-0.5", "-RCB-", ",", "step\\_num", "*", "warmup\\_steps^", "-LCB-", "-1.5", "-RCB-", "-RRB-", "\\", "-RRB-", "."]], "ner": [[], [[26, 27, "a"], [35, 35, "v"], [41, 41, "v"], [47, 47, "p"]], [[68, 68, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [[26, 26, "a"]], [[68, 68, "v"], [72, 72, "p"]]], "predicted_relations": [[], [[41, 41, 47, 47, "USED-FOR"], [47, 47, 26, 27, "USED-FOR"]], []]}
{"doc_key": "1810.03444-cb32eeba-2ef6-46d2-9fed-6ccae9ac3652", "sentences": [["We", "trained", "our", "models", "and", "the", "baseline", "on", "a", "single", "GPU", "for", "500,000", "steps.We", "were", "unable", "to", "replicate", "state-of-the-art", "results", "in", "-LSB-", "15", "-RSB-", "because", "of", "limited", "GPUs", "."], ["Hence", ",", "we", "conducted", "all", "the", "experiments", "including", "Transformer", "base", "in", "an", "identical", "setup", "for", "fair", "comparisons", "."], ["The", "batches", "were", "formed", "by", "sentence", "pairs", "containing", "approximately", "4096", "source", "and", "4096", "target", "tokens", "."], ["Similar", "to", "-LSB-", "15", "-RSB-", ",", "we", "also", "applied", "residual", "dropout", "with", "0.1", "probability", "and", "label", "smoothing", "with", "\\", "-LRB-", "\\epsilon", "_", "-LCB-", "ls", "-RCB-", "=", "0.1\\", "-RRB-", "."], ["Our", "models", "are", "implemented", "in", "the", "tensor2tensorhttps", ":", "//github.com/tensorflow/tensor2tensor", "library", "-LSB-", "16", "-RSB-", ",", "on", "top", "of", "the", "original", "Transformer", "codebase", "."], ["We", "trained", "our", "models", "on", "the", "standard", "WMT'16", "English-German", "dataset", "constaining", "about", "4.5", "million", "sentence", "pairs", ",", "using", "WMT", "newstest2013", "as", "our", "development", "set", "and", "newstest2014", "as", "our", "test", "set", "."], ["We", "used", "byte-pair", "encoding", "-LSB-", "12", "-RSB-", "with", "combined", "source", "and", "target", "vocabulary", "of", "37,000", "sub-words", "for", "English-German", "."], ["We", "took", "the", "average", "of", "the", "last", "5", "checkpoints", "-LRB-", "saved", "at", "10,000-iteration", "intervals", "-RRB-", "for", "evaluation", ",", "and", "used", "a", "beam", "search", "size", "of", "5", "and", "length", "penalty", "of", "0.6", "-LSB-", "19", "-RSB-", "."]], "ner": [[], [[37, 38, "a"]], [], [[75, 75, "v"], [89, 89, "v"], [72, 73, "a"], [78, 79, "a"]], [], [], [[147, 148, "a"]], [[185, 186, "a"], [191, 192, "p"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [12, 12, "v"]], [[37, 38, "a"]], [[56, 56, "v"], [59, 59, "v"]], [[72, 73, "a"], [75, 75, "v"], [78, 79, "a"], [89, 89, "v"]], [[111, 112, "a"]], [[117, 117, "a"], [126, 126, "v"], [139, 139, "a"]], [[147, 148, "a"], [159, 159, "v"]], [[171, 171, "v"], [185, 187, "p"], [189, 189, "v"], [194, 194, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [[191, 192, 185, 186, "USED-FOR"]]]}
{"doc_key": "1808.09935-38b06697-f37a-4245-ba9f-db05b8d5e4b7", "sentences": [["The", "training", "dataset", "class", "distribution", "is", "heavily", "skewed", "with", "about", "92", "%", "samples", "belonging", "to", "class", "0", "."], ["Hence", ",", "we", "use", "weighted-binary-cross-entropy", "as", "our", "loss", "function", "to", "penalize", "the", "classifier", "more", "heavily", "on", "mis-classification", "of", "a", "segment", "boundary", "."], ["The", "loss", "function", "is", "defined", "as", "\\", "-LRB-", "loss", "=", "-\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "N", "-RCB-", "\\sum", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "N", "-RCB-", "-LRB-", "t", "\\log", "-LRB-", "o", "-RRB-", "+", "\\frac", "-LCB-", "f_1", "-RCB-", "-LCB-", "f_0", "-RCB-", "-LRB-", "1", "-", "t", "-RRB-", "\\log", "-LRB-", "1", "-", "o", "-RRB-", "-RRB-", "-RRB-", "\\", "-RRB-", "where", "\\", "-LRB-", "t\\", "-RRB-", "and", "\\", "-LRB-", "o\\", "-RRB-", "are", "the", "target", "and", "the", "predicted", "outputs", "respectively", "."], ["\\", "-LRB-", "f_0\\", "-RRB-", "and", "\\", "-LRB-", "f_1\\", "-RRB-", "are", "the", "frequencies", "of", "class", "0", "and", "class", "1", "respectively", "."]], "ner": [[], [[22, 22, "a"]], [[67, 67, "p"], [83, 83, "p"], [98, 98, "p"], [70, 70, "p"], [89, 89, "p"], [103, 103, "p"], [78, 78, "p"], [75, 75, "p"]], [[116, 116, "p"], [121, 121, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[10, 11, "v"]], [[22, 22, "a"]], [[67, 67, "p"], [83, 83, "p"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1808.09935-a3d9b18b-2c11-415e-bd6c-b95a91205370", "sentences": [["We", "use", "`", "AdaDelta", "'", "-LSB-", "32", "-RSB-", "as", "the", "optimizer", "and", "use", "dropouts", "of", "0.2", "\u2013", "0.3", "for", "input", "and", "recurrent", "gates", "in", "the", "recurrent", "layers", "."], ["We", "also", "use", "dropouts", "of", "0.3", "after", "the", "dense", "fully", "connected", "layers", "to", "prevent", "over", "fitting", "on", "the", "training", "dataset", "."], ["We", "use", "filters", "of", "sizes", "\\", "-LRB-", "\\lbrace", "2", ",", "3", ",", "4", ",", "5\\rbrace", "\\", "-RRB-", "with", "200", "filters", "for", "each", "of", "the", "sizes", "."], ["The", "recurrent", "layers", "have", "600", "neurons", "."]], "ner": [[[3, 3, "a"], [13, 13, "a"], [17, 17, "v"], [25, 26, "a"]], [[31, 31, "a"], [33, 33, "v"]], [[59, 59, "v"], [51, 51, "a"], [68, 68, "a"], [61, 61, "v"], [63, 63, "v"]], [[79, 79, "v"], [76, 77, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "a"], [15, 15, "v"], [17, 17, "v"]], [[33, 33, "v"]], [[67, 67, "v"]], [[79, 79, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "1811.03087-71245d6c-34cb-4530-8e55-a0a076846d98", "sentences": [["Discussion", "."], ["We", "directly", "note", "that", ":", "-LRB-", "i", "-RRB-", "\\", "-LRB-", "\\overline", "-LCB-", "m", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\underline", "-LCB-", "m", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "\\", "-RRB-", "are", "random", "variables", "which", "depend", "on", "\\", "-LRB-", "-LCB-", "\\Theta", "^", "-LCB-", "k-1", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "while", "\\", "-LRB-", "\\underline", "-LCB-", "s", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "\\", "-RRB-", "is", "a", "random", "variable", "which", "depends", "on", "\\", "-LRB-", "-LCB-", "\\Theta", "^k", "-RCB-", "\\", "-RRB-", ";", "-LRB-", "ii", "-RRB-", "\\", "-LRB-", "\\underline", "-LCB-", "m", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "<", "0\\", "-RRB-", "by", "log-concavity", ";", "-LRB-", "iii", "-RRB-", "\\", "-LRB-", "\\underline", "-LCB-", "s", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "\\", "-RRB-", "is", "centered", "with", "\\", "-LRB-", "\\mathbb", "-LCB-", "E", "-RCB-", "_", "-LCB-", "-LCB-", "\\theta", "^k", "-RCB-", "-RCB-", "-LSB-", "-LCB-", "\\hspace", "-LCB-", "0.5pt", "-RCB-", "-RCB-", "\\underline", "-LCB-", "s", "-RCB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[], []], "predicted_relations": [[], []]}
{"doc_key": "1811.03087-6335389b-1933-4706-b3bb-e4d9e30e08b6", "sentences": [["We", "further", "note", "that", "each", "channel", "provides", "an", "independent", "contribution", "to", "\\", "-LRB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "=", "\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "N_k", "-RCB-", "\\sum", "_", "-LCB-", "-LCB-", "\\textnormal", "-LCB-", "c", "-RCB-", "-RCB-", "-RCB-", "\\nu", "_", "-LCB-", "2", ",", "-LCB-", "\\textnormal", "-LCB-", "c", "-RCB-", "-RCB-", "-RCB-", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "implying", "for", "large", "\\", "-LRB-", "N_k\\", "-RRB-", "that", "\\", "-LRB-", "\\underline", "-LCB-", "\\delta", "-RCB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "\\", "-RRB-", "has", "low", "expected", "deviation", "to", "1", "and", "that", "\\", "-LRB-", "|\\log", "\\underline", "-LCB-", "\\delta", "-RCB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "|", "\\ll", "1\\", "-RRB-", ",", "\\", "-LRB-", "|\\underline", "-LCB-", "m", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "|", "\\ll", "1\\", "-RRB-", ",", "\\", "-LRB-", "|\\underline", "-LCB-", "s", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "|", "\\ll", "1\\", "-RRB-", "with", "high", "probability", "."], ["The", "term", "\\", "-LRB-", "\\overline", "-LCB-", "m", "-RCB-", "-LSB-", "\\nu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "k", "-RCB-", "-RRB-", "-RSB-", "\\", "-RRB-", "is", "thus", "dominating", "as", "long", "as", "it", "is", "not", "vanishing", "."], ["The", "same", "reasoning", "applies", "to", "other", "positive", "moments", ",", "e.g", "."], ["\\", "-LRB-", "\\mu", "_2", "-LRB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RRB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\mu", "_2", "-LRB-", "-LCB-", "\\mathop", "-LCB-", "-RCB-", "\\", "!", "\\mathrm", "-LCB-", "d", "-RCB-", "-LCB-", "\\mathbf", "-LCB-", "x", "-RCB-", "-RCB-", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RRB-", "\\", "-RRB-", "."]], "ner": [[], [], [], []], "relations": [[], [], [], []], "predicted_ner": [[[107, 107, "v"]], [], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "1811.03087-d66d07eb-ec9c-4ff1-a234-83b36209d9a8", "sentences": [["We", "introduce", "the", "notation", "\\", "-LRB-", "a\\simeq", "b\\", "-RRB-", "when", "\\", "-LRB-", "a", "-LRB-", "1+\\epsilon", "_a", "-RRB-", "=", "b", "-LRB-", "1+\\epsilon", "_b", "-RRB-", "\\", "-RRB-", "with", "\\", "-LRB-", "|\\epsilon", "_a|\\ll", "1\\", "-RRB-", ",", "\\", "-LRB-", "|\\epsilon", "_b|", "\\ll", "1\\", "-RRB-", "with", "high", "probability", "."], ["And", "the", "notation", "\\", "-LRB-", "a\\lesssim", "b\\", "-RRB-", "when", "\\", "-LRB-", "a", "-LRB-", "1+\\epsilon", "_a", "-RRB-", "\\le", "b", "-LRB-", "1+\\epsilon", "_b", "-RRB-", "\\", "-RRB-", "with", "\\", "-LRB-", "|\\epsilon", "_a|\\ll", "1\\", "-RRB-", ",", "\\", "-LRB-", "|\\epsilon", "_b|", "\\ll", "1\\", "-RRB-", "with", "high", "probability", "."], ["From", "now", "on", ",", "we", "assume", "that", "the", "width", "is", "large", ",", "implying", "\\", "-LRB-", "\\delta", "-LCB-", "\\chi", "-RCB-", "^", "-LCB-", "l", "-RCB-", "=", "\\exp", "\\big", "-LRB-", "\\overline", "-LCB-", "m", "-RCB-", "-LSB-", "-LCB-", "\\chi", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RSB-", "+", "\\underline", "-LCB-", "m", "-RCB-", "-LSB-", "-LCB-", "\\chi", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RSB-", "+", "\\underline", "-LCB-", "s", "-RCB-", "-LSB-", "-LCB-", "\\chi", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RSB-", "\\big", "-RRB-", "\\simeq", "\\exp", "\\big", "-LRB-", "\\overline", "-LCB-", "m", "-RCB-", "-LSB-", "-LCB-", "\\chi", "-RCB-", "^", "-LCB-", "l", "-RCB-", "-RSB-", "\\big", "-RRB-", ".\\", "-RRB-"]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "1802.04765-5cdbcf5b-05f5-43a1-b834-a965b4394b37", "sentences": [["The", "policy", "network", "models", "a", "Gaussian", "distribution", "by", "outputting", "a", "state", "dependant", "mean", "."], ["We", "use", "a", "state", "independent", "standard", "deviation", "that", "normalized", "with", "respect", "to", "the", "action", "space", "and", "multiplied", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "."], ["We", "also", "use", "a", "version", "of", "epsilon", "greedy", "exploration", "where", "with", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "probability", "an", "exploration", "action", "is", "generated", "."], ["For", "all", "of", "our", "experiments", "we", "linearly", "anneal", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "from", "\\", "-LRB-", "0.2\\", "-RRB-", "to", "\\", "-LRB-", "0.1\\", "-RRB-", "in", "\\", "-LRB-", "100,000\\", "-RRB-", "iterations", "and", "leave", "it", "from", "that", "point", "on", "."], ["Each", "training", "simulation", "takes", "approximately", "5", "hours", "across", "8", "threads", "."], ["For", "network", "training", "we", "use", "SGD", "with", "momentum", "."], ["During", "the", "distillation", "step", "we", "use", "gradually", "anneal", "the", "probability", "of", "selecting", "an", "expert", "action", "from", "1", "to", "0", "over", "\\", "-LRB-", "10,000\\", "-RRB-", "iterations", "."]], "ner": [[[5, 6, "a"]], [[34, 34, "v"], [34, 34, "v"]], [], [[81, 81, "v"], [76, 76, "v"], [81, 81, "v"]], [], [[113, 115, "a"]], [[133, 133, "v"], [135, 135, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"]], [[34, 34, "v"]], [[43, 43, "a"]], [[76, 76, "v"], [81, 81, "v"], [86, 86, "v"]], [[102, 102, "v"], [105, 105, "v"]], [[113, 113, "a"], [115, 115, "a"]], [[133, 133, "v"], [135, 135, "v"], [139, 139, "v"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1805.09355-1e651155-18de-4fa1-8faf-47b6c761043e", "sentences": [["As", "input", "to", "the", "SDSN", "network", "we", "use", "300-dimensional", "dependency-based", "word", "embeddings", "by", "Levy2014a", "."], ["Layers", "\\", "-LRB-", "m_1\\", "-RRB-", "and", "\\", "-LRB-", "m_2\\", "-RRB-", "also", "have", "size", "300", "and", "layer", "\\", "-LRB-", "h\\", "-RRB-", "has", "size", "100", "."], ["For", "regularisation", ",", "we", "apply", "dropout", "to", "the", "embeddings", "with", "\\", "-LRB-", "p=0.5\\", "-RRB-", "."], ["The", "margin", "\\", "-LRB-", "R\\", "-RRB-", "is", "set", "to", "1", "for", "the", "supervised", "pre-training", "stage", "."], ["The", "model", "is", "optimised", "using", "AdaDelta", "-LSB-", "28", "-RSB-", "with", "learning", "rate", "\\", "-LRB-", "1.0\\", "-RRB-", "."], ["In", "order", "to", "control", "for", "random", "noise", ",", "we", "run", "each", "experiment", "with", "10", "different", "random", "seeds", "and", "average", "the", "results", "."], ["Our", "code", "and", "detailed", "configuration", "files", "will", "be", "made", "available", "online.http", ":", "//www.marekrei.com/projects/sdsn"]], "ner": [[[9, 11, "a"]], [], [[51, 51, "p"], [51, 51, "v"], [44, 44, "a"]], [], [[75, 75, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[4, 5, "a"], [8, 8, "v"]], [[23, 23, "v"], [28, 28, "v"], [37, 37, "v"]], [[44, 44, "a"], [51, 51, "v"]], [[63, 63, "v"]], [[75, 75, "a"], [80, 81, "p"], [84, 84, "v"]], [[100, 100, "v"]], []], "predicted_relations": [[], [], [[51, 51, 51, 51, "USED-FOR"], [51, 51, 51, 51, "USED-FOR"]], [], [], [], []]}
{"doc_key": "1811.08674-0a610f20-7fac-4280-8f4a-0bd412ec05ca", "sentences": [["Based", "on", "the", "pre-training", "dataset", ",", "we", "designed", "an", "architecture", "for", "the", "GNN", "model", "comprising", "an", "encoder", "with", "a", "receptive", "field", "of", "2", "as", "described", "in", "Section", "REF", ",", "obtained", "from", "the", "range", "\\", "-LRB-", "-LSB-", "1", ",", "\\dots", ",10", "-RSB-", "\\", "-RRB-", "."], ["Validation", "accuracy", "and", "validation", "loss", "on", "the", "pre-training", "dataset", "used", "to", "obtain", "the", "optimal", "number", "of", "GNN", "layers", "is", "depicted", "in", "Figure", "REF", "."], ["Each", "of", "the", "MLPs", ",", "\\", "-LRB-", "g_", "-LCB-", "\\dots", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", ",", "used", "in", "the", "encoder", "in", "Equations", "-LRB-", "REF", "-RRB-", "\u2013", "-LRB-", "-RRB-", "has", "two", "hidden", "layers", "chosen", "from", "the", "set", "\\", "-LRB-", "\\lbrace", "1,2,3,4\\rbrace", "\\", "-RRB-", "and", "the", "number", "of", "channels", "per", "layer", "parameter", "\\", "-LRB-", "E=8\\", "-RRB-", "chosen", "from", "\\", "-LRB-", "\\lbrace", "4,8,16", ",", "\\dots", ",256\\rbrace", "\\", "-RRB-", "."], ["A", "dropout", "rate", "of", "\\", "-LRB-", "0.5\\", "-RRB-", "was", "used", "between", "each", "layer", "in", "the", "MLPs", ",", "chosen", "from", "the", "set", "\\", "-LRB-", "\\lbrace", "0", ",", "0.1", ",", "\\dots", ",", "0.9\\rbrace", "\\", "-RRB-", "."], ["The", "number", "of", "training", "epochs", "for", "the", "GNN", "model", "was", "set", "to", "500", "."], ["Batch", "size", "of", "12", "was", "used", "during", "training", "."], ["Note", "that", "the", "GNN", "model", "can", "handle", "entire", "graphs", "utilising", "efficient", "sparse", "matrix", "operations", "and", "we", "do", "not", "require", "to", "subsample", "the", "graph", "as", "in", "the", "case", "of", "MFN", "model", ",", "as", "described", "in", "Section", "REF", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[12, 13, "a"], [19, 20, "p"], [22, 22, "v"], [3, 4, "a"]], [[51, 52, "a"], [47, 48, "a"]], [[108, 108, "v"], [71, 71, "p"], [113, 117, "p"], [121, 121, "v"], [128, 128, "v"]], [[150, 150, "p"], [136, 137, "p"], [141, 141, "v"]], [[176, 177, "a"], [170, 173, "p"], [181, 181, "v"]], [[186, 186, "v"]], [[195, 196, "a"], [220, 221, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[12, 13, "a"], [22, 22, "v"]], [[60, 60, "a"]], [[98, 98, "v"], [121, 121, "v"]], [[136, 137, "p"], [141, 141, "v"]], [[176, 177, "a"], [181, 181, "v"]], [[183, 184, "p"], [186, 186, "v"]], [[195, 196, "a"], [220, 221, "a"]], []], "predicted_relations": [[[19, 20, 12, 13, "USED-FOR"], [19, 20, 3, 4, "USED-FOR"], [22, 22, 19, 20, "USED-FOR"]], [], [[121, 121, 113, 117, "USED-FOR"]], [[141, 141, 136, 137, "USED-FOR"]], [[170, 173, 176, 177, "USED-FOR"], [181, 181, 170, 173, "USED-FOR"]], [], [], []]}
{"doc_key": "1805.01676-050537b9-768a-451a-9abe-f732807be948", "sentences": [["We", "built", "our", "neural", "machine", "translation", "-LRB-", "NMT", "-RRB-", "system", "by", "using", "Nematus", "-LSB-", "17", "-RSB-", ",", "an", "open-source", "NMT", "toolkit", "which", "implements", "the", "encoder-decoder", "NMT", "architecture", "with", "attention", "mechanism", "."], ["Our", "system", "is", "based", "on", "the", "NMT", "system", "in", "-LSB-", "16", "-RSB-", "."], ["We", "built", "an", "ensemble", "model", "consisting", "of", "4", "independent", "models", ",", "which", "are", "the", "cross", "product", "of", "two", "different", "deep", "RNN", "architectures", ",", "i.e.", ",", "deep", "stacked", "RNN", "and", "deep", "transition", "RNN", ",", "and", "two", "different", "recurrent", "unit", "functions", ",", "i.e.", ",", "GRU", "and", "LSTM", "."]], "ner": [[[12, 12, "a"], [24, 29, "a"]], [], [[47, 48, "a"], [69, 71, "a"], [73, 75, "a"], [86, 86, "a"], [88, 88, "a"]]], "relations": [[], [], []], "predicted_ner": [[[3, 9, "a"], [12, 12, "a"]], [[32, 32, "a"], [37, 38, "a"]], [[51, 51, "v"], [61, 61, "v"], [64, 64, "a"], [71, 71, "a"], [75, 75, "a"], [78, 78, "v"], [86, 86, "a"], [88, 88, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1805.01676-7a8e9e9f-9690-4d49-bcce-6150ac323ec1", "sentences": [["Training", "for", "each", "individual", "model", "progresses", "by", "updating", "the", "model", "parameters", "at", "each", "mini-batch", "of", "40", "sentence", "pairs", "to", "minimize", "the", "negative", "log-likelihood", "loss", "function", "on", "the", "parallel", "training", "data", "."], ["We", "use", "the", "Adam", "algorithm", "-LSB-", "7", "-RSB-", "with", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["At", "each", "update", ",", "we", "clip", "the", "gradient", "norm", "to", "\\", "-LRB-", "1.0\\", "-RRB-", "."], ["We", "apply", "layer", "normalization", "-LSB-", "0", "-RSB-", "on", "the", "model", "parameters", "for", "faster", "convergence", "and", "tie", "the", "target-side", "embedding", "with", "the", "transpose", "of", "the", "output", "weight", "matrix", "-LSB-", "14", "-RSB-", "."], ["Model", "parameters", "are", "saved", "at", "every", "checkpoint", "of", "10,000", "update", "iterations", "."], ["At", "this", "stage", ",", "the", "negative", "log-likelihood", "loss", "function", "on", "the", "development", "set", "is", "checked", "."], ["Training", "stops", "when", "there", "has", "been", "no", "improvement", "over", "the", "lowest", "loss", "function", "value", "on", "the", "development", "set", "for", "10", "consecutive", "checkpoints", "."]], "ner": [[[21, 24, "a"]], [[34, 35, "a"], [40, 41, "p"], [45, 45, "v"]], [[60, 60, "v"]], [[65, 66, "a"], [80, 81, "a"], [87, 89, "p"]], [], [[111, 114, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[15, 15, "v"]], [[34, 35, "a"], [40, 41, "p"], [45, 45, "v"]], [[55, 56, "p"], [60, 60, "v"]], [[65, 66, "a"]], [[102, 102, "v"], [103, 104, "p"]], [], [[141, 141, "v"]]], "predicted_relations": [[], [[40, 41, 34, 35, "USED-FOR"]], [], [[87, 89, 80, 81, "USED-FOR"]], [], [], []]}
{"doc_key": "1811.07738-ffdd84b3-bb06-4479-91db-1b00cdb15db7", "sentences": [["The", "proposed", "architecture", "is", "implemented", "in", "PyTorch", "."], ["We", "use", "AdamW", "-LSB-", "27", "-RSB-", "as", "optimization", "method", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "0.001\\", "-RRB-", "."], ["A", "combined", "binary", "cross-entropy", "and", "Jaccard", "loss", "function", "\\", "-LRB-", "L_", "-LCB-", "JBCE", "-RCB-", "\\", "-RRB-", "with", "a", "weighting", "factor", "\\", "-LRB-", "w=0.3\\", "-RRB-", "as", "proposed", "in", "-LSB-", "20", "-RSB-", "is", "utilized", ":", "\\", "-LRB-", "L_", "-LCB-", "JBCE", "-RCB-", "=", "L_", "-LCB-", "BCE", "-RCB-", "+", "w", "*", "-LRB-", "1-J", "-RRB-", ",", "\\", "-RRB-"]], "ner": [[], [[10, 10, "a"], [19, 20, "p"], [24, 24, "v"]], [[32, 33, "a"], [45, 46, "p"], [49, 49, "v"]]], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "a"]], [[10, 10, "a"], [19, 20, "p"], [24, 24, "v"]], [[29, 30, "a"], [37, 40, "a"], [45, 46, "p"], [49, 49, "v"], [62, 65, "a"], [67, 70, "a"]]], "predicted_relations": [[], [[19, 20, 10, 10, "USED-FOR"]], [[45, 46, 32, 33, "USED-FOR"], [49, 49, 45, 46, "USED-FOR"]]]}
{"doc_key": "1811.07738-5a63c805-5376-4029-bdff-6b18d0fc4a31", "sentences": [["For", "the", "DRIVE", "dataset", "we", "adopt", "the", "training-test", "split", "as", "proposed", "by", "the", "authors", "of", "the", "dataset", "-LRB-", "20", "training", "and", "20", "test", "images", "-RRB-", "-LSB-", "42", "-RSB-", "."], ["For", "CHASE_DB1", "we", "follow", "the", "suggestion", "of", "-LSB-", "17", "-RSB-", ",", "where", "the", "first", "8", "images", "form", "the", "training", "set", "and", "the", "remaining", "20", "the", "test", "set", "."], ["This", "split", "is", "also", "used", "in", "-LSB-", "32", "-RSB-", "."]], "ner": [[[2, 3, "a"], [7, 8, "p"], [18, 23, "v"], [7, 8, "p"]], [[30, 30, "a"], [42, 55, "v"]], []], "relations": [[], [], []], "predicted_ner": [[[2, 3, "a"], [18, 18, "v"], [21, 21, "v"]], [[30, 30, "a"], [43, 43, "v"], [52, 52, "v"]], []], "predicted_relations": [[[7, 8, 2, 3, "USED-FOR"], [18, 23, 7, 8, "USED-FOR"], [18, 23, 7, 8, "USED-FOR"], [7, 8, 2, 3, "USED-FOR"]], [], []]}
{"doc_key": "1811.07738-54c7659a-e63c-4dad-b59b-8e9071d85b97", "sentences": [["For", "HRF", "we", "adopt", "the", "split", "as", "proposed", "by", "Orlando", "-LSB-", "32", "-RSB-", "and", "adapted", "in", "-LSB-", "44", "-RSB-", ",", "who", "introduced", "the", "only", "supervised", "methods", "that", "have", "so", "far", "been", "evaluated", "on", "this", "dataset", "."], ["The", "training", "set", "contains", "the", "first", "five", "images", "of", "each", "category", "-LRB-", "healthy", ",", "diabetic", "retinopathy", "and", "glaucoma", "-RRB-", ";", "the", "remaining", "30", "images", "define", "the", "test", "set", "."]], "ner": [[[5, 5, "a"], [24, 25, "a"]], [[37, 38, "a"], [62, 63, "a"]]], "relations": [[], []], "predicted_ner": [[[9, 9, "a"]], [[42, 42, "v"], [58, 58, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "1811.07738-cf90209b-da86-4a70-87ca-0ffd6c65a52d", "sentences": [["No", "other", "preprocessing", "is", "conducted", "and", "during", "training", ",", "a", "set", "of", "random", "augmentations", "are", "applied", ":", "rotations", ",", "horizontal", "and", "vertical", "flips", ",", "elastic", "distortions", "and", "changes", "in", "brightness", ",", "contrast", ",", "saturation", "and", "hue", "."], ["Image", "augmentations", "are", "commonly", "used", "in", "biomedical", "image", "analysis", "tasks", ",", "especially", "when", "working", "with", "small", "datasets", ",", "as", "they", "can", "improve", "accuracy", "and", "generalization", "-LSB-", "13", "-RSB-", "."], ["We", "limit", "the", "rotations", "to", "a", "range", "from", "\\", "-LRB-", "-15\\", "-RRB-", "to", "\\", "-LRB-", "+15\\", "-RRB-", "degrees", "."], ["Brightness", ",", "contrast", ",", "saturation", "and", "hue", "are", "changed", "by", "a", "small", "random", "factor", "in", "the", "range", "\\", "-LRB-", "\\mathbb", "-LCB-", "R", "-RCB-", "\\cap", "-LSB-", "1-c,1+c", "-RSB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "c\\", "-RRB-", "determines", "the", "freedom", "of", "change", "."], ["The", "following", "values", "are", "selected", ":", "\\", "-LRB-", "c_", "-LCB-", "brightness", "-RCB-", "=0.3\\", "-RRB-", ",", "\\", "-LRB-", "c_", "-LCB-", "contrast", "-RCB-", "=0.3\\", "-RRB-", ",", "\\", "-LRB-", "c_", "-LCB-", "saturation", "-RCB-", "=0.02\\", "-RRB-", "and", "\\", "-LRB-", "c_", "-LCB-", "hue", "-RCB-", "=0.02\\", "-RRB-", "."], ["Elastic", "transformations", "are", "governed", "by", "the", "grid", "size", "and", "the", "magnitude", ",", "for", "which", "we", "selected", "values", "of", "\\", "-LRB-", "8\\times", "8\\", "-RRB-", "and", "1", "respectively", "-LSB-", "9", "-RSB-", "."]], "ner": [[], [[37, 38, "a"]], [], [[85, 85, "p"], [110, 110, "v"], [110, 110, "v"], [85, 85, "a"], [110, 110, "p"], [110, 110, "p"], [118, 118, "p"], [110, 110, "p"], [110, 110, "p"], [118, 118, "p"], [110, 110, "p"], [110, 110, "p"], [118, 118, "p"], [110, 110, "p"], [110, 110, "p"], [118, 118, "p"]], [[138, 138, "v"], [147, 147, "v"], [138, 138, "v"], [147, 147, "v"], [156, 156, "v"], [165, 165, "v"], [156, 156, "v"], [165, 165, "v"]], [[192, 192, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[76, 76, "v"], [81, 81, "v"]], [], [[138, 138, "v"], [147, 147, "v"], [165, 165, "v"]], [[189, 189, "v"], [192, 192, "v"]]], "predicted_relations": [[], [], [], [[85, 85, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 118, 118, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 110, 110, "USED-FOR"], [110, 110, 85, 85, "USED-FOR"]], [], []]}
{"doc_key": "1811.07738-110b1671-491d-47dd-a01a-058b4fe239c2", "sentences": [["Since", "our", "datasets", "contain", "a", "very", "small", "number", "of", "training", "images", "we", "derive", "separate", "validation", "sets", "from", "the", "training", "sets", ",", "using", "the", "same", "random", "augmentations", "."], ["During", "training", ",", "the", "model", "with", "the", "highest", "dice", "score", "on", "the", "validation", "set", "is", "selected", "."], ["Training", "is", "stopped", "after", "300", "epochs", "."]], "ner": [[[2, 2, "a"], [9, 9, "a"], [18, 18, "a"]], [[31, 31, "a"], [28, 28, "a"]], [[49, 49, "p"], [48, 48, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[48, 48, "v"], [49, 49, "p"]]], "predicted_relations": [[], [], [[48, 48, 49, 49, "USED-FOR"]]]}
{"doc_key": "1811.07738-83c24444-6b68-482b-8cc9-024a8d41b6e8", "sentences": [["On", "DRIVE", "we", "use", "a", "batch-size", "of", "4", "for", "ERFNet", "and", "M2U-Net", "and", "a", "batch", "size", "of", "2", "for", "U-Net", "due", "to", "it", "'s", "higher", "memory", "footprint", "."], ["On", "CHASE_DB1", "we", "use", "a", "batch-size", "of", "2", "for", "ERFNet", "and", "M2U-Net", "."], ["The", "U-Net", "can", "not", "be", "trained", "on", "CHASE_DB1", "and", "HRF", "without", "reverting", "to", "a", "patch-based", "training", "approach", ",", "due", "to", "insufficient", "GPU", "memory", "in", "our", "training", "setup", "-LRB-", "11", "GB", "-RRB-", "."], ["Similarly", "the", "memory", "requirement", "of", "ERFNet", "for", "HRF", "is", "too", "large", "for", "our", "setup", "."], ["As", "a", "consequence", "we", "train", "only", "M2U-Net", "on", "HRF", ",", "using", "a", "batch-size", "of", "1", "."]], "ner": [[[9, 9, "a"], [11, 11, "a"], [5, 5, "p"], [17, 17, "v"], [1, 1, "c"], [17, 17, "v"], [19, 19, "a"]], [[37, 37, "a"], [39, 39, "a"], [33, 33, "p"], [35, 35, "v"], [35, 35, "v"], [29, 29, "c"]], [[48, 48, "c"], [50, 50, "c"], [42, 42, "a"]], [[78, 78, "a"], [80, 80, "c"]], [[94, 94, "a"], [100, 100, "p"], [102, 102, "v"], [96, 96, "c"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[5, 5, "p"], [7, 7, "v"], [9, 9, "a"], [11, 11, "a"], [14, 15, "p"], [17, 17, "v"], [19, 19, "a"]], [[29, 29, "a"], [33, 33, "p"], [35, 35, "v"], [37, 37, "a"], [39, 39, "a"]], [[42, 42, "a"], [48, 48, "a"], [69, 70, "v"]], [[78, 78, "a"]], [[94, 94, "a"], [100, 100, "p"], [102, 102, "v"]]], "predicted_relations": [[[5, 5, 9, 9, "USED-FOR"]], [[33, 33, 37, 37, "USED-FOR"]], [], [], [[100, 100, 94, 94, "USED-FOR"]]]}
{"doc_key": "1806.05559-282ec971-46c2-4ae5-b68c-9cecbb5a9ac0", "sentences": [["The", "models", "of", "our", "approach", "are", "implemented", "in", "TensorFlow", "-LSB-", "0", "-RSB-", "."], ["We", "use", "a", "BiRNN", "with", "a", "single", "layer", "in", "each", "direction", "with", "512-dimensional", "word", "embeddings", "and", "512-dimensional", "recurrent", "states", "."], ["We", "use", "LSTM", "as", "recurrent", "activation", "functions", "."], ["The", "hidden", "layer", "of", "the", "feed-forward", "neural", "network", "has", "256", "hidden", "units", "."], ["To", "train", "our", "models", ",", "we", "use", "Adam", "-LSB-", "19", "-RSB-", "with", "a", "learning", "rate", "of", "0.0002", "and", "a", "minibatch", "of", "128", "examples", "."], ["Models", "are", "trained", "for", "a", "total", "of", "15", "epochs", "."], ["To", "avoid", "exploding", "gradients", ",", "we", "apply", "gradient", "clipping", "such", "that", "the", "norm", "of", "all", "gradients", "is", "no", "larger", "than", "5", "-LSB-", "28", "-RSB-", "."], ["We", "apply", "dropout", "to", "prevent", "overfitting", "with", "a", "probability", "of", "0.2", "and", "0.3", "for", "the", "non-recurrent", "input", "and", "output", "connections", "respectively", "-LSB-", "36", "-RSB-", "."]], "ner": [[], [[16, 16, "a"], [26, 27, "p"], [25, 25, "v"], [29, 29, "v"], [30, 31, "p"], [25, 25, "v"], [29, 29, "v"]], [[37, 39, "p"], [35, 35, "v"]], [[42, 43, "p"], [50, 52, "v"]], [[61, 61, "a"], [67, 68, "p"], [70, 70, "v"], [73, 73, "p"], [75, 76, "v"]], [[86, 86, "p"], [85, 85, "v"]], [[95, 96, "a"], [100, 103, "p"], [105, 108, "v"]], [[115, 115, "a"], [121, 121, "p"], [123, 123, "v"], [125, 125, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "a"]], [[16, 16, "a"], [25, 25, "v"], [29, 29, "v"], [30, 31, "p"]], [[35, 35, "a"]], [[46, 48, "a"], [50, 50, "v"], [51, 52, "p"]], [[61, 61, "a"], [67, 68, "p"], [70, 70, "v"], [73, 73, "a"], [75, 75, "v"]], [[85, 85, "v"], [86, 86, "p"]], [[95, 96, "a"], [108, 108, "v"]], [[115, 115, "a"], [123, 123, "v"], [125, 125, "v"]]], "predicted_relations": [[], [[26, 27, 16, 16, "USED-FOR"], [30, 31, 16, 16, "USED-FOR"]], [[35, 35, 37, 39, "USED-FOR"]], [], [[67, 68, 61, 61, "USED-FOR"], [73, 73, 61, 61, "USED-FOR"], [75, 76, 73, 73, "USED-FOR"]], [[85, 85, 86, 86, "USED-FOR"]], [[100, 103, 95, 96, "USED-FOR"], [105, 108, 100, 103, "USED-FOR"]], [[121, 121, 115, 115, "USED-FOR"]]]}
{"doc_key": "1806.05559-1a86d1d3-4317-45e6-8596-33f99a704c94", "sentences": [["To", "train", "the", "NMT", "systems", ",", "we", "use", "the", "PyTorch", "implementation", "of", "OpenNMT", "-LSB-", "20", "-RSB-", ".https", ":", "//github.com/OpenNMT/OpenNMT-py", "The", "NMT", "systems", "are", "one", "layer", "BiLSTMs", "with", "an", "attention", "mechanism", "-LSB-", "5", "-RSB-", "."], ["The", "dimensions", "of", "the", "word", "embeddings", "and", "recurrent", "states", "for", "the", "encoder", "and", "decoder", "are", "all", "set", "to", "256", "."], ["The", "systems", "are", "trained", "for", "10", "epochs", "with", "minibatch", "of", "64", "sentence", "pairs", "using", "SGD", "with", "an", "initial", "learning", "rate", "of", "1.0", "and", "linear", "decay.We", "could", "have", "trained", "NMT", "systems", "for", "more", "epochs", "to", "obtain", "better", "BLEU", "scores", ",", "but", "our", "objective", "is", "not", "to", "compare", "SMT", "with", "NMT", "systems", "."], ["The", "norm", "of", "the", "gradient", "is", "clipped", "such", "that", "it", "is", "not", "greater", "than", "5", "."]], "ner": [[[9, 12, "a"], [23, 29, "a"], [31, 31, "v"]], [], [[68, 68, "a"], [77, 78, "p"]], [[119, 119, "v"], [106, 109, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "a"], [9, 9, "a"], [12, 12, "a"], [23, 23, "v"], [25, 25, "a"], [28, 29, "a"]], [[52, 52, "v"]], [[59, 59, "v"], [60, 60, "p"], [62, 62, "a"], [64, 64, "v"], [68, 68, "a"], [72, 73, "p"], [75, 75, "v"], [82, 83, "a"], [86, 86, "p"]], [[119, 119, "v"]]], "predicted_relations": [[], [], [[77, 78, 68, 68, "USED-FOR"]], []]}
{"doc_key": "1803.09065-26edf988-be6b-4d11-a5cf-195732afdbe1", "sentences": [["Binary", "vectors", "of", "4", "different", "sizes", "are", "produced", ":", "64", ",", "128", ",", "256", "and", "512", "bits", "."], ["The", "optimal", "hyperparameters", "are", "found", "using", "a", "grid", "search", "and", "selected", "to", "minimize", "the", "reconstruction", "loss", "and", "the", "regularization", "loss", "described", "in", "Section", "."], ["The", "model", "uses", "a", "batch", "size", "of", "75", ",", "10", "epochs", "for", "dict2vec", "and", "fasttext", ",", "and", "5", "epochs", "for", "GloVe", "-LRB-", "the", "autoencoder", "converges", "faster", "due", "to", "the", "smaller", "vocabulary", "-RRB-", "and", "a", "learning", "rate", "of", "0.001", "."], ["The", "regularization", "hyperparameter", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "reg", "-RCB-", "\\", "-RRB-", "depends", "on", "the", "starting", "vectors", "and", "the", "binary", "vector", "size", "."], ["It", "varies", "from", "1", "to", "4", "in", "the", "experiments", "but", "its", "influence", "on", "the", "performance", "is", "small", "-LRB-", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "2", "%", "variation", "-RRB-", "."]], "ner": [[[3, 3, "v"]], [[25, 26, "a"], [32, 33, "a"], [36, 37, "a"]], [[46, 47, "a"], [52, 52, "a"], [60, 60, "a"], [54, 56, "c"], [62, 62, "c"], [76, 77, "a"]], [[82, 83, "p"], [82, 83, "a"]], [[107, 107, "v"], [109, 109, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "v"], [9, 9, "v"], [11, 11, "v"], [13, 13, "v"], [15, 15, "v"]], [[32, 33, "a"], [36, 37, "a"]], [[46, 47, "p"], [49, 49, "v"], [51, 51, "v"], [52, 52, "p"], [54, 54, "a"], [56, 56, "a"], [59, 59, "v"], [60, 60, "p"], [62, 62, "a"], [76, 77, "p"], [79, 79, "v"]], [[82, 83, "p"], [86, 90, "p"]], [[107, 107, "v"], [109, 109, "v"], [127, 128, "v"]]], "predicted_relations": [[], [], [], [[82, 83, 82, 83, "USED-FOR"]], []]}
{"doc_key": "1803.09092-97b3f844-f9a0-4965-b92b-48d38f4506f5", "sentences": [["In", "the", "video", "generation", "and", "segmentation", "experiments", ",", "we", "performed", "gradient-descent", "using", "ADAM", ",", "with", "an", "initial", "learning", "rate", "of", "0.0002", ",", "\\", "-LRB-", "\\beta", "_1", "=", "0.5\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", "and", "batch", "size", "of", "16", "."], ["For", "video", "generator", "training", "we", "used", "\\", "-LRB-", "\\alpha", "=1\\", "-RRB-", ",", "\\", "-LRB-", "s_", "-LCB-", "\\alpha", "-RCB-", "=0.2\\", "-RRB-", "and", "\\", "-LRB-", "E_", "-LCB-", "\\alpha", "-RCB-", "=2\\", "-RRB-", "-LRB-", "values", "set", "empirically", "-RRB-", "."], ["We", "trained", "the", "video", "generation", "models", "for", "25", "epochs", "and", "the", "video", "segmentation", "ones", "for", "200", "epochs", "."], ["For", "video", "action", "recognition", ",", "we", "used", "SGD", "with", "momentum", "and", "dampening", "of", "0.9", ",", "weight", "decay", "of", "0.001", "and", "learning", "rate", "of", "0.1", ",", "reduced", "by", "a", "factor", "of", "10", "when", "no", "improvement", "in", "validation", "accuracy", "occurred", "for", "10", "epochs", "."], ["Batch", "size", "was", "128", "and", "the", "number", "of", "epochs", "was", "130", "."]], "ner": [[[20, 20, "v"], [27, 27, "v"], [35, 35, "v"], [41, 41, "v"], [12, 12, "a"]], [[52, 52, "v"], [61, 61, "v"], [61, 61, "v"], [70, 70, "v"]], [], [[103, 103, "a"], [109, 109, "v"], [109, 109, "v"], [114, 114, "v"], [119, 119, "v"], [119, 119, "v"]], [[138, 139, "p"], [138, 139, "p"], [141, 141, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[10, 10, "a"], [12, 12, "a"], [17, 18, "p"], [20, 20, "v"], [27, 27, "v"], [32, 33, "p"], [35, 35, "v"], [38, 39, "p"], [41, 41, "v"]], [[52, 52, "v"], [61, 61, "v"], [70, 70, "v"]], [[85, 85, "v"], [86, 86, "p"], [93, 93, "v"], [94, 94, "p"]], [[103, 103, "a"], [107, 107, "p"], [109, 109, "v"], [111, 112, "p"], [114, 114, "v"], [116, 117, "p"], [119, 119, "v"], [126, 126, "v"], [135, 135, "v"], [136, 136, "p"]], [[138, 139, "p"], [141, 141, "v"], [148, 148, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "1804.08872-91c0c174-f15c-4f1c-91d2-90c16e60cff2", "sentences": [["As", "mentioned", "above", ",", "we", "evaluated", "ResNet50", "and", "InceptionV3", "for", "the", "classification", "task", "."], ["Both", "architectures", "were", "initialized", "with", "pre-trained", "weights", "from", "the", "ImageNet", "dataset", "and", "trained", "using", "cross-entropy", "as", "a", "cost", "function", "minimized", "by", "stochastic", "gradient", "descent", "."], ["Batch", "normalization", "was", "applied", "."], ["The", "initial", "learning", "rates", "for", "both", "architectures", "were", "set", "to", "\\", "-LRB-", "3\\cdot", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "in", "order", "to", "protect", "the", "pre-trained", "weights", "."], ["Training", "was", "performed", "with", "a", "batch", "size", "of", "48", "."], ["Analysis", "of", "the", "validation", "accuracy", "showed", "no", "significant", "gain", "after", "five", "epochs", ",", "thus", "early", "stopping", "was", "applied", "in", "order", "to", "avoid", "overfitting"]], "ner": [[[6, 6, "a"], [8, 8, "a"]], [[23, 24, "a"], [28, 28, "a"], [35, 37, "a"]], [], [], [[76, 77, "a"], [76, 77, "p"], [79, 79, "v"]], [[95, 96, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [8, 8, "a"]], [[23, 24, "a"], [28, 28, "a"], [35, 37, "a"]], [], [], [[76, 77, "p"], [79, 79, "v"]], [[91, 91, "v"], [92, 92, "p"]]], "predicted_relations": [[], [], [], [], [[79, 79, 76, 77, "USED-FOR"]], []]}
{"doc_key": "1805.11762-44474c69-f545-4680-b60b-3eb10c8d3ad9", "sentences": [["Before", "performing", "interactive", "adversarial", "learning", "with", "RL", ",", "we", "pretrain", "the", "dialog", "agent", "and", "the", "discriminative", "reward", "function", "with", "offline", "supervised", "learning", "on", "DSTC2", "dataset", "."], ["We", "find", "this", "being", "helpful", "in", "enabling", "the", "adversarial", "policy", "learning", "to", "start", "with", "a", "good", "initialization", "."], ["The", "dialog", "agent", "is", "pretrained", "to", "minimize", "the", "cross-entropy", "losses", "on", "agent", "action", "and", "slot", "value", "predictions", "."], ["Once", "we", "obtain", "a", "supervised", "training", "dialog", "agent", ",", "we", "simulate", "dialogs", "between", "the", "agent", "and", "the", "user", "simulator", "."], ["These", "simulated", "dialogs", "together", "with", "the", "dialogs", "in", "DSTC2", "dataset", "are", "then", "used", "to", "pretrain", "the", "discriminative", "reward", "function", "."], ["We", "sample", "500", "successful", "dialogs", "as", "positive", "examples", ",", "and", "500", "random", "dialogs", "as", "negative", "examples", "in", "pretraining", "the", "discriminator", "."], ["During", "dialog", "simulation", ",", "a", "dialog", "is", "marked", "as", "successful", "if", "the", "agent", "'s", "belief", "tracking", "outputs", "fully", "match", "the", "informable", "-LSB-", "6", "-RSB-", "user", "goal", "slot", "values", ",", "and", "all", "user", "requested", "slots", "are", "fulfilled", "."], ["This", "is", "the", "same", "evaluation", "criteria", "as", "used", "in", "-LSB-", "28", "-RSB-", "and", "-LSB-", "14", "-RSB-", "."], ["It", "is", "important", "to", "note", "that", "such", "dialog", "success", "signal", "is", "usually", "not", "available", "during", "real", "user", "interactions", ",", "unless", "we", "explicitly", "ask", "users", "to", "provide", "this", "feedback", "."]], "ner": [[[23, 24, "a"], [11, 12, "a"], [15, 17, "a"]], [], [[45, 46, "a"]], [[68, 69, "a"]], [[90, 91, "a"], [98, 100, "a"]], [[104, 104, "v"], [112, 112, "v"]], [], [[164, 165, "p"]], [[184, 186, "a"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[23, 24, "a"]], [], [[52, 53, "a"]], [], [[90, 91, "a"]], [[104, 104, "v"], [112, 112, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "1805.11762-4acf2c62-4f92-4fba-916b-49df4f72adb8", "sentences": [["During", "supervised", "pretraining", ",", "for", "the", "dialog", "agent", "we", "use", "LSTM", "with", "a", "state", "size", "of", "150", "."], ["Hidden", "layer", "size", "for", "the", "policy", "network", "MLP", "is", "set", "as", "100", "."], ["For", "the", "discriminator", "model", ",", "a", "state", "size", "of", "200", "is", "used", "for", "the", "bidirectional", "LSTM", "."], ["We", "perform", "mini-batch", "training", "with", "batch", "size", "of", "32", "using", "Adam", "optimization", "method", "-LSB-", "9", "-RSB-", "with", "initial", "learning", "rate", "of", "1e-3", "."], ["Dropout", "-LRB-", "\\", "-LRB-", "p=0.5\\", "-RRB-", "-RRB-", "is", "applied", "during", "model", "training", "to", "prevent", "the", "model", "from", "over-fitting", "."], ["Gradient", "clipping", "threshold", "is", "set", "to", "5", "."]], "ner": [[[10, 10, "a"], [13, 14, "p"], [16, 16, "v"]], [[25, 25, "a"], [29, 29, "v"]], [[46, 46, "a"], [37, 38, "p"], [40, 40, "v"]], [[58, 60, "a"], [65, 67, "p"], [69, 69, "v"]], [[71, 71, "a"], [75, 75, "p"], [75, 75, "v"], [75, 75, "v"]], [[90, 91, "a"], [92, 92, "p"], [96, 96, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[10, 10, "a"], [16, 16, "v"]], [[23, 24, "a"], [25, 25, "a"], [29, 29, "v"]], [[40, 40, "v"], [46, 46, "a"]], [[50, 51, "a"], [53, 54, "p"], [56, 56, "v"], [58, 58, "a"], [66, 67, "p"], [69, 69, "v"]], [[71, 71, "a"], [75, 75, "v"]], [[96, 96, "v"]]], "predicted_relations": [[[13, 14, 10, 10, "USED-FOR"], [16, 16, 13, 14, "USED-FOR"]], [], [[40, 40, 37, 38, "USED-FOR"]], [[65, 67, 58, 60, "USED-FOR"], [69, 69, 65, 67, "USED-FOR"]], [[75, 75, 75, 75, "USED-FOR"], [75, 75, 75, 75, "USED-FOR"], [75, 75, 75, 75, "USED-FOR"], [75, 75, 75, 75, "USED-FOR"]], [[92, 92, 90, 91, "USED-FOR"], [96, 96, 92, 92, "USED-FOR"]]]}
{"doc_key": "1805.11762-5043dae1-d7b9-4a8d-abbd-cfbc94f976f0", "sentences": [["During", "interactive", "learning", "with", "adversarial", "RL", ",", "we", "set", "the", "maximum", "allowed", "number", "of", "dialog", "turns", "as", "20", "."], ["A", "simulation", "is", "force", "to", "terminated", "after", "20", "dialog", "turns", "."], ["We", "update", "the", "model", "with", "every", "mini-batch", "of", "25", "samples", "."], ["Dialog", "rewards", "are", "calculated", "by", "the", "discriminative", "reward", "function", "."], ["Reward", "discount", "factor", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "is", "set", "as", "0.95", "."], ["These", "rewards", "are", "used", "to", "update", "the", "agent", "model", "via", "policy", "gradient", "."], ["At", "the", "same", "time", ",", "this", "mini-batch", "of", "simulated", "dialogs", "are", "used", "as", "negative", "examples", "to", "update", "the", "discriminator", "."]], "ner": [[], [], [], [], [[51, 53, "p"], [62, 62, "v"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[17, 17, "v"]], [[26, 26, "v"]], [[38, 38, "v"]], [], [[56, 56, "p"], [62, 62, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "1803.07187-926d34fc-0de4-496c-bd16-dcd0c2445b8a", "sentences": [["For", "the", "segmentation", "of", "the", "the", "training", "region", "\\", "-LRB-", "D_1\\", "-RRB-", "within", "the", "inpainting", "domain", "\\", "-LRB-", "D\\", "-RRB-", "we", "use", "the", "activecontour", "MATLAB", "function", "by", "which", "the", "Chan-Vese", "algorithm", "can", "be", "called", "."], ["For", "this", "we", "fixed", "the", "maximum", "number", "of", "iterations", "to", "maxiter\\", "-LRB-", "=1000\\", "-RRB-", "and", "use", "the", "default", "value", "as", "a", "tolerance", "on", "the", "relative", "error", "between", "iterates", "as", "a", "stopping", "criterion", "."], ["We", "use", "the", "default", "values", "for", "the", "parameters", "\\", "-LRB-", "\\mu", "\\", "-RRB-", "and", "\\", "-LRB-", "\\nu", "\\", "-RRB-", "in", "-LRB-", "REF", "-RRB-", "."], ["The", "subsequent", "labelling", "phase", "was", "performed", "by", "means", "of", "the", "standard", "MATLAB", "kmeans", "function", "after", "specifying", "a", "total", "of", "\\", "-LRB-", "K=35\\", "-RRB-", "labels", "to", "assign", "."], ["The", "labelling", "was", "iteratively", "repeated", "5", "times", "to", "avoid", "misclassification", "."], ["Once", "the", "detection", "of", "the", "inpainting", "domain", "is", "completed", ",", "in", "order", "to", "provide", "a", "good", "initialisation", "to", "the", "exemplar-based", "model", "we", "use", "the", "TV", "inpainting", "model", "-LRB-", "REF", "-RRB-", "with", "-LRB-", "REF", "-RRB-", "with", "the", "value", "\\", "-LRB-", "\\lambda", "=1000\\", "-RRB-", "and", "a", "maximum", "number", "of", "iterations", "equal", "to", "maxiter2\\", "-LRB-", "=1000\\", "-RRB-", "with", "a", "stopping", "criterion", "on", "the", "relative", "error", "between", "iterates", "depending", "on", "a", "default", "tolerance", "."], ["Finally", ",", "we", "followed", "-LSB-", "34", "-RSB-", "for", "the", "implementation", "of", "the", "exemplar-based", "inpainting", "model", ":", "for", "this", "we", "specified", "12", "propagation", "of", "iterations", "and", "tested", "different", "size", "of", "the", "patches", "."], ["In", "order", "to", "avoid", "memory", "shortage", ",", "we", "restricted", "to", "patches", "of", "the", "size", "\\", "-LRB-", "5\\times", "5\\", "-RRB-", ",", "\\", "-LRB-", "7\\times", "7\\", "-RRB-", "and", "\\", "-LRB-", "9\\times", "9\\", "-RRB-", "."]], "ner": [[[23, 25, "a"]], [[45, 45, "p"], [47, 47, "v"], [52, 52, "v"], [52, 52, "v"], [47, 47, "v"], [47, 47, "v"], [43, 43, "p"]], [[78, 78, "p"], [71, 71, "v"], [84, 84, "p"], [71, 71, "v"]], [[104, 105, "a"], [113, 113, "p"], [113, 113, "v"]], [], [[170, 170, "v"], [182, 182, "v"], [197, 197, "v"], [197, 197, "v"], [154, 156, "a"], [169, 169, "p"], [170, 170, "v"], [182, 182, "v"], [180, 180, "p"], [170, 170, "v"], [182, 182, "v"], [177, 177, "p"]], [[212, 214, "a"], [223, 223, "p"], [220, 220, "v"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[23, 23, "a"], [29, 30, "a"]], [[47, 47, "v"]], [], [[104, 105, "a"], [113, 113, "v"]], [[124, 124, "v"]], [[154, 156, "a"], [169, 170, "v"], [182, 182, "v"]], [[212, 214, "a"], [220, 220, "v"]], [[248, 249, "v"], [255, 255, "v"], [261, 261, "v"]]], "predicted_relations": [[], [[47, 47, 45, 45, "USED-FOR"], [47, 47, 43, 43, "USED-FOR"], [47, 47, 45, 45, "USED-FOR"], [47, 47, 43, 43, "USED-FOR"], [47, 47, 45, 45, "USED-FOR"], [47, 47, 43, 43, "USED-FOR"]], [[71, 71, 78, 78, "USED-FOR"], [71, 71, 84, 84, "USED-FOR"], [71, 71, 78, 78, "USED-FOR"], [71, 71, 84, 84, "USED-FOR"]], [[113, 113, 104, 105, "USED-FOR"], [113, 113, 113, 113, "USED-FOR"], [113, 113, 113, 113, "USED-FOR"]], [], [[170, 170, 169, 169, "USED-FOR"], [170, 170, 177, 177, "USED-FOR"], [182, 182, 169, 169, "USED-FOR"], [182, 182, 180, 180, "USED-FOR"], [182, 182, 177, 177, "USED-FOR"], [169, 169, 154, 156, "USED-FOR"], [170, 170, 169, 169, "USED-FOR"], [170, 170, 177, 177, "USED-FOR"], [182, 182, 169, 169, "USED-FOR"], [182, 182, 180, 180, "USED-FOR"], [182, 182, 177, 177, "USED-FOR"], [180, 180, 154, 156, "USED-FOR"], [170, 170, 169, 169, "USED-FOR"], [170, 170, 177, 177, "USED-FOR"], [182, 182, 169, 169, "USED-FOR"], [182, 182, 180, 180, "USED-FOR"], [182, 182, 177, 177, "USED-FOR"], [177, 177, 154, 156, "USED-FOR"]], [[223, 223, 212, 214, "USED-FOR"], [220, 220, 223, 223, "USED-FOR"]], []]}
{"doc_key": "1812.04180-abe2e8b0-bc3c-49ee-99cd-27c6cec78fe1", "sentences": [["For", "ResNet", ",", "we", "kept", "the", "same", "training", "schedule", "as", "AIG", "-LSB-", "48", "-RSB-", ",", "and", "follow", "the", "standard", "ResNet", "training", "procedure", ":", "batch", "size", "of", "256", ",", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "and", "weight", "decay", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "weight", "decay", "for", "gate", "parameters", ",", "we", "use", "\\", "-LRB-", "\\frac", "-LCB-", "20", "-RCB-", "-LCB-", "|\\mathcal", "-LCB-", "G", "-RCB-", "|", "-RCB-", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "train", "for", "100", "epochs", "from", "a", "pretrained", "model", "of", "the", "appropriate", "architecture", "with", "step-wise", "learning", "rate", "starting", "at", "\\", "-LRB-", "0.1\\", "-RRB-", ",", "and", "decay", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "after", "every", "30", "epochs", "."], ["This", "is", "the", "same", "training", "schedule", "as", "-LSB-", "48", "-RSB-", "."], ["We", "use", "standard", "training", "data-augmentation", "-LRB-", "random", "resize", "crop", "to", "224", ",", "random", "horizontal", "flip", "-RRB-", "and", "standard", "validation", "-LRB-", "resize", "the", "images", "to", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "followed", "by", "a", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "center", "crop", "-RRB-", "."]], "ner": [[[1, 1, "a"], [19, 19, "a"], [10, 10, "a"], [23, 24, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "a"], [28, 28, "p"], [32, 32, "v"], [36, 37, "a"], [36, 37, "p"], [37, 37, "a"], [37, 37, "p"]], [[50, 51, "a"], [50, 51, "p"], [50, 54, "p"], [51, 51, "a"], [51, 51, "p"]], [[83, 83, "a"], [113, 113, "a"], [83, 83, "p"], [113, 113, "p"], [82, 82, "v"], [86, 87, "a"], [93, 95, "a"], [93, 95, "p"], [100, 100, "v"], [108, 108, "v"], [104, 104, "a"], [104, 104, "p"], [100, 100, "v"], [108, 108, "v"]], [], [[152, 152, "v"], [153, 153, "v"], [129, 130, "a"], [144, 144, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [10, 10, "a"], [19, 19, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "p"], [32, 32, "v"], [36, 37, "p"], [41, 45, "v"]], [[50, 51, "p"]], [[82, 82, "v"], [83, 83, "p"], [94, 95, "p"], [100, 100, "v"], [108, 108, "v"], [112, 112, "v"], [113, 113, "p"]], [], [[136, 136, "v"], [153, 153, "v"], [161, 161, "v"]]], "predicted_relations": [[[23, 24, 10, 10, "USED-FOR"], [28, 28, 1, 1, "USED-FOR"], [28, 28, 19, 19, "USED-FOR"], [28, 28, 10, 10, "USED-FOR"], [28, 28, 23, 24, "USED-FOR"], [28, 28, 28, 28, "USED-FOR"], [32, 32, 36, 37, "USED-FOR"], [36, 37, 19, 19, "USED-FOR"], [36, 37, 10, 10, "USED-FOR"], [36, 37, 23, 24, "USED-FOR"], [36, 37, 28, 28, "USED-FOR"], [37, 37, 19, 19, "USED-FOR"], [37, 37, 10, 10, "USED-FOR"], [37, 37, 23, 24, "USED-FOR"], [37, 37, 28, 28, "USED-FOR"], [37, 37, 36, 37, "USED-FOR"], [37, 37, 37, 37, "USED-FOR"]], [[51, 51, 50, 51, "USED-FOR"], [51, 51, 51, 51, "USED-FOR"]], [[83, 83, 83, 83, "USED-FOR"], [83, 83, 86, 87, "USED-FOR"], [113, 113, 113, 113, "USED-FOR"], [113, 113, 93, 95, "USED-FOR"], [113, 113, 104, 104, "USED-FOR"], [82, 82, 83, 83, "USED-FOR"], [93, 95, 83, 83, "USED-FOR"], [93, 95, 86, 87, "USED-FOR"], [93, 95, 93, 95, "USED-FOR"], [100, 100, 93, 95, "USED-FOR"], [100, 100, 104, 104, "USED-FOR"], [108, 108, 113, 113, "USED-FOR"], [104, 104, 113, 113, "USED-FOR"], [104, 104, 86, 87, "USED-FOR"], [104, 104, 93, 95, "USED-FOR"], [104, 104, 104, 104, "USED-FOR"], [100, 100, 93, 95, "USED-FOR"], [100, 100, 104, 104, "USED-FOR"], [108, 108, 113, 113, "USED-FOR"]], [], []]}
{"doc_key": "1002.0773-f4b10e9b-4ceb-4dca-9c2e-7624e959f62d", "sentences": [["This", "Section", "presents", "further", "analysis", "of", "the", "results", "in", "Section", "REF", "."], ["We", "will", "develop", "a", "simple", "framework", "that", "we", "will", "use", "to", "examine", "what", "happens", "to", "the", "model", "parameters", "after", "100", "iterations", "of", "extended", "Baum-Welch", "."], ["We", "shall", "demonstrate", "that", "extended", "Baum-Welch", "expands", "the", "space", "that", "the", "model", "means", "occupy", "and", "that", "this", "expansion", "appears", "to", "be", "consistent", "with", "steady", "decrease", "in", "the", "sequences", "\\", "-LRB-", "-LRB-", "\\operatorname", "-LCB-", "num", "-RCB-", "-LRB-", "x", ",", "w", ";", "\\theta", "_k", ",", "\\kappa", ",", "\\mathcal", "-LCB-", "V", "-RCB-", "_", "-LCB-", "mle", "-RCB-", ",", "\\mathcal", "-LCB-", "R", "-RCB-", "_", "-LCB-", "mle", "-RCB-", "-RRB-", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "-LRB-", "\\operatorname", "-LCB-", "den", "-RCB-", "-LRB-", "x", ",", "w", ";", "\\theta", "_k", ",", "\\kappa", ",", "\\mathcal", "-LCB-", "V", "-RCB-", "_", "-LCB-", "mle", "-RCB-", ",", "\\mathcal", "-LCB-", "R", "-RCB-", "_", "-LCB-", "mle", "-RCB-", "-RRB-", "-RRB-", "\\", "-RRB-", "that", "we", "saw", "in", "Section", "REF", "."], ["We", "also", "show", "that", "extended", "Baum-Welch", "appears", "to", "be", "shrinking", "the", "model", "variances", ",", "but", "not", "in", "a", "dramatic", "way", "."]], "ner": [[], [[34, 35, "a"], [28, 29, "a"]], [[41, 42, "a"], [48, 49, "p"]], [[153, 154, "a"], [160, 161, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[31, 31, "v"], [35, 35, "a"]], [[42, 42, "a"]], [[154, 154, "a"]]], "predicted_relations": [[], [], [[48, 49, 41, 42, "USED-FOR"]], [[160, 161, 153, 154, "USED-FOR"]]]}
{"doc_key": "1002.0773-16421780-d63d-4651-8c56-d7112cf8bde5", "sentences": [["This", "is", "called", "the", "Mahalanobis", "distance", "."], ["The", "set", "of", "points", "in", "\\", "-LRB-", "\\mathbb", "-LCB-", "R", "-RCB-", "^d\\", "-RRB-", "satisfying", "\\", "-LRB-", "d_", "-LCB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RCB-", "-LRB-", "x", ",", "0", "-RRB-", "=", "1\\", "-RRB-", "is", "an", "ellipsoid", "\\", "-LRB-", "Ell", "-LRB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RRB-", "\\equiv", "\\lbrace", "x", "\\in", "\\mathbb", "-LCB-", "R", "-RCB-", "^d", ":", "x^t", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "x", "=", "1\\rbrace", ",", "\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[4, 5, "a"]], []], "predicted_relations": [[], []]}
{"doc_key": "1002.0773-255dabdd-b8ea-4f1e-a216-b951583fac38", "sentences": [["Then", "the", "collection", "of", "vectors", "\\", "-LRB-", "\\lbrace", "\\sqrt", "-LCB-", "\\lambda", "_i", "-RCB-", "u_i\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^d\\", "-RRB-", "are", "the", "semi-principal", "axes", "of", "\\", "-LRB-", "Ell", "-LRB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RRB-", "\\", "-RRB-", "."], ["The", "ratio", "\\", "-LRB-", "c", "-LRB-", "\\Sigma", "-RRB-", "\\equiv", "\\sqrt", "-LCB-", "\\lambda", "_d", "/", "\\lambda", "_1", "-RCB-", "\\", "-RRB-", "gives", "a", "sense", "of", "how", "elongated", "the", "ellipsoid", "\\", "-LRB-", "Ell", "-LRB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RRB-", "\\", "-RRB-", "is", ":", "\\", "-LRB-", "\\sqrt", "-LCB-", "\\lambda", "_d", "/", "\\lambda", "_1", "-RCB-", "\\ge", "1", "\\", "-RRB-", "with", "equality", "\\", "-LRB-", "\\iff", "\\", "-RRB-", "\\", "-LRB-", "Ell", "-LRB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RRB-", "=", "S^", "-LCB-", "d-1", "-RCB-", "\\", "-RRB-", ".The", "quantity", "\\", "-LRB-", "c^2\\", "-RRB-", "is", "the", "condition", "number", "of", "the", "matrix", "\\", "-LRB-", "\\Sigma", "\\", "-RRB-", "."], ["Also", "\\", "-LRB-", "\\sqrt", "-LCB-", "1", "-", "1", "/", "c^2", "-RCB-", "\\", "-RRB-", "is", "the", "eccentricity", "of", "the", "two-dimensional", "ellipse", "formed", "by", "the", "intersection", "of", "\\", "-LRB-", "Ell", "-LRB-", "\\Sigma", "^", "-LCB-", "-1", "-RCB-", "-RRB-", "\\", "-RRB-", "with", "the", "plane", "through", "the", "origin", "spanned", "by", "\\", "-LRB-", "u_1\\", "-RRB-", "and", "\\", "-LRB-", "u_d\\", "-RRB-", "."]], "ner": [[], [], []], "relations": [[], [], []], "predicted_ner": [[], [], [[154, 154, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "1002.0773-2785ce17-aef7-4012-a461-39674fa087b8", "sentences": [["First", "we", "examine", "the", "scatter", "of", "the", "collection", "of", "the", "1500", "state", "means", "in", "\\", "-LRB-", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "39", "-RCB-", "\\", "-RRB-", "."], ["We", "treat", "these", "means", "as", "points", "in", "\\", "-LRB-", "\\mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "39", "-RCB-", "\\", "-RRB-", "and", "compute", "the", "total", "mean", "vector", "-LRB-", "or", "centroid", "-RRB-", "\\", "-LRB-", "\\bar", "-LCB-", "\\mu", "-RCB-", "=", "\\frac", "-LCB-", "\\sum", "_", "-LCB-", "j=1", "-RCB-", "^", "-LCB-", "1500", "-RCB-", "\\mu", "_j", "-RCB-", "-LCB-", "1500", "-RCB-", ",", "\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[10, 10, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "1002.0773-233dbdf4-7cca-4544-bf62-0fecfb98cded", "sentences": [["For", "each", "state", "\\", "-LRB-", "j\\", "-RRB-", "let", "\\", "-LRB-", "\\sigma", "_", "-LCB-", "mle", ",", "j", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\sigma", "_", "-LCB-", "mmi", ",", "j", "-RCB-", "\\", "-RRB-", "denote", "the", "vectors", "of", "standard", "deviations", "for", "state", "\\", "-LRB-", "j\\", "-RRB-", "before", "and", "after", "100", "iterations", "of", "extended", "Baum-Welch", ",", "and", "define", "\\", "-LRB-", "V_j", "\\equiv", "\\log", "\\frac", "-LCB-", "\\prod", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "39", "-RCB-", "\\sigma", "_", "-LCB-", "mmi", ",", "j", ",", "i", "-RCB-", "-RCB-", "-LCB-", "\\prod", "_", "-LCB-", "i=1", "-RCB-", "^", "-LCB-", "39", "-RCB-", "\\sigma", "_", "-LCB-", "mle", ",", "j", ",", "i", "-RCB-", "-RCB-", ".\\", "-RRB-"]], "ner": [[]], "relations": [[]], "predicted_ner": [[[46, 46, "v"], [50, 50, "a"]]], "predicted_relations": [[]]}
{"doc_key": "2207.10213-ef0955b2-73bc-47c9-9c61-fbe232564ae7", "sentences": [["We", "train", "E2E-Spot", "using", "100", "frame", "long", "clips", "by", "default", "and", "a", "batch", "size", "of", "8", "clips", "."], ["Batches", "are", "formed", "by", "randomly", "sampling", "clips", "from", "the", "training", "videos", "."], ["We", "group", "every", "625", "training", "steps", "into", "a", "training", "cycle", "-LRB-", "i.e.", ",", "a", "pseudo-epoch", "of", "500K", "frames", "-RRB-", "."], ["A", "single", "cycle", "runs", "in", "approximately", "8.5", "and", "14", "minutes", "on", "a", "single", "A5000", "GPU", "-LSB-", "43", "-RSB-", "for", "the", "200MF", "and", "800MF", "variants", ",", "respectively", "."], ["All", "variations", "of", "E2E-Spot", "are", "trained", "for", "50", "cycles", "on", "the", "Tennis", ",", "Figure", "Skating", ",", "and", "FineDiving", "datasets", "."], ["We", "train", "the", "200MF", "model", "for", "100", "cycles", "and", "the", "800MF", "model", "for", "150", "cycles", "on", "FineGym", "and", "SoccerNet-v2", ",", "due", "to", "the", "larger", "dataset", "sizes", "-LRB-", "see", "sec", ":", "suppdataset", "-RRB-", "."], ["Training", "is", "performed", "with", "AdamW", "-LSB-", "42", "-RSB-", ",", "setting", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "with", "3", "linear", "warmup", "cycles", "followed", "by", "cosine", "decay", "-LSB-", "41", "-RSB-", "."]], "ner": [[[2, 2, "a"], [4, 4, "v"], [12, 13, "p"], [15, 15, "v"]], [], [[38, 39, "a"], [34, 35, "p"], [33, 33, "v"]], [[56, 56, "v"]], [[80, 80, "a"]], [[103, 103, "v"]], [[134, 134, "a"], [141, 143, "p"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [12, 13, "p"], [15, 15, "v"]], [], [[33, 33, "v"], [46, 46, "v"]], [[56, 56, "v"], [58, 58, "v"], [70, 70, "v"], [72, 72, "v"]], [[80, 80, "a"], [84, 84, "v"], [94, 94, "a"]], [[100, 100, "v"], [103, 103, "v"], [107, 107, "v"], [110, 110, "v"], [113, 113, "a"], [115, 115, "a"]], [[134, 134, "a"], [147, 149, "v"], [155, 155, "v"], [161, 162, "a"]]], "predicted_relations": [[], [], [[34, 35, 38, 39, "USED-FOR"], [33, 33, 34, 35, "USED-FOR"]], [], [], [], [[141, 143, 134, 134, "USED-FOR"]]]}
{"doc_key": "2207.10213-e8880c89-c38d-4063-b30f-9818487f30b3", "sentences": [["We", "train", "the", "TCN", ",", "MS-TCN", ",", "GRU", ",", "ASFormer", ",", "and", "GCN", "models", "on", "randomly", "sampled", ",", "500", "frame", "long", "clips", "\u2014", "with", "a", "batch", "size", "of", "50", ",", "a", "train-val", "cycle", "of", "40", "steps", "-LRB-", "1M", "frames", "-RRB-", ",", "and", "for", "50", "cycles", "."], ["Updates", "are", "performed", "using", "AdamW", "-LSB-", "42", "-RSB-", "with", "a", "base", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "linear", "warmup", "-LRB-", "3", "cycles", "-RRB-", ",", "and", "cosine", "annealing", "-LSB-", "41", "-RSB-", "."], ["The", "StridedTransformer", "and", "NetVLAD++", "-LSB-", "22", "-RSB-", "baselines", "make", "singular", "predictions", "on", "a", "window", "of", "frames", "."], ["We", "train", "these", "with", "a", "batch", "size", "of", "100", "clips", ",", "train-val", "cycles", "of", "1,000", "steps", ",", "and", "for", "50", "cycles", "."], ["We", "use", "the", "same", "AdamW", "-LSB-", "42", "-RSB-", "optimizer", "and", "LR", "schedule", "as", "the", "other", "models", "."], ["Validation", "mAP", ",", "computed", "at", "the", "end", "of", "every", "training", "cycle", ",", "is", "used", "for", "model", "selection", "."]], "ner": [[[3, 3, "a"], [5, 5, "a"], [5, 5, "a"], [7, 7, "a"], [9, 9, "a"], [12, 12, "a"]], [[50, 50, "a"], [56, 58, "p"], [69, 70, "p"], [72, 73, "v"], [77, 78, "p"], [80, 80, "v"]], [[84, 84, "a"]], [], [[126, 126, "a"]], [[139, 140, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [7, 7, "a"], [12, 12, "a"], [18, 18, "v"], [25, 26, "p"], [28, 28, "v"], [31, 32, "p"], [34, 34, "v"], [37, 37, "v"], [43, 43, "v"]], [[50, 50, "a"], [62, 64, "v"], [69, 70, "a"], [72, 72, "v"], [77, 78, "a"]], [[84, 84, "a"], [86, 86, "a"]], [[105, 106, "p"], [108, 108, "v"], [111, 112, "p"], [114, 114, "v"], [119, 119, "v"]], [[126, 126, "a"]], []], "predicted_relations": [[], [[56, 58, 50, 50, "USED-FOR"], [69, 70, 50, 50, "USED-FOR"], [77, 78, 50, 50, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2205.05128-cdd71106-f5bb-4261-a234-a6fdb9e2fe70", "sentences": [["We", "use", "2.4447e-4", "as", "the", "learning", "rate", "for", "training", "HaRT", ",", "with", "1", "user", "train", "batch", "size", ",", "15", "users", "eval", "batch", "size", "and", "early", "stopping", "patience", "set", "to", "3", "."], ["For", "GPT-2HLC", ",", "we", "use", "the", "default", "settings", "from", "-LSB-", "47", "-RSB-", "with", "train", "and", "eval", "batch", "size", "set", "to", "60", "and", "early", "stopping", "patience", "set", "to", "3", "."]], "ner": [[[9, 9, "a"], [5, 6, "p"], [2, 2, "v"], [13, 16, "p"], [12, 12, "v"], [19, 22, "p"], [18, 18, "v"], [24, 26, "p"], [29, 29, "v"], [14, 16, "p"], [20, 22, "p"], [24, 26, "p"], [29, 29, "v"]], [[53, 55, "p"], [58, 58, "v"], [32, 32, "a"], [51, 51, "v"], [46, 48, "p"], [51, 51, "v"], [53, 55, "p"], [58, 58, "v"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "v"], [5, 6, "p"], [12, 12, "v"], [18, 18, "v"], [29, 29, "v"]], [[32, 32, "a"], [51, 51, "v"], [58, 58, "v"]]], "predicted_relations": [[[5, 6, 9, 9, "USED-FOR"], [2, 2, 5, 6, "USED-FOR"], [13, 16, 9, 9, "USED-FOR"], [12, 12, 14, 16, "USED-FOR"], [19, 22, 9, 9, "USED-FOR"], [18, 18, 13, 16, "USED-FOR"], [18, 18, 14, 16, "USED-FOR"], [14, 16, 9, 9, "USED-FOR"], [20, 22, 9, 9, "USED-FOR"]], [[53, 55, 32, 32, "USED-FOR"], [51, 51, 53, 55, "USED-FOR"], [51, 51, 46, 48, "USED-FOR"], [51, 51, 53, 55, "USED-FOR"], [46, 48, 32, 32, "USED-FOR"], [51, 51, 53, 55, "USED-FOR"], [51, 51, 46, 48, "USED-FOR"], [51, 51, 53, 55, "USED-FOR"], [53, 55, 32, 32, "USED-FOR"]]]}
{"doc_key": "2212.10766-199c21c3-123c-43f6-9f17-0a327b72e72a", "sentences": [["CIFAR-10", "and", "CIFAR-100", "."], ["For", "all", "the", "experiments", "on", "CIFAR", ",", "we", "train", "our", "DNN", "model", "as", "well", "as", "class", "prototypes", "in", "CPC", "via", "SGD", "with", "a", "momentum", "of", "0.9", ",", "a", "weight", "decay", "of", "0.0005", ",", "and", "a", "batch", "size", "of", "128", "."], ["The", "network", "is", "trained", "for", "450", "epochs", "."], ["We", "set", "the", "initial", "learning", "rate", "as", "0.02", ",", "and", "reduce", "it", "by", "a", "factor", "of", "10", "after", "225", "epochs", "."], ["The", "warm", "up", "period", "for", "the", "DNN", "is", "10", "epochs", "."], ["The", "weight", "\\", "-LRB-", "\\lambda", "^", "-LCB-", "-LRB-", "\\mathcal", "-LCB-", "U^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "set", "to", "\\", "-LRB-", "\\lbrace", "0,25,50,150\\rbrace", "\\", "-RRB-", "as", "in", "DivideMix", "."], ["Clthing1M", "."], ["We", "train", "our", "DNN", "model", "as", "well", "as", "class", "prototypes", "in", "CPC", "via", "SGD", "with", "a", "momentum", "of", "0.9", ",", "a", "weight", "decay", "of", "0.001", ",", "and", "a", "batch", "size", "of", "32", "."], ["The", "model", "is", "trained", "for", "80", "epochs", "."], ["The", "warm", "up", "period", "for", "the", "DNN", "is", "1", "epoch", "."], ["The", "initial", "learning", "rate", "is", "set", "as", "0.002", "and", "reduced", "by", "a", "factor", "of", "10", "after", "40", "epochs", "."], ["For", "each", "epoch", ",", "we", "sample", "1000", "mini-batches", "from", "the", "training", "data", "."], ["The", "weight", "\\", "-LRB-", "\\lambda", "^", "-LCB-", "-LRB-", "\\mathcal", "-LCB-", "U^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "set", "to", "0", "."], ["WebVision", "."], ["We", "train", "our", "DNN", "model", "as", "well", "as", "class", "prototypes", "in", "CPC", "via", "SGD", "with", "a", "momentum", "of", "0.9", ",", "a", "weight", "decay", "of", "0.001", ",", "and", "a", "batch", "size", "of", "32", "."], ["The", "model", "is", "trained", "for", "100", "epochs", "."], ["The", "warm", "up", "period", "for", "the", "DNN", "is", "1", "epoch", "."], ["The", "initial", "learning", "rate", "is", "set", "as", "0.01", "and", "reduced", "by", "a", "factor", "of", "10", "after", "50", "epochs", "."], ["For", "each", "epoch", ",", "we", "sample", "1000", "mini-batches", "from", "the", "training", "data", "."], ["The", "weight", "\\", "-LRB-", "\\lambda", "^", "-LCB-", "-LRB-", "\\mathcal", "-LCB-", "U^", "-LCB-", "\\prime", "-RCB-", "-RCB-", "-RRB-", "-RCB-", "\\", "-RRB-", "is", "set", "to", "0", "."]], "ner": [[[0, 0, "a"], [2, 2, "a"], [0, 0, "c"], [2, 2, "c"], [0, 0, "c"], [2, 2, "c"], [0, 0, "c"], [2, 2, "c"], [0, 0, "v"], [0, 0, "c"], [2, 2, "c"], [0, 0, "c"], [2, 2, "c"], [0, 0, "c"], [2, 2, "c"], [0, 0, "c"], [2, 2, "c"]], [[24, 24, "a"], [27, 27, "p"], [29, 29, "v"], [32, 33, "p"], [35, 35, "v"], [9, 9, "c"], [39, 40, "p"], [42, 42, "v"], [9, 9, "c"], [9, 9, "c"], [9, 9, "c"], [32, 32, "p"], [29, 29, "v"], [35, 35, "v"], [9, 9, "c"], [9, 9, "c"], [9, 9, "c"]], [], [[55, 57, "p"], [59, 59, "v"], [68, 68, "v"], [59, 59, "v"]], [[74, 76, "p"], [81, 81, "v"]], [[85, 85, "p"], [109, 109, "v"], [109, 109, "v"], [109, 109, "v"], [109, 109, "v"]], [], [[131, 131, "a"], [134, 134, "p"], [136, 136, "v"], [139, 140, "p"], [142, 142, "v"], [146, 147, "p"], [149, 149, "v"], [139, 139, "p"], [136, 136, "v"], [142, 142, "v"]], [], [[160, 162, "p"], [167, 167, "v"]], [[171, 173, "p"], [177, 177, "v"], [184, 184, "v"], [177, 177, "v"]], [], [[203, 203, "p"], [224, 224, "v"]], [[226, 226, "a"], [226, 226, "c"]], [], [], [], [[281, 283, "p"], [287, 287, "v"], [294, 294, "v"], [287, 287, "v"], [296, 296, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [2, 2, "a"]], [[9, 9, "a"], [14, 15, "a"], [22, 22, "a"], [29, 29, "v"], [32, 33, "p"], [35, 35, "v"], [39, 40, "p"], [42, 42, "v"]], [[49, 49, "v"], [50, 50, "p"]], [[56, 57, "p"], [59, 59, "v"], [68, 68, "v"], [70, 70, "v"]], [[79, 79, "a"], [81, 81, "v"], [82, 82, "p"]], [], [], [[121, 122, "a"], [131, 131, "a"], [136, 136, "v"], [142, 142, "v"], [146, 147, "p"], [149, 149, "v"]], [[156, 156, "v"]], [[165, 165, "a"], [167, 167, "v"], [168, 168, "p"]], [[172, 173, "p"], [177, 177, "v"], [184, 184, "v"], [186, 186, "v"]], [[195, 195, "v"]], [[224, 224, "v"]], [], [[231, 232, "a"], [246, 246, "v"], [249, 250, "p"], [252, 252, "v"], [259, 259, "v"]], [[266, 266, "v"], [267, 267, "p"]], [[275, 275, "a"], [277, 277, "v"], [278, 278, "p"]], [[282, 283, "p"], [287, 287, "v"], [294, 294, "v"], [296, 296, "v"]], [[305, 305, "v"]], [[334, 334, "v"]]], "predicted_relations": [[[0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"], [0, 0, 0, 0, "USED-FOR"], [2, 2, 0, 0, "USED-FOR"]], [[27, 27, 24, 24, "USED-FOR"], [29, 29, 32, 32, "USED-FOR"], [32, 33, 24, 24, "USED-FOR"], [35, 35, 27, 27, "USED-FOR"], [35, 35, 32, 33, "USED-FOR"], [35, 35, 32, 32, "USED-FOR"], [39, 40, 24, 24, "USED-FOR"], [42, 42, 32, 32, "USED-FOR"], [32, 32, 24, 24, "USED-FOR"], [29, 29, 32, 32, "USED-FOR"], [35, 35, 27, 27, "USED-FOR"], [35, 35, 32, 33, "USED-FOR"], [35, 35, 32, 32, "USED-FOR"]], [], [[59, 59, 55, 57, "USED-FOR"], [59, 59, 55, 57, "USED-FOR"]], [[81, 81, 74, 76, "USED-FOR"]], [], [], [[134, 134, 131, 131, "USED-FOR"], [136, 136, 139, 139, "USED-FOR"], [139, 140, 131, 131, "USED-FOR"], [142, 142, 139, 140, "USED-FOR"], [146, 147, 131, 131, "USED-FOR"], [149, 149, 139, 140, "USED-FOR"], [149, 149, 139, 139, "USED-FOR"], [139, 139, 131, 131, "USED-FOR"], [136, 136, 139, 139, "USED-FOR"], [142, 142, 139, 140, "USED-FOR"]], [], [[167, 167, 160, 162, "USED-FOR"]], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2211.07277-5e0b319e-ff54-4748-86c1-0e3a0027eac1", "sentences": [["We", "train", "convolutional", "neural", "networks", "-LRB-", "CNNs", "-RRB-", "and", "Vision", "Transformers", "-LRB-", "ViTs", "-RRB-", "using", "our", "methodology", "."], ["Among", "the", "CNN", "models", ",", "similar", "to", "-LSB-", "16", "-RSB-", ",", "we", "show", "results", "on", "ResNet50", ",", "ResNet101", ",", "and", "ResNet152", "."], ["For", "training", "the", "ResNet", "models", ",", "we", "supplemented", "ImageNet", "data", "with", "an", "equal", "number", "of", "augmented", "images", "."], ["We", "trained", "them", "for", "100", "epochs", "with", "a", "starting", "learning", "rate", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "which", "is", "reduced", "by", "a", "factor", "of", "10", "at", "the", "30th", ",", "60th", "and", "90th", "epoch", "."], ["Similar", "to", "TSD", ",", "while", "training", "the", "ResNet", "models", ",", "we", "also", "use", "auxiliary", "batch", "norm", "-LSB-", "23", "-RSB-", "."], ["As", "ViTs", "are", "compute-intensive", ",", "we", "finetune", "ImageNet", "pretrained", "ViT", "models", "for", "20k", "steps", "with", "a", "cosine", "learning", "rate", "schedule", "with", "a", "starting", "learning", "rate", "of", "\\", "-LRB-", "0.01\\", "-RRB-", "."], ["The", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "a", "momentum", "of", "\\", "-LRB-", "0.9\\", "-RRB-", "is", "used", "to", "train", "the", "models", "."], ["We", "train", "all", "our", "models", "on", "8", "A100", "GPUs", "with", "a", "batch", "size", "of", "512", "for", "ResNets", ",", "256", "for", "ViT-Small", "and", "ViT-Base", "and", "128", "for", "ViT-Large", "."], ["We", "find", "that", "values", "\\", "-LRB-", "\\alpha", "=4\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "=1\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\eta", "=0.65\\", "-RRB-", "produce", "the", "best", "results", "for", "all", "models", "."]], "ner": [[], [[33, 33, "a"], [35, 35, "a"], [38, 38, "a"]], [[48, 49, "a"], [55, 56, "a"]], [[67, 68, "p"], [72, 72, "v"], [67, 68, "p"], [72, 72, "v"], [67, 68, "p"], [72, 72, "v"]], [], [[128, 129, "p"], [134, 135, "p"], [139, 139, "v"], [128, 129, "p"], [134, 135, "p"], [139, 139, "v"], [128, 129, "p"], [134, 135, "p"], [139, 139, "v"], [118, 121, "a"], [127, 130, "a"]], [[151, 151, "p"], [155, 155, "v"], [151, 151, "p"], [155, 155, "v"], [151, 151, "p"], [155, 155, "v"]], [], [[198, 198, "p"], [199, 199, "v"], [204, 204, "p"], [205, 205, "v"], [211, 211, "p"], [212, 212, "v"], [198, 198, "p"], [199, 199, "v"], [204, 204, "p"], [205, 205, "v"], [211, 211, "p"], [212, 212, "v"], [198, 198, "p"], [199, 199, "v"], [204, 204, "p"], [205, 205, "v"], [211, 211, "p"], [212, 212, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 7, "a"], [9, 13, "a"], [16, 16, "a"]], [[33, 33, "a"], [35, 35, "a"], [38, 38, "a"]], [[43, 43, "a"], [48, 48, "a"]], [[62, 62, "v"], [63, 63, "p"], [67, 68, "p"], [72, 72, "v"], [81, 81, "v"], [86, 86, "v"], [88, 88, "v"]], [[93, 93, "a"], [98, 98, "a"]], [[112, 112, "a"], [118, 118, "a"], [123, 123, "v"], [124, 124, "p"], [134, 135, "p"], [139, 139, "v"]], [[143, 148, "a"], [155, 155, "v"]], [[170, 170, "v"], [171, 171, "v"], [175, 176, "p"], [178, 178, "v"], [180, 180, "a"], [182, 182, "v"], [184, 184, "a"], [186, 186, "a"], [188, 188, "v"], [190, 190, "a"]], [[199, 199, "v"], [204, 205, "p"], [212, 212, "v"]]], "predicted_relations": [[], [], [], [], [], [[128, 129, 118, 121, "USED-FOR"], [128, 129, 127, 130, "USED-FOR"], [134, 135, 127, 130, "USED-FOR"], [128, 129, 118, 121, "USED-FOR"], [128, 129, 127, 130, "USED-FOR"], [134, 135, 127, 130, "USED-FOR"], [128, 129, 118, 121, "USED-FOR"], [128, 129, 127, 130, "USED-FOR"], [134, 135, 127, 130, "USED-FOR"]], [], [], [[199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [199, 199, 198, 198, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [205, 205, 198, 198, "USED-FOR"], [205, 205, 204, 204, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"], [212, 212, 204, 204, "USED-FOR"], [212, 212, 211, 211, "USED-FOR"]]]}
{"doc_key": "2212.10179-7e8bf588-8041-4cfc-9829-aa627d682c8d", "sentences": [["We", "set", "\\", "-LRB-", "k=10\\", "-RRB-", "when", "applying", "the", "top-\\", "-LRB-", "k\\", "-RRB-", "sampling", "method", "to", "find", "candidate", "tokens", "."], ["For", "a", "fair", "comparison", ",", "we", "set", "the", "batch", "size", "to", "4", "for", "all", "experiments", "."]], "ner": [[[4, 4, "p"], [11, 11, "p"], [4, 4, "v"]], [[28, 29, "p"], [31, 31, "v"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "v"], [11, 11, "p"]], [[28, 29, "p"], [31, 31, "v"], [32, 34, "c"]]], "predicted_relations": [[[4, 4, 4, 4, "USED-FOR"], [4, 4, 4, 4, "USED-FOR"]], []]}
{"doc_key": "2209.11379-703deb31-902e-4b9e-a0f1-c036e00c8165", "sentences": [["Models", "are", "trained", "using", "Adam", "optimizer", "-LSB-", "13", "-RSB-", "with", "a", "fixed", "batch-size", "of", "1024", "."], ["En\\", "-LRB-", "\\rightarrow", "\\", "-RRB-", "-LCB-", "Zh", ",", "Fr", "-RCB-", "models", "are", "trained", "for", "530038", "steps", "while", "the", "rest", "of", "models", "-LRB-", "due", "to", "smaller", "training", "data", "size", "-RRB-", "are", "trained", "for", "397529", "steps", "."], ["For", "all", "the", "runs", ",", "we", "use", "40K", "steps", "of", "linear", "warm-up", "and", "then", "use", "a", "learning", "rate", "schedule", "of", "the", "form", "\\", "-LRB-", "\\frac", "-LCB-", "\\eta", "-RCB-", "-LCB-", "\\sqrt", "-LCB-", "t", "-RCB-", "-RCB-", ",", "\\qquad", "\\eta", ":", "\\mbox", "-LCB-", "base", "learning", "rate", ",", "-RCB-", "\\qquad", "t", ":", "\\mbox", "-LCB-", "training", "step", "."], ["-RCB-", "\\", "-RRB-"]], "ner": [[[4, 5, "a"], [12, 12, "p"], [14, 14, "v"]], [], [[67, 69, "p"]], []], "relations": [[], [], [], []], "predicted_ner": [[[4, 4, "a"], [12, 12, "p"], [14, 14, "v"]], [[30, 30, "v"], [48, 48, "v"]], [[58, 58, "v"], [61, 62, "a"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2209.11379-32e0a46a-d4a1-449c-92f6-980d3aaf664f", "sentences": [["For", "each", "model", "run", ",", "we", "sweep", "for", "\\", "-LRB-", "\\eta", "\\", "-RRB-", "in", "the", "grid", "\\", "-LRB-", "\\lbrace", "0.05", ",", "0.1", ",", "0.5", ",", "1.0", ",", "2.5", ",", "5.0\\rbrace", "\\", "-RRB-", "."], ["Often", "times", ",", "\\", "-LRB-", "\\eta", "=", "0.5\\", "-RRB-", "yields", "the", "optimal", "performance", "and", "\\", "-LRB-", "\\eta", "=", "5.0\\", "-RRB-", "diverges", "."], ["For", "sampling", "experiments", ",", "we", "sweep", "the", "rate", "for", "En\\", "-LRB-", "\\rightarrow", "\\", "-RRB-", "Fr", "in", "the", "grid", "\\", "-LRB-", "\\lbrace", "i", "/", "10", "\\rbrace", "_", "-LCB-", "i=1", "-RCB-", "^9\\", "-RRB-", "."], ["This", "determines", "the", "rate", "for", "the", "other", "language", "pair", "automatically", "."], ["As", "such", ",", "to", "derive", "each", "scalarization", "front", ",", "we", "train", "a", "total", "of", "54", "models", "."]], "ner": [[[2, 2, "a"], [10, 10, "p"], [19, 19, "v"], [21, 21, "v"], [23, 23, "v"], [25, 25, "v"], [27, 27, "v"], [29, 29, "v"]], [[38, 38, "p"], [49, 49, "p"], [40, 40, "v"], [51, 51, "v"]], [[56, 57, "a"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[40, 40, "v"], [51, 51, "v"]], [], [], [[112, 112, "v"]]], "predicted_relations": [[[10, 10, 2, 2, "USED-FOR"]], [[40, 40, 38, 38, "USED-FOR"], [51, 51, 49, 49, "USED-FOR"]], [], [], []]}
{"doc_key": "2209.11379-93da7c2b-3b93-4ffb-a0fc-ff44a5ef7280", "sentences": [["When", "examining", "the", "generalization", "performance", "-LRB-", "left", "hand", "side", "of", "Figures", "REF", ",", "REF", ",", "and", "REF", "-RRB-", "we", "use", "early", "stopping", ":", "we", "evaluate", "the", "model", "every", "5000", "steps", "and", "use", "the", "step", "that", "yields", "the", "smallest", "average", "validation", "loss", "for", "the", "two", "tasks", "."], ["For", "En\\", "-LRB-", "\\rightarrow", "\\", "-RRB-", "-LCB-", "Zh", ",", "Fr", "-RCB-", "and", "En\\", "-LRB-", "\\rightarrow", "\\", "-RRB-", "-LCB-", "De", ",", "Fr", "-RCB-", "models", ",", "it", "is", "often", "the", "case", "that", "the", "final", "step", "is", "the", "optimal", "step", "."], ["As", "such", "early", "stopping", "does", "n't", "significantly", "change", "the", "picture", "."], ["For", "En\\", "-LRB-", "\\rightarrow", "\\", "-RRB-", "-LCB-", "Ro", ",", "Fr", "-RCB-", ",", "performance", "statistics", "change", "noticeably", "with", "early", "stopping", "but", "the", "overall", "qualitative", "picture", "remains", "the", "same", "."], ["For", "the", "training", "performance", "-LRB-", "right", "hand", "side", "of", "Figures", "REF", ",", "REF", ",", "and", "REF", "-RRB-", "we", "report", "the", "final", "step", "training", "statistics", "."]], "ner": [[], [], [], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[20, 21, "a"], [28, 28, "v"], [43, 43, "v"]], [], [[86, 87, "a"]], [], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2210.10246-8667dd40-20ef-4a8e-98cb-2edd24524d81", "sentences": [["We", "also", "evaluate", "on", "other", "hardware", "platforms", "as", "well", "as", "model", "parameters", "."], ["First", ",", "we", "use", "an", "increased", "hidden", "layer", "size", "for", "various", "configurations", "."], ["These", "experiments", "are", "conducted", "on", "a", "platform", "with", "an", "NVIDIA", "A100", "GPU", "-LSB-", "42", "-RSB-", "across", "sequence", "lengths", "of", "128", "and", "512", "."], ["We", "maintain", "the", "hidden", "layer", "size", "\\", "-LRB-", "H\\", "-RRB-", "to", "the", "number", "of", "attention", "heads", "\\", "-LRB-", "A\\", "-RRB-", "ratio", "of", "64", "which", "is", "in", "line", "with", "prior", "works", "-LSB-", "62", "-RSB-", ",", "-LSB-", "11", "-RSB-", "."], ["The", "results", "are", "shown", "in", "Figure", "REF", "."], ["The", "figure", "demonstrates", "two", "important", "generalizations", "of", "Tempo", "."], ["First", ",", "note", "that", "even", "on", "newer", "and", "more", "advanced", "GPUs", ",", "Tempo", "continues", "to", "provide", "a", "tangible", "benefit", "."], ["Second", ",", "across", "larger", "hidden", "layer", "sizes", "Tempo", "consistently", "demonstrates", "a", "clear", "improvement", "over", "the", "baseline", "-LRB-", "as", "shown", "in", "the", "figure", ",", "this", "can", "be", "as", "high", "as", "a", "39", "%", "speedup", "over", "Baseline", "which", "corresponds", "to", "a", "16", "%", "speedup", "over", "Checkpoint", "-RRB-", "."], ["The", "speedup", "over", "Checkpoint", "is", "as", "high", "as", "20", "%", "."], ["We", "conclude", "that", "Tempo", "will", "continue", "to", "be", "applicable", "to", "new", "hardware", "and", "larger", "models", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[], [[19, 21, "p"]], [[35, 37, "a"], [45, 45, "v"], [47, 47, "v"]], [[52, 54, "p"], [71, 71, "v"], [61, 64, "p"]], [], [[102, 102, "a"]], [[116, 116, "a"]], [[131, 131, "a"]], [], [[184, 184, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[45, 45, "v"], [47, 47, "v"]], [[71, 71, "v"]], [], [[98, 98, "v"], [102, 102, "a"]], [], [[154, 155, "v"], [163, 164, "v"]], [[178, 179, "v"]], [[184, 184, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2210.10246-df185d22-43ce-4fb5-845c-d736d04845bb", "sentences": [["We", "also", "conduct", "experiments", "on", "BERT\\", "-LRB-", "_", "-LCB-", "LARGE", "-RCB-", "\\", "-RRB-", "-LRB-", "modified", "to", "use", "12", "Layers", "instead", "of", "24", "for", "more", "data", "points", "-RRB-", "for", "sequence", "lengths", "larger", "than", "512", "."], ["Figure", "REF", "shows", "the", "results", "for", "this", "experiment", ",", "where", "we", "demonstrate", "that", "Tempo", "outperforms", "Baseline", "on", "longer", "sequence", "lengths", "as", "well", "which", "can", "be", "as", "high", "as", "a", "27", "%", "speedup", "over", "Baseline", "."], ["At", "the", "same", "settings", ",", "we", "observe", "16", "%", "speedup", "over", "Checkpoint", "."], ["Tempo", "also", "outperforms", "Checkpoint", "by", "as", "much", "as", "20", "%", "."], ["We", "conclude", "that", "yet", "again", "Tempo", "will", "be", "able", "to", "take", "advantage", "of", "modern", "hardware", ",", "as", "well", "as", "remain", "advantageous", "as", "sequence", "lengths", "increase", "."], ["Note", "that", "the", "largest", "sequence", "length", "of", "3072", "on", "Baseline", "does", "not", "have", "enough", "memory", "to", "run", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[18, 18, "p"], [17, 17, "v"]], [[47, 47, "a"], [49, 49, "a"], [67, 67, "a"]], [[80, 80, "a"]], [[82, 82, "a"], [85, 85, "a"]], [[98, 98, "a"]], [[128, 128, "a"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[17, 17, "v"], [18, 18, "p"], [21, 21, "v"], [32, 32, "v"]], [[47, 47, "a"], [63, 64, "v"]], [[76, 77, "v"]], [[82, 82, "a"], [90, 91, "v"]], [[98, 98, "a"]], [[126, 126, "v"]], []], "predicted_relations": [[[17, 17, 18, 18, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2202.06725-d789b565-c64e-4c77-be4f-7ae5bc7c3348", "sentences": [["We", "train", "our", "model", "for", "800k", "steps", "on", "the", "provided", "training", "data", "on", "a", "standard", "MSE", "loss", "using", "the", "ADAM", "optimizer", "-LSB-", "5", "-RSB-", "."], ["The", "learning", "rate", "schedule", "contains", "2k", "steps", "of", "warm-up", "."], ["After", "warm-up", ",", "the", "learning", "rate", "is", "\\", "-LRB-", "0.002\\", "-RRB-", "and", "decays", "from", "there", "exponentially", "at", "a", "rate", "of", "\\", "-LRB-", "0.98\\", "-RRB-", "every", "100", "steps", "."], ["The", "minimal", "learning", "rate", "is", "\\", "-LRB-", "0.0002\\", "-RRB-", "."], ["At", "each", "step", ",", "we", "sample", "valid", "starting", "frames", "for", "the", "seed", "sequences", "-LRB-", "model", "input", "-RRB-", ",", "which", "are", "frames", "that", "correspond", "to", "a", "time", "between", "00:00", "and", "22:00", "o'clock", "."], ["We", "take", "the", "average", "over", "the", "gradient", "of", "16", "successive", "samples", "to", "update", "the", "model", "parameters", "."], ["This", "effectively", "corresponds", "to", "taking", "a", "batch", "size", "of", "16", "."], ["We", "submitted", "the", "exact", "same", "model", "to", "both", "competitions", "."], ["Hence", ",", "we", "consider", "the", "temporal", "generalization", "problem", "from", "the", "core", "challenge", "as", "a", "kind", "of", "spatial", "generalization", "problem", "as", "well", "."], ["This", "is", "possible", "as", "data", "from", "2020", "is", "included", "in", "the", "training", "set", ",", "just", "for", "different", "cities", "than", "used", "in", "the", "evaluation", "."]], "ner": [[[15, 16, "a"], [19, 20, "a"]], [], [[57, 57, "v"]], [[70, 70, "v"]], [], [[113, 113, "v"]], [[128, 129, "p"], [131, 131, "v"], [128, 129, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "v"], [15, 16, "a"], [19, 19, "a"]], [[30, 30, "v"]], [[39, 40, "p"], [44, 44, "v"], [57, 57, "v"], [60, 60, "v"]], [[65, 66, "p"], [70, 70, "v"]], [[100, 100, "v"], [102, 102, "v"]], [[113, 113, "v"]], [[128, 129, "p"], [131, 131, "v"]], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2210.00430-b3c6e09b-d540-4b37-9fd4-553b3fea6de3", "sentences": [["On", "MNIST", ",", "we", "use", "LeNet5", "for", "the", "classifier", "and", "2", "layers", "MLP", "-LRB-", "with", "hidden", "size", "256", "and", "784", "-RRB-", "for", "the", "encoder", "and", "decoder", "of", "conditional", "VAE", "."], ["For", "standard", "training", "of", "the", "classifier", ",", "we", "use", "30", "epochs", ",", "batch", "size", "128", ",", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "and", "weight", "decay", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "CVAE", ",", "we", "use", "20", "epochs", ",", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "batch", "size", "64", ",", "and", "latent", "size", "10", "."], ["For", "standard", "adversarial", "training", "and", ",", "we", "use", "\\", "-LRB-", "\\varepsilon", "=0.3\\", "-RRB-", "for", "FGSM", "and", "PGD", "."], ["in", "PGD", ",", "we", "use", "40", "steps", "for", "the", "inner", "part", "."], ["Adversarial", "training", "start", "after", "10", "epochs", "standard", "training", "."], ["For", "generative", "adversarial", "training", ",", "we", "use", "\\", "-LRB-", "\\varepsilon", "=1\\", "-RRB-", "in", "the", "latent", "space", "with", "FGSM", "and", "PGD", "."], ["We", "use", "40", "steps", "PGD", "for", "latent", "space", "adversarial", "training", "."], ["Adversarial", "training", "start", "after", "10", "epoches", "standard", "training", "."], ["In", "the", "attack", "part", ",", "we", "use", "the", "same", "\\", "-LRB-", "\\varepsilon", "\\", "-RRB-", "as", "the", "adversarial", "training", "part", "."]], "ner": [[[5, 5, "a"], [12, 12, "a"], [19, 19, "v"]], [[31, 32, "a"], [42, 43, "p"]], [[90, 91, "p"], [95, 96, "p"], [72, 72, "a"]], [[113, 113, "a"], [115, 115, "a"]], [[122, 122, "v"], [123, 123, "p"], [118, 118, "a"]], [[135, 136, "a"]], [[155, 155, "a"], [157, 157, "a"], [139, 141, "a"]], [[161, 161, "v"], [162, 162, "p"], [163, 163, "a"]], [[176, 177, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "a"], [10, 10, "v"], [11, 11, "p"], [12, 12, "a"], [17, 17, "v"], [19, 19, "v"], [27, 28, "a"]], [[39, 39, "v"], [40, 40, "p"], [42, 43, "p"], [44, 44, "v"], [46, 47, "p"], [50, 53, "v"], [58, 59, "p"], [63, 66, "v"]], [[72, 72, "a"], [76, 76, "v"], [77, 77, "p"], [79, 80, "p"], [83, 86, "v"], [90, 91, "p"], [92, 92, "v"], [95, 96, "p"], [97, 97, "v"]], [[110, 110, "v"], [113, 113, "a"], [115, 115, "a"]], [[118, 118, "a"], [122, 122, "v"]], [[133, 133, "v"], [134, 134, "p"]], [[155, 155, "a"], [157, 157, "a"]], [[161, 161, "v"], [163, 163, "a"]], [[174, 174, "v"]], []], "predicted_relations": [[], [[42, 43, 31, 32, "USED-FOR"]], [[90, 91, 72, 72, "USED-FOR"], [95, 96, 72, 72, "USED-FOR"]], [], [[122, 122, 123, 123, "USED-FOR"]], [], [], [[161, 161, 162, 162, "USED-FOR"]], [], []]}
{"doc_key": "2210.00430-cb8d6292-de37-4fd5-8e05-a2742c885e9d", "sentences": [["On", "CIFAR-10", ",", "we", "use", "ResNet32", "for", "the", "classifier", "and", "4", "layers", "CNN", "for", "the", "encoder", "and", "decoder", "of", "conditional", "VAE", "."], ["For", "standard", "training", "of", "the", "classifier", ",", "we", "use", "200", "epochs", ",", "batch", "size", "128", "."], ["The", "learning", "rate", "schedule", "is", "0.1", "for", "the", "first", "100", "epochs", ",", "0.01", "for", "the", "following", "50", "epochs", ",", "and", "0.001", "for", "the", "last", "50", "epochs", "."], ["The", "weight", "decay", "is", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "CVAE", ",", "we", "use", "200", "epochs", ",", "learning", "rate", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "batch", "size", "64", ",", "and", "latent", "size", "128", "."]], "ner": [[[1, 1, "a"], [5, 5, "a"], [10, 12, "a"], [19, 20, "a"]], [[23, 24, "a"], [32, 32, "p"], [31, 31, "v"], [34, 35, "p"], [36, 36, "v"], [32, 32, "p"], [31, 31, "v"], [34, 35, "p"], [36, 36, "v"]], [[48, 48, "p"], [55, 55, "p"], [63, 63, "p"], [47, 47, "v"], [46, 46, "c"], [54, 54, "v"], [62, 62, "v"], [53, 53, "c"], [54, 54, "v"], [62, 62, "v"], [61, 61, "c"], [39, 40, "p"], [43, 43, "v"], [46, 46, "c"], [50, 50, "v"], [53, 53, "c"], [58, 58, "v"], [61, 61, "c"], [48, 48, "p"], [55, 55, "p"], [63, 63, "p"], [39, 40, "p"]], [[66, 67, "p"]], [[86, 86, "p"], [85, 85, "v"], [99, 100, "p"], [106, 106, "v"], [101, 101, "v"], [88, 89, "p"], [81, 81, "a"], [86, 86, "p"], [85, 85, "v"], [88, 89, "p"], [99, 100, "p"], [101, 101, "v"], [104, 105, "p"], [106, 106, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "a"], [10, 10, "v"], [11, 11, "p"], [12, 12, "a"], [19, 20, "a"]], [[31, 31, "v"], [32, 32, "p"], [34, 35, "p"], [36, 36, "v"]], [[43, 43, "v"], [47, 47, "v"], [48, 48, "p"], [50, 50, "v"], [54, 54, "v"], [55, 55, "p"], [58, 58, "v"], [62, 62, "v"], [63, 63, "p"]], [[66, 67, "p"], [72, 74, "v"]], [[81, 81, "a"], [85, 85, "v"], [86, 86, "p"], [88, 89, "p"], [92, 95, "v"], [99, 100, "p"], [101, 101, "v"], [104, 105, "p"], [106, 106, "v"]]], "predicted_relations": [[], [[32, 32, 23, 24, "USED-FOR"], [31, 31, 32, 32, "USED-FOR"], [31, 31, 32, 32, "USED-FOR"], [34, 35, 23, 24, "USED-FOR"], [36, 36, 32, 32, "USED-FOR"], [36, 36, 32, 32, "USED-FOR"], [32, 32, 23, 24, "USED-FOR"], [31, 31, 32, 32, "USED-FOR"], [31, 31, 32, 32, "USED-FOR"], [34, 35, 23, 24, "USED-FOR"], [36, 36, 32, 32, "USED-FOR"], [36, 36, 32, 32, "USED-FOR"]], [[47, 47, 48, 48, "USED-FOR"], [47, 47, 55, 55, "USED-FOR"], [47, 47, 48, 48, "USED-FOR"], [47, 47, 55, 55, "USED-FOR"], [54, 54, 48, 48, "USED-FOR"], [54, 54, 55, 55, "USED-FOR"], [54, 54, 63, 63, "USED-FOR"], [54, 54, 48, 48, "USED-FOR"], [54, 54, 55, 55, "USED-FOR"], [54, 54, 63, 63, "USED-FOR"], [62, 62, 55, 55, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [62, 62, 55, 55, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [53, 53, 50, 50, "USED-FOR"], [53, 53, 58, 58, "USED-FOR"], [54, 54, 48, 48, "USED-FOR"], [54, 54, 55, 55, "USED-FOR"], [54, 54, 63, 63, "USED-FOR"], [54, 54, 48, 48, "USED-FOR"], [54, 54, 55, 55, "USED-FOR"], [54, 54, 63, 63, "USED-FOR"], [62, 62, 55, 55, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [62, 62, 55, 55, "USED-FOR"], [62, 62, 63, 63, "USED-FOR"], [43, 43, 48, 48, "USED-FOR"], [43, 43, 48, 48, "USED-FOR"], [50, 50, 55, 55, "USED-FOR"], [50, 50, 55, 55, "USED-FOR"], [53, 53, 50, 50, "USED-FOR"], [53, 53, 58, 58, "USED-FOR"], [58, 58, 63, 63, "USED-FOR"], [58, 58, 63, 63, "USED-FOR"]], [], [[86, 86, 81, 81, "USED-FOR"], [85, 85, 86, 86, "USED-FOR"], [85, 85, 86, 86, "USED-FOR"], [99, 100, 81, 81, "USED-FOR"], [101, 101, 104, 105, "USED-FOR"], [88, 89, 81, 81, "USED-FOR"], [86, 86, 81, 81, "USED-FOR"], [85, 85, 86, 86, "USED-FOR"], [85, 85, 86, 86, "USED-FOR"], [88, 89, 81, 81, "USED-FOR"], [99, 100, 81, 81, "USED-FOR"], [101, 101, 104, 105, "USED-FOR"], [104, 105, 81, 81, "USED-FOR"]]]}
{"doc_key": "2210.00430-8f88efce-66c3-4d16-a9d3-9fa8fe9ea0ff", "sentences": [["For", "standard", "adversarial", "training", ",", "we", "use", "\\", "-LRB-", "\\varepsilon", "=8/255\\", "-RRB-", "for", "FGSM", "and", "PGD", "."], ["in", "PGD", ",", "we", "use", "10", "steps", "for", "the", "inner", "part", "."], ["For", "generative", "adversarial", "training", ",", "we", "use", "\\", "-LRB-", "\\varepsilon", "=0.1\\", "-RRB-", "in", "the", "latent", "space", "with", "FGSM", "and", "PGD", "."], ["Since", "we", "see", "that", "the", "modeling", "power", "of", "VAE", "in", "CIFAR10", "is", "not", "good", "enough", "."], ["For", "each", "of", "the", "image", ",", "the", "encode", "variance", "is", "very", "small", "."], ["When", "we", "add", "a", "small", "perturbation", "to", "the", "encode", "mean", "value", ",", "the", "output", "image", "are", "blured", "."], ["Hence", "we", "only", "use", "a", "small", "\\", "-LRB-", "\\varepsilon", "=0.1\\", "-RRB-", "."], ["In", "the", "attack", "part", ",", "we", "use", "\\", "-LRB-", "\\varepsilon", "=8/255\\", "-RRB-", "for", "norm-based", "attacks", "and", "\\", "-LRB-", "\\varepsilon", "=0.1\\", "-RRB-", "for", "generative", "attack", "on", "the", "test", "set", "."]], "ner": [[[10, 10, "v"], [13, 15, "c"], [10, 10, "v"], [15, 15, "c"]], [[23, 23, "p"], [22, 22, "v"], [18, 18, "c"]], [[46, 48, "c"], [39, 39, "v"], [39, 39, "v"], [48, 48, "c"]], [], [], [], [[106, 106, "v"], [106, 106, "v"]], [[119, 119, "v"], [128, 128, "v"], [119, 119, "v"], [128, 128, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[18, 18, "a"], [22, 22, "v"]], [[39, 39, "v"]], [[58, 58, "a"], [60, 60, "a"]], [], [], [], []], "predicted_relations": [[[13, 15, 10, 10, "USED-FOR"], [13, 15, 10, 10, "USED-FOR"]], [[22, 22, 23, 23, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2201.04684-48c0bd32-ddb6-4632-a1ca-e83bcbf87e76", "sentences": [["For", "all", "the", "baselines", "and", "our", "methods", ",", "we", "use", "DeepLab-v3", "-LSB-", "8", "-RSB-", "with", "Resnet-50", "-LSB-", "29", "-RSB-", "as", "the", "image", "backbone", "model", "."], ["We", "use", "the", "SGD", "optimizer", "with", "learning", "rate", "\\", "-LRB-", "0.01\\", "-RRB-", ",", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "weight-decay", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["We", "use", "polynomial", "learning", "rate", "decay", "with", "power", "\\", "-LRB-", "0.9\\", "-RRB-", "."], ["We", "use", "batch", "size", "64", "for", "all", "tasks", "and", "train", "for", "200", "epochs", "."], ["For", "augmentation", ",", "we", "use", "random", "resize", "with", "scales", "from", "\\", "-LRB-", "0.5-2.0\\", "-RRB-", "."], ["random", "crop", "and", "random", "horizontal", "filp", "."], ["We", "use", "resolution", "224", "for", "both", "training", "and", "testing", "."], ["When", "training", "with", "our", "synthetic", "dataset", ",", "we", "use", "the", "same", "training", "schedule", "and", "augmentation", "policy", "as", "described", "here", "."]], "ner": [[[10, 10, "a"], [15, 15, "a"]], [[28, 29, "a"], [31, 32, "p"], [35, 35, "v"], [38, 38, "p"], [41, 41, "v"], [44, 44, "p"], [47, 47, "v"], [41, 41, "v"]], [[53, 54, "p"], [60, 60, "v"], [52, 55, "a"], [57, 57, "p"], [60, 60, "v"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[10, 10, "a"], [15, 15, "a"]], [[28, 28, "a"], [31, 32, "p"], [35, 35, "v"], [38, 38, "p"], [41, 41, "v"], [44, 44, "p"], [47, 47, "v"]], [[57, 57, "p"], [60, 60, "v"]], [[65, 66, "p"], [67, 67, "v"], [68, 70, "c"], [74, 74, "v"], [75, 75, "p"]], [[82, 83, "a"], [85, 85, "p"], [89, 89, "v"]], [[97, 97, "a"]], [[101, 101, "p"], [102, 102, "v"]], []], "predicted_relations": [[], [[31, 32, 28, 29, "USED-FOR"], [38, 38, 28, 29, "USED-FOR"], [44, 44, 28, 29, "USED-FOR"], [47, 47, 44, 44, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2211.05295-e08e46ab-2f46-4c3d-acf4-c7cc99ccfbf1", "sentences": [["For", "hardware", ",", "a", "Linux", "station", "composed", "of", "I7", "12700K", "CPU", "and", "two", "24G", "RTX3090Ti", "GPUs", "is", "used", "in", "this", "research", "for", "training", "."], ["Pytorch", "is", "used", "as", "framework", "."], ["We", "use", "stochastic", "gradient", "descent", "as", "the", "optimizer", "with", "the", "initial", "learning", "rate", "\\", "-LRB-", "0.01\\", "-RRB-", ",", "the", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "batch", "size", "32", "."], ["The", "experiments", "set", "a", "fixed", "random", "seed", ",", "and", "all", "training", "datasets", "are", "augmented", "-LRB-", "flip", ",", "contrast", ",", "brightness", ",", "saturation", "-RRB-", "."], ["The", "models", "are", "trained", "50", "epochs", ",", "and", "every", "5", "epochs", "the", "validation", "datasets", "is", "tested", "and", "\\", "-LRB-", "IoU\\", "-RRB-", ",", "\\", "-LRB-", "PA\\", "-RRB-", "and", "\\", "-LRB-", "OII\\", "-RRB-", "are", "estimated", "."], ["All", "following", "experiments", "are", "performed", "with", "the", "same", "configuration", "."]], "ner": [[], [], [[45, 45, "v"], [52, 52, "v"], [57, 57, "v"]], [], [[102, 102, "a"], [107, 107, "a"], [112, 112, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[8, 9, "v"], [12, 12, "v"], [13, 13, "v"]], [[24, 24, "a"]], [[32, 34, "a"], [41, 42, "p"], [45, 45, "v"], [49, 49, "p"], [52, 52, "v"], [55, 56, "p"], [57, 57, "v"]], [], [[87, 87, "v"], [88, 88, "p"], [92, 92, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2211.02077-6b674cf1-3cc1-45e9-8638-05ac0a0bf5dc", "sentences": [["Network", "Architecture", ":", "For", "all", "of", "our", "experiments", ",", "we", "use", "modality-agnostic", "Transformer", "variant", "in", "-LSB-", "10", "-RSB-", ",", "VATT-MA-Medium", "."], ["Specifically", ",", "we", "use", "a", "12-layer", "Transformer", ",", "in", "which", "each", "layer", "has", "a", "feed-forward", "MLP", "with", "hidden", "size", "of", "4096", ",", "and", "16", "attention", "heads", "with", "a", "hidden", "size", "of", "1024", "."]], "ner": [[[12, 13, "a"]], [[38, 39, "p"], [49, 50, "p"], [41, 41, "v"], [52, 52, "v"], [45, 46, "p"], [44, 44, "v"]]], "relations": [[], []], "predicted_ner": [[], [[26, 26, "v"], [35, 36, "a"], [41, 41, "v"], [44, 44, "v"], [52, 52, "v"]]], "predicted_relations": [[], [[41, 41, 38, 39, "USED-FOR"], [52, 52, 49, 50, "USED-FOR"], [44, 44, 45, 46, "USED-FOR"]]]}
{"doc_key": "2211.02077-2afff1c3-9c14-469b-a952-1fa5db145bfe", "sentences": [["Pre-training", "Hyperparameter", ":", "We", "strictly", "follow", "the", "setting", "in", "-LSB-", "10", "-RSB-", ",", "pre-training", "VATT", "from", "scratch", "with", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "1e-4", ",", "10k", "warmup", "steps", ",", "500k", "steps", "in", "total", ",", "a", "batch", "size", "of", "2048", "and", "using", "a", "cosine", "learning", "rate", "scheduler", "to", "anneal", "the", "learning", "rate", "from", "1e-4", "to", "5e-5", "."], ["Our", "framework", "is", "implemented", "in", "Tensorflow", "2.8", ",", "and", "train", "with", "256", "TPUV3s", ",", "it", "took", "a", "total", "of", "3", "days", "to", "train", "our", "models", "."]], "ner": [[[18, 19, "a"], [22, 24, "p"], [26, 26, "v"], [55, 55, "v"], [29, 30, "p"], [28, 28, "v"], [32, 32, "v"], [38, 39, "p"], [41, 41, "v"], [46, 48, "p"], [45, 45, "v"], [14, 14, "a"], [13, 13, "a"]], [[64, 65, "a"]]], "relations": [[], []], "predicted_ner": [[[14, 14, "a"], [18, 18, "a"], [23, 24, "p"], [26, 26, "v"], [28, 28, "v"], [29, 30, "p"], [32, 32, "v"], [38, 39, "p"], [41, 41, "v"], [52, 53, "p"], [55, 57, "v"]], [[60, 60, "a"], [70, 70, "v"], [71, 71, "a"], [78, 78, "v"]]], "predicted_relations": [[[22, 24, 18, 19, "USED-FOR"], [22, 24, 14, 14, "USED-FOR"], [22, 24, 13, 13, "USED-FOR"], [26, 26, 22, 24, "USED-FOR"], [26, 26, 29, 30, "USED-FOR"], [55, 55, 46, 48, "USED-FOR"], [29, 30, 18, 19, "USED-FOR"], [29, 30, 14, 14, "USED-FOR"], [29, 30, 13, 13, "USED-FOR"], [28, 28, 22, 24, "USED-FOR"], [28, 28, 29, 30, "USED-FOR"], [32, 32, 29, 30, "USED-FOR"], [38, 39, 18, 19, "USED-FOR"], [38, 39, 14, 14, "USED-FOR"], [38, 39, 13, 13, "USED-FOR"], [41, 41, 29, 30, "USED-FOR"], [41, 41, 38, 39, "USED-FOR"], [46, 48, 14, 14, "USED-FOR"], [45, 45, 29, 30, "USED-FOR"]], []]}
{"doc_key": "2211.02100-33786e38-34dd-4216-a40a-8c0b0a4ef7d1", "sentences": [["When", "pretraining", "CVL", ",", "we", "first", "optimize", "the", "critic", "on", "unlabeled", "data", "from", "dataset", "for", "all", "the", "semantically", "related", "tasks", ",", "i.e", "."], ["tasks", "which", "belong", "to", "the", "same", "domain", ",", "and", "then", "finetune", "both", "the", "critic", "and", "the", "policy", "on", "reward-labeled", "data", "from", "the", "target", "task", "."], ["Semantically", "related", "tasks", "in", "MetaWorld", "are", "easily", "identifiable", "by", "their", "domain", "name", ",", "e.g", "."], ["drawer-open", "and", "drawer-close", "belong", "to", "the", "drawer", "domain", "."], ["We", "use", "a", "similar", "approach", "when", "pretraining", "CQL+UDS", ",", "where", "we", "perform", "TD", "updates", "with", "all", "rewards", "equal", "to", "0", "during", "the", "pretraining", "phase", "."]], "ner": [[[2, 2, "a"]], [], [], [], [[79, 79, "a"], [84, 85, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [], [], [[63, 63, "a"], [65, 65, "a"], [69, 69, "a"]], [[79, 79, "a"], [84, 85, "a"], [91, 91, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2211.07371-4b7d1ab0-06e0-4d16-9262-e82a9d2e03ed", "sentences": [["The", "network", "architecture", "of", "the", "encoder", "model", "is", "ResNet-50", "-LSB-", "18", "-RSB-", ",", "which", "is", "one", "of", "the", "widely", "used", "architectures", "in", "recent", "SOTA", "FR", "-LSB-", "13", "-RSB-", ",", "-LSB-", "0", "-RSB-", ",", "-LSB-", "22", "-RSB-", ",", "-LSB-", "3", "-RSB-", "."], ["Following", "-LSB-", "17", "-RSB-", ",", "the", "momentum", "encoder", "is", "updated", "with", "a", "momentum", "coefficient", "of", "0.999", "-LSB-", "17", "-RSB-", "and", "the", "temperature", "value", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "of", "contrastive", "loss", "is", "set", "to", "0.07", "-LSB-", "17", "-RSB-", "."], ["The", "feature", "representation", "dimensions", "is", "initially", "set", "to", "512-D", "in", "the", "results", "presented", "in", "Sections", "REF", ",", "REF", ",", "REF", "."], ["Later", ",", "in", "Section", "REF", "we", "present", "an", "ablation", "study", "on", "the", "optimal", "feature", "representation", "dimensions", "of", "128", ",", "256", ",", "512", ",", "and", "1024-D", "."], ["The", "queue", "size", "is", "set", "to", "32768", "based", "on", "sensitivity", "study", "presented", "in", "Section", "REF", "."], ["An", "optimizer", "Stochastic", "Gradient", "Descent", "-LRB-", "SGD", "-RRB-", "is", "used", "with", "initial", "learning", "rate", "of", "0.1", "."], ["The", "momentum", "is", "set", "to", "0.9", "and", "the", "weight", "decay", "to", "5e-4", "."], ["The", "learning", "rate", "is", "divided", "by", "10", "after", "8", ",", "16", ",", "24", ",", "and", "32", "epochs", "."], ["The", "models", "presented", "in", "Sections", "REF", ",", "REF", ",", "REF", ",", "REF", "are", "trained", "for", "40", "epochs", "in", "total", "with", "a", "batch", "size", "of", "512", "on", "100K", "synthetic", "images", "."], ["All", "models", "are", "implemented", "using", "PyTorch", "-LSB-", "27", "-RSB-", "and", "trained", "on", "two", "CPU", "16", "core", "Intel", "Xeon", "Gold", "5218", "and", "four", "NVIDIA", "Quadro", "RTX6000", "GPUs", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[8, 8, "a"]], [[47, 48, "a"], [70, 71, "a"], [47, 47, "p"], [53, 53, "p"]], [], [], [], [[154, 156, "p"]], [[171, 171, "v"], [161, 161, "p"], [168, 169, "p"]], [], [], [[226, 226, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"], [15, 15, "v"]], [[47, 48, "p"], [53, 54, "p"], [56, 56, "v"], [62, 63, "p"], [70, 71, "a"], [75, 75, "v"]], [[88, 88, "v"]], [[118, 118, "v"], [120, 120, "v"], [122, 122, "v"], [125, 125, "v"]], [[128, 129, "p"], [133, 133, "v"]], [[145, 150, "a"], [155, 156, "p"], [158, 158, "v"]], [[165, 165, "v"], [168, 169, "p"], [171, 171, "v"]], [[174, 175, "p"], [179, 179, "v"], [181, 181, "v"], [183, 183, "v"], [185, 185, "v"], [188, 188, "v"], [189, 189, "p"]], [[206, 206, "v"], [207, 207, "p"], [212, 213, "p"], [215, 215, "v"], [217, 217, "v"]], [[226, 226, "a"], [233, 233, "v"], [235, 235, "v"], [242, 242, "v"]], []], "predicted_relations": [[], [[53, 53, 47, 48, "USED-FOR"]], [], [], [], [], [[171, 171, 168, 169, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2211.04198-4c3cf3a5-a3bd-460d-bf19-49f1af926610", "sentences": [["We", "fine-tune", "XLM", "and", "mBERT", "models", "for", "10", "epochs", "over", "the", "parallel", "fine-tuning", "corpus", "for", "each", "language", "pair", ",", "with", "a", "batch", "size", "of", "8", "."], ["We", "use", "AdamW", "-LSB-", "23", "-RSB-", "with", "learning", "rate", "of", "1e-5", "."], ["The", "dropout", "rate", "is", "set", "to", "0.1", "."], ["The", "training", "process", "typically", "takes", "2", "to", "3", "hours", "."], ["The", "hyper-parameters", "are", "tuned", "based", "on", "the", "development", "set", "performances", "."], ["Regarding", "the", "threshold", "\\", "-LRB-", "c\\", "-RRB-", "in", "the", "word", "alignment", "prediction", ",", "it", "is", "set", "to", "1e-6", "for", "Ro-En", "and", "0.1", "for", "the", "others", "."], ["Regarding", "the", "hyper-parameters", "in", "integrating", "the", "various", "third-party", "supervisions", ",", "\\", "-LRB-", "f\\", "-RRB-", "is", "set", "to", "0.45", "and", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "set", "to", "0.5", "for", "all", "language", "pairs", "."]], "ner": [[[2, 2, "a"], [4, 4, "a"]], [[28, 28, "a"], [33, 34, "p"], [36, 36, "v"]], [[39, 40, "a"], [39, 40, "p"], [44, 44, "v"], [44, 44, "v"]], [], [[57, 57, "a"]], [[88, 88, "v"], [84, 84, "v"], [86, 86, "c"], [88, 88, "v"], [91, 91, "c"]], [[95, 95, "a"], [105, 105, "p"], [110, 110, "v"], [114, 114, "p"], [120, 120, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [7, 7, "v"], [8, 8, "p"], [21, 22, "p"], [24, 24, "v"]], [[28, 28, "a"], [33, 34, "p"], [36, 36, "v"]], [[39, 40, "p"], [44, 44, "v"]], [[51, 51, "v"], [53, 53, "v"]], [], [[72, 72, "p"], [84, 84, "v"], [86, 86, "a"], [88, 88, "v"]], [[110, 110, "v"], [114, 114, "p"], [120, 120, "v"]]], "predicted_relations": [[], [[33, 34, 28, 28, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"]], [[39, 40, 39, 40, "USED-FOR"], [44, 44, 39, 40, "USED-FOR"], [44, 44, 39, 40, "USED-FOR"]], [], [], [[91, 91, 88, 88, "USED-FOR"], [91, 91, 88, 88, "USED-FOR"]], [[105, 105, 95, 95, "USED-FOR"], [110, 110, 114, 114, "USED-FOR"], [114, 114, 95, 95, "USED-FOR"]]]}
{"doc_key": "2209.15270-ff3426b3-68d7-47b3-983a-2eaac805f141", "sentences": [["We", "build", "our", "Chinese", "model", "following", "the", "similar", "settings", "except", "initializing", "the", "textual", "encoder", "with", "ERNIE", "-LSB-", "32", "-RSB-", ",", "-LSB-", "33", "-RSB-", ",", "-LSB-", "34", "-RSB-", "and", "training", "with", "a", "total", "batch", "size", "of", "23200", "."], ["Besides", ",", "we", "explore", "another", "visual", "backbone", "widely", "used", "in", "VLP", "-LRB-", "i.e.", ",", "Vision", "Transformer", "-LRB-", "ViT", "-RRB-", "-LSB-", "35", "-RSB-", "-RRB-", "as", "our", "image", "encoder", "-LRB-", "the", "details", "in", "Appendix", "-RRB-", "."]], "ner": [[[15, 15, "a"]], []], "relations": [[], []], "predicted_ner": [[[3, 4, "a"], [15, 15, "a"], [32, 33, "p"], [35, 35, "v"]], [[51, 55, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2209.15301-9cf40e3e-2c40-421d-8578-37761d093f3a", "sentences": [["We", "adopt", "the", "BART", "encoder-decoder", "model", "-LSB-", "23", "-RSB-", ",", "as", "it", "set", "a", "state", "of", "the", "art", "in", "abstractive", "summarization", "benchmarks", "."], ["We", "train", "our", "model", "using", "the", "HuggingFace", "implementation", "-LSB-", "36", "-RSB-", ",", "on", "a", "learning", "rate", "of", "\\", "-LRB-", "2", "\\cdot", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "."], ["The", "question", "matching", "pool", "retrieved", "by", "TF-IDF", "is", "comprised", "of", "\\", "-LRB-", "k", "=", "32\\", "-RRB-", "knowledge", "base", "FAQs", "."], ["Our", "answer", "selection", "loss", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_\\mathrm", "-LCB-", "sel", "-RCB-", "\\", "-RRB-", "is", "optimized", "to", "select", "up", "to", "\\", "-LRB-", "n", "=", "3\\", "-RRB-", "sentences", "."], ["We", "use", "\\", "-LRB-", "\\lambda", "=", "0.01\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "=", "0.01\\", "-RRB-", "as", "weights", "for", "the", "self-supervised", "losses", "."], ["The", "BART", "encoder", "is", "used", "for", "embedding", "sentences", "for", "question", "matching", "and", "answer", "selection", "."]], "ner": [[[3, 5, "a"]], [[29, 30, "a"]], [[57, 57, "a"], [63, 63, "p"], [65, 65, "v"]], [[72, 74, "a"], [95, 95, "p"], [97, 97, "v"]], [[105, 105, "p"], [107, 107, "v"], [114, 114, "v"], [112, 112, "p"], [107, 107, "v"], [114, 114, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 5, "a"]], [[26, 26, "a"], [37, 38, "p"], [42, 42, "v"]], [[63, 63, "p"], [63, 65, "v"]], [[95, 97, "v"]], [[107, 107, "v"], [114, 114, "v"]], [[124, 124, "a"]]], "predicted_relations": [[], [], [[63, 63, 57, 57, "USED-FOR"], [65, 65, 63, 63, "USED-FOR"]], [], [], []]}
{"doc_key": "2209.15301-be6d8dcc-cb8b-43bf-93a3-8ccf0ce4ad55", "sentences": [["We", "train", "for", "50", "epochs", "for", "MeQSum", ",", "and", "20", "epochs", "for", "HealthCareMagic", "."], ["Each", "training", "epoch", "takes", "about", "10", "minutes", "for", "MeQSum", ",", "and", "about", "35", "minutes", "for", "HealthCareMagic", "."], ["Inference", "takes", "1", "minute", "for", "the", "MeQSum", "test", "set", "and", "3", "minutes", "for", "the", "HealthCareMagic", "test", "set", "."], ["The", "best", "checkpoint", "is", "selected", "based", "on", "the", "lowest", "loss", "value", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "\\", "-RRB-", "on", "the", "dev", "set", "."]], "ner": [[[6, 6, "a"], [12, 12, "a"], [3, 3, "v"], [6, 6, "c"], [9, 9, "v"], [12, 12, "c"]], [[22, 22, "a"], [29, 29, "a"], [15, 16, "a"], [22, 22, "c"], [29, 29, "c"]], [[37, 37, "a"], [45, 45, "a"], [37, 37, "c"], [45, 45, "c"], [33, 34, "v"], [37, 39, "c"], [41, 42, "v"], [45, 47, "c"]], [[57, 59, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 3, "v"], [4, 4, "p"], [6, 6, "a"], [9, 9, "v"], [10, 10, "p"], [12, 12, "a"]], [[19, 19, "v"], [22, 22, "a"], [26, 26, "v"], [29, 29, "a"]], [[33, 33, "v"], [37, 37, "a"], [41, 41, "v"], [45, 45, "a"]], []], "predicted_relations": [[[6, 6, 9, 9, "USED-FOR"], [12, 12, 3, 3, "USED-FOR"], [12, 12, 9, 9, "USED-FOR"]], [], [[45, 45, 41, 42, "USED-FOR"], [37, 39, 33, 34, "USED-FOR"], [37, 39, 41, 42, "USED-FOR"], [45, 47, 33, 34, "USED-FOR"], [45, 47, 41, 42, "USED-FOR"]], []]}
{"doc_key": "2208.09694-d8ed3ce5-46f9-4191-b066-0a3c87a43604", "sentences": [["In", "all", "settings", ",", "we", "train", "segmentation", "networks", "from", "ImageNet", "pre-trained", "weights", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "the", "momentum", "-LRB-", "0.9", "-RRB-", "and", "the", "weight", "decay", "-LRB-", "0.0001", "-RRB-", "with", "batch", "size", "8", "."], ["The", "learning", "rate", "is", "initialized", "to", "be", "0.01", "and", "is", "multiplied", "by", "\\", "-LRB-", "-LRB-", "1-\\frac", "-LCB-", "iter", "-RCB-", "-LCB-", "max\\_iter", "-RCB-", "-RRB-", "^", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "number", "of", "training", "steps", ",", "we", "sweep", "over", "-LCB-", "80K", ",", "160K", ",", "320K", ",", "640K", ",", "1280K", "-RCB-", "as", "the", "optimal", "iteration", "number", "depends", "on", "training", "strategies", "."], ["We", "apply", "standard", "augmentations", ",", "including", "random", "scaling", "-LRB-", "from", "0.5", "to", "2.0", "-RRB-", "and", "random", "horizontal", "flipping", ",", "except", "for", "the", "Distill-Aux", "setting", ",", "where", "we", "have", "massive", "data", "and", "do", "not", "need", "to", "care", "about", "overfitting", "."], ["In", "all", "settings", ",", "patches", "of", "size", "512", "\u00d7", "1024", "are", "randomly", "cropped", "from", "-LRB-", "possibly", "augmented", "-RRB-", "images", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[23, 23, "v"], [30, 30, "v"], [35, 35, "v"]], [[62, 62, "v"], [44, 44, "v"]], [[78, 78, "v"], [80, 80, "v"], [82, 82, "v"], [84, 84, "v"], [86, 86, "v"]], [[108, 108, "v"], [110, 110, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"], [13, 18, "a"], [21, 21, "p"], [23, 23, "v"], [27, 28, "p"], [30, 30, "v"], [33, 34, "p"], [35, 35, "v"]], [[38, 39, "p"], [44, 44, "v"], [62, 62, "v"]], [[78, 78, "v"], [80, 80, "v"], [82, 82, "v"], [84, 84, "v"], [86, 86, "v"], [91, 92, "p"]], [[108, 108, "v"], [110, 110, "v"], [120, 120, "a"]], [[144, 146, "v"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2208.09694-d25bba40-bf89-4915-87de-b3387dc8125a", "sentences": [["Similar", "to", "semantic", "segmentation", ",", "we", "train", "detection", "networks", "from", "ImageNet", "pre-trained", "weights", "using", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "the", "momentum", "-LRB-", "0.9", "-RRB-", "and", "the", "weight", "decay", "-LRB-", "0.0001", "-RRB-", "with", "batch", "size", "32", "."], ["The", "learning", "rate", "is", "initialized", "to", "be", "0.01", "and", "is", "multiplied", "by", "\\", "-LRB-", "-LRB-", "1-\\frac", "-LCB-", "iter", "-RCB-", "-LCB-", "max\\_iter", "-RCB-", "-RRB-", "^", "-LCB-", "0.9", "-RCB-", "\\", "-RRB-", "."], ["For", "the", "number", "of", "training", "steps", ",", "we", "sweep", "over", "-LCB-", "80K", ",", "160K", ",", "320K", ",", "640K", "-RCB-", "."], ["We", "apply", "standard", "augmentations", ",", "including", "random", "scaling", "-LRB-", "from", "0.5", "to", "2.0", "-RRB-", "and", "random", "horizontal", "flipping", ",", "except", "for", "the", "Distill-Aux", "setting", "as", "in", "semantic", "segmentation", "."]], "ner": [[[22, 22, "p"], [24, 24, "v"], [28, 29, "p"], [31, 31, "v"], [34, 35, "p"], [36, 36, "v"]], [[63, 63, "v"], [39, 40, "p"], [45, 45, "v"]], [[70, 73, "p"], [79, 79, "v"], [81, 81, "v"], [83, 83, "v"], [85, 85, "v"]], [[90, 91, "a"], [94, 95, "p"], [98, 100, "v"], [103, 105, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[10, 10, "a"], [14, 19, "a"], [22, 22, "p"], [24, 24, "v"], [28, 29, "p"], [31, 31, "v"], [34, 35, "p"], [36, 36, "v"]], [[39, 40, "p"], [45, 45, "v"], [63, 63, "v"]], [[79, 79, "v"], [81, 81, "v"], [83, 83, "v"], [85, 85, "v"]], [[98, 98, "v"], [100, 100, "v"], [110, 110, "a"]]], "predicted_relations": [[[31, 31, 28, 29, "USED-FOR"], [36, 36, 28, 29, "USED-FOR"]], [], [[79, 79, 70, 73, "USED-FOR"], [81, 81, 70, 73, "USED-FOR"], [83, 83, 70, 73, "USED-FOR"]], [[94, 95, 90, 91, "USED-FOR"], [98, 100, 94, 95, "USED-FOR"], [98, 100, 103, 105, "USED-FOR"], [103, 105, 90, 91, "USED-FOR"]]]}
{"doc_key": "2208.01762-8def9da2-e209-4294-8bd3-e95ff06cd23b", "sentences": [["We", "follow", "previous", "works", "-LSB-", "5", "-RSB-", ",", "-LSB-", "46", "-RSB-", ",", "-LSB-", "11", "-RSB-", ",", "-LSB-", "61", "-RSB-", "and", "train", "our", "model", "on", "the", "conventional", "training", "set", "which", "contains", "1,485", "samples", "from", "the", "NJU2K-train", "-LSB-", "14", "-RSB-", "and", "700", "samples", "from", "the", "NLPR-train", "-LSB-", "31", "-RSB-", "."], ["For", "testing", "benchmarks", ",", "we", "observe", "that", "the", "depth", "quality", "within", "each", "dataset", "varies", ",", "which", "is", "mainly", "due", "to", "acquisition", "methods", "."], ["Specifically", ",", "DES", "-LSB-", "2", "-RSB-", "contains", "135", "images", "of", "indoor", "scenes", "captured", "by", "a", "Kinect", "camera", "."], ["SIP", "-LSB-", "4", "-RSB-", "provides", "a", "human", "dataset", "that", "contains", "929", "images", "captured", "by", "a", "mobile", "device", "."], ["Therefore", ",", "these", "two", "datasets", "can", "be", "considered", "moderate", "with", "less", "noisy", "depths", "."]], "ner": [[[34, 34, "a"], [43, 43, "a"]], [], [[73, 73, "a"]], [[89, 89, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[22, 22, "a"], [30, 30, "v"], [34, 34, "a"], [39, 39, "v"], [43, 43, "a"]], [], [[73, 73, "a"], [78, 78, "v"]], [[89, 89, "a"], [99, 99, "v"]], [[110, 110, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2210.07365-18b6a0fc-297d-41ca-ad69-d130fceef338", "sentences": [["We", "finetune", "our", "models", "on", "the", "TweetEval", "-LRB-", "Section", "REF", "-RRB-", "and", "ToxiGen", "-LRB-", "Section", "REF", "-RRB-", "datasets", "."], ["We", "use", "the", "same", "training", "budget", "and", "hyperparameter", "setup", "for", "all", "the", "models", "."], ["We", "retrieve", "pretrained", "models", "and", "tokenizers", "from", "the", "HuggingFace", "Hub", "-LSB-", "28", "-RSB-", "."], ["We", "set", "a", "maximum", "sequence", "length", "of", "256", ",", "batch", "size", "of", "32", ",", "and", "peak", "learning", "rate", "of", "0.00002", "with", "linear", "warmup", "scheduling", ",", "increasing", "it", "during", "10", "%", "of", "the", "total", "training", "steps", "."], ["On", "ToxiGen", ",", "we", "train", "for", "a", "maximum", "of", "3", "epochs", ",", "on", "TweetEval", ",", "for", "a", "maximum", "of", "10", "."], ["We", "evaluate", "every", "500", "steps", "and", "use", "the", "checkpoint", "with", "the", "best", "validation", "loss", "for", "testing", "."], ["For", "TweetEval", ",", "we", "repeat", "experiments", "on", "5", "initialization", "seeds", "."]], "ner": [[[6, 6, "a"], [12, 12, "a"], [12, 12, "a"], [6, 6, "a"]], [], [[41, 42, "a"]], [[50, 52, "p"], [54, 54, "v"], [56, 57, "p"], [59, 59, "v"], [62, 64, "p"], [66, 66, "v"], [68, 70, "a"], [75, 75, "v"]], [[96, 96, "a"], [84, 84, "a"], [84, 84, "a"], [92, 92, "v"], [96, 96, "a"], [102, 102, "v"]], [[107, 107, "v"]], [[122, 122, "a"], [122, 122, "a"], [129, 130, "p"], [128, 128, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [12, 12, "a"]], [], [[41, 42, "a"]], [[54, 54, "v"], [56, 57, "p"], [59, 59, "v"], [63, 64, "p"], [66, 66, "v"], [75, 76, "v"]], [[84, 84, "a"], [92, 92, "v"], [93, 93, "p"], [96, 96, "a"], [102, 102, "v"]], [[107, 107, "v"]], [[122, 122, "a"], [128, 128, "v"]]], "predicted_relations": [[], [], [], [[66, 66, 62, 64, "USED-FOR"]], [], [], [[129, 130, 122, 122, "USED-FOR"], [129, 130, 122, 122, "USED-FOR"]]]}
{"doc_key": "2208.12343-fe4ea373-2503-4927-8da6-8d2e949d0601", "sentences": [["In", "the", "first", ",", "\u201c", "pretraining", "\u201d", "stage", ",", "we", "use", "a", "weighted", "sum", "of", "L1", "loss", ",", "SSIM", "loss", ",", "and", "our", "three", "aforementioned", "\u201c", "Bokeh", "\u201d", "losses", ",", "using", "the", "depth", "map", "as", "a", "greyscale", "mask", "to", "separate", "the", "foreground", "from", "the", "background", "."], ["The", "final", "loss-function", "for", "this", "stage", "was", "given", "by", "\\", "-LRB-", "L_", "-LCB-", "pretrain", "-RCB-", "=", "0.5", "\\times", "L_", "-LCB-", "1", "-RCB-", "&", "+", "0.05", "\\times", "L_", "-LCB-", "SSIM", "-RCB-", "+", "0.005", "\\times", "L_", "-LCB-", "edgediff", "-RCB-", "\\\\", "&", "+", "0.1", "\\times", "L_", "-LCB-", "backblur", "-RCB-", "+", "0.005", "\\times", "L_", "-LCB-", "foreedge", "-RCB-", "\\nonumber", "\\", "-RRB-"]], "ner": [[[15, 16, "a"], [18, 19, "a"], [15, 16, "c"], [18, 19, "c"]], [[62, 62, "v"], [70, 70, "v"], [77, 77, "v"], [93, 93, "v"], [86, 86, "v"], [77, 77, "v"], [93, 93, "v"]]], "relations": [[], []], "predicted_ner": [[[15, 16, "a"], [18, 19, "a"], [23, 23, "v"]], [[57, 60, "a"], [62, 62, "v"], [70, 70, "v"], [72, 75, "a"], [77, 77, "v"], [79, 82, "a"], [86, 86, "v"], [88, 91, "a"], [93, 93, "v"], [95, 98, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2208.12343-d41f5b1c-3114-4899-b3f9-c396e665414b", "sentences": [["In", "the", "second", "stage", ",", "the", "model", "is", "finetuned", "with", "a", "weighted", "sum", "of", "L1", "loss", ",", "SSIM", "loss", ",", "VGG", "perceptual", "loss", ",", "and", "an", "adversarial", "loss", "from", "the", "dual-scale", "PatchGAN", "discriminator", "that", "is", "trained", "jointly", "in", "the", "second", "stage", "using", "the", "WGGAN-GP", "method", "-LSB-", "8", "-RSB-", "."], ["This", "second", "stage", "refines", "the", "distorted", "edges", "and", "the", "background", "to", "generate", "a", "realistic", "bokeh", "effect", "."], ["The", "refinement", "loss", "thus", "took", "the", "form", "\\", "-LRB-", "L_", "-LCB-", "refinement", "-RCB-", "=", "0.5", "\\times", "L_", "-LCB-", "1", "-RCB-", "&", "+", "0.1", "\\times", "L_", "-LCB-", "VGG", "-RCB-", "+", "0.05", "\\times", "L_", "-LCB-", "SSIM", "-RCB-", "+", "L_", "-LCB-", "adv", "-RCB-", "\\", "-RRB-"]], "ner": [[[14, 15, "a"], [17, 18, "a"], [20, 22, "a"], [30, 32, "a"], [43, 44, "a"], [11, 12, "p"], [14, 15, "c"], [20, 22, "c"], [17, 18, "c"], [26, 27, "c"]], [], [[67, 68, "a"], [80, 80, "v"], [88, 88, "v"], [95, 95, "v"], [84, 84, "v"], [88, 88, "v"]]], "relations": [[], [], []], "predicted_ner": [[[14, 15, "a"], [17, 18, "a"], [20, 20, "a"], [26, 27, "a"], [31, 31, "a"], [43, 44, "a"]], [], [[67, 68, "a"], [75, 78, "a"], [80, 80, "v"], [88, 88, "v"], [90, 93, "a"], [95, 95, "v"], [97, 100, "a"], [102, 105, "a"]]], "predicted_relations": [[[11, 12, 14, 15, "USED-FOR"], [11, 12, 17, 18, "USED-FOR"]], [], []]}
{"doc_key": "2201.13063-8cb75b43-5703-4ab8-911a-592842c6f540", "sentences": [["We", "found", "it", "beneficial", "to", "use", "one-cyclic", "learning", "rate", "scheduling", ",", "following", "recommendations", "of", "-LSB-", "38", "-RSB-", ",", "with", "the", "maximum", "learning", "rate", "of", "0.002", "."], ["We", "train", "all", "models", "for", "350", "epochs", "with", "Adam", "optimizer", "-LSB-", "17", "-RSB-", "and", "batch", "size", "of", "30", "with", "early", "stopping", "enabled", "for", "when", "the", "model", "does", "not", "improve", "for", "consecutive", "100", "epochs", "."], ["The", "training", "pipeline", "is", "implemented", "with", "PyTorch", "-LSB-", "31", "-RSB-", ",", "PyG", "-LSB-", "10", "-RSB-", ",", "and", "Weights", "and", "Biases", "-LSB-", "3", "-RSB-", "."]], "ner": [[[20, 22, "p"], [24, 24, "v"], [6, 9, "a"]], [[34, 35, "a"], [45, 46, "a"], [57, 57, "v"]], [[66, 66, "a"], [71, 71, "a"], [77, 79, "a"]]], "relations": [[], [], []], "predicted_ner": [[[6, 6, "v"], [21, 22, "p"], [24, 24, "v"]], [[31, 31, "v"], [32, 32, "p"], [34, 34, "a"], [40, 41, "p"], [43, 43, "v"], [45, 46, "a"], [57, 57, "v"], [58, 58, "p"]], [[66, 66, "a"], [71, 71, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2205.01068-c1f22ba5-1abb-4503-b661-189372a6462a", "sentences": [["For", "weight", "initialization", ",", "we", "follow", "the", "same", "settings", "provided", "in", "the", "Megatron-LM", "codebase", ",", "https", ":", "//github.com/NVIDIA/Megatron-LM/blob/main/examples/pretrain_gpt3_175B.sh", "using", "a", "normal", "distribution", "with", "zero", "mean", "and", "standard", "deviation", "of", "0.006", "."], ["Standard", "deviation", "for", "output", "layers", "are", "scaled", "by", "a", "\\", "-LRB-", "1.0/\\sqrt", "-LCB-", "2", "L", "-RCB-", "\\", "-RRB-", "term", "where", "\\", "-LRB-", "L\\", "-RRB-", "is", "the", "total", "number", "of", "layers", "."], ["All", "bias", "terms", "are", "initialized", "as", "0", ",", "and", "all", "models", "are", "trained", "with", "ReLU", "activation", "and", "a", "sequence", "length", "of", "2048", "."]], "ner": [[[1, 2, "a"], [20, 21, "p"], [23, 24, "v"], [26, 29, "v"], [26, 27, "p"], [29, 29, "v"], [12, 13, "a"]], [[42, 42, "v"]], [[63, 64, "p"], [68, 68, "v"], [77, 77, "p"], [76, 76, "v"], [80, 81, "p"], [83, 83, "v"]]], "relations": [[], [], []], "predicted_ner": [[[12, 13, "a"], [23, 23, "v"], [29, 29, "v"]], [[53, 53, "p"]], [[68, 68, "v"], [76, 77, "a"], [83, 83, "v"]]], "predicted_relations": [[[20, 21, 12, 13, "USED-FOR"], [23, 24, 26, 27, "USED-FOR"], [26, 29, 20, 21, "USED-FOR"], [26, 29, 26, 27, "USED-FOR"], [26, 27, 12, 13, "USED-FOR"], [29, 29, 26, 27, "USED-FOR"]], [], [[76, 76, 77, 77, "USED-FOR"], [76, 76, 80, 81, "USED-FOR"], [83, 83, 80, 81, "USED-FOR"]]]}
{"doc_key": "2205.01068-9ea6d3b7-39ab-4251-ae10-4180ee1c3b12", "sentences": [["We", "use", "a", "dropout", "of", "0.1", "throughout", ",", "but", "we", "do", "not", "apply", "any", "dropout", "to", "embeddings", "."], ["We", "clip", "gradient", "norms", "at", "1.0", ",", "except", "for", "some", "mid-flight", "changes", "that", "reduce", "this", "threshold", "down", "from", "1.0", "to", "0.3", "-LRB-", "see", "Section", "REF", "-RRB-", "."], ["We", "also", "include", "a", "gradient", "predivide", "factor", "to", "reduce", "the", "risk", "of", "over/underflows", "when", "computing", "the", "gradient", "across", "all", "ranks", "-LRB-", "splitting", "the", "division", "by", "the", "world", "size", "of", "\\", "-LRB-", "N\\", "-RRB-", "into", "two", "division", "operations", "by", "\\", "-LRB-", "\\sqrt", "-LCB-", "N", "-RCB-", "\\", "-RRB-", "-RRB-", "."]], "ner": [[[3, 3, "a"], [14, 14, "a"], [5, 5, "v"]], [[33, 33, "p"], [23, 23, "v"], [36, 36, "v"], [38, 38, "v"], [28, 29, "c"]], [[49, 51, "a"], [71, 72, "p"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "p"], [5, 5, "v"]], [[23, 23, "v"], [36, 36, "v"], [38, 38, "v"]], [[79, 79, "v"]]], "predicted_relations": [[], [[23, 23, 33, 33, "USED-FOR"], [36, 36, 33, 33, "USED-FOR"], [28, 29, 23, 23, "USED-FOR"], [28, 29, 36, 36, "USED-FOR"], [28, 29, 38, 38, "USED-FOR"]], [[71, 72, 49, 51, "USED-FOR"]]]}
{"doc_key": "2204.04213-710757cd-6575-4420-8178-61009434fe7d", "sentences": [["Datasets", "."], ["We", "merge", "two", "datasets", "from", "the", "Deeploc", "dataset", "-LSB-", "0", "-RSB-", "and", "the", "Enzyme", "dataset", "-LSB-", "10", "-RSB-", ",", "and", "perform", "pretraining", "on", "the", "merged", "dataset", "."], ["For", "the", "Deeploc", "dataset", ",", "we", "acquire", "the", "available", "protein", "structures", "from", "the", "alphafold", "protein", "database", "https", ":", "//alphafold.ebi.ac.uk/", "."], ["For", "the", "Enzyme", "dataset", ",", "we", "use", "PDB", "files", "in", "the", "Protein", "Data", "Bank", "-LSB-", "3", "-RSB-", "to", "obtain", "protein", "structures", "."], ["Besides", ",", "we", "exclude", "proteins", "with", "a", "sequence", "length", "of", "more", "than", "400", "residues", ",", "which", "results", "in", "a", "total", "of", "around", "40,000", "protein", "structures", "for", "pretraining", "."]], "ner": [[], [[8, 9, "a"], [15, 16, "a"]], [[31, 32, "a"]], [[51, 52, "a"]], [[78, 79, "p"], [83, 84, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[4, 4, "v"], [8, 9, "a"], [15, 16, "a"]], [[31, 32, "a"], [42, 44, "a"]], [[51, 52, "a"]], [[83, 83, "v"], [93, 93, "v"]]], "predicted_relations": [[], [], [], [], [[83, 84, 78, 79, "USED-FOR"]]]}
{"doc_key": "2204.04213-7aea5f8a-33a6-4c1f-a52f-f4ada94c49a0", "sentences": [["Training", "details", "."], ["For", "the", "GNN", "model", ",", "we", "set", "the", "dimension", "of", "hidden", "representation", "as", "1280", "and", "the", "layer", "number", "as", "2", "in", "our", "experiments", "."], ["The", "threshold", "to", "determine", "whether", "there", "is", "an", "edge", "between", "two", "residues", "is", "set", "as", "7", "\u00c5", "which", "is", "consistent", "with", "previous", "study", "-LSB-", "23", "-RSB-", "."], ["We", "parameterize", "both", "\\", "-LRB-", "\\rm", "-LCB-", "NN", "-RCB-", "_", "-LCB-", "dis", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\rm", "-LCB-", "NN", "-RCB-", "_", "-LCB-", "ang", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", "as", "two", "fully-connected", "layers", "with", "a", "ReLU", "activation", "in", "the", "middle", "."], ["For", "\\", "-LRB-", "\\rm", "-LCB-", "NN", "-RCB-", "_", "-LCB-", "dis", "-RCB-", "-LRB-", "\\cdot", "-RRB-", "\\", "-RRB-", ",", "we", "set", "\\", "-LRB-", "T\\", "-RRB-", "=30", "and", "apply", "softmax", "to", "the", "output", "logits", "."], ["Besides", ",", "we", "adopt", "the", "available", "protein", "BERT", "model", "in", "-LSB-", "7", "-RSB-", "as", "the", "pretrained", "protein", "language", "model", "."], ["We", "use", "the", "cosine", "learning", "rate", "decay", "schedule", "for", "a", "total", "of", "10", "epochs", "for", "pretraining", "."], ["We", "set", "the", "learning", "rate", "for", "the", "GNN", "model", "as", "\\", "-LRB-", "0.001\\", "-RRB-", "and", "the", "learning", "rate", "for", "the", "protein", "LM", "as", "\\", "-LRB-", "0.0001\\", "-RRB-", "in", "the", "pseudo", "bi-level", "optimization", "scheme", "."], ["The", "Adam", "optimizer", "is", "adopted", "to", "update", "the", "GNN", "parameters", "with", "\\", "-LRB-", "\\beta", "_1", "=", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2", "=", "0.999\\", "-RRB-", "."]], "ner": [[], [[5, 6, "a"], [11, 14, "p"], [16, 16, "v"], [19, 20, "p"], [22, 22, "v"]], [[28, 38, "p"], [42, 43, "v"]], [], [[121, 121, "p"], [123, 123, "v"], [121, 121, "p"]], [[138, 140, "a"]], [[155, 159, "a"], [164, 164, "v"], [156, 157, "p"], [156, 157, "p"]], [[176, 177, "a"], [172, 173, "p"], [185, 186, "p"], [181, 181, "v"], [172, 173, "p"], [185, 186, "p"], [194, 194, "v"]], [[204, 205, "a"], [219, 219, "v"], [227, 227, "v"]]], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[5, 6, "a"], [16, 16, "v"], [22, 22, "v"]], [[37, 37, "v"], [42, 43, "v"]], [[89, 89, "v"], [94, 95, "a"]], [[121, 121, "p"], [126, 126, "a"]], [[138, 140, "a"]], [[164, 164, "v"], [165, 165, "p"]], [[176, 177, "a"], [181, 181, "v"], [185, 186, "p"], [194, 194, "v"]], [[204, 204, "a"], [211, 211, "a"], [219, 219, "v"], [224, 227, "p"], [227, 227, "v"]]], "predicted_relations": [[], [[11, 14, 5, 6, "USED-FOR"], [16, 16, 11, 14, "USED-FOR"], [16, 16, 19, 20, "USED-FOR"], [19, 20, 5, 6, "USED-FOR"]], [[42, 43, 28, 38, "USED-FOR"]], [], [[123, 123, 121, 121, "USED-FOR"], [123, 123, 121, 121, "USED-FOR"]], [], [], [[172, 173, 176, 177, "USED-FOR"], [185, 186, 176, 177, "USED-FOR"], [181, 181, 185, 186, "USED-FOR"], [181, 181, 185, 186, "USED-FOR"], [172, 173, 176, 177, "USED-FOR"], [185, 186, 176, 177, "USED-FOR"]], []]}
{"doc_key": "2204.04292-8bc1e017-387e-4b56-9911-25d25aab197f", "sentences": [["Meta", "training", "details", "The", "population", "is", "1,000", "individuals", "and", "the", "maximum", "graph", "size", "is", "60", "nodes", "."], ["All", "are", "initialized", "using", "SAC", "as", "a", "warm-start", "-LRB-", "see", "Appendix", "-RRB-", "."], ["For", "the", "RL", "algorithm", "evaluation", ",", "we", "use", "10", "different", "seeds", "\\", "-LRB-", "S_", "-LCB-", "train", "-RCB-", "\\", "-RRB-", ",", "fix", "the", "number", "of", "evaluation", "episodes", "\\", "-LRB-", "N_", "-LCB-", "eval", "-RCB-", "\\", "-RRB-", "to", "20", ",", "and", "normalize", "all", "fitness", "scores", "to", "the", "range", "-LSB-", "0", ",", "1", "-RSB-", "."], ["We", "set", "\\", "-LRB-", "\\kappa", "=", "1\\", "-RRB-", "in", "Equation", "REF", "."], ["Additional", "details", "are", "in", "Appendix", "."]], "ner": [[[6, 6, "v"]], [[21, 21, "a"]], [[32, 33, "a"], [52, 55, "p"], [65, 65, "v"], [78, 78, "v"]], [[85, 85, "p"], [87, 87, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[6, 6, "v"], [14, 14, "v"]], [[21, 21, "a"]], [[32, 33, "a"], [38, 38, "v"], [65, 65, "v"], [76, 76, "v"], [78, 78, "v"]], [], []], "predicted_relations": [[], [], [[52, 55, 32, 33, "USED-FOR"], [65, 65, 52, 55, "USED-FOR"]], [[87, 87, 85, 85, "USED-FOR"]], []]}
{"doc_key": "2202.11490-d4c3010b-912c-4806-9feb-705d14a499da", "sentences": [["We", "apply", "a", "batch", "size", "of", "32", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "0.005\\", "-RRB-", "and", "decays", "under", "cosine", "rule", "."], ["When", "training", "SuperNet", ",", "we", "use", "Adam", "to", "optimize", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "and", "momentum", "SGD", "to", "optimize", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "\\", "-RRB-", "."], ["The", "weight", "decay", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "\\", "-RRB-", "is", "\\", "-LRB-", "4\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "while", "we", "do", "not", "use", "weight", "decay", "for", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "."]], "ner": [[[3, 4, "a"]], [[9, 11, "a"], [18, 21, "a"]], [[29, 29, "a"], [38, 39, "a"]], [[52, 53, "a"], [79, 80, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "p"], [6, 6, "v"]], [[10, 11, "p"], [15, 15, "v"]], [[29, 29, "a"], [34, 34, "p"], [38, 39, "a"]], [[52, 53, "p"], [67, 70, "v"], [79, 80, "p"], [84, 84, "p"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2202.11490-f761b491-e324-4d57-a966-6861339e1ad2", "sentences": [["We", "apply", "a", "batch", "size", "of", "128", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "0.025\\", "-RRB-", "and", "decays", "under", "cosine", "rule", "."], ["When", "training", "SuperNet", ",", "we", "use", "Adam", "to", "optimize", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "and", "momentum", "SGD", "to", "optimize", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "\\", "-RRB-", "."], ["The", "weight", "decay", "of", "\\", "-LRB-", "\\mathbf", "-LCB-", "w", "-RCB-", "\\", "-RRB-", "is", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "while", "we", "do", "not", "use", "weight", "decay", "for", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "."]], "ner": [[[3, 4, "a"]], [[9, 11, "a"], [18, 21, "a"]], [[29, 29, "a"], [38, 39, "a"]], [[52, 53, "a"], [79, 80, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[3, 4, "p"], [6, 6, "v"]], [[10, 11, "p"], [15, 15, "v"]], [[29, 29, "a"], [34, 34, "p"], [38, 39, "a"]], [[52, 53, "p"], [67, 70, "v"], [79, 80, "p"], [84, 84, "p"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2202.11490-0b027c95-b5d9-4117-a3e4-0c9bf1817d3c", "sentences": [["We", "moved", "the", "FDNAS", "normal", "net", "to", "ImageNet", "for", "training", "to", "evaluate", "the", "generalization", "performance", "on", "larger", "image", "classification", "tasks", "."], ["Following", "the", "general", "mobile", "setting", "-LSB-", "14", "-RSB-", ",", "we", "set", "the", "input", "image", "size", "to", "\\", "-LRB-", "224\\times", "224\\", "-RRB-", "."], ["We", "set", "the", "FDNAS", "normal", "net", "'s", "Layer", "1", ",", "3", ",", "6", ",", "8", ",", "and", "16", "as", "the", "downsampling", "layers", "."], ["The", "model", "'s", "FLOPs", "are", "constrained", "to", "below", "600M", "."], ["We", "use", "an", "SGD", "optimizer", "with", "a", "momentum", "of", "0.9", "."], ["The", "initial", "learning", "rate", "is", "0.4", "and", "decays", "to", "0", "by", "the", "cosine", "decay", "rule", "."], ["Then", "the", "weight", "decay", "is", "kept", "consistent", "at", "\\", "-LRB-", "4\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["The", "dropout", "rate", "is", "0.2", "."]], "ner": [[[3, 5, "a"], [7, 7, "a"]], [], [[46, 48, "a"]], [], [[79, 80, "a"], [83, 83, "p"], [85, 85, "v"]], [[88, 90, "p"], [92, 92, "v"], [99, 101, "a"]], [[105, 106, "p"]], [[122, 123, "p"], [125, 125, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 5, "a"], [7, 7, "a"]], [[40, 40, "v"]], [[46, 48, "a"], [60, 60, "v"]], [[74, 74, "v"]], [[79, 79, "a"], [85, 85, "v"]], [[89, 90, "p"], [92, 92, "v"], [96, 96, "v"]], [[105, 106, "p"], [114, 117, "v"]], [[122, 123, "p"], [125, 125, "v"]]], "predicted_relations": [[], [], [], [], [[83, 83, 79, 80, "USED-FOR"]], [], [], [[125, 125, 122, 123, "USED-FOR"]]]}
{"doc_key": "2211.09117-77540a8d-4e6a-452b-9226-79391f5ec270", "sentences": [["We", "set", "the", "input", "image", "resolution", "as", "256x256", "to", "be", "consistent", "with", "previous", "generative", "models", "."], ["After", "passing", "through", "the", "VQGAN", "tokenizer", ",", "the", "token", "sequence", "length", "is", "16x16", "-LRB-", "256", "tokens", "-RRB-", "."], ["Following", "MAE", "-LSB-", "25", "-RSB-", ",", "we", "use", "strong", "random", "crop", "and", "resize", "-LRB-", "0.2", "to", "1", "-RRB-", "and", "random", "flipping", "as", "our", "default", "augmentations", "."], ["We", "also", "trained", "models", "with", "a", "weaker", "version", "of", "random", "crop", "and", "resize", "-LRB-", "range", "from", "0.8", "to", "1", "-RRB-", ",", "which", "we", "call", "\u201c", "w.a", ".", "''"], ["in", "the", "results", "."], ["We", "pre-train", "base-", "and", "large-size", "vision", "Transformers", "-LSB-", "19", "-RSB-", ",", "i.e.", ",", "ViT-B", "and", "ViT-L", ",", "respectively", "."], ["We", "use", "AdamW", "to", "train", "the", "model", "for", "1600", "epochs", "with", "batch", "size", "of", "4096", "for", "ViT-B", ",", "and", "batch", "size", "of", "2048", "for", "ViT-L.", "We", "use", "a", "cosine", "learning", "rate", "schedule", "with", "an", "80-epoch", "warmup", "."], ["The", "base", "learning", "rate", "is", "\\", "-LRB-", "1.5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "both", "ViT-B", "and", "ViT-L", ",", "and", "is", "further", "scaled", "by", "batchsize/256", "."], ["More", "details", "are", "in", "the", "Appendix", "."]], "ner": [[], [[20, 21, "a"]], [[35, 35, "a"], [42, 46, "a"], [48, 50, "v"], [53, 54, "a"]], [[74, 74, "p"], [76, 78, "v"]], [], [[105, 105, "a"], [107, 107, "a"]], [[127, 127, "a"], [135, 135, "a"], [113, 113, "a"], [139, 142, "a"], [146, 146, "p"], [145, 145, "v"]], [[164, 164, "a"], [166, 166, "a"], [149, 151, "p"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 7, "v"]], [[20, 20, "a"], [28, 28, "v"], [30, 30, "v"]], [[35, 35, "a"], [48, 48, "v"], [50, 50, "v"]], [[76, 76, "v"], [78, 78, "v"]], [], [[105, 105, "a"], [107, 107, "a"]], [[113, 113, "a"], [119, 119, "v"], [120, 120, "p"], [122, 123, "p"], [125, 125, "v"], [127, 127, "a"], [130, 131, "p"], [133, 133, "v"], [145, 145, "v"]], [[149, 151, "p"], [156, 159, "v"], [164, 164, "a"], [166, 166, "a"]], []], "predicted_relations": [[], [], [], [[76, 78, 74, 74, "USED-FOR"]], [], [], [[146, 146, 139, 142, "USED-FOR"], [145, 145, 146, 146, "USED-FOR"]], [], []]}
{"doc_key": "2207.14287-cacdbe5b-1dfd-40e3-a0ae-37b079388fb2", "sentences": [["We", "implemented", "our", "models", "using", "PyTorch", ",", "with", "distributed", "training", "across", "eight", "A100", "GPUs", "."], ["We", "used", "grid", "search", "to", "choose", "training", "parameters", ",", "that", "include", ":", "view", "synthesis", "weight", "\\", "-LRB-", "\\lambda", "_s", "=", "5.0\\", "-RRB-", ",", "virtual", "camera", "loss", "weight", "\\", "-LRB-", "\\lambda", "_v=0.5\\", "-RRB-", ",", "virtual", "camera", "projection", "noise", "\\", "-LRB-", "\\sigma", "_v", "=", "0.25\\", "-RRB-", ",", "canonical", "jittering", "noise", "\\", "-LRB-", "\\sigma", "_t=\\sigma", "_r=0.1\\", "-RRB-", ",", "and", "batch", "size", "\\", "-LRB-", "b=32\\", "-RRB-", "-LRB-", "4", "per", "GPU", "-RRB-", "."], ["We", "use", "the", "AdamW", "optimizer", "-LSB-", "28", "-RSB-", ",", "with", "standard", "parameters", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.999\\", "-RRB-", ",", "a", "weight", "decay", "of", "\\", "-LRB-", "w=10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "lr=2", "\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["For", "our", "stereo", "experiments", ",", "we", "train", "for", "200", "epochs", ",", "halving", "the", "learning", "rate", "every", "80", "epochs", "."], ["For", "our", "video", "experiments", ",", "we", "train", "for", "100", "epochs", ",", "halving", "the", "learning", "rate", "every", "40", "epochs", "."], ["Higher-resolution", "fine-tuning", "is", "performed", "for", "50", "epochs", "for", "stereo", "experiments", ",", "and", "10", "epochs", "for", "video", "experiments", ",", "with", "\\", "-LRB-", "lr=2", "\\cdot", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[5, 5, "a"], [8, 9, "a"]], [[17, 18, "a"]], [[86, 87, "a"], [98, 98, "v"], [104, 104, "v"], [108, 109, "p"], [122, 124, "p"], [113, 113, "v"], [130, 130, "v"], [123, 124, "p"]], [[139, 140, "a"], [146, 146, "p"], [154, 154, "p"], [145, 145, "v"], [152, 154, "v"], [146, 146, "p"], [154, 154, "p"], [146, 146, "p"], [154, 154, "p"], [139, 140, "c"], [150, 151, "p"]], [[165, 165, "p"], [173, 173, "p"], [158, 159, "a"], [165, 165, "p"], [173, 173, "p"], [164, 164, "v"], [171, 173, "v"], [165, 165, "p"], [173, 173, "p"], [158, 159, "c"], [169, 170, "p"]], [[183, 184, "a"], [181, 181, "p"], [188, 188, "p"], [190, 191, "a"], [181, 181, "p"], [188, 188, "p"], [181, 181, "p"], [188, 188, "p"], [180, 180, "v"], [183, 184, "c"], [187, 187, "v"], [198, 198, "v"], [190, 191, "c"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 5, "a"], [11, 11, "v"], [12, 12, "v"]], [[17, 18, "a"], [27, 29, "p"], [32, 33, "p"], [35, 35, "v"], [38, 41, "p"], [48, 51, "p"], [57, 57, "v"], [60, 62, "p"], [71, 72, "p"], [75, 75, "v"], [78, 78, "v"]], [[86, 86, "a"], [108, 109, "p"], [113, 116, "v"], [123, 124, "p"], [128, 128, "v"]], [[145, 145, "v"], [146, 146, "p"], [150, 151, "p"], [153, 153, "v"], [154, 154, "p"]], [[164, 164, "v"], [165, 165, "p"], [169, 170, "p"], [172, 172, "v"], [173, 173, "p"]], [[180, 180, "v"], [181, 181, "p"], [187, 187, "v"], [188, 188, "p"], [196, 196, "v"]]], "predicted_relations": [[], [], [[108, 109, 86, 87, "USED-FOR"], [122, 124, 86, 87, "USED-FOR"], [113, 113, 108, 109, "USED-FOR"], [113, 113, 122, 124, "USED-FOR"], [113, 113, 123, 124, "USED-FOR"], [130, 130, 122, 124, "USED-FOR"], [130, 130, 123, 124, "USED-FOR"], [123, 124, 86, 87, "USED-FOR"]], [[146, 146, 139, 140, "USED-FOR"], [154, 154, 139, 140, "USED-FOR"], [145, 145, 146, 146, "USED-FOR"], [145, 145, 154, 154, "USED-FOR"], [145, 145, 146, 146, "USED-FOR"], [145, 145, 154, 154, "USED-FOR"], [145, 145, 146, 146, "USED-FOR"], [145, 145, 154, 154, "USED-FOR"], [152, 154, 146, 146, "USED-FOR"], [152, 154, 154, 154, "USED-FOR"], [152, 154, 146, 146, "USED-FOR"], [152, 154, 154, 154, "USED-FOR"], [152, 154, 146, 146, "USED-FOR"], [152, 154, 154, 154, "USED-FOR"], [146, 146, 139, 140, "USED-FOR"], [154, 154, 139, 140, "USED-FOR"], [146, 146, 139, 140, "USED-FOR"], [154, 154, 139, 140, "USED-FOR"], [139, 140, 145, 145, "USED-FOR"], [139, 140, 152, 154, "USED-FOR"], [150, 151, 139, 140, "USED-FOR"]], [[165, 165, 158, 159, "USED-FOR"], [173, 173, 158, 159, "USED-FOR"], [165, 165, 158, 159, "USED-FOR"], [173, 173, 158, 159, "USED-FOR"], [164, 164, 165, 165, "USED-FOR"], [164, 164, 173, 173, "USED-FOR"], [164, 164, 165, 165, "USED-FOR"], [164, 164, 173, 173, "USED-FOR"], [164, 164, 165, 165, "USED-FOR"], [164, 164, 173, 173, "USED-FOR"], [171, 173, 165, 165, "USED-FOR"], [171, 173, 173, 173, "USED-FOR"], [171, 173, 165, 165, "USED-FOR"], [171, 173, 173, 173, "USED-FOR"], [171, 173, 165, 165, "USED-FOR"], [171, 173, 173, 173, "USED-FOR"], [165, 165, 158, 159, "USED-FOR"], [173, 173, 158, 159, "USED-FOR"], [158, 159, 164, 164, "USED-FOR"], [158, 159, 171, 173, "USED-FOR"], [169, 170, 158, 159, "USED-FOR"]], [[181, 181, 183, 184, "USED-FOR"], [181, 181, 190, 191, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 190, 191, "USED-FOR"], [181, 181, 183, 184, "USED-FOR"], [181, 181, 190, 191, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 190, 191, "USED-FOR"], [181, 181, 183, 184, "USED-FOR"], [181, 181, 190, 191, "USED-FOR"], [188, 188, 183, 184, "USED-FOR"], [188, 188, 190, 191, "USED-FOR"], [180, 180, 181, 181, "USED-FOR"], [180, 180, 188, 188, "USED-FOR"], [180, 180, 181, 181, "USED-FOR"], [180, 180, 188, 188, "USED-FOR"], [180, 180, 181, 181, "USED-FOR"], [180, 180, 188, 188, "USED-FOR"], [183, 184, 180, 180, "USED-FOR"], [183, 184, 187, 187, "USED-FOR"], [183, 184, 198, 198, "USED-FOR"], [187, 187, 181, 181, "USED-FOR"], [187, 187, 188, 188, "USED-FOR"], [187, 187, 181, 181, "USED-FOR"], [187, 187, 188, 188, "USED-FOR"], [187, 187, 181, 181, "USED-FOR"], [187, 187, 188, 188, "USED-FOR"], [198, 198, 188, 188, "USED-FOR"], [198, 198, 188, 188, "USED-FOR"], [198, 198, 188, 188, "USED-FOR"], [190, 191, 198, 198, "USED-FOR"]]]}
{"doc_key": "2203.12574-14d573ff-f90d-4bd4-9701-d8842a73a91a", "sentences": [["We", "use", "GPT2\u2013small", ",", "a", "12", "layer", "transformer-based", "LM", "comprising", "of", "\\", "-LRB-", "\\sim", "\\", "-RRB-", "124M", "parameters", ",", "as", "the", "teacher", "model", "and", "a", "six-layer", "version", "of", "GPT\u20132", "as", "the", "student", "model", "."], ["We", "use", "OpenWebText", "corpus", ",", "which", "is", "an", "open-source", "reproduction", "of", "WebText", "corpus", "that", "was", "used", "to", "train", "GPT\u20132", "in", "-LSB-", "36", "-RSB-", "."], ["Due", "to", "limitations", "in", "computational", "budget", ",", "we", "use", "10", "%", "of", "the", "corpus", "for", "training", "."], ["We", "used", "the", "knowledge", "distillation", "procedure", "presented", "in", "-LSB-", "38", "-RSB-", ",", "but", "without", "the", "cosine", "loss", "between", "representations", "during", "knowledge", "transfer", "because", "adopting", "knowledge", "distillation", "for", "fair", "learning", "requires", "correcting", "the", "`", "biased", "knowledge", "'", "from", "the", "teacher", ",", "but", "it", "is", "hard", "to", "amend", "biased", "contextual", "representations", "."], ["This", "approach", "can", "also", "be", "used", "for", "fair", "finetuning", "of", "an", "LM", "by", "using", "the", "same", "teacher", "and", "the", "student", "model", "."], ["In", "that", "case", ",", "one", "may", "initialize", "with", "the", "pre-trained", "teacher", "'s", "weights", "."], ["For", "fair", "finetuning", "experiments", ",", "we", "use", "GPT2\u2013small", "as", "both", "the", "teacher", "and", "the", "student", "."], ["Details", "on", "training", ",", "text", "generation", ",", "and", "hyperparameters", "are", "provided", "in", "Appendix", "."]], "ner": [[[2, 2, "a"]], [[36, 37, "a"]], [], [[90, 93, "p"], [78, 79, "a"], [99, 100, "a"]], [], [], [[168, 168, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [5, 5, "v"], [6, 6, "p"], [7, 7, "a"], [16, 16, "v"], [25, 25, "v"], [28, 28, "a"]], [[36, 37, "a"], [45, 46, "a"], [52, 52, "a"]], [[67, 68, "v"]], [[78, 79, "a"], [99, 100, "a"]], [], [[151, 151, "v"]], [[168, 168, "a"]], []], "predicted_relations": [[], [], [], [[90, 93, 78, 79, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2203.12485-648ba76f-bf85-4dad-a1e3-51c221866093", "sentences": [["To", "aid", "reproducibility", ",", "we", "report", "training", "parameters", "and", "hyperparameters", "."], ["We", "use", "identical", "training", "parameters", "and", "align", "with", "our", "baseline", "-LSB-", "21", "-RSB-", "where", "possible", "."], ["We", "use", "the", "Ranger", "optimiser", "yong2020gradient", "and", "batch", "sizes", "of", "8", ",", "a", "learning", "rate", "of", "\\", "-LRB-", "1e", "-LCB-", "-", "-RCB-", "4\\", "-RRB-", "with", "an", "exponential", "learning", "rate", "decay", "."], ["We", "train", "all", "considered", "methods", "for", "50", "epochs", "."]], "ner": [[], [], [[30, 31, "a"], [40, 41, "p"], [54, 55, "p"], [53, 56, "p"]], [[65, 65, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [[34, 35, "p"], [37, 37, "v"], [40, 41, "p"], [45, 49, "v"], [54, 56, "p"]], [[64, 64, "v"], [65, 65, "p"]]], "predicted_relations": [[], [], [[40, 41, 30, 31, "USED-FOR"]], []]}
{"doc_key": "2204.11370-55845f9f-a89b-419e-8fd8-61519a4347d7", "sentences": [["The", "neural", "networks", "have", "been", "trained", "with", "an", "RMSprop", "optimizer", "and", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["The", "selected", "minibatch", "size", "was", "128", "."], ["We", "set", "a", "limit", "of", "training", "of", "4000", "episodes", "for", "the", "scenario", ",", "and", "the", "replay", "memory", "has", "size", "30000", "."], ["The", "limit", "was", "defined", "empirically", "since", "good", "results", "could", "be", "observed", "around", "these", "values", "."]], "ner": [[[8, 9, "a"], [13, 14, "p"]], [[27, 28, "a"], [28, 28, "p"]], [[40, 40, "p"], [39, 39, "v"], [47, 48, "a"], [50, 50, "p"], [51, 51, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[8, 8, "a"], [13, 14, "p"], [18, 20, "v"]], [[27, 27, "a"], [27, 28, "p"], [30, 30, "v"]], [[39, 39, "v"], [51, 51, "v"]], []], "predicted_relations": [[[13, 14, 8, 9, "USED-FOR"]], [[28, 28, 27, 28, "USED-FOR"]], [[39, 39, 40, 40, "USED-FOR"], [50, 50, 47, 48, "USED-FOR"], [51, 51, 50, 50, "USED-FOR"]], []]}
{"doc_key": "2206.02593-4459913b-14c3-41d5-b275-05b0bccf8f2a", "sentences": [["Cascade", "Model", ":", "In", "CM", "-LRB-", "sec", ":", "cascade", "model", "-RRB-", ",", "the", "value", "of", "a", "list", "depends", "only", "on", "the", "attraction", "probabilities", "of", "its", "items", "."], ["Let", "\\", "-LRB-", "L_", "-LCB-", "\\theta", ",", "a", "-RCB-", "\\", "-RRB-", "be", "the", "LCB", "on", "the", "attraction", "probability", "of", "item", "\\", "-LRB-", "a\\", "-RRB-", ",", "that", "is", "\\", "-LRB-", "\\theta", "_a", "\\ge", "L_", "-LCB-", "\\theta", ",", "a", "-RCB-", "\\", "-RRB-", "."], ["If", "we", "apply", "LCB", "on", "attraction", "probabilities", "\\", "-LRB-", "\\theta", "\\", "-RRB-", ",", "then", "\\", "-LRB-", "\\displaystyle", "1", "-", "\\prod", "_", "-LCB-", "k", "=", "1", "-RCB-", "^K", "-LRB-", "1", "-", "L_", "-LCB-", "\\theta", ",", "A_k", "-RCB-", "-RRB-", "\\le", "1", "-", "\\prod", "_", "-LCB-", "k=1", "-RCB-", "^K", "-LRB-", "1", "-", "\\theta", "_", "-LCB-", "A_k", "-RCB-", "-RRB-", "\\", "-RRB-", "and", "we", "get", "the", "LCB", "for", "the", "whole", "list", "\\", "-LRB-", "A\\", "-RRB-", "as", "we", "have", "an", "upper", "bound", "on", "each", "term", "in", "the", "product", "."], ["Suppose", "that", "we", "have", "LCBs", "for", "all", "model", "parameters", "."], ["Then", "we", "have", "an", "LCB", "for", "any", "fixed", "list", "."], ["Now", "suppose", "that", "we", "have", "\\", "-LRB-", "1", "-", "\\delta", "\\", "-RRB-", "LCBs", "for", "each", "model", "parameter", "."], ["Then", ",", "by", "the", "union", "bound", ",", "all", "model", "parameter", "LCBs", "hold", "jointly", "with", "probability", "at", "least", "\\", "-LRB-", "1", "-", "\\delta", "\\left|\\mathcal", "-LCB-", "E", "-RCB-", "\\right|\\", "-RRB-", ",", "and", "so", "do", "the", "LCBs", "for", "all", "lists", "."]], "ner": [[[0, 1, "a"], [21, 22, "p"]], [[40, 40, "v"], [40, 40, "a"]], [[73, 74, "p"], [71, 71, "v"], [129, 129, "v"], [71, 71, "a"], [129, 129, "a"]], [], [[165, 165, "v"], [165, 165, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 1, "a"], [4, 4, "a"], [8, 9, "a"]], [], [[71, 71, "a"]], [[155, 155, "a"]], [], [[180, 180, "p"], [183, 183, "a"]], []], "predicted_relations": [[[21, 22, 0, 1, "USED-FOR"]], [], [[73, 74, 71, 71, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2206.02593-ebd65002-c22b-426d-977d-d4cb17a64ca5", "sentences": [["Dependent-Click", "Model", ":", "Apart", "from", "attraction", "probabilities", "\\", "-LRB-", "\\theta", "\\", "-RRB-", ",", "DCM", "-LRB-", "sec", ":", "dependent-click", "model", "-RRB-", "has", "position", "parameters", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "expressing", "the", "probability", "that", "a", "user", "continues", "exploring", "further", "down", "the", "list", "after", "a", "click", "."], ["Let", "\\", "-LRB-", "L_", "-LCB-", "\\lambda", ",", "k", "-RCB-", "\\", "-RRB-", "be", "LCB", "on", "the", "probability", "that", "satisfactory", "click", "occurred", "on", "position", "\\", "-LRB-", "k\\", "-RRB-", ",", "that", "is", "\\", "-LRB-", "1", "-", "\\lambda", "_k", "\\ge", "L_", "-LCB-", "\\lambda", ",", "k", "-RCB-", "\\", "-RRB-", "."], ["If", "we", "apply", "LCB", "on", "attraction", "probabilities", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "and", "position", "probabilities", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", ",", "then", "\\", "-LRB-", "\\displaystyle", "1", "-", "\\prod", "_", "-LCB-", "k", "=", "1", "-RCB-", "^K", "-LRB-", "1", "-", "L_", "-LCB-", "\\lambda", ",", "k", "-RCB-", "L_", "-LCB-", "\\theta", ",", "A_k", "-RCB-", "-RRB-", "\\le", "1", "-", "\\prod", "_", "-LCB-", "k=1", "-RCB-", "^K", "-LRB-", "1", "-", "-LRB-", "1", "-", "\\lambda", "_k", "-RRB-", "\\theta", "_", "-LCB-", "A_k", "-RCB-", "-RRB-", "\\", "-RRB-", "and", "we", "get", "the", "LCB", "for", "the", "whole", "list", "\\", "-LRB-", "A\\", "-RRB-", "as", "we", "have", "an", "upper", "bound", "on", "each", "term", "in", "the", "product", "."], ["Now", "suppose", "that", "we", "have", "\\", "-LRB-", "1", "-", "\\delta", "\\", "-RRB-", "LCBs", "for", "each", "model", "parameter", "."], ["Then", ",", "by", "the", "union", "bound", ",", "all", "model", "parameter", "LCBs", "hold", "jointly", "with", "probability", "at", "least", "\\", "-LRB-", "1", "-", "\\delta", "-LRB-", "\\left|\\mathcal", "-LCB-", "E", "-RCB-", "\\right|", "+", "K", "-RRB-", "\\", "-RRB-", ",", "and", "so", "do", "the", "LCBs", "for", "all", "lists", "."]], "ner": [[[0, 1, "a"], [5, 6, "p"], [21, 22, "p"]], [[56, 56, "a"], [59, 65, "p"], [51, 51, "v"], [68, 68, "v"], [84, 84, "v"], [56, 59, "p"]], [[94, 95, "p"], [92, 92, "a"], [170, 170, "a"], [119, 119, "v"], [131, 131, "v"], [146, 146, "v"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 1, "a"], [13, 13, "a"], [17, 18, "a"]], [[77, 78, "p"]], [[92, 92, "a"], [155, 156, "p"]], [], []], "predicted_relations": [[[21, 22, 0, 1, "USED-FOR"]], [[59, 65, 56, 56, "USED-FOR"], [68, 68, 59, 65, "USED-FOR"]], [[94, 95, 92, 92, "USED-FOR"]], [], []]}
{"doc_key": "2206.02593-d0dffaa3-c65d-4841-b2a9-960da9284bec", "sentences": [["Position-Based", "Model", ":", "Let", "\\", "-LRB-", "L_", "-LCB-", "p", ",", "k", "-RCB-", "\\", "-RRB-", "be", "the", "LCB", "on", "the", "examination", "probability", "of", "position", "\\", "-LRB-", "k\\", "-RRB-", ",", "that", "is", "\\", "-LRB-", "p_k", "\\ge", "L_", "-LCB-", "p", ",", "k", "-RCB-", "\\", "-RRB-", "."], ["If", "we", "apply", "LCB", "on", "attraction", "probabilities", "\\", "-LRB-", "\\theta", "\\", "-RRB-", "and", "position", "probabilities", "\\", "-LRB-", "p\\", "-RRB-", "in", "PBM", "-LRB-", "sec", ":", "position-based", "model", "-RRB-", ",", "then", "\\", "-LRB-", "\\displaystyle", "\\sum", "_", "-LCB-", "k=1", "-RCB-", "^KL_", "-LCB-", "p", ",", "k", "-RCB-", "L_", "-LCB-", "\\theta", ",", "A_k", "-RCB-", "\\le", "\\sum", "_", "-LCB-", "k=1", "-RCB-", "^Kp_k\\theta", "_", "-LCB-", "A_k", "-RCB-", "\\", "-RRB-", "and", "we", "get", "the", "LCB", "for", "the", "whole", "list", "\\", "-LRB-", "A\\", "-RRB-", "as", "we", "have", "a", "lower", "bound", "on", "each", "term", "in", "the", "sum", "."], ["Now", "suppose", "that", "we", "have", "\\", "-LRB-", "1", "-", "\\delta", "\\", "-RRB-", "LCBs", "for", "each", "model", "parameter", "."], ["Then", ",", "by", "the", "union", "bound", ",", "all", "model", "parameter", "LCBs", "hold", "jointly", "with", "probability", "at", "least", "\\", "-LRB-", "1", "-", "\\delta", "-LRB-", "\\left|\\mathcal", "-LCB-", "E", "-RCB-", "\\right|", "+", "K", "-RRB-", "\\", "-RRB-", ",", "and", "so", "do", "the", "LCBs", "for", "all", "lists", "."], ["The", "single-variable", "LCBs", "are", "presented", "in", "section", ":", "lower", "confidence", "bounds", "."], ["All", "variables", "are", "means", "of", "Bernoulli", "random", "variables", ",", "which", "we", "use", "in", "the", "derivations", "."]], "ner": [[[0, 1, "a"], [16, 16, "p"]], [[46, 46, "p"], [109, 109, "p"]], [], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [], [[140, 140, "p"], [143, 143, "a"]], [], [], []], "predicted_relations": [[[16, 16, 0, 1, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2206.02593-3d910c55-966c-4537-98e1-6eda5db7fcec", "sentences": [["Bayesian", "Lower", "Confidence", "Bounds", ":", "Let", "\\", "-LRB-", "Z\\", "-RRB-", "be", "the", "mean", "of", "a", "Bernoulli", "random", "variable", "and", "\\", "-LRB-", "z\\", "-RRB-", "be", "its", "value", "."], ["Let", "\\", "-LRB-", "Y_1", ",", "\\dots", ",", "Y_n\\", "-RRB-", "be", "\\", "-LRB-", "n\\", "-RRB-", "i.i.d", "."], ["observations", "of", "\\", "-LRB-", "Z\\", "-RRB-", "."], ["We", "define", "\\", "-LRB-", "n_+", "=", "\\sum", "_", "-LCB-", "i", "=", "1", "-RCB-", "^n", "Y_i\\", "-RRB-", "and", "\\", "-LRB-", "n_-", "=", "n", "-", "n_+\\", "-RRB-", "."], ["In", "the", "Bayesian", "setting", ",", "we", "make", "an", "additional", "assumption", "that", "\\", "-LRB-", "Z", "\\sim", "\\mathrm", "-LCB-", "Beta", "-RCB-", "-LRB-", "\\alpha", ",", "\\beta", "-RRB-", "\\", "-RRB-", "."], ["By", "definition", ",", "\\", "-LRB-", "Z", "\\mid", "Y_1", ",", "\\dots", ",", "Y_n", "\\sim", "\\mathrm", "-LCB-", "Beta", "-RCB-", "-LRB-", "\\alpha", "+", "n_+", ",", "\\beta", "+", "n_-", "-RRB-", "\\", "-RRB-", "."], ["Thus", "\\", "-LRB-", "1", "-", "\\delta", "\\", "-RRB-", "LCB", "on", "\\", "-LRB-", "Z\\", "-RRB-", "is", "\\", "-LRB-", "L_Z", "=", "\\max", "\\left\\lbrace", "\\ell", "\\in", "-LSB-", "0", ",", "1", "-RSB-", ":", "\\int", "_", "-LCB-", "z", "=", "0", "-RCB-", "^\\ell", "\\mathrm", "-LCB-", "Beta", "-RCB-", "-LRB-", "z", ";", "\\alpha", "+", "n_+", ",", "\\beta", "+", "n_-", "-RRB-", "\\mathop", "-LCB-", "-RCB-", "\\", "!", "\\mathrm", "-LCB-", "d", "-RCB-", "z", "\\le", "\\delta", "\\right\\rbrace", "\\", ",", ".\\", "-RRB-"]], "ner": [[[0, 3, "a"]], [], [], [], [], [], [[137, 137, "p"], [195, 195, "p"], [137, 137, "v"], [195, 195, "v"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[], [], [], [], [], [], [[137, 137, "p"], [140, 140, "a"]]], "predicted_relations": [[], [], [], [], [], [], [[137, 137, 137, 137, "USED-FOR"], [195, 195, 195, 195, "USED-FOR"]]]}
{"doc_key": "2206.02593-5f2a8b6a-8072-40a2-b115-49b716ce75a6", "sentences": [["Frequentist", "Lower", "Confidence", "Bounds", ":", "If", "the", "prior", "on", "\\", "-LRB-", "Z\\", "-RRB-", "is", "unknown", "or", "poorly", "estimated", ",", "Bayesian", "estimates", "could", "be", "biased", "."], ["In", "this", "case", ",", "Hoeffding", "'s", "inequality", "would", "be", "preferred", ",", "since", "it", "provides", "a", "confidence", "interval", "for", "any", "random", "variable", "on", "\\", "-LRB-", "-LSB-", "0", ",", "1", "-RSB-", "\\", "-RRB-", "."], ["Specifically", ",", "let", "\\", "-LRB-", "Z\\", "-RRB-", "be", "set", "to", "any", "value", "in", "\\", "-LRB-", "-LSB-", "0", ",", "1", "-RSB-", "\\", "-RRB-", ",", "and", "all", "other", "quantities", "be", "defined", "as", "in", "the", "Bayesian", "estimator", "."], ["Then", "\\", "-LRB-", "1", "-", "\\delta", "\\", "-RRB-", "LCB", "on", "\\", "-LRB-", "Z\\", "-RRB-", "is", "\\", "-LRB-", "L_Z", "=", "\\frac", "-LCB-", "n_+", "-RCB-", "-LCB-", "n_+", "+", "n_-", "-RCB-", "-", "\\sqrt", "-LCB-", "\\log", "-LRB-", "1", "/", "\\delta", "-RRB-", "/", "-LRB-", "2n", "-RRB-", "-RCB-", "\\", ",", ",\\", "-RRB-"]], "ner": [[[0, 3, "a"]], [], [], [[97, 97, "p"], [127, 127, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2206.02593-3dd804b6-d336-47ee-a7d2-c868e6a117d6", "sentences": [["The", "empirical", "Bayes", "-LSB-", "30", "-RSB-", "is", "a", "statistical", "procedure", "that", "chooses", "\\", "-LRB-", "-LRB-", "\\alpha", ",", "\\beta", "-RRB-", "\\", "-RRB-", "that", "maximize", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "-LRB-", "\\alpha", ",", "\\beta", "-RRB-", "\\", "-RRB-", "."], ["To", "find", "the", "maximizer", ",", "we", "search", "on", "a", "grid", "."], ["For", "instance", ",", "let", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "=", "-LSB-", "m", "-RSB-", "\\", "-RRB-", "for", "some", "integer", "\\", "-LRB-", "m", ">", "0\\", "-RRB-", "."], ["Then", "we", "search", "over", "all", "\\", "-LRB-", "-LRB-", "\\alpha", ",", "\\beta", "-RRB-", "\\in", "\\mathcal", "-LCB-", "G", "-RCB-", "^2\\", "-RRB-", "."]], "ner": [[[1, 2, "a"], [15, 15, "p"], [30, 30, "p"], [17, 17, "p"], [32, 32, "p"]], [], [], [[82, 82, "p"], [84, 84, "p"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"]], [], [[69, 69, "p"]], []], "predicted_relations": [[[15, 15, 1, 2, "USED-FOR"], [30, 30, 1, 2, "USED-FOR"], [17, 17, 1, 2, "USED-FOR"], [32, 32, 1, 2, "USED-FOR"]], [], [], []]}
{"doc_key": "2206.02539-c5747f38-8fd7-4281-b550-b448499a1fd6", "sentences": [["Training", "was", "performed", "using", "the", "implementation", "of", "FBF", "adversarial", "training", "in", "-LSB-", "10", "-RSB-", ",", "modified", "for", "use", "with", "non-classifiers", ",", "using", "inputs", "in", "the", "space", "\\", "-LRB-", "-LSB-", "-1", ",", "1", "-RSB-", "^", "-LCB-", "3\\times", "720\\times", "1280", "-RCB-", "\\", "-RRB-", "."], ["The", "dataset", "used", "for", "development", "was", "the", "TuSimple", "lane", "detection", "challenge", "-LSB-", "24", "-RSB-", ",", "with", "a", "train/validation/test", "split", "of", "3082/181/363", "images", "."], ["We", "used", "the", "SGD", "optimizer", "with", "a", "momentum", "factor", "of", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "a", "perturbation", "bound", "of", "\\", "-LRB-", "\\varepsilon", "=", "8/255\\", "-RRB-", "for", "both", "FBF", "and", "TRADES", ",", "\\", "-LRB-", "N", "=", "10\\", "-RRB-", "steps", "of", "size", "\\", "-LRB-", "\\eta", "=", "\\varepsilon", "/10\\", "-RRB-", "for", "TRADES", ",", "and", "a", "regularization", "weighting", "of", "\\", "-LRB-", "\\beta", "=", "2.0\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "that", "was", "tuned", "through", "experimentation", "."], ["The", "TRADES", "repository", "-LSB-", "33", "-RSB-", "recommends", "\\", "-LRB-", "1", "\\le", "\\beta", "\\le", "10\\", "-RRB-", "for", "training", "a", "classifier", "for", "which", "the", "KL", "divergence", "is", "calculated", "over", "a", "one-dimensional", "array", "of", "class", "probabilities", "."], ["As", "our", "KL", "divergence", "was", "calculated", "over", "a", "\\", "-LRB-", "320\\times", "180\\", "-RRB-", "-dimensional", "array", "of", "probabilities", ",", "this", "translates", "to", "a", "recommendation", "of", "\\", "-LRB-", "1.74\\times", "10^", "-LCB-", "-5", "-RCB-", "\\le", "\\beta", "\\le", "17.4\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "in", "line", "with", "our", "choice", "of", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "."], ["We", "used", "\\", "-LRB-", "L^", "-LCB-", "\\infty", "-RCB-", "\\", "-RRB-", "-norm", "perturbations", "for", "TRADES", ",", "corresponding", "to", "the", "use", "of", "FGSM", "in", "FBF", "adversarial", "training", "."]], "ner": [[[7, 9, "a"], [12, 12, "v"]], [[49, 52, "a"]], [[81, 82, "p"], [88, 88, "v"], [98, 98, "p"], [100, 100, "v"], [110, 110, "v"], [125, 125, "v"], [107, 107, "p"], [122, 122, "p"], [68, 69, "a"], [72, 73, "p"], [77, 77, "v"], [94, 94, "a"], [113, 113, "a"], [122, 122, "p"]], [[150, 150, "v"], [148, 148, "p"], [138, 138, "a"], [148, 148, "p"]], [[198, 198, "v"], [206, 206, "v"], [203, 203, "p"], [221, 221, "p"], [203, 203, "p"], [221, 221, "p"]], [[247, 249, "a"], [238, 238, "a"], [245, 245, "v"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[37, 37, "v"]], [], [[68, 68, "a"], [72, 73, "p"], [77, 77, "v"], [88, 88, "v"], [100, 100, "v"], [117, 118, "p"]], [[146, 146, "v"], [150, 150, "v"], [159, 160, "p"], [165, 165, "v"]], [[173, 174, "p"], [182, 182, "v"]], [[245, 245, "a"]]], "predicted_relations": [[], [], [[81, 82, 68, 69, "USED-FOR"], [88, 88, 81, 82, "USED-FOR"], [88, 88, 72, 73, "USED-FOR"], [98, 98, 68, 69, "USED-FOR"], [98, 98, 94, 94, "USED-FOR"], [98, 98, 113, 113, "USED-FOR"], [100, 100, 81, 82, "USED-FOR"], [110, 110, 81, 82, "USED-FOR"], [110, 110, 107, 107, "USED-FOR"], [125, 125, 81, 82, "USED-FOR"], [125, 125, 107, 107, "USED-FOR"], [125, 125, 122, 122, "USED-FOR"], [125, 125, 122, 122, "USED-FOR"], [107, 107, 68, 69, "USED-FOR"], [107, 107, 94, 94, "USED-FOR"], [122, 122, 94, 94, "USED-FOR"], [122, 122, 113, 113, "USED-FOR"], [77, 77, 81, 82, "USED-FOR"], [77, 77, 72, 73, "USED-FOR"], [122, 122, 94, 94, "USED-FOR"], [122, 122, 113, 113, "USED-FOR"]], [[148, 148, 138, 138, "USED-FOR"], [148, 148, 138, 138, "USED-FOR"]], [[206, 206, 203, 203, "USED-FOR"], [206, 206, 203, 203, "USED-FOR"]], []]}
{"doc_key": "2203.10945-319e77ee-d58a-4979-80e1-7dfc67290809", "sentences": [["AraBART", "pretraining", "took", "approximately", "60h", "."], ["The", "pretraining", "was", "carried", "out", "on", "128", "Nvidia", "V100", "GPUs", "which", "allowed", "for", "25", "full", "passes", "over", "the", "pretraining", "corpus", "."], ["We", "used", "the", "Adam", "optimizer", "with", "\\", "-LRB-", "\\epsilon", "=", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "and", "\\", "-LRB-", "\\beta", "_2=0.98\\", "-RRB-", "following", "-LSB-", "32", "-RSB-", "."], ["We", "use", "a", "warm", "up", "for", "6", "%", "of", "the", "pretraining", "were", "the", "learning", "rate", "linearly", "increases", "from", "0", "to", "0.0006", ",", "then", "decreases", "linearly", "to", "reach", "0", "at", "the", "end", "of", "the", "pretraining", "."], ["We", "fixed", "the", "update", "frequency", "to", "2", "and", "we", "use", "a", "dropout", "0.1", "in", "the", "first", "20", "epochs", "and", "we", "changed", "it", "to", "0", "in", "the", "last", "5", "epochs", "."], ["Finally", "we", "used", "FP16", "to", "speed-up", "the", "pretraining", "."], ["The", "pretraining", "is", "done", "using", "Fairseq", "-LSB-", "37", "-RSB-", "."]], "ner": [[], [], [[30, 31, "a"], [35, 35, "p"], [47, 47, "v"], [54, 54, "v"], [47, 47, "v"], [54, 54, "v"]], [[64, 65, "a"], [74, 75, "p"], [79, 81, "v"], [79, 79, "v"], [81, 81, "v"], [88, 88, "v"]], [[99, 100, "a"], [99, 100, "p"], [102, 102, "v"], [107, 107, "a"], [108, 108, "v"], [111, 113, "c"], [108, 108, "v"], [119, 119, "v"], [122, 124, "c"]], [[129, 129, "a"]], [[140, 140, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [4, 4, "v"]], [[12, 12, "v"], [19, 19, "v"]], [[30, 30, "a"], [37, 40, "v"], [54, 54, "v"]], [[67, 68, "v"], [74, 75, "p"], [79, 79, "v"], [81, 81, "v"], [88, 88, "v"]], [[99, 100, "p"], [102, 102, "v"], [107, 107, "p"], [108, 108, "v"], [112, 112, "v"], [113, 113, "p"], [119, 119, "v"], [123, 123, "v"], [124, 124, "p"]], [[129, 129, "a"]], [[140, 140, "a"]]], "predicted_relations": [[], [], [[35, 35, 30, 31, "USED-FOR"]], [[74, 75, 64, 65, "USED-FOR"], [79, 81, 74, 75, "USED-FOR"]], [[99, 100, 99, 100, "USED-FOR"], [102, 102, 99, 100, "USED-FOR"], [111, 113, 108, 108, "USED-FOR"], [111, 113, 108, 108, "USED-FOR"], [111, 113, 119, 119, "USED-FOR"], [122, 124, 119, 119, "USED-FOR"]], [], []]}
{"doc_key": "2202.11822-beff327d-3781-4dc5-a755-1ffe0239bc7c", "sentences": [["Our", "data", "sampling", "strategy", "consists", "in", "first", "randomly", "selecting", "a", "data", "source", "-LRB-", "either", "monolingual", "or", "parallel", "data", "-RRB-", "with", "equal", "probability", ",", "then", "sampling", "uniformly", "from", "the", "datasets", "in", "the", "selected", "source", "."], ["We", "continue", "training", "with", "the", "same", "learning", "rate", "schedule", "and", "Adafactor", "optimizer", "-LSB-", "33", "-RSB-", "states", "as", "mT5", "."], ["For", "parallel", "data", ",", "we", "use", "the", "standard", "cross-entropy", "objective", "."], ["For", "monolingual", "data", ",", "we", "use", "the", "MASS", "-LSB-", "34", "-RSB-", "objective", "."], ["We", "additionally", "use", "a", "dropout", "rate", "of", "0.1", "and", "label", "smoothing", "set", "to", "0.1", "."]], "ner": [[], [[44, 45, "a"]], [], [[71, 71, "a"]], [[84, 84, "v"], [90, 90, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[40, 41, "p"], [44, 44, "a"], [51, 51, "a"]], [[61, 61, "a"]], [[71, 71, "a"]], [[81, 82, "p"], [84, 84, "v"], [90, 90, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2204.05660-a6b5ba07-8b46-4731-9537-f9d87928922a", "sentences": [["All", "the", "experiments", "were", "ran", "with", "the", "following", "hyper", "parameters", ",", "batch", "size", "was", "kept", "at", "16", "where", "as", "the", "eval", "batch", "size", "was", "5", "."], ["The", "maximum", "number", "of", "epoch", "ran", "for", "the", "experiments", "were", "5", "with", "the", "warm-up", "kept", "at", "0.06", "."], ["The", "learning", "rate", "used", "was", "1.5e-5", "and", "the", "weight", "decay", "was", "0.01", "."]], "ner": [[[8, 9, "a"], [11, 12, "p"], [21, 22, "p"], [16, 16, "v"], [24, 24, "v"], [20, 22, "c"], [24, 24, "v"]], [[36, 36, "v"], [27, 30, "p"], [36, 36, "v"], [39, 39, "p"], [42, 42, "v"]], [[49, 49, "v"], [49, 49, "v"], [45, 46, "p"], [49, 49, "v"], [52, 53, "p"], [55, 55, "v"]]], "relations": [[], [], []], "predicted_ner": [[[11, 12, "p"], [16, 16, "v"], [20, 22, "p"], [24, 24, "v"]], [[36, 36, "v"], [39, 39, "p"], [42, 42, "v"]], [[45, 46, "p"], [49, 49, "v"], [52, 53, "p"], [55, 55, "v"]]], "predicted_relations": [[[11, 12, 8, 9, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [[36, 36, 39, 39, "USED-FOR"], [36, 36, 39, 39, "USED-FOR"], [42, 42, 39, 39, "USED-FOR"]], [[49, 49, 45, 46, "USED-FOR"], [49, 49, 45, 46, "USED-FOR"], [49, 49, 45, 46, "USED-FOR"], [55, 55, 52, 53, "USED-FOR"]]]}
{"doc_key": "2211.02145-08ef628b-20e3-427d-be2b-f31bad7588fb", "sentences": [["We", "feed", "random", "noise", "to", "initialize", "the", "decomposition", "network", "in", "the", "same", "way", "as", "Omnimatte", "lu2021omnimatte", "."], ["We", "set", "up", "one", "discriminator", "for", "the", "foreground", "layer", ",", "and", "one", "for", "the", "residual", "layer", "."], ["Their", "receptive", "fields", "are", "at", "three", "scales", ":", "16\\", "-LRB-", "\\times", "\\", "-RRB-", "16", ",", "32\\", "-LRB-", "\\times", "\\", "-RRB-", "32", ",", "and", "64\\", "-LRB-", "\\times", "\\", "-RRB-", "64", "."], ["The", "patches", "are", "sampled", "over", "the", "entire", "frame", ",", "so", "that", "the", "discriminator", "loss", "\\", "-LRB-", "L_\\textit", "-LCB-", "adv", "-RCB-", "\\", "-RRB-", "provides", "an", "alternative", "supervision", "to", "zero-alpha", "regions", "that", "can", "not", "be", "supervised", "by", "\\", "-LRB-", "L_\\textit", "-LCB-", "recon", "-RCB-", "\\", "-RRB-", "-LRB-", "\\", "-LRB-", "L_\\textit", "-LCB-", "RGB-warp", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "L_", "-LCB-", "\\alpha", "\\textit", "-LCB-", "-warp", "-RCB-", "-RCB-", "\\", "-RRB-", "are", "other", "supervisions", "on", "those", "regions", "-RRB-", "."], ["In", "Stage", "1", ",", "we", "use", "SIFT", "features", "-LSB-", "26", "-RSB-", "and", "FLANN-based", "matcher", "to", "pre-compute", "a", "homography", "for", "each", "frame", "."], ["Thus", "the", "model", "only", "needs", "to", "estimate", "a", "background", "canvas", "and", "warp", "it", "to", "each", "frame", "with", "an", "appropriate", "homography", "."], ["Then", "we", "freeze", "the", "environment", "layer", "in", "the", "later", "stages", "to", "simplify", "the", "factorization", "optimization", "."], ["We", "use", "all", "aforementioned", "losses", "and", "train", "on", "NVIDIA", "RTX", "A6000", "for", "1200", "epochs", "in", "both", "Stage", "1", "and", "3", ",", "and", "only", "use", "\\", "-LRB-", "L_\\textit", "-LCB-", "adv", "-RCB-", "\\", "-RRB-", "in", "Stage", "3", "."], ["We", "use", "the", "ADAM", "optimizer", "-LSB-", "16", "-RSB-", "when", "training", "the", "decomposition", "network", "and", "discriminators", ",", "with", "learning", "rate", "0.001", "and", "batch", "size", "16", "."], ["When", "applying", "strategies", "in", "Section", "REF", ",", "we", "use", "3", "temporal", "scales", ":", "the", "frame", "at", "time", "step", "\\", "-LRB-", "t\\", "-RRB-", "is", "paired", "with", "\\", "-LRB-", "t+1\\", "-RRB-", ",", "\\", "-LRB-", "t+4\\", "-RRB-", ",", "and", "\\", "-LRB-", "t+8\\", "-RRB-", "as", "inputs", "."], ["All", "flow-related", "losses", "are", "optimized", "for", "all", "scales", "."]], "ner": [[[14, 14, "a"]], [], [[42, 42, "v"], [47, 47, "v"]], [], [[143, 144, "a"], [149, 150, "a"]], [], [], [], [[235, 236, "a"], [251, 251, "v"], [238, 238, "v"], [255, 255, "v"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[14, 14, "a"]], [[20, 20, "v"], [28, 28, "v"]], [[39, 39, "v"], [47, 47, "v"], [54, 54, "v"], [62, 62, "v"]], [[76, 77, "a"], [80, 83, "a"], [91, 91, "v"]], [[139, 139, "v"]], [], [], [[208, 208, "v"], [209, 209, "p"], [213, 213, "v"], [215, 215, "v"], [230, 230, "v"]], [[235, 235, "a"], [249, 250, "p"], [251, 251, "v"], [253, 254, "p"], [255, 255, "v"]], [[266, 266, "v"], [277, 277, "p"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2211.02145-50ff1c64-5666-491f-8ff9-a146c2f43e42", "sentences": [["where", "\\", "-LRB-", "\\lambda", "_1", "=", "\\lambda", "_2", "=", "\\lambda", "_3", "=", "0.005\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_4", "=", "\\lambda", "_5", "=", "\\lambda", "_7", "=", "0.0005\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_6", "=", "25\\", "-RRB-", ",", "and", "\\", "-LRB-", "L_\\textit", "-LCB-", "mask-init", "-RCB-", "\\", "-RRB-", "is", "turned", "off", "after", "it", "falls", "below", "0.05", "."]], "ner": [[[12, 12, "v"], [12, 12, "v"], [12, 12, "v"], [26, 26, "v"], [26, 26, "v"], [34, 34, "v"], [26, 26, "v"]]], "relations": [[]], "predicted_ner": [[[12, 12, "v"], [31, 34, "p"], [53, 53, "v"]]], "predicted_relations": [[]]}
{"doc_key": "2211.02213-9c0019c1-8ef1-4d20-a4ba-4fcda0988bcb", "sentences": [["In", "all", "experiments", ",", "we", "choose", "YOLOv5", "with", "Large", "parameters", "-LRB-", "YOLOv5-L", "-RRB-", "as", "the", "detector", "for", "its", "comparable", "detection", "accuracy", "with", "state-of-the-art", "object", "detection", "methods", "in", "about", "real-time", "."], ["All", "training", "and", "testing", "images", "are", "padded", "and", "resized", "in", "shape", "\\", "-LRB-", "-LRB-", "960", ",", "960", ",", "3", "-RRB-", "\\", "-RRB-", "."], ["During", "training", ",", "each", "batch", "consists", "of", "two", "pairs", "of", "images", ":", "\\", "-LRB-", "-LRB-", "\\mathbf", "-LCB-", "I", "-RCB-", "^s", ",", "\\mathbf", "-LCB-", "I", "-RCB-", "^s_", "-LCB-", "f", "-RCB-", "-RRB-", "\\", "-RRB-", "with", "labels", "and", "\\", "-LRB-", "-LRB-", "\\mathbf", "-LCB-", "I", "-RCB-", "^t", ",", "\\mathbf", "-LCB-", "I", "-RCB-", "^t_", "-LCB-", "f", "-RCB-", "-RRB-", "\\", "-RRB-", "without", "labels", "."], ["We", "can", "set", "the", "batchsize", "to", "10", "in", "one", "24GB", "GTX3090", "GPU", "."], ["Total", "epochs", "are", "200", "."], ["The", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "in", "EMA", "for", "the", "teacher", "model", "is", "set", "to", "\\", "-LRB-", "0.99\\", "-RRB-", "."], ["In", "filters", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "_\\mathcal", "-LCB-", "B", "-RCB-", "-LSB-", "\\cdot", "-RSB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\mathcal", "-LCB-", "G", "-RCB-", "_\\mathcal", "-LCB-", "C", "-RCB-", "-LSB-", "\\cdot", "-RSB-", "\\", "-RRB-", ",", "we", "set", "the", "IoU", "threshold", "\\", "-LRB-", "\\tau", "_", "-LCB-", "box", "-RCB-", "=0.3\\", "-RRB-", "and", "the", "category", "score", "threshold", "\\", "-LRB-", "\\tau", "_", "-LCB-", "cls", "-RCB-", "=0.8\\", "-RRB-", "."], ["Other", "not", "mentioned", "settings", "keep", "consistent", "with", "the", "setup", "in", "YOLOv5", "-LSB-", "20", "-RSB-", "."], ["For", "the", "hyper-parameters", "in", "SSDA-YOLO", ",", "we", "set", "\\", "-LRB-", "\\alpha", "=0.005\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "=2.0\\", "-RRB-", "in", "the", "overall", "loss", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "\\", "-RRB-", "."], ["And", "the", "consistency", "loss", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "con", "-RCB-", "\\", "-RRB-", "adopts", "L2", "distance", "."], ["These", "selected", "settings", "will", "be", "discussed", "in", "our", "ablation", "studies", "."]], "ner": [[[6, 6, "a"], [11, 11, "a"], [9, 9, "p"], [8, 8, "v"]], [], [], [], [], [[136, 136, "a"], [132, 132, "p"], [146, 146, "v"]], [[150, 150, "a"], [186, 187, "p"], [195, 195, "v"], [199, 201, "p"], [209, 209, "v"]], [[222, 222, "a"]], [[229, 229, "p"], [231, 231, "a"], [237, 237, "p"], [238, 238, "v"], [243, 243, "p"], [244, 244, "v"]], [[261, 262, "p"], [276, 277, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [11, 11, "a"]], [[44, 48, "v"]], [[60, 60, "v"]], [[115, 115, "p"], [117, 117, "v"], [119, 119, "v"], [120, 120, "v"], [121, 121, "a"]], [[127, 127, "v"]], [[132, 132, "p"], [136, 136, "a"], [146, 146, "v"]], [[186, 187, "p"], [195, 195, "v"], [199, 201, "p"], [209, 209, "v"]], [[222, 222, "a"]], [[231, 231, "a"], [237, 237, "p"], [244, 244, "v"], [248, 249, "a"]], [[261, 262, "a"], [276, 276, "v"]], []], "predicted_relations": [[[9, 9, 6, 6, "USED-FOR"], [9, 9, 11, 11, "USED-FOR"]], [], [], [], [], [], [[186, 187, 150, 150, "USED-FOR"]], [], [[229, 229, 231, 231, "USED-FOR"], [238, 238, 229, 229, "USED-FOR"], [238, 238, 237, 237, "USED-FOR"], [238, 238, 243, 243, "USED-FOR"], [243, 243, 231, 231, "USED-FOR"], [244, 244, 229, 229, "USED-FOR"], [244, 244, 237, 237, "USED-FOR"], [244, 244, 243, 243, "USED-FOR"]], [], []]}
{"doc_key": "2211.02162-0d615b32-c263-4f79-acaf-ef3a3aa675c6", "sentences": [["For", "training", "on", "all", "datasets", "with", "BART", ",", "we", "first", "follow", "the", "hyperparameter", "setting", "provided", "by", "the", "original", "BART", "training", "script", "for", "XSumhttps", ":", "//github.com/pytorch/fairseq/blob/main/examples/bart/README.summarization.md", "except", "that", "we", "set", "the", "total", "number", "of", "update", "steps", "to", "\\", "-LRB-", "30", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "for", "TempWikiBio", "and", "\\", "-LRB-", "35", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "for", "the", "content", "transfer", "dataset", "."], ["In", "addition", ",", "we", "adjust", "the", "accumulated", "batch", "size", "for", "training", "on", "TempWikiBio", "to", "have", "\\", "-LRB-", "65", "-LCB-", ",", "-RCB-", "536\\", "-RRB-", "tokens", "in", "each", "batch", "."], ["We", "then", "tune", "the", "learning", "rates", "on", "TempWikiBio", "and", "the", "content", "transfer", "dataset", "by", "searching", "through", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "with", "the", "model", "without", "prompts", "."], ["Based", "on", "the", "BLEU-4", "scores", "on", "the", "development", "sets", ",", "we", "choose", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "TempWikiBio", "and", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "the", "content", "transfer", "dataset", "."], ["Each", "model", "is", "trained", "for", "one", "run", "with", "one", "random", "seed", "due", "to", "the", "high", "computational", "cost", "of", "fine-tuning", "large", "models", "."], ["For", "experiments", "with", "T5", ",", "we", "follow", "the", "default", "parameters", "suggested", "by", "HuggingFace", "."]], "ner": [[[6, 6, "a"], [18, 18, "a"], [45, 45, "a"], [30, 34, "p"]], [[73, 73, "a"], [67, 69, "p"]], [[96, 96, "a"], [93, 94, "p"]], [[163, 163, "a"]], [], [[205, 205, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [18, 18, "a"], [38, 42, "v"], [45, 45, "a"], [49, 53, "v"], [57, 59, "a"]], [[68, 69, "p"], [73, 73, "a"], [78, 82, "v"]], [[93, 94, "p"], [96, 96, "a"], [99, 101, "a"]], [[144, 144, "a"], [163, 163, "a"], [176, 178, "a"]], [[185, 185, "v"], [188, 188, "v"]], [[205, 205, "a"]]], "predicted_relations": [[[30, 34, 6, 6, "USED-FOR"], [30, 34, 18, 18, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2206.03113-f97dd228-b4ee-4328-85be-3ad86982a52e", "sentences": [["The", "proposed", "method", "is", "implemented", "with", "PyTorch", "."], ["The", "original", "input", "and", "output", "size", "of", "the", "inpainting", "model", "are", "both", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "as", "many", "other", "inpainting", "methods", "."], ["And", "the", "input", "size", "to", "Haar", "transform", "is", "upsampled", "to", "\\", "-LRB-", "512\\times", "512\\", "-RRB-", "from", "\\", "-LRB-", "256\\times", "256\\", "-RRB-", "."], ["We", "train", "the", "model", "in", "240k", "steps", "in", "Celeba-HQ", "and", "1000k", "steps", "in", "Places2", "in", "Adam", "optimizer", "-LSB-", "50", "-RSB-", "of", "\\", "-LRB-", "\\beta", "_1=0\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2=0.9\\", "-RRB-", "."], ["The", "initial", "learning", "rates", "are", "\\", "-LRB-", "2e-4\\", "-RRB-", "and", "\\", "-LRB-", "2e-5\\", "-RRB-", "for", "the", "generator", "and", "discriminator", "respectively", "."], ["Then", ",", "the", "learning", "rate", "is", "decayed", "with", "0.5", "for", "\\", "-LRB-", "1/5\\", "-RRB-", "of", "the", "total", "steps", "."], ["Our", "model", "is", "trained", "in", "Pytorch", "v1.3.1", ",", "and", "costs", "about", "1", "day", "to", "train", "in", "Celeba-HQ", "and", "5", "days", "to", "train", "in", "Places2", "with", "a", "single", "NVIDIA", "-LRB-", "R", "-RRB-", "Tesla", "-LRB-", "R", "-RRB-", "V100", "16GB", "GPU", "."]], "ner": [[[6, 6, "a"]], [], [[36, 37, "a"], [33, 34, "p"]], [[68, 69, "a"], [77, 77, "v"], [83, 83, "v"], [83, 83, "v"]], [], [[115, 115, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [6, 6, "a"]], [[23, 23, "v"]], [[44, 44, "v"], [50, 50, "v"]], [[58, 58, "v"], [61, 61, "a"], [63, 63, "v"], [68, 68, "a"], [77, 77, "v"], [83, 83, "v"]], [[88, 89, "p"], [93, 93, "v"], [98, 98, "v"]], [[110, 111, "p"], [115, 115, "v"], [119, 119, "v"]], [[127, 127, "a"], [137, 137, "v"], [142, 142, "a"], [144, 144, "v"], [149, 149, "a"], [162, 162, "v"]]], "predicted_relations": [[], [], [[33, 34, 36, 37, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2212.10405-f01e3b3b-cd67-4cf5-9faa-e6c4cd00d3c7", "sentences": [["We", "implement", "AnnoBERT", "and", "the", "BERT", "baseline", "using", "the", "Huggingface", "transformers", "library", "-LSB-", "50", "-RSB-", "."], ["Models", "are", "trained", "for", "4", "epochs", "-LRB-", "except", "LEAM", "for", "15", "epochs", "-RRB-", ",", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "cross-entropy", "loss", ",", "and", "a", "batch-size", "of", "32", "."], ["Adam", "-LSB-", "26", "-RSB-", "is", "used", "as", "the", "optimiser", ",", "with", "Tanh", "activation", "function", "."], ["LEAM", "model", "uses", "FastText", "embeddings", "of", "dimension", "300", "-LSB-", "19", "-RSB-", "as", "the", "encoder", ",", "and", "softmax", "function", "in", "the", "output", "layer", "."], ["We", "report", "average", "results", "for", "10", "separate", "runs", "of", "each", "model", "."]], "ner": [[[2, 2, "a"], [5, 6, "a"]], [[32, 33, "p"], [45, 45, "p"], [49, 49, "p"], [51, 51, "v"], [32, 33, "p"], [45, 45, "p"], [49, 49, "p"], [51, 51, "v"], [24, 24, "a"], [32, 33, "p"], [45, 45, "p"], [49, 49, "p"], [51, 51, "v"]], [[61, 61, "p"], [53, 53, "v"], [65, 66, "p"], [64, 64, "v"], [61, 61, "p"], [53, 53, "v"], [65, 66, "p"], [64, 64, "v"], [61, 61, "p"], [53, 53, "v"], [65, 66, "p"], [64, 64, "v"], [53, 53, "a"]], [[68, 68, "a"], [81, 81, "p"], [71, 75, "v"], [88, 89, "p"], [84, 85, "v"], [71, 72, "a"], [74, 74, "p"], [75, 75, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [5, 5, "a"]], [[20, 20, "v"], [21, 21, "p"], [24, 24, "a"], [26, 26, "v"], [27, 27, "p"], [32, 33, "p"], [37, 39, "v"], [44, 45, "a"], [49, 49, "p"], [51, 51, "v"]], [[53, 53, "a"], [64, 64, "a"]], [[68, 68, "a"], [74, 74, "p"], [75, 75, "v"]], [[96, 96, "v"]]], "predicted_relations": [[], [[32, 33, 24, 24, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [32, 33, 24, 24, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [32, 33, 24, 24, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"], [51, 51, 45, 45, "USED-FOR"]], [[61, 61, 53, 53, "USED-FOR"], [65, 66, 53, 53, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [65, 66, 53, 53, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [61, 61, 53, 53, "USED-FOR"], [65, 66, 53, 53, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"], [64, 64, 65, 66, "USED-FOR"]], [[81, 81, 68, 68, "USED-FOR"], [81, 81, 71, 72, "USED-FOR"], [71, 75, 74, 74, "USED-FOR"], [88, 89, 68, 68, "USED-FOR"], [88, 89, 71, 72, "USED-FOR"], [74, 74, 68, 68, "USED-FOR"], [74, 74, 71, 72, "USED-FOR"], [75, 75, 74, 74, "USED-FOR"]], []]}
{"doc_key": "2203.06456-5b400ab5-3103-4857-ac9f-2c6e6cece8d4", "sentences": [["Data", "is", "generated", "by", "solving", "the", "problem", "-LRB-", "REF", "-RRB-", "using", "a", "high", "precision", "numerical", "scheme", "with", "a", "pseudo-spectral", "method", "for", "spatial", "discretization", "and", "4th", "order", "Runge-Kutta", "for", "temporal", "discretization", "-LRB-", "with", "time", "step", "size", "\\", "-LRB-", "\\delta", "t", "=", "0.01\\", "-RRB-", "-RRB-", "."], ["We", "assume", "periodic", "boundary", "conditions", "and", "the", "initial", "value", "\\", "-LRB-", "u", "-LRB-", "x", ",", "y", ",", "0", "-RRB-", "=", "\\sum", "_", "-LCB-", "|k|", ",", "|l|", "\\le", "N", "-RCB-", "\\lambda", "_", "-LCB-", "k", ",", "l", "-RCB-", "cos", "-LRB-", "kx", "+", "ly", "-RRB-", "+", "\\gamma", "_", "-LCB-", "k", ",", "l", "-RCB-", "sin", "-LRB-", "kx", "+", "ly", "-RRB-", "\\", "-RRB-"]], "ner": [[[18, 19, "a"], [32, 34, "p"], [40, 40, "v"]], []], "relations": [[], []], "predicted_ner": [[[18, 19, "a"], [24, 26, "a"], [40, 40, "v"]], []], "predicted_relations": [[], []]}
{"doc_key": "2204.02791-b09e0a67-4c5b-4553-8e12-8a51ec3fb110", "sentences": [["The", "training", "data", "consists", "of", "three", "parts", ":", "1", "-RRB-", "all", "training", "data", "from", "the", "\\", "-LRB-", "\\textit", "-LCB-", "DAVIS", "-RCB-", "_", "-LCB-", "\\textit", "-LCB-", "16", "-RCB-", "-RCB-", "\\", "-RRB-", ",", "including", "30", "videos", "with", "about", "2K", "frames", ";", "2", "-RRB-", "a", "subset", "of", "the", "training", "set", "of", "\\", "-LRB-", "\\textit", "-LCB-", "YouTube-VOS", "-RCB-", "\\", "-RRB-", "selected", "18K", "frames", ",", "which", "is", "obtained", "by", "sampling", "images", "containing", "a", "single", "object", "per", "sequence", ";", "3", "-RRB-", "\\", "-LRB-", "\\textit", "-LCB-", "DUTS-TR", "-RCB-", "\\", "-RRB-", "which", "is", "the", "training", "set", "of", "\\", "-LRB-", "\\textit", "-LCB-", "DUTS", "-RCB-", "\\", "-RRB-", "has", "more", "than", "10K", "images", "."], ["The", "training", "process", "is", "divided", "into", "two", "stages", "."], ["Stage", "1", ":", "we", "first", "pre-train", "our", "network", "for", "200K", "iterations", "on", "a", "subset", "of", "\\", "-LRB-", "\\textit", "-LCB-", "YouTube-VOS", "-RCB-", "\\", "-RRB-", "."], ["During", "this", "training", "period", ",", "the", "entire", "network", "is", "trained", "using", "Adam", "optimizer", "-LRB-", "\\", "-LRB-", "\\beta", "_", "-LCB-", "1", "-RCB-", "=0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_", "-LCB-", "2", "-RCB-", "=0.999\\", "-RRB-", "-RRB-", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "for", "the", "FEM", ",", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "the", "ACM", "and", "APM", "decoder", ",", "and", "the", "MCM", "is", "set", "as", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "batch", "size", "is", "set", "to", "8", ",", "and", "the", "weight", "decay", "is", "0", "."], ["Stage", "2", ":", "we", "fine-tune", "the", "entire", "network", "on", "the", "training", "set", "of", "\\", "-LRB-", "\\textit", "-LCB-", "DAVIS", "-RCB-", "_", "-LCB-", "\\textit", "-LCB-", "16", "-RCB-", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\textit", "-LCB-", "DUTS", "-RCB-", "\\", "-RRB-", "with", "our", "joint", "training", "strategy", "."], ["In", "this", "stage", ",", "the", "Adam", "optimizer", "is", "used", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-7", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", ",", "and", "\\", "-LRB-", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "each", "of", "the", "above-mention", "modules", ",", "respectively", "."], ["We", "train", "our", "network", "for", "155K", "iterations", "in", "the", "second", "training", "stage", "."], ["Data", "augmentation", "-LRB-", "e.g.", ",", "scaling", ",", "flipping", ",", "and", "rotation", "-RRB-", "is", "also", "adopted", "for", "both", "image", "and", "video", "data", "."], ["Our", "IMCNet", "is", "implemented", "in", "PyTorch", "."], ["All", "experiments", "and", "analyses", "are", "conducted", "on", "an", "NVIDIA", "TITAN", "RTX", "GPU", ",", "and", "the", "overall", "training", "time", "is", "about", "72", "hours", "."]], "ner": [[[52, 52, "a"], [79, 79, "a"]], [], [[131, 131, "a"]], [[157, 157, "v"], [167, 167, "v"], [185, 185, "a"], [172, 173, "p"], [197, 200, "a"], [172, 173, "p"], [204, 204, "a"], [172, 173, "p"], [172, 173, "p"], [172, 173, "p"], [172, 173, "p"]], [], [], [[280, 281, "a"], [287, 288, "p"], [287, 288, "p"], [287, 288, "p"], [280, 281, "a"], [287, 288, "p"], [287, 288, "p"], [287, 288, "p"]], [], [[339, 340, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "v"], [32, 32, "v"], [36, 36, "v"], [57, 57, "v"], [100, 100, "v"]], [[109, 109, "v"]], [[119, 119, "a"], [121, 121, "v"]], [[147, 147, "a"], [157, 157, "v"], [167, 167, "v"], [172, 173, "p"], [177, 180, "v"], [185, 185, "a"], [189, 192, "v"], [197, 197, "a"], [204, 204, "a"], [210, 213, "v"]], [[218, 219, "p"], [223, 223, "v"], [227, 228, "p"], [230, 230, "v"]], [[263, 266, "a"]], [[280, 280, "a"], [287, 288, "p"], [292, 295, "v"], [301, 304, "v"], [311, 314, "v"]], [[329, 329, "a"], [331, 331, "v"]], [], [[362, 362, "a"], [366, 366, "a"]], [[388, 388, "v"]]], "predicted_relations": [[], [], [], [[157, 157, 172, 173, "USED-FOR"], [157, 157, 172, 173, "USED-FOR"], [157, 157, 172, 173, "USED-FOR"], [157, 157, 172, 173, "USED-FOR"], [157, 157, 172, 173, "USED-FOR"], [157, 157, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [167, 167, 172, 173, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"], [172, 173, 185, 185, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2202.07036-2e087d5e-9705-4c76-8695-b88b258b3da7", "sentences": [["For", "all", "experiments", "we", "use", "Nvidia", "Tesla", "V100-SXM2", "GPUs", "with", "32", "GB", "VRAM", "equipped", "with", "Core", "Xeon", "CPUs", "and", "192", "GB", "RAM", "."], ["We", "use", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["We", "run", "each", "experiment", "for", "1,000", "epochs", "with", "a", "batch", "size", "of", "50", "-LRB-", "unless", "stated", "differently", "-RRB-", "and", "report", "results", "for", "the", "best", "epoch", "."], ["We", "split", "each", "dataset", "into", "five", "approx", "."], ["80/20", "train/test", "splits", ",", "and", "report", "the", "mean", "and", "standard", "deviation", "of", "the", "WER", "and", "CER", "."], ["We", "use", "our", "OnHW-equations", ",", "OnHW-words500", "-LRB-", "R", "-RRB-", ",", "OnHW-wordsRandom", "and", "OnHW-wordsTraj", "as", "well", "as", "the", "IAM-OnDB", "and", "VNOnDB-words", "datasets", "for", "the", "sequence-based", "classification", "task", ",", "and", "the", "OnHW-symbols", ",", "split", "OnHW-equations", "and", "OnHW-chars", "datasets", "for", "the", "single", "character-based", "classification", "task", "."], ["Each", "model", "is", "trained", "from", "scratch", "for", "every", "dataset", "."], ["We", "make", "use", "of", "the", "time-series", "classification", "toolbox", "tsai", "that", "contains", "a", "variety", "of", "state-of-the-art", "techniques", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", "."]], "ner": [[], [[26, 27, "a"], [30, 31, "p"]], [], [], [], [[96, 96, "a"], [125, 125, "a"], [103, 103, "a"], [105, 105, "a"], [110, 110, "a"], [112, 112, "a"], [122, 122, "a"], [124, 125, "a"], [127, 127, "a"]], [], [[154, 154, "a"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[10, 11, "v"], [12, 12, "a"], [19, 20, "v"]], [[26, 26, "a"], [30, 31, "p"], [35, 39, "v"]], [[47, 47, "v"], [48, 48, "p"], [51, 52, "p"], [54, 54, "v"]], [[73, 73, "v"]], [], [[110, 110, "a"], [112, 112, "a"]], [], [[154, 154, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2205.03512-abde715c-f0e8-4ede-8b9d-8a1d8351e2a2", "sentences": [["For", "the", "joint", "related", "work", "tagger", "training", ",", "we", "use", "GeForce", "GTX", "1080", "11", "GB", "GPUs", "."], ["The", "training", "process", "lasts", "2.5", "hours", "on", "a", "single", "GPU", "using", "Huggingface", "'s", "-LSB-", "56", "-RSB-", "SciBERT", ",", "BERT-base", "or", "Roberta-base", "as", "the", "paragraph", "encoders", ",", "and", "it", "lasts", "6.5", "hours", "using", "LED-base", "encoder", "."], ["We", "train", "the", "models", "for", "15", "epochs", "."], ["It", "takes", "approximately", "one", "week", "to", "run", "the", "hyper-parameter", "search", "using", "five-fold", "cross-validation", "for", "all", "language", "models", ",", "using", "8", "GPUs", "in", "total", "."]], "ner": [[[10, 15, "a"]], [[28, 33, "a"], [35, 35, "a"], [37, 37, "a"], [49, 50, "a"]], [], [[71, 72, "a"], [68, 69, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[13, 14, "v"]], [[21, 21, "v"], [33, 33, "a"], [35, 35, "a"], [37, 37, "a"], [46, 46, "v"], [49, 49, "a"]], [[57, 57, "v"], [58, 58, "p"]], [[63, 63, "v"], [68, 69, "c"], [71, 71, "v"], [72, 72, "a"], [79, 79, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2205.03512-a1ccaa6b-26ea-4cb2-a561-0c6772dec7dd", "sentences": [["For", "training", "the", "citation", "span", "generation", "model", ",", "we", "use", "Tesla", "V100s-PCIE-32GB", "GPUs", "."], ["The", "training", "process", "lasts", "for", "2", "days", "on", "a", "single", "GPU", "."], ["We", "run", "the", "training", "for", "a", "maximum", "of", "3", "epochs", "with", "early", "stopping", "based", "on", "the", "validation", "loss", "."]], "ner": [[[10, 12, "a"]], [[15, 16, "a"]], [[32, 35, "p"], [34, 34, "v"], [32, 35, "c"], [37, 38, "p"], [37, 38, "a"]]], "relations": [[], [], []], "predicted_ner": [[[3, 6, "a"]], [[19, 19, "v"]], [[34, 34, "v"], [35, 35, "p"], [42, 43, "p"]]], "predicted_relations": [[], [], [[32, 35, 37, 38, "USED-FOR"], [37, 38, 37, 38, "USED-FOR"]]]}
{"doc_key": "2212.07652-a3d9e719-c069-4326-a776-7ff2e84096e1", "sentences": [["Datasets", ":", "We", "mainly", "expect", "to", "evaluate", "the", "association", "quality", "of", "BPJDet", ",", "while", "maintaining", "high", "object", "detection", "accuracy", "."], ["Three", "public", "datasets", "including", "CityPersons", ",", "CrowdHuman", "and", "BodyHands", "are", "chosen", "."], ["The", "former", "two", "are", "for", "pedestrian", "detection", "tasks", "."], ["In", "CityPersons", ",", "it", "has", "2,975", "and", "500", "images", "for", "training", "and", "validation", ",", "respectively", "."], ["In", "CrowdHuman", ",", "there", "are", "15,000", "images", "for", "training", "and", "4,375", "images", "for", "validation", "."], ["Following", "BFJDet", ",", "we", "use", "its", "re-annotated", "box", "labels", "of", "visible", "faces", "for", "conducting", "corresponding", "experiments", "."], ["The", "last", "dataset", "BodyHands", "is", "for", "hand-body", "associations", "tasks", "."], ["It", "has", "18,861", "and", "1,629", "images", "in", "train-set", "and", "test-set", "with", "annotations", "for", "hand", "and", "body", "locations", "and", "correspondences", "."], ["We", "implement", "body-hand", "joint", "detection", "task", "in", "it", "for", "comparing", "."]], "ner": [[], [[24, 24, "a"], [26, 26, "a"], [28, 28, "a"]], [], [[42, 42, "a"], [49, 51, "p"]], [[58, 58, "a"], [63, 65, "p"], [62, 62, "v"], [67, 67, "v"], [68, 70, "c"]], [], [[92, 92, "a"]], [[104, 106, "p"], [101, 101, "v"], [103, 103, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "a"]], [[20, 20, "v"], [24, 24, "a"], [26, 26, "a"], [28, 28, "a"]], [[34, 34, "v"]], [[42, 42, "a"], [46, 46, "v"], [48, 48, "v"]], [[58, 58, "a"], [62, 62, "v"], [67, 67, "v"]], [[73, 73, "a"]], [[92, 92, "a"]], [[101, 101, "v"], [103, 103, "v"]], []], "predicted_relations": [[], [], [], [[49, 51, 42, 42, "USED-FOR"]], [[63, 65, 58, 58, "USED-FOR"], [62, 62, 63, 65, "USED-FOR"], [67, 67, 63, 65, "USED-FOR"], [68, 70, 62, 62, "USED-FOR"], [68, 70, 67, 67, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2212.07652-3b979513-c8d7-4d5b-9fb4-39bdb2c4f932", "sentences": [["Implementation", "Details", ":", "We", "adopt", "the", "PyTorch", "1.10", "and", "4", "RTX-3090", "GPUs", "for", "training", "."], ["Depending", "on", "the", "dataset", "complexity", "and", "scale", ",", "we", "train", "on", "the", "CityPersons", ",", "CrowdHuman", "and", "BodyHands", "datasets", "for", "100", ",", "150", "and", "100", "epochs", "using", "the", "SGD", "optimizer", ",", "respectively", "."], ["Following", "the", "original", "YOLOv5", "architecture", ",", "we", "train", "three", "kinds", "of", "models", "including", "BFJDet-S/M/L", "by", "controlling", "the", "depth", "and", "width", "of", "bottlenecks", "in", "\\", "-LRB-", "\\mathcal", "-LCB-", "N", "-RCB-", "\\", "-RRB-", "."], ["The", "shape", "of", "input", "images", "is", "resized", "and", "zero-padded", "to", "\\", "-LRB-", "1536\\times", "1536\\times", "3\\", "-RRB-", "following", "settings", "in", "JointDet", "and", "BFJDet", "."], ["We", "adopt", "the", "data", "training", "augmentation", "but", "leave", "out", "test", "time", "augmentation", "-LRB-", "TTA", "-RRB-", "."], ["As", "for", "many", "hyperparameters", ",", "we", "keep", "most", "of", "them", "unchanged", ",", "including", "adaptive", "anchors", "boxes", "\\", "-LRB-", "\\mathcal", "-LCB-", "B", "-RCB-", "^s\\", "-RRB-", ",", "the", "grid", "balance", "weight", "\\", "-LRB-", "w_s\\", "-RRB-", ",", "and", "the", "loss", "weights", "\\", "-LRB-", "\\alpha", "\\", "!", "=\\", "!", "0.05\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "\\", "!", "=\\", "!", "0.7\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "\\", "!", "=\\", "!", "0.3\\", "-RRB-", "."], ["We", "set", "\\", "-LRB-", "\\lambda", "\\", "!", "=\\", "!", "0.015\\", "-RRB-", "based", "on", "ablation", "studies", "."], ["When", "testing", ",", "we", "use", "thresholds", "\\", "-LRB-", "\\tau", "^b_", "-LCB-", "conf", "-RCB-", "\\", "!", "=\\", "!", "0.05\\", "-RRB-", ",", "\\", "-LRB-", "\\tau", "^b_", "-LCB-", "iou", "-RCB-", "\\", "!", "=\\", "!", "0.6\\", "-RRB-", ",", "\\", "-LRB-", "\\tau", "^p_", "-LCB-", "conf", "-RCB-", "\\", "!", "=\\", "!", "0.1\\", "-RRB-", ",", "\\", "-LRB-", "\\tau", "^p_", "-LCB-", "iou", "-RCB-", "\\", "!", "=\\", "!", "0.3\\", "-RRB-", "and", "\\", "-LRB-", "\\tau", "^", "-LCB-", "inner", "-RCB-", "_", "-LCB-", "iou", "-RCB-", "\\", "!", "=\\", "!", "0.6\\", "-RRB-", "for", "applying", "\\", "-LRB-", "\\mathsf", "-LCB-", "NMS", "-RCB-", "\\", "-RRB-", "on", "\\", "-LRB-", "\\widehat", "-LCB-", "\\mathbf", "-LCB-", "O", "-RCB-", "-RCB-", "\\", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 6, "a"]], [[42, 42, "a"], [27, 27, "a"], [29, 29, "a"], [31, 31, "a"]], [[50, 50, "a"], [60, 60, "a"]], [[98, 98, "a"], [100, 100, "a"]], [], [[149, 149, "p"], [158, 158, "p"], [163, 163, "v"], [168, 168, "p"], [173, 173, "v"], [178, 178, "p"], [183, 183, "v"], [163, 163, "v"], [183, 183, "v"]], [[190, 190, "p"], [195, 195, "v"]], [[219, 219, "v"], [261, 261, "v"], [219, 219, "v"], [233, 233, "v"], [279, 279, "v"], [247, 247, "v"], [261, 261, "v"], [233, 233, "v"], [279, 279, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[9, 9, "v"], [10, 10, "a"]], [[34, 34, "v"], [36, 36, "v"], [38, 38, "v"], [39, 39, "p"], [42, 42, "a"]], [[50, 50, "a"], [55, 55, "v"], [60, 60, "a"]], [[93, 93, "v"], [98, 98, "a"], [100, 100, "a"]], [[105, 107, "a"]], [[144, 146, "p"], [154, 155, "p"], [158, 158, "p"], [163, 163, "v"], [168, 168, "p"], [173, 173, "v"], [178, 178, "p"], [183, 183, "v"]], [[190, 190, "p"], [195, 195, "v"]], [[210, 214, "a"], [219, 219, "v"], [224, 228, "a"], [233, 233, "v"], [238, 242, "a"], [247, 247, "v"], [252, 256, "a"], [261, 261, "v"], [279, 279, "v"], [285, 288, "a"]], []], "predicted_relations": [[], [], [], [], [], [[173, 173, 168, 168, "USED-FOR"]], [], [], []]}
{"doc_key": "2212.04983-f151bfa9-cffd-4b0d-89c6-104ff7ac6b23", "sentences": [["Optimization", "hyperparameters", "."], ["We", "use", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "0.01", "and", "weight", "decay", "of", "0.0005", "."], ["All", "models", "are", "trained", "for", "200", "epochs", "with", "no", "weight", "scheduling", "."], ["We", "add", "a", "dropout", "layer", "with", "rate", "\\", "-LRB-", "p=0.5\\", "-RRB-", "after", "each", "GNN", "layer", "during", "training", "."], ["We", "apply", "no", "early", "stopping", "and", "the", "optimal", "model", "is", "selected", "with", "its", "performance", "on", "the", "validation", "set", "."], ["The", "test", "set", "is", "never", "touched", "during", "training", "."]], "ner": [[], [[6, 7, "a"], [10, 11, "p"], [12, 12, "v"], [14, 15, "p"], [17, 17, "v"], [11, 11, "p"]], [], [[34, 35, "a"], [37, 37, "p"], [40, 40, "v"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[6, 6, "a"], [10, 11, "p"], [12, 12, "v"], [14, 15, "p"], [17, 17, "v"]], [[24, 24, "v"], [25, 25, "p"]], [[34, 34, "a"], [40, 40, "v"], [44, 44, "a"]], [], []], "predicted_relations": [[], [[10, 11, 6, 7, "USED-FOR"], [12, 12, 14, 15, "USED-FOR"], [12, 12, 11, 11, "USED-FOR"], [14, 15, 6, 7, "USED-FOR"], [17, 17, 14, 15, "USED-FOR"], [11, 11, 6, 7, "USED-FOR"]], [], [[37, 37, 34, 35, "USED-FOR"]], [], []]}
{"doc_key": "2212.04983-1bcf26c6-71d7-4fb6-8b44-39a412771d52", "sentences": [["Train/val/test", "split", "."], ["The", "evaluation", "procedures", "of", "GNNs", "on", "node", "classification", "tasks", "have", "suffered", "overfitting", "bias", "from", "using", "a", "single", "train-test", "split", "."], ["-LSB-", "19", "-RSB-", "showed", "that", "different", "splits", "could", "significantly", "affect", "the", "performance", "and", "ranking", "of", "models", "."], ["In", "all", "our", "experiments", "on", "node", "classification", "tasks", ",", "we", "apply", "the", "split", "setting", "in", "-LSB-", "36", "-RSB-", ",", "which", "utilizes", "10", "%", "samples", "for", "training", ",", "10", "%", "samples", "for", "validating", ",", "and", "80", "%", "samples", "for", "testing", "."], ["We", "generate", "20", "random", "splits", "and", "for", "each", "split", "we", "train", "10", "models", "with", "different", "random", "initialization", "."], ["We", "report", "the", "mean", "and", "standard", "deviation", "of", "the", "accuracy", "of", "the", "200", "random", "models", "in", "our", "results", "."]], "ner": [[[0, 1, "a"]], [], [], [[61, 61, "v"], [67, 67, "v"]], [[82, 82, "v"], [91, 91, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[], [[7, 7, "a"]], [], [[61, 62, "v"], [67, 68, "v"], [74, 75, "v"]], [[82, 82, "v"], [91, 91, "v"]], [[110, 110, "v"]]], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2203.10852-10c078dd-8d5a-4c67-9a94-cd3869a71535", "sentences": [["For", "self-supervised", "learning", "for", "generating", "brain", "networks", ",", "the", "autoencoder", "adopts", "mean", "squared", "error", "loss", "-LRB-", "MSELoss", "-RRB-", ",", "the", "Adam", "optimizer", "with", "a", "weight", "decay", "of", "0.0005", "and", "a", "batch", "size", "of", "50", "."], ["We", "implement", "the", "following", "hyperparameters", ":", "1000", "training", "epochs", "."], ["We", "set", "the", "initial", "learning", "rate", "as", "0.001", ",", "and", "the", "learning", "rate", "is", "reduced", "to", "90", "%", "after", "every", "50", "epochs", "."], ["For", "edge", "reconstruction", ",", "we", "adopt", "the", "SGD", "optimizer", "-LSB-", "26", "-RSB-", "with", "a", "weight", "decay", "of", "0.0005", "and", "a", "batch", "size", "of", "50", "with", "1000", "training", "epochs", "."], ["We", "set", "the", "initial", "learning", "rate", "as", "0.001", ",", "and", "the", "learning", "rate", "is", "reduced", "to", "90", "%", "after", "every", "50", "epochs", "."]], "ner": [[[20, 21, "a"]], [], [[63, 66, "c"]], [[75, 76, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 9, "a"], [11, 14, "a"], [20, 20, "a"], [24, 25, "p"], [27, 27, "v"], [30, 31, "p"], [33, 33, "v"]], [[41, 41, "v"], [42, 43, "p"]], [[49, 50, "p"], [52, 52, "v"], [56, 57, "p"], [61, 62, "v"], [65, 65, "v"], [66, 66, "p"]], [[75, 75, "a"], [82, 83, "p"], [85, 85, "v"], [88, 89, "p"], [91, 91, "v"], [93, 93, "v"]], [[101, 102, "p"], [104, 104, "v"], [108, 109, "p"], [113, 114, "v"], [117, 117, "v"], [118, 118, "p"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2203.10852-6ef764a2-2a53-4299-86c3-c470f64e3ce5", "sentences": [["For", "multi-modal", "learning", ",", "we", "adopt", "the", "SGD", "optimizer", "to", "optimize", "the", "network", "with", "a", "weight", "decay", "of", "0.0005", "and", "a", "batch", "size", "of", "20", "."], ["We", "implement", "the", "following", "hyperparameters", ":", "1000", "training", "epochs", ";", "a", "mini-batch", "size", "of", "20", "."], ["We", "set", "the", "initial", "learning", "rate", "as", "0.001", ",", "and", "the", "learning", "rate", "is", "reduced", "to", "90", "%", "after", "every", "50", "epochs", "."], ["Data", "augmentation", "is", "performed", "by", "rotating", "both", "images", "and", "points", "cloud", "data", "with", "the", "same", "angles", "."]], "ner": [[[7, 8, "a"], [15, 16, "p"], [18, 18, "v"], [21, 22, "p"], [24, 24, "v"], [24, 24, "v"], [7, 7, "a"]], [[37, 38, "p"], [40, 40, "v"], [33, 34, "p"], [32, 32, "v"], [37, 38, "p"], [40, 40, "v"]], [[45, 47, "p"], [49, 49, "v"]], [[70, 80, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"], [15, 16, "p"], [18, 18, "v"], [21, 22, "p"], [24, 24, "v"]], [[32, 32, "v"], [33, 34, "p"], [37, 38, "p"], [40, 40, "v"]], [[46, 47, "p"], [49, 49, "v"], [53, 54, "p"], [58, 59, "v"], [62, 62, "v"], [63, 63, "p"]], []], "predicted_relations": [[[15, 16, 7, 8, "USED-FOR"], [15, 16, 7, 7, "USED-FOR"], [18, 18, 15, 16, "USED-FOR"], [21, 22, 7, 7, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [[40, 40, 33, 34, "USED-FOR"], [32, 32, 33, 34, "USED-FOR"], [40, 40, 33, 34, "USED-FOR"]], [], []]}
{"doc_key": "2203.10852-d4db8153-beb6-42a8-b936-5307cffc4aef", "sentences": [["For", "population", "graph-based-GNN", ",", "we", "adopt", "the", "Adam", "optimizer", "-LSB-", "26", "-RSB-", "with", "a", "weight", "a", "batch", "size", "of", "20", "."], ["We", "apply", "binary", "cross-entropy", "loss", "for", "patient", "classification", "."], ["We", "implement", "the", "following", "hyperparameters", ":", "200", "training", "epoch", ";", "a", "mini-batch", "size", "of", "20", "."], ["We", "set", "the", "initial", "learning", "rate", "as", "0.001", ",", "and", "the", "learning", "rate", "is", "reduced", "to", "90", "%", "after", "every", "50", "epochs", "."]], "ner": [[[7, 8, "a"], [14, 14, "p"], [16, 17, "p"], [19, 19, "v"]], [[23, 25, "a"]], [[41, 42, "p"], [44, 44, "v"], [37, 38, "a"], [41, 42, "a"]], [[49, 51, "a"], [53, 53, "v"], [66, 66, "v"], [67, 67, "c"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"], [19, 19, "v"]], [[23, 25, "a"]], [[36, 36, "v"], [37, 38, "p"], [41, 42, "p"], [44, 44, "v"]], [[50, 51, "p"], [53, 53, "v"], [57, 58, "p"], [62, 63, "v"], [66, 66, "v"], [67, 67, "p"]]], "predicted_relations": [[[14, 14, 7, 8, "USED-FOR"], [16, 17, 7, 8, "USED-FOR"], [19, 19, 14, 14, "USED-FOR"], [19, 19, 16, 17, "USED-FOR"]], [], [[41, 42, 37, 38, "USED-FOR"], [41, 42, 41, 42, "USED-FOR"]], []]}
{"doc_key": "2212.01612-cbd8c534-6827-45ec-960a-86c26aadec7e", "sentences": [["During", "training", ",", "we", "finetune", "the", "models", "by", "AdamW", "-LSB-", "18", "-RSB-", "optimizer", "."], ["In", "all", "experiments", ",", "we", "use", "the", "grid", "search", "to", "find", "the", "learning", "rate", "for", "the", "embeddings", "within", "\\", "-LRB-", "-LSB-", "1\\times", "10^", "-LCB-", "-6", "-RCB-", ",", "5\\times", "10^", "-LCB-", "-5", "-RCB-", "-RSB-", "\\", "-RRB-", "."], ["We", "use", "a", "learning", "rate", "of", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "and", "a", "batch", "size", "of", "4", "for", "task", "model", "training", "."], ["Following", "ITA", "-LSB-", "28", "-RSB-", ",", "we", "use", "the", "cross-view", "alignment", "loss", "to", "minimize", "the", "KL", "divergence", "between", "the", "output", "distributions", "of", "retrieval", "based", "input", "and", "original", "input", "."], ["For", "MoE", ",", "we", "use", "the", "same", "learning", "rate", "and", "a", "batch", "size", "of", "64", "instead", "."], ["The", "task", "models", "are", "trained", "for", "10", "epochs", "and", "the", "MoE", "models", "are", "trained", "for", "50", "epochs", "."], ["All", "of", "the", "results", "are", "averaged", "from", "3", "runs", "with", "different", "random", "seeds", "."]], "ner": [[[8, 8, "a"], [8, 8, "a"]], [[26, 27, "p"], [26, 27, "a"], [21, 22, "a"]], [[53, 54, "p"], [53, 54, "a"], [67, 68, "a"]], [[85, 87, "a"], [91, 92, "a"], [77, 77, "a"]], [[112, 113, "p"], [112, 113, "a"], [116, 117, "a"], [106, 106, "a"]], [[129, 129, "a"], [138, 138, "a"], [132, 132, "a"]], [[151, 152, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[21, 22, "a"], [26, 27, "p"]], [[53, 54, "p"], [67, 68, "p"], [70, 70, "v"], [71, 74, "c"]], [[77, 77, "a"], [85, 87, "a"]], [[106, 106, "a"], [112, 113, "p"], [116, 117, "p"], [119, 119, "v"]], [[128, 128, "v"], [137, 137, "v"], [138, 138, "p"]], [[147, 147, "v"]]], "predicted_relations": [[], [[26, 27, 21, 22, "USED-FOR"]], [], [], [[112, 113, 106, 106, "USED-FOR"]], [], []]}
{"doc_key": "2208.05838-1d1b6058-28e0-4bac-a946-34d2e568a9bb", "sentences": [["Dataset", "pre-processing", "."], ["For", "the", "PCD", "dataset", ",", "original", "images", "are", "cropped", "into", "224\u00d7224", "."], ["By", "sliding", "56", "pixels", "in", "width", "and", "data", "augmentation", "of", "plane", "rotation", ",", "each", "image", "pair", "is", "expanded", "into", "60", "patches", "with", "a", "224\u00d7224", "resolution", "."], ["In", "total", ",", "12000", "image", "pairs", "are", "generated", "."], ["As", "the", "input", ",", "the", "image", "pairs", "will", "be", "resized", "into", "256\u00d7256", "."], ["For", "the", "VL-CMU-CD", "dataset", ",", "we", "follow", "the", "random", "training", "and", "testing", "splits", "reported", "in", "-LSB-", "9", "-RSB-", ",", "-LSB-", "3", "-RSB-", "."], ["Nine", "hundred", "thirty-three", "image", "pairs", "-LRB-", "98", "sequences", "-RRB-", "for", "training", "and", "429", "-LRB-", "54", "sequences", "-RRB-", "for", "testing", "are", "resized", "into", "a", "256\u00d7256", "resolution", "."], ["Note", "that", "only", "images", "belonging", "to", "the", "train", "set", "-LRB-", "without", "labels", "-RRB-", "are", "used", "to", "train", "the", "DSP", "model", "."], ["For", "data", "pre-processing", ",", "training", ",", "and", "validation", "split", ",", "we", "follow", "the", "steps", "mentioned", "in", "-LSB-", "3", "-RSB-", "for", "pretraining", "in", "VL-CMU-CD", "and", "PCD", "datasets", "."]], "ner": [[], [[5, 6, "a"]], [[39, 39, "p"], [39, 39, "p"]], [], [], [[65, 66, "a"]], [[110, 110, "p"], [110, 110, "p"]], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[13, 13, "v"]], [[17, 17, "v"], [34, 34, "v"], [38, 38, "v"]], [[44, 44, "v"]], [[61, 61, "v"]], [[65, 66, "a"]], [[88, 88, "v"], [92, 92, "v"], [98, 98, "v"], [100, 100, "v"], [109, 109, "v"]], [], [[155, 155, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2208.05838-2121f77e-abeb-40bb-8f6c-e4a92fb81ca2", "sentences": [["Architecture", "."], ["The", "proposed", "DSP", "method", "has", "a", "Siamese", "architecture", "that", "consists", "of", "ResNet50", "-LSB-", "11", "-RSB-", "-LRB-", "without", "the", "final", "classification", "layer", "-RRB-", "as", "a", "feature", "extractor", "followed", "by", "a", "projector", "network", "."], ["We", "use", "dilated", "convolutions", "and", "reduce", "the", "input", "image", "size", "by", "a", "stride", "of", "16", "to", "output", "feature", "vectors", "of", "size", "\\", "-LRB-", "16", "\\times", "16", "\\times", "2048\\", "-RRB-", "."], ["Then", ",", "the", "feature", "vectors", "are", "passed", "to", "the", "projection", "head", "by", "applying", "a", "2-D", "adaptive", "average", "pooling", "."], ["The", "projector", "network", "has", "two", "linear", "layers", ",", "each", "with", "a", "hidden", "layer", "size", "of", "512", "output", "units", "."], ["Owing", "to", "the", "high", "computational", "requirements", ",", "the", "output", "of", "the", "projector", "network", "was", "modified", "to", "generate", "embeddings", "of", "size", "\\", "-LRB-", "1", "\\times", "256\\", "-RRB-", "."], ["The", "first", "layer", "of", "the", "projector", "is", "followed", "by", "a", "batch", "normalization", "layer", "and", "rectified", "linear", "units", "."], ["Then", ",", "an", "absolute", "difference", "is", "applied", "to", "the", "output", "embedding", "to", "get", "difference", "embeddings", "."], ["The", "Barlow", "Twins", "loss", "function", "is", "applied", "on", "the", "difference", "embeddings", "of", "size", "\\", "-LRB-", "1", "\\times", "256\\", "-RRB-", "to", "generate", "a", "cross-correlation", "matrix", "of", "shape", "\\", "-LRB-", "256", "\\times", "256\\", "-RRB-", "."], ["Additionally", ",", "as", "discussed", "in", "Section", ",", "we", "incorporate", "Invariant", "prediction", "and", "Change", "Consistency", "regularization", "loss", "in", "our", "DSP", "framework", "."], ["As", "shown", "in", "Figure", "REF", ",", "the", "output", "of", "the", "projector", "before", "the", "difference", "is", "used", "to", "calculate", "the", "invariant", "prediction", "loss", "while", "the", "change", "consistency", "regularizer", "is", "applied", "to", "the", "output", "of", "the", "feature", "extractor", "."]], "ner": [[], [[13, 13, "a"]], [], [], [], [], [], [], [[164, 167, "a"]], [[205, 206, "a"], [208, 210, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[4, 5, "a"], [13, 13, "a"]], [[48, 48, "v"], [57, 57, "v"], [59, 59, "v"], [61, 61, "v"]], [[78, 78, "v"], [79, 81, "a"]], [[87, 87, "v"], [98, 98, "v"]], [[124, 126, "v"]], [], [], [[164, 165, "a"], [178, 180, "v"], [191, 191, "v"], [193, 193, "v"]], [[214, 215, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2208.05838-fc1ab77c-85fd-4b75-a111-cc936b6ab4e0", "sentences": [["Training", "and", "Optimization", "."], ["We", "follow", "the", "optimization", "protocol", "described", "in", "Barlow", "Twins", "."], ["We", "use", "the", "LARS", "optimizer", "-LSB-", "29", "-RSB-", "and", "train", "for", "400", "epochs", "with", "a", "batch", "size", "of", "16", "on", "two", "NVIDIA", "RTX-2080", "Ti", "GPU", "."], ["We", "use", "a", "learning", "rate", "of", "0.003", ",", "multiply", "the", "learning", "rate", "by", "the", "batch", "size", ",", "and", "divide", "it", "by", "256", "."], ["The", "learning", "rate", "is", "reduced", "by", "a", "factor", "of", "1000", "using", "a", "cosine", "decay", "schedule", "-LSB-", "16", "-RSB-", "."], ["We", "use", "a", "weight", "decay", "parameter", "of", "1x10\\", "-LRB-", "^-6\\", "-RRB-", "."], ["Finally", ",", "the", "loss", "balancing", "parameters", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "used", "for", "training", "our", "pretraining", "model", "is", "100", "and", "3000", "respectively", "."], ["We", "tuned", "these", "parameters", "by", "cross-validation", "on", "the", "validation", "sets", "of", "the", "VL-CMU-CD", "dataset", "and", "balanced", "these", "losses", "to", "the", "same", "scale", "."], ["For", "self-supervised", "Barlow", "Twins", "training", ",", "we", "followed", "the", "exact", "data", "preprocessing", ",", "training", "and", "optimization", "procedure", "."]], "ner": [[], [], [[17, 18, "a"]], [[43, 44, "p"], [50, 51, "p"], [46, 46, "v"]], [[64, 65, "p"], [75, 77, "a"]], [[85, 87, "p"]], [[97, 99, "p"]], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[], [[11, 12, "a"]], [[17, 17, "a"], [25, 25, "v"], [26, 26, "p"], [29, 30, "p"], [32, 32, "v"], [34, 34, "v"]], [[43, 44, "p"], [46, 46, "v"], [50, 51, "p"], [54, 55, "p"], [61, 61, "v"]], [[64, 65, "p"], [72, 72, "v"]], [[85, 87, "p"], [91, 91, "v"]], [[102, 102, "p"], [108, 108, "p"], [118, 118, "v"], [120, 120, "v"]], [[128, 128, "a"], [135, 136, "a"]], [[148, 149, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], []]}
{"doc_key": "2205.01703-3753a570-a34f-425f-b455-0336392d72bd", "sentences": [["For", "the", "pretrained", "language", "model", "checkpoints", ",", "we", "use", "the", "125", "million", "parameters", "-LRB-", "125M", "-RRB-", "and", "the", "1.3", "billion", "parameters", "-LRB-", "1.3B", "-RRB-", "dense", "model", "from", "-LSB-", "2", "-RSB-", "."], ["These", "pretrained", "models", "have", "shown", "results", "comparable", "to", "GPT3", "across", "various", "tasks", "."]], "ner": [[[12, 12, "p"], [20, 20, "p"], [10, 11, "v"], [18, 25, "a"], [12, 12, "p"], [20, 20, "p"], [18, 19, "v"]], []], "relations": [[], []], "predicted_ner": [[[10, 10, "v"], [14, 14, "v"], [18, 18, "v"], [22, 22, "v"]], [[39, 39, "a"]]], "predicted_relations": [[[20, 20, 18, 25, "USED-FOR"], [10, 11, 12, 12, "USED-FOR"], [10, 11, 12, 12, "USED-FOR"], [20, 20, 18, 25, "USED-FOR"], [18, 19, 20, 20, "USED-FOR"], [18, 19, 20, 20, "USED-FOR"]], []]}
{"doc_key": "2205.01703-6074dea8-953d-46db-8af0-f7741cf7ab88", "sentences": [["For", "self-supervised", "training", ",", "we", "use", "a", "subset", "of", "documents", "from", "the", "RoBERTa", "training", "corpus", "-LSB-", "40", "-RSB-", "that", "contains", "four", "domains", ":", "BookCorpus", "plus", "Wikipedia", ",", "CC-News", ",", "OpenWebText", ",", "and", "Stories", "."], ["Specifically", ",", "we", "randomly", "sample", "100k", "documents", "from", "each", "domain", "except", "Stories", "where", "we", "only", "sample", "10k", "documents", "as", "the", "documents", "there", "are", "much", "longer", "than", "the", "others", "."], ["The", "final", "training", "data", "contains", "approximately", "1", "million", "instances", "with", "250k", "training", "instances", "per", "task.The", "average", "numbers", "of", "example", "per", "instance", "for", "each", "data", "source", "are", ":", "6.9", "for", "BookCorpus", "plus", "Wikipedia", ",", "5.3", "for", "CC-News", ",", "3.5", "for", "OpenWebText", ",", "and", "7.2", "for", "Stories", "."], ["For", "the", "125M", "model", ",", "we", "train", "for", "10", "epochs", ",", "which", "takes", "roughly", "1", "day", "on", "a", "V100", "GPU", "."], ["For", "the", "1.3B", "model", ",", "we", "train", "for", "5", "epochs", ",", "which", "takes", "roughly", "3", "days", "on", "2", "V100", "GPUs", "."]], "ner": [[[12, 14, "a"]], [], [[96, 96, "v"], [100, 100, "v"]], [[111, 112, "a"], [118, 118, "p"], [117, 117, "v"], [118, 118, "p"]], [[139, 139, "p"], [132, 133, "a"], [139, 139, "p"], [138, 138, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 14, "a"], [20, 20, "v"], [27, 27, "a"]], [[39, 39, "v"], [50, 50, "v"]], [[69, 69, "v"], [73, 73, "v"], [90, 90, "v"], [96, 96, "v"], [98, 98, "a"], [100, 100, "v"], [105, 105, "v"]], [[111, 111, "v"], [117, 117, "v"], [118, 118, "p"], [123, 123, "v"], [127, 127, "v"]], [[132, 132, "v"], [138, 138, "v"], [139, 139, "p"], [144, 144, "v"], [147, 147, "v"], [148, 148, "p"]]], "predicted_relations": [[], [], [], [[118, 118, 111, 112, "USED-FOR"], [117, 117, 118, 118, "USED-FOR"], [117, 117, 118, 118, "USED-FOR"], [118, 118, 111, 112, "USED-FOR"]], [[139, 139, 132, 133, "USED-FOR"], [139, 139, 132, 133, "USED-FOR"], [138, 138, 139, 139, "USED-FOR"], [138, 138, 139, 139, "USED-FOR"]]]}
{"doc_key": "2207.04614-06e937cf-1276-469d-a419-08748f54d27d", "sentences": [["We", "train", "our", "network", "by", "adopting", "the", "strategies", "of", "CondInst", "-LSB-", "59", "-RSB-", "and", "AdelaiDet", "-LSB-", "69", "-RSB-", "."], ["First", ",", "we", "adopt", "the", "weights", "of", "ResNeXt-101-BiFPN", "-LSB-", "70", "-RSB-", ",", "-LSB-", "71", "-RSB-", "trained", "on", "ImageNet", "-LSB-", "72", "-RSB-", "to", "initialize", "the", "backbone", "network", "parameters", ",", "set", "the", "mini-batch", "size", "as", "two", ",", "and", "optimize", "our", "network", "on", "one", "NVidia", "RTX", "3090", "GPU", "."], ["Second", ",", "we", "set", "the", "base", "learning", "rate", "as", "\\", "-LRB-", "0.001\\", "-RRB-", ",", "adopt", "a", "warm-up", "-LSB-", "73", "-RSB-", "strategy", "to", "linearly", "increase", "the", "learning", "rate", "from", "\\", "-LRB-", "0.0001\\", "-RRB-", "to", "\\", "-LRB-", "0.001\\", "-RRB-", "in", "the", "first", "\\", "-LRB-", "1,00\\", "-RRB-", "iterations", ",", "reduce", "the", "learning", "rate", "to", "\\", "-LRB-", "0.0001\\", "-RRB-", "after", "\\", "-LRB-", "40,000\\", "-RRB-", "iterations", ",", "and", "stop", "the", "learning", "after", "\\", "-LRB-", "45,000\\", "-RRB-", "iterations", "."], ["Third", ",", "we", "re-scale", "the", "input", "images", ",", "such", "that", "the", "longer", "side", "is", "smaller", "than", "\\", "-LRB-", "1,333\\", "-RRB-", "and", "the", "shorter", "side", "was", "smaller", "than", "640", ",", "without", "changing", "the", "image", "aspect", "ratio", "."], ["Lastly", ",", "we", "apply", "random", "horizontal", "flip", "to", "the", "input", "images", "as", "data", "augmentation", "."]], "ner": [[[9, 9, "a"], [14, 14, "a"]], [[26, 26, "a"], [36, 36, "a"]], [[81, 81, "a"], [70, 72, "p"], [76, 76, "v"], [100, 100, "v"], [95, 95, "v"], [118, 118, "v"], [95, 95, "v"], [118, 118, "v"]], [[149, 150, "p"], [156, 156, "v"], [160, 161, "p"], [165, 165, "v"]], [[178, 180, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [9, 9, "a"], [14, 14, "a"]], [[26, 26, "a"], [36, 36, "a"], [49, 50, "p"], [52, 52, "v"], [57, 57, "a"], [59, 59, "v"]], [[71, 72, "p"], [76, 76, "v"], [81, 81, "a"], [90, 91, "p"], [95, 95, "v"], [100, 100, "v"], [107, 107, "v"], [113, 114, "p"], [118, 118, "v"], [123, 123, "v"], [134, 134, "v"]], [[156, 156, "v"], [165, 165, "v"]], []], "predicted_relations": [[], [], [[70, 72, 81, 81, "USED-FOR"], [76, 76, 70, 72, "USED-FOR"]], [[156, 156, 149, 150, "USED-FOR"], [156, 156, 160, 161, "USED-FOR"], [165, 165, 149, 150, "USED-FOR"], [165, 165, 160, 161, "USED-FOR"]], []]}
{"doc_key": "2206.13155-4cfd140b-80c2-4072-99e7-93ad2608a3bf", "sentences": [["Following", "previous", "works", "-LSB-", "30", "-RSB-", ",", "-LSB-", "2", "-RSB-", ",", "we", "initialize", "the", "weight", "of", "Bi-VLDoc", "model", "with", "the", "existing", "pre-trained", "models", "."], ["For", "24-layer", "transformer", "encoder", "layers", "and", "the", "text", "embedding", "layer", ",", "we", "use", "the", "RoBERTa-Large", "-LSB-", "20", "-RSB-", "to", "initialize", "."], ["For", "the", "visual", "part", "in", "the", "Bi-VLDoc", ",", "we", "use", "the", "backbone", "of", "a", "Mask", "R-CNN", "-LSB-", "43", "-RSB-", "model", "trained", "on", "PubLayNet", "-LSB-", "44", "-RSB-", "following", "LayoutLM", "v2", "-LSB-", "2", "-RSB-", "."], ["The", "cross", "attention", "layer", "and", "the", "rest", "of", "the", "parameters", "in", "the", "model", "are", "randomly", "initialized", "."], ["The", "Bi-VLDoc", "is", "trained", "by", "using", "Adam", "optimizer", "with", "the", "learning", "rate", "of", "2e-5", "and", "a", "linear", "decay", "learning", "rate", "schedule", "."], ["We", "use", "batch", "size", "384", "to", "train", "Bi-VLDoc", "for", "10", "epochs", "on", "the", "IIT-CDIP", "dataset", "."]], "ner": [[], [[38, 38, "a"]], [[59, 60, "a"], [67, 67, "a"], [72, 73, "a"]], [], [[101, 102, "a"], [105, 106, "p"], [113, 114, "p"], [108, 108, "v"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[16, 17, "a"]], [[25, 25, "v"], [38, 38, "a"]], [[51, 51, "a"], [60, 60, "a"], [67, 67, "a"], [72, 73, "a"]], [], [[96, 96, "a"], [101, 101, "a"], [105, 106, "p"], [108, 108, "v"], [111, 112, "a"]], [[119, 120, "p"], [121, 121, "v"], [124, 124, "a"], [126, 126, "v"], [127, 127, "p"]]], "predicted_relations": [[], [], [], [], [[105, 106, 101, 102, "USED-FOR"], [113, 114, 101, 102, "USED-FOR"], [108, 108, 105, 106, "USED-FOR"], [108, 108, 113, 114, "USED-FOR"]], []]}
{"doc_key": "2206.13155-1d2c661b-7d27-4cca-931a-6e0f4a679799", "sentences": [["For", "pre-training", "on", "IIT-CDIP", "dataset", ",", "we", "set", "the", "maximum", "sequence", "length", "to", "512", "and", "keep", "the", "head", "and", "the", "tail", "of", "the", "text", "sequence", "if", "the", "text", "is", "too", "long", "."], ["All", "text", "tokens", "are", "set", "to", "the", "segment", "0", "and", "visual", "feature", "tokens", "are", "set", "to", "the", "segment", "1", "."], ["The", "output", "of", "the", "visual", "backbone", "is", "transformed", "by", "a", "pooling", "layer", "to", "49", "-LRB-", "\\", "-LRB-", "7\\times", "7\\", "-RRB-", "-RRB-", "image", "tokens", "."], ["Following", "-LSB-", "5", "-RSB-", ",", "we", "mask", "15", "%", "text", "tokens", "in", "which", "80", "%", "are", "replaced", "by", "the", "-LSB-", "MASK", "-RSB-", "token", ",", "10", "%", "are", "replaced", "by", "a", "random", "token", ",", "and", "10", "%", "keeps", "unchanged", "."], ["In", "BTIA", ",", "15", "%", "text", "blocks", "are", "covered", "and", "the", "visual", "parts", "performs", "image-text-alignment", "according", "to", "the", "text", "blocks", "that", "contains", "-LSB-", "MASK", "-RSB-", "token", "from", "MVLM", "."], ["In", "TIPA", ",", "the", "2D-positions", "of", "15", "%", "text", "blocks", "are", "masked", "by", "-LRB-", "0,0,0,0", "-RRB-", "."]], "ner": [[[3, 4, "a"], [9, 11, "p"], [13, 13, "v"]], [], [], [], [[142, 142, "a"], [116, 116, "a"]], [[145, 145, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [13, 13, "v"]], [[40, 40, "v"], [50, 50, "v"]], [[65, 65, "v"], [70, 70, "v"]], [[83, 84, "v"], [89, 90, "v"], [100, 101, "v"], [110, 111, "v"]], [[116, 116, "a"], [118, 119, "v"], [142, 142, "a"]], [[145, 145, "a"], [150, 151, "v"], [158, 158, "v"]]], "predicted_relations": [[[9, 11, 3, 4, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2205.10955-501ffe5c-08db-40d5-925e-29e6a8b06994", "sentences": [["We", "use", "the", "popular", "ResNet50", "architecture", "-LSB-", "12", "-RSB-", "for", "image", "classification", "with", "ADAM", "optimizer", "."], ["We", "choose", "cross-entropy", "or", "top-1", "accuracy", "as", "loss", "function", "."], ["The", "model", "'s", "weights", "have", "been", "chosen", "randomly", "."], ["As", "the", "classes", "are", "balanced", ",", "there", "is", "no", "need", "for", "class", "weights", "."], ["20", "%", "of", "the", "training", "set", "\\", "-LRB-", "T_", "-LCB-", "N", "-RCB-", "\\", "-RRB-", "is", "held", "out", "as", "validation", "data", "."], ["It", "is", "used", "to", "determine", "when", "the", "model", "has", "converged", "."], ["In", "models", "with", "equal", "training", "volume", "the", "same", "data", "is", "held", "out", "."], ["We", "use", "early", "stopping", "on", "the", "validation-accuracy", "with", "a", "patience", "of", "50", "epochs", ",", "and", "a", "maximum", "of", "100", "training", "epochs", "."], ["The", "only", "data-augmentation", "used", "is", "a", "50", "%", "chance", "to", "horizontally", "flip", "the", "image", "and", "rescaling", "to", "224x224", "pixels", "."], ["Validation", "accuracy", "and", "loss", "is", "either", "reported", "for", "the", "model", "that", "triggered", "the", "early", "stopping", ",", "or", "the", "best", "model", "found", "."], ["To", "evaluate", "the", "trained", "models", ",", "we", "classify", "900", "images", "of", "the", "overall", "held", "out", "test", "set", "."], ["This", "is", "independent", "of", "\\", "-LRB-", "N\\", "-RRB-", ",", "the", "volume", "of", "the", "training", "set", "and", "validation", "set", "used", "."], ["Due", "to", "random", "choices", "each", "configuration", "of", "training", "is", "repeated", "5", "times", "."], ["We", "plot", "the", "mean", "loss", "of", "these", "5", "models", ",", "as", "well", "as", "plus/minus", "one", "standard", "deviation", "from", "the", "mean", "."]], "ner": [[[4, 4, "a"], [13, 14, "a"]], [[18, 18, "a"], [20, 21, "a"]], [], [], [], [], [], [[96, 97, "a"], [103, 103, "p"], [105, 106, "v"], [110, 110, "p"], [112, 114, "v"]], [[118, 118, "a"], [124, 124, "p"]], [[149, 150, "a"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "a"]], [[18, 18, "a"]], [], [], [[49, 50, "v"]], [], [], [[96, 97, "a"], [105, 105, "v"], [106, 106, "p"], [112, 112, "v"]], [[122, 123, "v"], [133, 133, "v"]], [], [[166, 166, "v"]], [], [[206, 206, "v"]], [[216, 216, "v"], [223, 223, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [[103, 103, 96, 97, "USED-FOR"], [105, 106, 103, 103, "USED-FOR"], [105, 106, 110, 110, "USED-FOR"], [110, 110, 96, 97, "USED-FOR"], [112, 114, 110, 110, "USED-FOR"]], [[124, 124, 118, 118, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2209.10063-c9e58e35-ec62-44c6-9aaa-7ffd3bb5f3bb", "sentences": [["Figure", "REF", "shows", "the", "scaling", "of", "performance", "with", "GPT-3", "generator", "parameters", ",", "including", "Ada-150M", ",", "Babbage-1.3B", ",", "Curie-6.7B", "and", "Davinci-175B", "."], ["We", "note", "that", "for", "both", "FiD", "and", "our", "GenRead", ",", "we", "use", "the", "FiD-xl", "with", "10", "input", "documents", "either", "retrieved", "from", "Wikipedia", "or", "generated", "by", "GPT-3", "."], ["The", "performance", "of", "both", "TriviaQA", "and", "WebQ", "continues", "to", "improve", "as", "the", "generator", "model", "parameters", "increase", ",", "as", "does", "the", "slope", "."], ["Only", "with", "the", "largest", "size", "GPT-3", ",", "GenRead", "can", "outperform", "the", "DPR-FiD", "."], ["This", "indicates", "using", "large", "language", "model", "to", "generate", "contextual", "documents", "is", "an", "\u201c", "emergent", "ability", "\u201d", "of", "scaling", ",", "which", "is", "not", "present", "in", "smaller", "models", "but", "is", "present", "in", "larger", "models", "-LSB-", "45", "-RSB-", "."]], "ner": [[[8, 9, "a"], [13, 13, "v"], [15, 15, "v"], [17, 17, "v"], [19, 19, "v"]], [[26, 26, "a"], [34, 34, "a"], [34, 34, "p"], [36, 38, "v"]], [[61, 62, "p"], [52, 52, "a"], [54, 54, "a"]], [[81, 81, "a"], [81, 81, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[26, 26, "a"], [29, 29, "a"], [34, 34, "a"], [36, 36, "v"], [46, 46, "a"]], [[52, 52, "a"], [54, 54, "a"]], [[75, 75, "a"], [77, 77, "a"]], []], "predicted_relations": [[], [[34, 34, 34, 34, "USED-FOR"], [36, 38, 34, 34, "USED-FOR"]], [[61, 62, 52, 52, "USED-FOR"], [61, 62, 54, 54, "USED-FOR"]], [], []]}
{"doc_key": "2209.10080-c1ea2114-9354-4609-b0ec-1ea75f688c9e", "sentences": [["The", "training", "settings", "are", "the", "same", "for", "CIFAR-10", "and", "CIFAR-100", "."], ["All", "ConvNets", "are", "trained", "for", "4000", "epochs", "with", "SGD", "with", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", ",", "fixed", "learning", "rate", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-3\\", "-RRB-", ",", "batch", "size", "128", ",", "and", "no", "weight", "decay", "."], ["All", "learned", "layers", "are", "initialized", "with", "Pytorch", "'s", "default", "weight", "initialization", "-LRB-", "version", "1.11.0", "-RRB-", "."], ["To", "stabilize", "prolonged", "training", "in", "the", "absence", "of", "batch", "normalization", ",", "we", "use", "learning", "rate", "warmup", ":", "starting", "from", "a", "base", "value", "of", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-4\\", "-RRB-", "the", "learning", "rate", "is", "linearly", "increased", "to", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-3\\", "-RRB-", "during", "the", "first", "5", "epochs", "of", "training", ",", "after", "which", "it", "remains", "constant", "at", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-3\\", "-RRB-", "."]], "ner": [[], [[19, 19, "a"], [21, 21, "p"], [24, 24, "v"], [28, 29, "p"], [39, 40, "p"], [41, 41, "v"], [45, 46, "p"], [44, 44, "v"], [17, 17, "p"], [16, 16, "v"], [12, 12, "a"], [17, 17, "p"]], [[54, 58, "a"]], [[77, 78, "p"], [96, 97, "p"], [84, 85, "p"], [114, 114, "p"], [77, 79, "a"], [84, 85, "p"], [114, 114, "p"], [113, 113, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "a"], [9, 9, "a"]], [[12, 12, "a"], [16, 16, "v"], [17, 17, "p"], [19, 19, "a"], [21, 21, "p"], [24, 24, "v"], [28, 29, "p"], [32, 36, "v"], [39, 40, "p"], [41, 41, "v"], [45, 46, "p"]], [[54, 54, "a"], [61, 61, "v"]], [[72, 73, "a"], [77, 79, "a"], [89, 93, "v"], [96, 97, "p"], [104, 108, "v"], [113, 113, "v"], [114, 114, "p"], [126, 130, "v"]]], "predicted_relations": [[], [[21, 21, 19, 19, "USED-FOR"], [21, 21, 12, 12, "USED-FOR"], [24, 24, 21, 21, "USED-FOR"], [24, 24, 28, 29, "USED-FOR"], [28, 29, 19, 19, "USED-FOR"], [28, 29, 12, 12, "USED-FOR"], [39, 40, 19, 19, "USED-FOR"], [39, 40, 12, 12, "USED-FOR"], [45, 46, 19, 19, "USED-FOR"], [45, 46, 12, 12, "USED-FOR"], [17, 17, 19, 19, "USED-FOR"], [17, 17, 12, 12, "USED-FOR"], [16, 16, 21, 21, "USED-FOR"], [16, 16, 17, 17, "USED-FOR"], [16, 16, 17, 17, "USED-FOR"], [17, 17, 19, 19, "USED-FOR"], [17, 17, 12, 12, "USED-FOR"]], [], [[96, 97, 77, 79, "USED-FOR"], [84, 85, 77, 79, "USED-FOR"], [114, 114, 77, 79, "USED-FOR"], [84, 85, 77, 79, "USED-FOR"], [114, 114, 77, 79, "USED-FOR"], [113, 113, 114, 114, "USED-FOR"], [113, 113, 114, 114, "USED-FOR"]]]}
{"doc_key": "2209.10080-22488ca5-3aaa-4e27-abea-2e8255f59cbb", "sentences": [["All", "ResNets", "are", "trained", "for", "4000", "epochs", "using", "Adam", "with", "base", "learning", "rate", "\\", "-LRB-", "1\\mathrm", "-LCB-", "e", "-RCB-", "-4\\", "-RRB-", ",", "batch", "size", "128", ",", "and", "no", "weight", "decay", "."], ["All", "learned", "layers", "are", "initialized", "with", "Pytorch", "'s", "default", "initialization", "-LRB-", "version", "1.11.0", "-RRB-", "."], ["All", "residual", "networks", "are", "trained", "with", "data", "augmentation", ",", "consisting", "of", "\\", "-LRB-", "4-pixel\\", "-RRB-", "random", "shifts", ",", "and", "random", "horizontal", "flips", "."]], "ner": [[[8, 8, "a"], [10, 12, "p"], [22, 23, "a"], [28, 29, "a"]], [[37, 40, "a"]], [[52, 53, "a"], [61, 62, "p"], [59, 59, "v"], [65, 67, "p"]]], "relations": [[], [], []], "predicted_ner": [[[1, 1, "a"], [5, 5, "v"], [6, 6, "p"], [8, 8, "a"], [11, 12, "p"], [22, 23, "p"], [24, 24, "v"], [28, 29, "p"]], [[37, 37, "a"], [43, 43, "v"]], [[47, 48, "a"]]], "predicted_relations": [[[10, 12, 8, 8, "USED-FOR"]], [], [[65, 67, 52, 53, "USED-FOR"]]]}
{"doc_key": "2203.11926-fd6ec4a3-fba6-4f77-a094-13a8683c190b", "sentences": [["We", "train", "FocalNet-B", "and", "FocalNet-L", "for", "90", "epochs", "with", "a", "batch", "size", "of", "4096", "and", "input", "resolution", "\\", "-LRB-", "224", "\\times", "224\\", "-RRB-", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "after", "a", "warmup", "of", "5", "epochs", "."], ["We", "set", "the", "the", "stochastic", "depth", "drop", "rates", "to", "\\", "-LRB-", "0.2\\", "-RRB-", "for", "both", "networks", "."], ["For", "stability", ",", "we", "use", "LayerScale", "-LSB-", "57", "-RSB-", "with", "initial", "value", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "for", "all", "layers", "."], ["The", "other", "settings", "follow", "those", "for", "ImageNet-1K", "."], ["After", "the", "pretraining", ",", "we", "finetune", "the", "models", "on", "ImageNet-1K", "for", "30", "epochs", "with", "initial", "learning", "rate", "of", "\\", "-LRB-", "3\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", ",", "cosine", "learning", "rate", "scheduler", "and", "AdamW", "optimizer", "."], ["The", "stochastic", "depth", "drop", "rate", "is", "set", "to", "\\", "-LRB-", "0.3\\", "-RRB-", "and", "both", "CutMix", "and", "Mixup", "are", "muted", "during", "the", "finetuning", "."]], "ner": [[[2, 2, "a"], [4, 4, "a"]], [], [], [[68, 68, "a"], [73, 74, "p"]], [], [[128, 129, "a"], [123, 126, "a"]], [[145, 145, "a"], [147, 147, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "a"], [6, 6, "v"], [7, 7, "p"], [10, 11, "p"], [13, 13, "v"], [15, 16, "p"], [19, 19, "v"], [21, 21, "v"]], [[26, 27, "p"], [33, 36, "v"], [43, 43, "v"], [44, 44, "p"]], [[50, 53, "p"], [57, 57, "v"], [59, 61, "c"]], [[68, 68, "a"], [77, 79, "v"], [83, 85, "c"]], [[93, 93, "a"]], [[104, 104, "a"], [106, 106, "v"], [107, 107, "p"], [110, 111, "p"], [128, 128, "a"]], [[132, 135, "p"], [141, 141, "v"], [145, 145, "a"], [147, 147, "a"]]], "predicted_relations": [[], [], [], [[73, 74, 68, 68, "USED-FOR"]], [], [], []]}
{"doc_key": "2210.03380-c10e745b-979b-4e9b-8ac4-0af0e12d0014", "sentences": [["We", "use", "the", "pre-trained", "uncased", "BERT-base", "-LSB-", "8", "-RSB-", "as", "the", "encoder", "with", "768-dim", "embedding", ",", "the", "learning", "rate", "is", "2e-5", ",", "and", "the", "coefficient", "of", "L2-regularization", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "set", "to", "1e-5", "."], ["Adam", "is", "utilized", "as", "the", "optimizer", "."], ["The", "mini-batch", "is", "set", "to", "32", "."], ["For", "contrastive", "learning", "loss", ",", "we", "set", "the", "hyper-parameters", "\\", "-LRB-", "\\tau", "=0.07", "\\", "-RRB-", ",", "\\", "-LRB-", "\\eta", "=0.1", "\\", "-RRB-", "and", "dropout", "probablity", "\\", "-LRB-", "p=0.1", "\\", "-RRB-", "."], ["We", "use", "LDA", "-LSB-", "3", "-RSB-", "to", "generate", "topic", "words", "for", "masking", "sentences", ",", "where", "T", "=", "6", "and", "K", "=", "5", "."], ["For", "BiCond", "and", "CrossNet", ",", "the", "word", "embeddings", "are", "initialized", "with", "the", "pre-trained", "200-dimensional", "GloVe", "vectors", "-LSB-", "25", "-RSB-", "."], ["The", "reported", "results", "are", "averaged", "scores", "of", "10", "runs", "to", "obtain", "statistically", "results", "."]], "ner": [[[5, 5, "a"], [14, 14, "p"], [13, 13, "v"], [17, 18, "p"], [20, 20, "v"], [24, 26, "p"], [35, 35, "v"], [20, 20, "v"], [35, 35, "v"]], [[42, 42, "p"], [37, 37, "v"]], [[45, 45, "p"], [49, 49, "v"]], [[52, 54, "a"], [63, 63, "v"], [70, 70, "v"], [78, 78, "v"], [74, 75, "p"], [70, 70, "v"], [78, 78, "v"]], [[84, 84, "a"], [97, 97, "p"], [99, 99, "v"], [101, 101, "p"], [103, 103, "v"]], [[119, 119, "a"], [111, 112, "p"], [118, 118, "v"]], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [13, 13, "v"], [17, 18, "p"], [20, 20, "v"], [26, 26, "a"], [29, 29, "p"], [35, 35, "v"]], [[37, 37, "a"]], [[45, 45, "p"], [49, 49, "v"]], [[52, 54, "a"], [74, 75, "p"], [78, 79, "v"]], [[84, 84, "a"], [97, 97, "p"], [99, 99, "v"], [101, 101, "p"], [101, 103, "v"]], [[106, 106, "a"], [108, 108, "a"], [118, 118, "v"], [119, 120, "a"]], [[132, 132, "v"]]], "predicted_relations": [[[14, 14, 5, 5, "USED-FOR"], [13, 13, 14, 14, "USED-FOR"], [13, 13, 17, 18, "USED-FOR"], [17, 18, 5, 5, "USED-FOR"], [20, 20, 14, 14, "USED-FOR"], [20, 20, 17, 18, "USED-FOR"], [24, 26, 5, 5, "USED-FOR"], [35, 35, 24, 26, "USED-FOR"], [20, 20, 14, 14, "USED-FOR"], [20, 20, 17, 18, "USED-FOR"], [35, 35, 24, 26, "USED-FOR"]], [], [], [[78, 78, 74, 75, "USED-FOR"], [74, 75, 52, 54, "USED-FOR"], [78, 78, 74, 75, "USED-FOR"]], [[99, 99, 97, 97, "USED-FOR"], [99, 99, 101, 101, "USED-FOR"], [101, 101, 84, 84, "USED-FOR"], [103, 103, 97, 97, "USED-FOR"], [103, 103, 101, 101, "USED-FOR"]], [[111, 112, 119, 119, "USED-FOR"]], []]}
{"doc_key": "2210.12582-3336601d-b4ca-4d7e-a0c9-c0ef09663cae", "sentences": [["We", "adopt", "the", "VOA", "corpus", "constructed", "by", "-LSB-", "11", "-RSB-", "for", "sparse", "latent", "type", "pre-training", ",", "which", "was", "extracted", "from", "108,693", "multimedia", "news", "articles", "openly", "available", "on", "the", "Voice", "of", "America", "website", "between", "2006", "and", "2017", "."], ["We", "use", "the", "bert-base-uncased", "version", "of", "the", "BERT", "-LSB-", "3", "-RSB-", "model", "as", "our", "encoder", ",", "and", "a", "single", "transformer", "decoder", "layer", "to", "reconstruct", "the", "sentence", ",", "following", "-LSB-", "7", "-RSB-", ",", "-LSB-", "16", "-RSB-", "."], ["While", "our", "approach", "is", "generally", "applicable", "for", "both", "encoder-only", "Masked", "Language", "Model", "-LRB-", "MLM", "-RRB-", "and", "the", "encoder-decoder", "Denoising", "Language", "Model", "-LRB-", "e.g", "."], ["BART", "-LSB-", "10", "-RSB-", "-RRB-", ",", "we", "focus", "on", "MLM", "because", "MLM", "is", "more", "widely", "used", "in", "the", "downstream", "information", "extraction", "tasks", "."], ["The", "implementation", "details", "can", "be", "found", "in", "Appendix", "."]], "ner": [[[3, 4, "a"]], [[44, 44, "a"], [56, 58, "a"]], [[91, 93, "a"]], [[97, 97, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 4, "a"], [20, 20, "v"]], [[44, 44, "a"]], [[75, 75, "a"]], [[97, 97, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2212.04613-0988e63f-5109-4985-8e8e-90feaf5b7033", "sentences": [["Pretraining", "is", "performed", "with", "the", "provided", "InsLoc", "implementation", "-LSB-", "46", "-RSB-", "."], ["Faster", "R-CNN", "-LSB-", "29", "-RSB-", ",", "with", "a", "ResNet-50", "backbone", "and", "FPN", ",", "serves", "as", "the", "trained", "detector", "."], ["With", "high", "computational", "costs", "for", "contrastive", "pretraining", ",", "these", "experiments", "consider", "a", "fixed", "pretraining", "budget", "of", "200", "epochs", "."], ["For", "COCO", ",", "pretraining", "is", "performed", "with", "per-GPU", "batch", "size", "64", "and", "learning", "rate", "0.03", "on", "4", "NVIDIA", "Quadro", "RTX", "5000", "GPUs", "with", "memory", "16", "GB", "."], ["For", "ImageNet-Subset", ",", "pretraining", "is", "performed", "with", "per-GPU", "batch", "size", "32", "and", "learning", "rate", "0.015", "on", "2", "NVIDIA", "GeForce", "GTX", "1080", "Ti", "GPUs", "with", "memory", "11", "GB", "."], ["All", "pretraining", "uses", "a", "dictionary", "size", "of", "K=8,192", "."], ["Full", "finetuning", "of", "all", "layers", "is", "performed", "within", "the", "Detectron2", "-LSB-", "41", "-RSB-", "framework", "with", "a", "24k", "iteration", "schedule", ",", "a", "learning", "rate", "of", "0.02", ",", "and", "a", "batch", "size", "of", "4", "on", "2", "NVIDIA", "GeForce", "GTX", "1080", "Ti", "GPUs", ",", "unless", "otherwise", "noted", "."]], "ner": [[[6, 6, "a"]], [[12, 13, "a"], [21, 21, "p"], [20, 20, "v"], [23, 23, "p"]], [], [], [], [], [[123, 123, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[13, 13, "a"], [20, 20, "a"], [23, 23, "a"]], [[47, 47, "v"], [48, 48, "p"]], [[51, 51, "a"], [60, 60, "v"], [62, 63, "p"], [64, 64, "v"], [66, 66, "v"], [74, 75, "v"]], [[78, 78, "a"], [87, 87, "v"], [89, 90, "p"], [91, 91, "v"], [93, 93, "v"], [102, 103, "v"]], [[109, 110, "p"], [112, 112, "v"]], [[123, 123, "a"], [130, 130, "v"], [131, 132, "p"], [135, 136, "p"], [138, 138, "v"], [142, 143, "p"], [145, 145, "v"], [147, 147, "v"]]], "predicted_relations": [[], [[21, 21, 12, 13, "USED-FOR"], [20, 20, 21, 21, "USED-FOR"], [20, 20, 23, 23, "USED-FOR"], [23, 23, 12, 13, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2212.04663-6118cb56-59ef-4adc-8527-886152b9dfdc", "sentences": [["In", "1D", "examples", ",", "we", "use", "the", "modified", "fully", "connected", "architecture", "with", "depth", "of", "5", "layers", "and", "width", "of", "100", "neurons", "for", "both", "branch", "and", "trunk", "nets", ",", "and", "the", "design", "of", "the", "optional", "layers", "\\", "-LRB-", "P\\", "-RRB-", "and", "\\", "-LRB-", "D\\", "-RRB-", "in", "Figure", "REF", "will", "be", "detailed", "in", "each", "of", "the", "following", "examples", "."], ["The", "batch", "size", "is", "chosen", "to", "be", "100", "with", "ADAM", "optimizer", ",", "where", "the", "initial", "learning", "rate", "\\", "-LRB-", "lr=0.001\\", "-RRB-", "and", "a", "0.95", "decay", "rate", "in", "every", "5000", "steps", "."], ["Same", "architecture", "is", "used", "in", "2D", "examples", "except", "that", "a", "depth", "of", "6", "layers", "is", "used", "."], ["In", "the", "transfer", "learning", "step", ",", "to", "solve", "the", "optimization", "problem", "-LRB-", "REF", "-RRB-", ",", "we", "use", "the", "lstsq", "function", "-LRB-", "with", "rcond=1e-6", "-RRB-", "from", "Numpy", "-LSB-", "8", "-RSB-", "for", "linear", "operators", "and", "the", "leastsq", "function", "in", "Scipy", "-LSB-", "21", "-RSB-", "-LRB-", "using", "default", "setting", "with", "\\", "-LRB-", "ftol=\\", "-RRB-", "1e-5", ",", "\\", "-LRB-", "xtol=\\", "-RRB-", "1e-5", "-RRB-", "for", "nonlinear", "operators", "."], ["All", "of", "the", "neural", "networks", "are", "trained", "on", "a", "single", "K40m", "GPU", ",", "and", "the", "prediction", "step", "is", "computed", "on", "a", "AMD", "Ryzen", "7", "3700x", "Processor", "."]], "ner": [[[7, 10, "a"], [12, 12, "p"], [14, 15, "v"], [17, 17, "p"], [19, 20, "v"]], [[58, 59, "a"], [66, 67, "a"], [71, 73, "p"], [76, 76, "v"], [81, 82, "p"], [80, 80, "v"], [84, 86, "c"]], [[98, 98, "p"], [100, 101, "v"]], [[123, 124, "a"], [127, 127, "p"], [127, 127, "v"], [139, 140, "a"], [153, 153, "p"], [155, 155, "v"], [161, 161, "v"], [159, 159, "p"], [155, 155, "v"], [161, 161, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[1, 1, "v"], [14, 14, "v"], [19, 19, "v"], [42, 42, "p"]], [[58, 59, "p"], [64, 64, "v"], [66, 66, "a"], [72, 73, "p"], [76, 76, "v"], [80, 80, "v"], [81, 82, "p"], [85, 85, "v"]], [[93, 93, "v"], [100, 100, "v"]], [[123, 124, "a"], [142, 142, "a"], [155, 155, "v"], [161, 161, "v"]], [[177, 177, "v"], [191, 191, "v"]]], "predicted_relations": [[[12, 12, 7, 10, "USED-FOR"], [14, 15, 12, 12, "USED-FOR"], [14, 15, 17, 17, "USED-FOR"], [17, 17, 7, 10, "USED-FOR"]], [[71, 73, 58, 59, "USED-FOR"], [71, 73, 66, 67, "USED-FOR"], [76, 76, 71, 73, "USED-FOR"], [76, 76, 81, 82, "USED-FOR"], [81, 82, 58, 59, "USED-FOR"], [81, 82, 66, 67, "USED-FOR"], [80, 80, 81, 82, "USED-FOR"], [84, 86, 76, 76, "USED-FOR"], [84, 86, 80, 80, "USED-FOR"]], [], [[127, 127, 123, 124, "USED-FOR"], [127, 127, 127, 127, "USED-FOR"], [153, 153, 123, 124, "USED-FOR"], [153, 153, 139, 140, "USED-FOR"], [155, 155, 153, 153, "USED-FOR"], [155, 155, 159, 159, "USED-FOR"], [161, 161, 153, 153, "USED-FOR"], [161, 161, 159, 159, "USED-FOR"], [159, 159, 123, 124, "USED-FOR"], [159, 159, 139, 140, "USED-FOR"], [155, 155, 153, 153, "USED-FOR"], [155, 155, 159, 159, "USED-FOR"], [161, 161, 153, 153, "USED-FOR"], [161, 161, 159, 159, "USED-FOR"]], []]}
{"doc_key": "2210.08355-4464cdb0-ef52-4272-a78f-ded6ab7021ef", "sentences": [["We", "implemented", "all", "models", "based", "on", "PyTorch", "-LSB-", "29", "-RSB-", "with", "PyTorch", "Lightning", "-LSB-", "4", "-RSB-", "and", "used", "language", "models", "from", "Transformers", "-LSB-", "35", "-RSB-", "."], ["We", "used", "base", "models", ",", "such", "as", "BERT-base-cased", ",", "RoBERTa-base", ",", "for", "all", "the", "experiments", "."], ["The", "dimension", "of", "hidden", "layers", "in", "FFNs", "was", "set", "to", "512", ",", "and", "the", "dropout", "rate", "was", "set", "to", "0.2", "."], ["By", "following", "-LSB-", "8", "-RSB-", ",", "we", "employed", "span-based", "batch", "rather", "than", "document-based", "batch", "."], ["The", "mini-batch", "size", "is", "5", "spans/action", "."], ["We", "optimized", "all", "models", "with", "the", "AdamW", "-LSB-", "24", "-RSB-", "optimizer", "."], ["We", "used", "a", "learning", "rate", "of", "1e-5", "for", "language", "models", "and", "1e-5/2e-4", "for", "other", "parametersThe", "learning", "rate", "was", "determined", "by", "using", "the", "development", "dataset", "."], ["such", "as", "FFN", "and", "biaffine", "layers", "."], ["We", "scheduled", "the", "learning", "rate", "by", "linear", "warm-up", ",", "which", "increases", "the", "learning", "rate", "linearly", "during", "the", "first", "epoch", "and", "then", "decreases", "it", "linearly", "to", "0", "until", "the", "final", "epoch", "."], ["We", "trained", "the", "model", "up", "to", "20", "epochs", "and", "applied", "early", "stopping", "with", "a", "patience", "of", "5", "by", "monitoring", "the", "fully", "labeled", "span", "F1", "score", "on", "the", "development", "dataset", "."], ["Details", "of", "other", "hyperparameters", "are", "in", "Appendix", "."]], "ner": [[[6, 6, "a"], [11, 11, "a"], [21, 21, "a"], [18, 19, "c"]], [[33, 33, "a"], [35, 35, "a"]], [[48, 48, "a"], [43, 46, "p"], [52, 52, "v"], [56, 57, "p"], [61, 61, "v"]], [], [], [[91, 91, "a"]], [[100, 101, "p"], [112, 113, "p"], [103, 103, "v"], [108, 108, "v"], [105, 106, "c"], [108, 108, "v"]], [], [[132, 133, "p"], [141, 142, "p"], [135, 136, "a"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [11, 12, "a"], [21, 21, "a"]], [[35, 35, "a"]], [[45, 46, "p"], [48, 48, "a"], [52, 52, "v"], [56, 57, "p"], [61, 61, "v"]], [], [[79, 80, "p"], [82, 82, "v"]], [[91, 91, "a"]], [[100, 101, "p"], [103, 103, "v"], [112, 113, "p"]], [[124, 124, "a"]], [[132, 133, "p"], [135, 136, "a"], [154, 154, "v"]], [[166, 166, "v"], [167, 167, "p"], [170, 171, "a"], [174, 174, "p"], [176, 176, "v"]], []], "predicted_relations": [[], [], [[43, 46, 48, 48, "USED-FOR"], [56, 57, 48, 48, "USED-FOR"], [61, 61, 56, 57, "USED-FOR"]], [], [], [], [[103, 103, 100, 101, "USED-FOR"], [108, 108, 100, 101, "USED-FOR"], [108, 108, 112, 113, "USED-FOR"], [105, 106, 108, 108, "USED-FOR"], [105, 106, 108, 108, "USED-FOR"], [108, 108, 100, 101, "USED-FOR"], [108, 108, 112, 113, "USED-FOR"]], [], [[141, 142, 135, 136, "USED-FOR"]], [], []]}
{"doc_key": "2208.08118-86821fa9-9e25-4041-8ef9-40a69103ef9f", "sentences": [["In", "our", "experiments", ",", "we", "set", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "rec", "-RCB-", "=50\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "region", "-RCB-", "=100\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "sync", "-RCB-", "=0.05\\", "-RRB-", "."], ["We", "provide", "the", "details", "regarding", "pre-processing", "and", "training", "settings", "in", "supplementary", "file", "on", "our", "project", "page", "."]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[[8, 12, "p"], [13, 13, "v"], [18, 22, "p"], [28, 32, "p"]], []], "predicted_relations": [[], []]}
{"doc_key": "2208.08118-743ab82a-20f1-4ed8-a067-28dafd3c773a", "sentences": [["Datasets", ":", "We", "train", "our", "model", "using", "AVSpeech", "-LSB-", "15", "-RSB-", "and", "VoxCeleb2", "-LSB-", "7", "-RSB-", "datasets", ";", "both", "containing", "talking-face", "videos", "spanning", "a", "wide", "variety", "of", "identities", ",", "languages", "and", "poses", "."], ["For", "AVSpeech", "data", ",", "we", "extract", "the", "face", "tracks", "using", "an", "off-the-shelf", "face", "detector", "-LSB-", "55", "-RSB-", "."], ["We", "curate", "a", "set", "of", "50", "hours", "for", "training", "and", "\\", "-LRB-", "\\sim", "3\\", "-RRB-", "hours", "from", "the", "official", "test", "split", "for", "testing", "and", "verified", "it", "for", "accurate", "lip-sync", "using", "SyncNet", "-LSB-", "8", "-RSB-", "."], ["We", "also", "benchmark", "our", "model", "on", "VoxCeleb2", "data", "which", "comprises", "face", "tracks", "with", "a", "fair", "amount", "of", "background", "."], ["Owing", "to", "computational", "limitations", ",", "we", "randomly", "sample", "a", "subset", "of", "100", "hours", "for", "training", "and", "use", "the", "full", "official", "test", "split", "for", "testing", "."], ["Note", "that", "there", "are", "no", "overlaps", "between", "the", "identities", "used", "in", "training", "and", "testing", "sets", "in", "both", "datasets", "."], ["The", "code", ",", "models", "and", "file-lists", "are", "released", "on", "our", "website", "for", "reproducibility", "and", "future", "research", "."]], "ner": [[[7, 7, "a"], [12, 12, "a"]], [[34, 34, "a"], [44, 46, "a"]], [[81, 81, "a"]], [[92, 92, "a"]], [[111, 114, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"], [7, 7, "a"], [12, 12, "a"]], [], [[56, 56, "v"], [81, 81, "a"]], [[90, 90, "a"], [92, 92, "a"]], [[116, 116, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2203.14632-9a7e647d-4399-439b-92d3-5e40b540755d", "sentences": [["Mapping", ":", "Using", "fasttext", "-LSB-", "15", "-RSB-", "with", "the", "default", "parameters", "These", "are", "300-dimensional", "vectors", "with", "10", "negative", "samples", ",", "a", "sub-sampling", "threshold", "of", "1e-5", "and", "5", "training", "iterations", ",", "we", "first", "gather", "monolingual", "word", "embeddings", "for", "each", "of", "the", "respective", "languages", "."], ["After", "this", ",", "we", "map", "the", "embeddings", "to", "a", "cross-lingual", "space", "using", "VecMap", "-LSB-", "1", "-RSB-", "in", "the", "unsupervised", "mode", "as", "we", "do", "not", "have", "any", "bilingual", "dictionaries", "."], ["In", "this", "mode", "an", "initial", "solution", "is", "found", "using", "heuristics", "and", "iteratively", "refined", "."]], "ner": [[[3, 3, "a"], [13, 13, "v"], [17, 18, "p"], [16, 16, "v"], [21, 22, "p"], [24, 24, "v"], [27, 28, "p"], [24, 24, "v"], [26, 26, "v"]], [[55, 55, "a"], [62, 62, "p"], [61, 61, "v"]], [[74, 74, "p"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [13, 13, "v"], [16, 16, "v"], [24, 24, "v"], [26, 26, "v"]], [[55, 55, "a"]], []], "predicted_relations": [[[17, 18, 3, 3, "USED-FOR"], [16, 16, 17, 18, "USED-FOR"], [16, 16, 27, 28, "USED-FOR"], [21, 22, 3, 3, "USED-FOR"], [24, 24, 17, 18, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [24, 24, 17, 18, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 27, 28, "USED-FOR"], [26, 26, 17, 18, "USED-FOR"], [26, 26, 21, 22, "USED-FOR"], [26, 26, 27, 28, "USED-FOR"]], [[62, 62, 55, 55, "USED-FOR"]], []]}
{"doc_key": "2204.01341-93b812c1-6ab8-4b2e-81e7-096d1f8294d5", "sentences": [["In", "Eq", "."], ["REF", ",", "\\", "-LRB-", "z_", "-LCB-", "i", "-RCB-", "\\", "-RRB-", "is", "the", "output", "in", "the", "\\", "-LRB-", "i\\", "-RRB-", "th", "node", ",", "C", "is", "the", "number", "of", "output", "nodes", ",", "representing", "the", "number", "of", "classified", "categories", "."], ["The", "classification", "prediction", "can", "be", "converted", "into", "the", "probabilities", "by", "using", "the", "Softmax", "function", ",", "which", "distributes", "in", "the", "range", "of", "-LSB-", "0", ",", "1", "-RSB-", ",", "and", "the", "sum", "of", "probability", "is", "1", "."], ["Because", "the", "image", "segmentation", "for", "yeast", "counting", "is", "to", "distinguish", "the", "foreground", "and", "the", "background", "."], ["Hence", "it", "is", "a", "binary", "classification", ",", "the", "Eq", "."], ["REF", "can", "be", "rewritten", "as", "Eq", "."], ["REF", "."], ["\\", "-LRB-", "Softmax", "-LRB-", "z_", "-LCB-", "1", "-RCB-", "-RRB-", "=\\frac", "-LCB-", "e^", "-LCB-", "z_", "-LCB-", "1", "-RCB-", "-RCB-", "-RCB-", "-LCB-", "e^", "-LCB-", "z_", "-LCB-", "1", "-RCB-", "-RCB-", "+e^", "-LCB-", "z_", "-LCB-", "2", "-RCB-", "-RCB-", "-RCB-", "=\\frac", "-LCB-", "1", "-RCB-", "-LCB-", "1+e^", "-LCB-", "-", "-LRB-", "z_", "-LCB-", "1", "-RCB-", "-z_", "-LCB-", "2", "-RCB-", "-RRB-", "-RCB-", "-RCB-", "=Sigmoid", "-LRB-", "\\beta", "-RRB-", "\\", "-RRB-"]], "ner": [[], [[25, 25, "p"]], [[52, 53, "a"]], [], [], [], [], [[167, 167, "p"], [167, 167, "p"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [], [[73, 73, "v"]], [], [], [], [], [[112, 112, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2204.01341-94e4f6db-521b-4977-9ac2-8d059355502f", "sentences": [["Adam", "optimizer", "is", "applied", "to", "minimize", "the", "loss", "function", ",", "which", "can", "adjust", "the", "learning", "rate", "automatically", "by", "considering", "the", "gradient", "momentum", "of", "the", "previous", "time", "steps", "-LSB-", "34", "-RSB-", "."], ["In", "our", "training", "process", ",", "learning", "rate", "is", "set", "as", "0.001", "and", "batch", "size", "is", "8", "."], ["The", "epoch", "is", "set", "as", "100", "by", "considering", "the", "converge", "speed", "of", "experimental", "models", ",", "the", "example", "of", "loss", "and", "intersection", "over", "union", "-LRB-", "IoU", "-RRB-", "curves", "of", "models", "is", "shown", "in", "Fig", "."], ["REF", "."], ["Though", "there", "are", "92,319,298", "params", "to", "be", "trained", "in", "PID-Net", ",", "but", "it", "can", "converge", "rapidly", "and", "smoothly", ",", "without", "over", "fitting", "."], ["There", "is", "a", "jump", "in", "loss", "and", "IoU", "plots", "for", "all", "3", "tested", "networks", "from", "40", "to", "80", "epochs", ",", "which", "is", "caused", "by", "the", "small", "batch", "size", "."], ["Small", "batch", "size", "may", "lead", "to", "huge", "difference", "between", "each", "batch", ",", "and", "the", "loss", "and", "IoU", "curves", "may", "jump", "while", "convergence", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[0, 1, "a"], [14, 15, "p"], [7, 8, "a"]], [[36, 37, "p"], [41, 41, "v"], [43, 44, "p"], [46, 46, "v"]], [[49, 49, "p"], [53, 53, "v"]], [], [], [[133, 134, "p"]], [[137, 138, "p"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [14, 15, "p"]], [[36, 37, "p"], [41, 41, "v"], [43, 44, "p"], [46, 46, "v"]], [[53, 53, "v"]], [], [[87, 87, "v"], [93, 93, "a"]], [[118, 118, "v"], [122, 122, "v"], [124, 124, "v"], [125, 125, "p"]], [], []], "predicted_relations": [[[14, 15, 0, 1, "USED-FOR"], [14, 15, 7, 8, "USED-FOR"]], [], [], [], [], [], [], []]}
{"doc_key": "2204.01366-c8e39137-1821-4962-a5e1-2273ae3e82af", "sentences": [["fig", ":", "appendix-gcn-mean", "shows", "mean", "evaluation", "plots", "of", "five", "training", "runs", "of", "GCN_W_BN", "on", "\\", "-LRB-", "3.15M\\", "-RRB-", "instances", "of", "RandomMP", "."], ["No", "CCL", "was", "applied", "in", "the", "first", "\\", "-LRB-", "3M\\", "-RRB-", "instances", "."], ["Then", ",", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "was", "linearly", "increased", "over", "\\", "-LRB-", "100k\\", "-RRB-", "instances", "to", "\\", "-LRB-", "\\alpha", "=0.01\\", "-RRB-", "."], ["Afterwards", ",", "the", "training", "continued", "for", "\\", "-LRB-", "50k\\", "-RRB-", "instances", "with", "\\", "-LRB-", "\\alpha", "=0.01\\", "-RRB-", "."], ["The", "node", "embedding", "dimensionality", "was", "set", "to", "128", "and", "the", "number", "of", "GCN", "layers", "to", "20", "."], ["The", "MLP", "edge", "classifier", "consists", "of", "2", "hidden", "layers", "with", "256", "neurons", "."], ["Optimization", "was", "performed", "with", "Adam", "-LSB-", "31", "-RSB-", "-LRB-", "\\", "-LRB-", "0.001\\", "-RRB-", "learning", "rate", ",", "\\", "-LRB-", "5\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "weight", "decay", ",", "\\", "-LRB-", "-LRB-", "0.9", ",", "0.999", "-RRB-", "\\", "-RRB-", "betas", "-RRB-", "and", "a", "batch", "size", "of", "200", "."], ["Each", "training", "was", "performed", "on", "a", "MEGWARE", "Gigabyte", "G291-Z20", "server", "on", "one", "NVIDIA", "Quadro", "RTX", "8000", "GPU", "and", "took", "24hrs", "on", "average", ",", "whereof", "the", "training", "time", "of", "the", "last", "\\", "-LRB-", "150k\\", "-RRB-", "-LRB-", "CCL", "-RRB-", "instances", "took", "around", "18hrs", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[12, 12, "a"]], [[23, 23, "a"]], [[39, 39, "p"], [54, 54, "p"], [55, 55, "v"], [55, 55, "v"]], [[72, 72, "p"], [73, 73, "v"], [73, 73, "v"]], [[77, 79, "p"], [83, 83, "v"], [86, 89, "p"], [91, 91, "v"]], [[94, 96, "a"], [99, 99, "v"], [103, 103, "v"]], [[110, 110, "a"], [119, 120, "p"], [117, 117, "v"], [131, 132, "p"], [143, 143, "p"], [147, 148, "p"], [150, 150, "v"], [117, 117, "v"], [137, 137, "v"], [139, 139, "v"]], [[187, 187, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "v"], [12, 12, "a"], [16, 16, "v"], [20, 20, "a"]], [[23, 23, "a"], [31, 31, "v"]], [[39, 39, "p"], [48, 48, "v"], [54, 54, "p"], [55, 55, "v"]], [[66, 66, "v"], [72, 72, "p"], [73, 73, "v"]], [[83, 83, "v"], [88, 88, "a"], [91, 91, "v"]], [[94, 96, "a"], [99, 99, "v"], [103, 103, "v"], [104, 104, "p"]], [[110, 110, "a"], [117, 117, "v"], [119, 120, "p"], [131, 132, "p"], [137, 139, "v"], [143, 143, "p"], [147, 148, "p"], [150, 150, "v"]], [[160, 160, "v"], [163, 163, "v"], [184, 184, "v"]], []], "predicted_relations": [[], [], [], [], [[83, 83, 77, 79, "USED-FOR"], [83, 83, 86, 89, "USED-FOR"], [91, 91, 77, 79, "USED-FOR"], [91, 91, 86, 89, "USED-FOR"]], [], [[119, 120, 110, 110, "USED-FOR"], [117, 117, 119, 120, "USED-FOR"], [131, 132, 110, 110, "USED-FOR"], [150, 150, 143, 143, "USED-FOR"], [150, 150, 147, 148, "USED-FOR"], [117, 117, 119, 120, "USED-FOR"], [137, 137, 131, 132, "USED-FOR"], [137, 137, 143, 143, "USED-FOR"], [139, 139, 131, 132, "USED-FOR"], [139, 139, 143, 143, "USED-FOR"]], [], []]}
{"doc_key": "2210.02414-6dfee948-533c-44cc-b760-4c428f7e77dd", "sentences": [["Self-Supervised", "Blank", "Infilling", "-LRB-", "95", "%", "tokens", "-RRB-", "."], ["Recall", "that", "GLM-130B", "uses", "both", "-LSB-", "MASK", "-RSB-", "and", "-LSB-", "gMASK", "-RSB-", "for", "this", "task", "."], ["Specifically", ",", "-LSB-", "MASK", "-RSB-", "is", "used", "to", "mask", "consecutive", "spans", "in", "30", "%", "of", "training", "tokens", "for", "blank", "infilling", "."], ["The", "lengths", "of", "spans", "follow", "a", "Poisson", "distribution", "-LRB-", "\\", "-LRB-", "\\lambda", "=3\\", "-RRB-", "-RRB-", "and", "add", "up", "to", "15", "%", "of", "the", "input", "."], ["For", "the", "other", "70", "%", "tokens", ",", "the", "prefix", "of", "each", "sequence", "is", "kept", "as", "context", "and", "-LSB-", "gMASK", "-RSB-", "is", "used", "to", "mask", "the", "rest", "of", "it", "."], ["The", "masked", "length", "is", "sampled", "from", "the", "Uniform", "distribution", "."]], "ner": [[[0, 2, "a"]], [[15, 15, "p"], [19, 19, "p"]], [[28, 28, "p"]], [[52, 53, "p"], [58, 58, "v"], [57, 57, "c"]], [[89, 89, "p"]], [[107, 108, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[4, 5, "v"]], [[11, 11, "a"]], [[37, 38, "v"]], [[57, 58, "p"], [65, 66, "v"]], [[74, 75, "v"]], []], "predicted_relations": [[], [], [], [[58, 58, 52, 53, "USED-FOR"], [57, 57, 58, 58, "USED-FOR"]], [], []]}
{"doc_key": "2209.07118-b8f1a8e7-3781-4bd8-8273-0ecafdabdc0d", "sentences": [["Implementation", "Details", "For", "the", "uni-modal", "encoders", ",", "we", "use", "the", "vision", "encoder", "with", "CLIP-ViT-B", "-LSB-", "41", "-RSB-", "-LRB-", "\\", "-LRB-", "L_", "-LCB-", "v", "-RCB-", "=12\\", "-RRB-", "-RRB-", "and", "the", "language", "encoder", "with", "RoBERTa-base", "-LSB-", "32", "-RSB-", "-LRB-", "\\", "-LRB-", "L_", "-LCB-", "l", "-RCB-", "=12\\", "-RRB-", "-RRB-", "."], ["For", "the", "multi-modal", "fusion", "module", ",", "we", "set", "the", "number", "of", "Transformer", "layers", "\\", "-LRB-", "L_", "-LCB-", "m", "-RCB-", "=6\\", "-RRB-", ",", "and", "the", "dimension", "of", "the", "hidden", "states", "\\", "-LRB-", "D=768\\", "-RRB-", "with", "the", "number", "of", "heads", "set", "to", "12", "."], ["For", "knowledge", "representation", "and", "injection", ",", "we", "set", "the", "dimension", "of", "the", "hidden", "states", "\\", "-LRB-", "D_", "-LCB-", "e", "-RCB-", "=256\\", "-RRB-", "."], ["For", "the", "pretext", "tasks", ",", "we", "adopt", "-LRB-", "knowledge-enhanced", "-RRB-", "MLM", ",", "MIM", "-LSB-", "16", "-RSB-", ",", "and", "ITM", ",", "where", "the", "masking", "ratios", "of", "MLM", "and", "MIM", "are", "set", "to", "15", "%", "and", "75", "%", ",", "respectively", "."], ["For", "the", "optimization", ",", "the", "models", "are", "trained", "with", "AdamW", "optimizer", "-LSB-", "33", "-RSB-", "for", "100,000", "steps", "with", "the", "learning", "rates", "for", "the", "uni-modal", "encoders", "and", "the", "remaining", "parameters", "set", "to", "1e-5", "and", "5e-5", ",", "respectively", "."], ["The", "warm-up", "ratio", "is", "set", "to", "10", "%", ",", "and", "the", "learning", "rate", "is", "linearly", "decayed", "to", "0", "after", "warm-up", "."], ["Besides", ",", "we", "use", "center-crop", "to", "resize", "each", "image", "to", "the", "size", "of", "288\\", "-LRB-", "\\times", "\\", "-RRB-", "288", "."]], "ner": [[[13, 13, "a"], [24, 24, "v"], [43, 43, "v"], [32, 32, "a"], [24, 24, "v"], [43, 43, "v"]], [[87, 87, "v"], [87, 87, "v"], [58, 58, "a"], [66, 66, "v"], [78, 78, "p"], [78, 78, "v"]], [], [[122, 122, "a"], [137, 137, "a"], [124, 124, "a"], [139, 139, "a"], [130, 130, "a"]], [[160, 160, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[13, 13, "a"], [32, 32, "a"]], [[78, 78, "v"], [87, 87, "v"]], [], [[122, 122, "a"], [124, 124, "a"], [130, 130, "a"], [137, 137, "a"], [139, 139, "a"], [143, 144, "v"], [146, 147, "v"]], [[160, 160, "a"], [166, 166, "v"], [170, 171, "p"], [182, 182, "v"], [184, 184, "v"]], [[189, 190, "p"], [194, 195, "v"], [199, 200, "p"], [205, 205, "v"]], [[213, 213, "a"], [227, 227, "v"]]], "predicted_relations": [[], [[87, 87, 78, 78, "USED-FOR"], [87, 87, 78, 78, "USED-FOR"], [78, 78, 58, 58, "USED-FOR"], [78, 78, 78, 78, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2209.07098-11ecbcfe-0ba7-49e4-8b45-87210d14bcbe", "sentences": [["We", "conduct", "our", "experiments", "on", "two", "datasets", ",", "i.e.", ",", "ROCO", "-LSB-", "19", "-RSB-", "and", "MedICaT", "-LSB-", "22", "-RSB-", ",", "where", "the", "former", "contains", "over", "81,000", "medical", "image-text", "pairs", "and", "the", "latter", "consists", "of", "over", "217,000", "medical", "images", "with", "their", "captions", "and", "inline", "textual", "references", "."], ["For", "ROCO", ",", "we", "adopt", "their", "official", "splits", ",", "and", "for", "MedICaT", ",", "we", "randomly", "sample", "1,000", "images", "for", "validation", ",", "1,000", "images", "for", "testing", ",", "and", "the", "remaining", "images", "are", "used", "for", "training", "."], ["For", "pre-training", ",", "we", "use", "the", "training", "set", "of", "ROCO", "and", "MedICaT", "to", "train", "models", "with", "the", "pre-training", "tasks", "presented", "in", "Section", "together", "with", "the", "common", "image-text", "matching", "task", "-LSB-", "1", "-RSB-", "by", "default", "."]], "ner": [[[10, 10, "a"], [15, 15, "a"]], [[47, 47, "a"], [57, 57, "a"]], [[90, 90, "a"], [92, 92, "a"], [106, 109, "a"]]], "relations": [[], [], []], "predicted_ner": [[[5, 5, "v"], [10, 10, "a"], [15, 15, "a"], [25, 25, "v"], [35, 35, "v"]], [[47, 47, "a"], [57, 57, "a"], [62, 62, "v"], [67, 67, "v"]], [[90, 90, "a"], [92, 92, "a"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2209.13948-69ddbc08-791c-407f-be50-09922070dcec", "sentences": [["Our", "training", "configuration", "directly", "follows", "Deformable-DETR", "-LSB-", "63", "-RSB-", "."], ["Obj2Seq", "takes", "16", "images", "as", "a", "training", "batch", "."], ["It", "is", "trained", "with", "an", "AdamW", "optimizer", "-LSB-", "37", "-RSB-", "for", "50", "epochs", ",", "with", "\\", "-LRB-", "\\beta", "_1=0.9", ",", "\\beta", "_2", "=", "0.999\\", "-RRB-", "and", "weight", "decay", "\\", "-LRB-", "1\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "initial", "learning", "rate", "is", "\\", "-LRB-", "2\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "it", "decays", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "after", "the", "40th", "epoch", "."], ["As", "to", "the", "input", "images", ",", "we", "apply", "scale", "augmentation", "and", "scale", "augmentation", "as", "in", "-LSB-", "3", "-RSB-", ",", "-LSB-", "63", "-RSB-", "."], ["We", "train", "Obj2Seq", "with", "16", "Nvidia", "V100", "GPUs", "."]], "ner": [[[5, 5, "a"]], [], [[24, 25, "a"], [42, 42, "v"], [45, 46, "p"]], [[78, 78, "v"], [58, 60, "p"]], [[93, 94, "a"], [96, 97, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[10, 10, "a"], [12, 12, "v"]], [[24, 24, "a"], [30, 30, "v"], [31, 31, "p"], [42, 42, "v"], [45, 46, "p"], [50, 53, "v"]], [[59, 60, "p"], [78, 78, "v"], [82, 82, "v"], [83, 83, "p"]], [[93, 94, "a"], [96, 97, "c"]], [[110, 110, "a"], [112, 112, "v"]]], "predicted_relations": [[], [], [[45, 46, 24, 25, "USED-FOR"]], [], [], []]}
{"doc_key": "2201.12093-da7e4db3-bdbf-49fd-a99b-379af26c6398", "sentences": [["We", "follow", "common", "practices", "and", "carry", "out", "preliminary", "grid", "search", "on", "the", "development", "set", "of", "STSb", "to", "decide", "the", "hyper-parameter", "configuration", "."], ["The", "learning", "rate", "is", "set", "to", "3e-5", "for", "base", "models", "and", "1e-5", "for", "large", "models", ",", "respectively", "."], ["Except", "for", "learning", "rate", ",", "We", "use", "the", "same", "training", "hyper-parameters", "for", "all", "experiments", "with", "the", "batch", "size", "of", "64", "and", "the", "maximum", "length", "of", "32", "."], ["The", "temperature", "parameter", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "is", "set", "to", "0.05", ",", "and", "the", "dropout", "probability", "is", "set", "to", "0.1", "."], ["We", "train", "our", "model", "for", "1", "epoch", "and", "evaluate", "the", "model", "on", "the", "STSb", "development", "set", "every", "125", "steps", ",", "and", "keep", "the", "best", "checkpoint", "by", "following", "-LSB-", "14", "-RSB-", "."]], "ner": [[[15, 15, "a"]], [[30, 31, "a"], [35, 36, "a"]], [[56, 57, "p"], [49, 50, "a"], [62, 63, "p"]], [[87, 87, "v"], [68, 69, "p"], [82, 83, "p"]], [[102, 102, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[8, 9, "c"], [15, 15, "a"]], [[23, 24, "p"], [28, 28, "v"], [33, 33, "v"]], [[42, 43, "p"], [51, 53, "c"], [56, 57, "p"], [59, 59, "v"], [65, 65, "v"]], [[68, 69, "p"], [78, 78, "v"], [82, 83, "p"], [87, 87, "v"]], [[92, 92, "a"], [94, 94, "v"], [95, 95, "p"], [102, 102, "a"], [106, 106, "v"]]], "predicted_relations": [[], [], [[62, 63, 49, 50, "USED-FOR"]], [[87, 87, 82, 83, "USED-FOR"]], []]}
{"doc_key": "2204.05862-6aa69ee0-534c-4a94-a3fe-a0b90105a354", "sentences": [["where", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\rm", "KL", "-RCB-", "\\ge", "0\\", "-RRB-", "is", "a", "hyperparameter", "."], ["In", "practice", "we", "use", "a", "very", "small", "value", "of", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "\\rm", "KL", "-RCB-", "=", "0.001\\", "-RRB-", ",", "which", "likely", "has", "a", "very", "minor", "impact", "during", "most", "of", "RL", "training", "-LRB-", "as", "\\", "-LRB-", "D_", "-LCB-", "\\rm", "KL", "-RCB-", "<", "100\\", "-RRB-", "typically", "-RRB-", ",", "and", "might", "actually", "be", "wholly", "unnecessary", "."], ["More", "details", "about", "RL", "are", "provided", "in", "REF", "."]], "ner": [[], [[47, 47, "a"], [34, 34, "v"]], [[74, 74, "a"]]], "relations": [[], [], []], "predicted_ner": [[[3, 8, "p"]], [[27, 32, "p"], [34, 34, "v"], [59, 59, "v"]], []], "predicted_relations": [[], [], []]}
{"doc_key": "2204.05862-b3c8addd-734f-4e60-8051-ce56b695e057", "sentences": [["In", "order", "to", "produce", "additional", "prompts", "-LRB-", "i.e", "."], ["the", "human", "side", "of", "the", "conversations", "-RRB-", "for", "RLHF", "training", ",", "we", "used", "a", "large", "LM", "to", "generate", "them", "."], ["For", "this", "purpose", ",", "we", "simply", "used", "few-shot", "learning", ",", "creating", "a", "context", "with", "about", "10", "existing", "high-quality", "human", "queries", ",", "and", "then", "sampling", "to", "generate", "more", "."], ["We", "find", "that", "the", "sample", "efficiency", "of", "RLHF", "is", "roughly", "the", "same", "on", "the", "original", "crowdworker-written", "prompt", "dataset", "and", "the", "model-generated", "one", ",", "so", "we", "combine", "the", "two", "for", "greater", "diversity", "during", "RLHF", "training", "."], ["We", "used", "137k", "prompts", "from", "the", "`", "static", "'", "dataset", ",", "and", "369k", "model-generated", "prompts", "."]], "ner": [[], [[17, 17, "a"]], [[36, 37, "a"]], [[64, 64, "a"], [89, 89, "a"], [61, 62, "p"], [66, 68, "v"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[], [[17, 17, "a"]], [[44, 44, "v"]], [[64, 64, "a"], [72, 74, "a"], [78, 78, "v"], [84, 84, "v"], [89, 89, "a"]], [[94, 94, "v"], [104, 104, "v"]]], "predicted_relations": [[], [], [], [[61, 62, 64, 64, "USED-FOR"]], []]}
{"doc_key": "2211.11602-208b22b7-5464-4976-aca6-510dd0fe7441", "sentences": [["For", "behavioural", "cloning", ",", "we", "used", "the", "same", "setup", "as", "in", "-LSB-", "17", "-RSB-", "."], ["Observations", "from", "human-human", "episodes", "were", "sequentially", "given", "to", "the", "agent", "to", "obtain", "movement", "and", "language", "actions", "distributions", "for", "each", "timestep", "and", "we", "maximized", "the", "likelihood", "of", "the", "ground", "truth", "actions", "taken", "by", "humans", "."], ["We", "used", "different", "coefficient", "for", "movement", "and", "language", "actions", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "BC", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "move", "-RCB-", "-RCB-", "=", "1\\", "-RRB-", "and", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "BC", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "lang", "-RCB-", "-RCB-", "=", "5\\", "-RRB-", ",", "respectively", "-RRB-", "."]], "ner": [[], [], [[76, 76, "v"], [96, 96, "v"]]], "relations": [[], [], []], "predicted_ner": [[], [], [[76, 76, "v"], [96, 96, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2211.11602-02f12e29-20fd-4085-93f3-479aabdfaf1e", "sentences": [["For", "contrastive", "self-supervised", "learning", ",", "we", "used", "the", "same", "technique", "as", "in", "-LSB-", "16", "-RSB-", ",", "-LSB-", "17", "-RSB-", "wherein", "the", "agent", "must", "predict", "whether", "vision", "and", "language", "embeddings", "match", "-LRB-", "i.e.", ",", "they", "are", "produced", "from", "a", "trajectory", "from", "the", "dataset", "as", "normal", "-RRB-", ",", "or", "they", "do", "not", "match", "-LRB-", "i.e.", ",", "visual", "embeddings", "are", "produced", "from", "the", "input", "image", "of", "one", "trajectory", "in", "the", "dataset", ",", "and", "language", "embeddings", "are", "produced", "from", "the", "language", "input", "from", "a", "different", "trajectory", "-RRB-", "."], ["We", "implemented", "this", "by", "adding", "an", "MLP", "discriminator", "that", "produces", "a", "binary", "prediction", "and", "used", "the", "same", "batch", "of", "data", "used", "for", "the", "behavioural", "cloning", "for", "the", "\u201c", "matches", "\u201d", ",", "and", "a", "shuffling", "of", "vision", "and", "language", "embeddings", "for", "the", "mis-matches", "."], ["We", "added", "this", "auxiliary", "loss", "to", "the", "total", "loss", "with", "a", "weight", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "CSS", "-RCB-", "-RCB-", "=1\\", "-RRB-", "."]], "ner": [[], [[90, 91, "a"]], [[138, 138, "p"], [148, 148, "v"]]], "relations": [[], [], []], "predicted_ner": [[[63, 63, "v"]], [[90, 90, "a"]], []], "predicted_relations": [[], [], [[148, 148, 138, 138, "USED-FOR"]]]}
{"doc_key": "2211.11602-67064f4c-f08a-488e-bbbe-aea3bdd6c0bd", "sentences": [["For", "reinforcement", "learning", ",", "we", "used", "V-trace", "-LSB-", "13", "-RSB-", "."], ["The", "value", "function", "baseline", "was", "implemented", "in", "the", "agent", "by", "an", "additional", "MLP", "head", "with", "a", "hidden", "layer", "size", "of", "512", "taking", "in", "the", "same", "inputs", "as", "policy", "heads", "do", "."], ["Both", "the", "movement", "and", "language", "policy", "shared", "the", "same", "rewards", "and", "value", "function", "."], ["We", "used", "a", "discount", "factor", "of", "\\", "-LRB-", "\\gamma", "=0.96\\", "-RRB-", "and", "different", "coefficients", "for", "weighing", "the", "movement", "policy", "updates", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "RL", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "move", "-RCB-", "-RCB-", "=0.5\\", "-RRB-", "-RRB-", ",", "language", "policy", "updates", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "RL", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "lang", "-RCB-", "-RCB-", "=0.1\\", "-RRB-", "-RRB-", "and", "the", "value", "function", "loss", "-LRB-", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "V", "-RCB-", "-RCB-", "=1\\", "-RRB-", "-RRB-", "."]], "ner": [[[6, 6, "a"]], [[23, 24, "a"], [27, 29, "p"], [31, 31, "v"]], [], [[59, 60, "a"], [64, 64, "p"], [65, 65, "v"], [73, 75, "a"], [93, 93, "v"], [97, 99, "a"], [117, 117, "v"], [122, 124, "a"], [117, 117, "v"], [135, 135, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[6, 6, "a"]], [[27, 29, "p"], [31, 31, "v"]], [], [[59, 60, "p"], [64, 64, "p"], [65, 65, "v"], [93, 93, "v"], [117, 117, "v"], [122, 124, "a"], [135, 135, "v"]]], "predicted_relations": [[], [[27, 29, 23, 24, "USED-FOR"]], [], [[65, 65, 64, 64, "USED-FOR"]]]}
{"doc_key": "2211.11602-7d48ee41-74bb-43b5-b55f-11cc84988b1c", "sentences": [["In", "the", "RL", "experiments", ",", "we", "initialize", "the", "agent", "'s", "parameters", "with", "those", "of", "a", "pretrained", "BC", "agent", "and", "continue", "training", "with", "the", "BC", ",", "CSS", "and", "RL", "objectives", "."], ["Additionally", ",", "we", "add", "a", "loss", "that", "penalises", "the", "KL", "divergence", "between", "the", "training", "policy", "and", "the", "initial", "BC", "policy", "."], ["In", "practice", ",", "we", "found", "that", "the", "only", "component", "of", "the", "policy", "that", "required", "this", "penalty", "was", "the", "one", "controlling", "when", "to", "produce", "language", "outputs", ",", "for", "which", "we", "used", "a", "weight", "of", "\\", "-LRB-", "w^", "-LCB-", "\\text", "-LCB-", "KL", "-RCB-", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "lang", "-RCB-", "-RCB-", "=0.001\\", "-RRB-", "."]], "ner": [[[16, 17, "a"], [25, 25, "a"], [2, 2, "a"], [27, 27, "a"]], [[39, 40, "a"]], [[82, 82, "p"], [100, 100, "v"]]], "relations": [[], [], []], "predicted_ner": [[[16, 16, "a"], [25, 25, "a"]], [], [[69, 69, "v"], [100, 100, "v"]]], "predicted_relations": [[], [], []]}
{"doc_key": "2206.06363-3fd5cc68-b90f-450c-8ab1-416a8a3259ae", "sentences": [["We", "use", "a", "DeepLab-v3", "-LSB-", "13", "-RSB-", "segmentation", "model", "with", "dilated", "-LSB-", "86", "-RSB-", "ResNet-50", "backbone", "-LSB-", "36", "-RSB-", "to", "facilitate", "a", "fair", "comparison", "with", "-LSB-", "75", "-RSB-", "."], ["The", "weights", "are", "initialized", "via", "self-supervised", "MoCo", "-LSB-", "16", "-RSB-", "pre-training", "on", "ImageNet", "."], ["We", "train", "the", "segmentation", "model", "for", "45", "epochs", "using", "batches", "of", "size", "16", "."], ["The", "weights", "are", "updated", "through", "SGD", "with", "momentum", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "weight", "decay", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["The", "learning", "rate", "is", "\\", "-LRB-", "2\\cdot", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "at", "the", "start", "and", "reduced", "to", "\\", "-LRB-", "2\\cdot", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "after", "40", "epochs", "."], ["Further", ",", "we", "use", "confidence", "threshold", "\\", "-LRB-", "\\tau", "=", "0.9\\", "-RRB-", "to", "select", "the", "most", "confident", "masks", "from", "our", "Mask", "R-CNN", "model", "-LRB-", "see", "Section", "REF", "-RRB-", "."], ["We", "keep", "the", "mask", "with", "the", "largest", "confidence", "score", "when", "thresholding", "excludes", "all", "predictions", "in", "an", "image", "from", "being", "used", "."], ["The", "cross-entropy", "loss", "in", "Eq", "."], ["REF", "uses", "the", "top-20", "%", "hardest", "pixels", "."], ["Following", "-LSB-", "75", "-RSB-", ",", "we", "freeze", "the", "first", "two", "ResNet", "blocks", "to", "increase", "speed", "."]], "ner": [[[3, 3, "a"]], [[35, 35, "a"]], [], [[62, 62, "a"], [64, 64, "p"], [67, 67, "v"], [70, 71, "p"], [67, 67, "v"]], [[82, 83, "p"], [94, 96, "c"], [109, 111, "c"]], [[123, 123, "v"], [117, 118, "a"], [118, 118, "p"], [123, 123, "v"]], [], [[164, 165, "a"]], [[172, 175, "p"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [7, 8, "a"], [14, 14, "a"]], [[35, 35, "a"], [41, 41, "a"]], [[46, 47, "a"], [49, 49, "v"], [50, 50, "p"], [55, 55, "v"]], [[62, 62, "a"], [64, 64, "p"], [67, 67, "v"], [70, 71, "p"], [74, 77, "v"]], [[82, 83, "p"], [110, 110, "v"], [111, 111, "p"]], [[117, 118, "p"], [123, 123, "v"], [134, 135, "a"]], [], [[164, 165, "a"]], [], [[186, 186, "v"], [187, 187, "a"]]], "predicted_relations": [[], [], [], [[64, 64, 62, 62, "USED-FOR"], [67, 67, 70, 71, "USED-FOR"], [70, 71, 62, 62, "USED-FOR"], [67, 67, 70, 71, "USED-FOR"]], [], [[118, 118, 117, 118, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2206.06336-e4894a4e-bc9d-46f0-8506-71265bcdb001", "sentences": [["We", "use", "sinusoidal", "position", "embeddings", "-LSB-", "103", "-RSB-", "for", "the", "language", "model", "."], ["The", "number", "of", "layers", "is", "\\", "-LRB-", "L=24\\", "-RRB-", ",", "each", "layer", "consists", "of", "\\", "-LRB-", "A=32\\", "-RRB-", "attention", "heads", "and", "the", "hidden", "dimension", "is", "\\", "-LRB-", "H=2048\\", "-RRB-", "."], ["The", "number", "of", "parameters", "is", "about", "1.3B", "."], ["For", "the", "non-causal", "part", ",", "we", "use", "encoder-only", "Transformers", ",", "where", "\\", "-LRB-", "A=16\\", "-RRB-", ",", "\\", "-LRB-", "H=1024\\", "-RRB-", ",", "\\", "-LRB-", "L=24\\", "-RRB-", "."], ["We", "utilize", "the", "learnable", "position", "embedding", "and", "relative", "position", "bias", "-LSB-", "81", "-RSB-", "for", "the", "non-causal", "model", "."], ["The", "number", "of", "parameters", "is", "about", "366M", "."], ["We", "use", "DeepNorm", "-LSB-", "107", "-RSB-", "for", "Transformers", "."], ["The", "connector", "module", "is", "a", "linear", "projection", "layer", "in", "our", "implementation", "."]], "ner": [[[2, 4, "a"]], [], [], [], [[80, 86, "a"]], [], [[105, 105, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[], [[20, 20, "v"], [29, 29, "v"], [35, 36, "p"], [40, 40, "v"]], [[49, 49, "v"]], [[64, 64, "v"], [69, 69, "v"], [74, 74, "v"]], [], [[101, 101, "v"]], [[105, 105, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2206.06336-e907fa44-aae1-4c85-b171-784b21bfce31", "sentences": [["The", "maximum", "input", "lengths", "for", "non-causal", "and", "semi-causal", "models", "are", "512", "and", "2048", ",", "respectively", "."], ["We", "randomly", "sample", "random", "spans", "whose", "lengths", "are", "between", "64", "and", "128", ",", "and", "feed", "them", "to", "the", "non-causal", "part", "."], ["The", "total", "length", "of", "non-causal", "spans", "is", "25", "%", "of", "the", "original", "sequence", "length", "."], ["The", "spans", "do", "not", "cross", "document", "boundaries", "."], ["We", "pretrain", "the", "semi-causal", "language", "model", "from", "scratch", "."], ["The", "non-causal", "module", "is", "initialized", "from", "a", "pretrained", "bidirectional", "encoder", ",", "using", "the", "replaced", "token", "detection", "task", "-LSB-", "20", "-RSB-", "."], ["During", "pretraining", ",", "we", "freeze", "all", "parameters", "of", "the", "non-causal", "encoder", "except", "the", "last", "two", "layers", "."], ["We", "pretrain", "MetaLM", "for", "300k", "steps", "with", "a", "batch", "size", "of", "1024", "and", "use", "Adam", "-LSB-", "48", "-RSB-", "for", "optimization", "."], ["We", "disable", "dropout", "of", "the", "semi-causal", "model", "and", "set", "the", "dropout", "rate", "of", "the", "non-causal", "model", "to", "0.1", "."], ["We", "use", "a", "learning", "rate", "of", "6e-4", "with", "warm-up", "."], ["Please", "refer", "to", "Appendix", "REF", "for", "more", "pretraining", "details", "."]], "ner": [[[1, 3, "p"], [5, 8, "a"], [5, 5, "c"], [7, 7, "c"]], [[34, 34, "c"], [27, 27, "v"]], [[38, 42, "p"], [41, 41, "c"]], [], [[63, 63, "c"]], [[70, 70, "c"]], [[99, 99, "c"]], [[121, 121, "a"], [109, 109, "a"]], [[142, 142, "c"], [133, 133, "c"]], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[10, 10, "v"], [12, 12, "v"]], [[25, 25, "v"], [27, 27, "v"]], [[44, 45, "v"]], [], [], [], [[104, 104, "v"]], [[109, 109, "a"], [111, 111, "v"], [115, 116, "p"], [118, 118, "v"], [121, 121, "a"]], [[130, 130, "a"], [138, 139, "p"], [145, 145, "v"]], [[150, 151, "p"], [153, 153, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2206.06336-ac1fcd48-d562-4388-86eb-b38d99cedccf", "sentences": [["We", "use", "a", "12-layer", "non-causal", "vision-language", "encoder", "and", "a", "24-layer", "language", "model", "."], ["The", "universal", "task", "layer", "follows", "the", "same", "network", "architectures", "and", "configurations", "of", "GPT-2", "-LSB-", "78", "-RSB-", "."], ["The", "hidden", "size", "is", "1024", ",", "and", "there", "are", "16", "attention", "heads", "."], ["We", "employ", "sinusoidal", "position", "embeddings", "-LSB-", "103", "-RSB-", "."], ["The", "number", "of", "parameters", "is", "353M", "."], ["For", "the", "non-causal", "encoder", ",", "we", "use", "a", "vision-language", "model", "pretrained", "as", "in", "VLMo", "-LSB-", "109", "-RSB-", "."], ["The", "number", "of", "parameters", "is", "192M", "."], ["We", "use", "224x224", "resolution", "during", "pretraining", "for", "images", "."], ["The", "connector", "is", "a", "three-layer", "feed-forward", "network", "."], ["More", "details", "about", "hyper-parameters", "can", "be", "found", "in", "Appendix", "REF", "."]], "ner": [[[4, 6, "a"]], [], [[31, 32, "p"], [34, 34, "v"], [40, 41, "p"], [39, 39, "v"]], [[45, 47, "a"]], [], [[67, 68, "a"]], [], [[87, 87, "p"], [86, 86, "v"]], [[97, 99, "a"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "v"], [9, 9, "v"]], [[25, 25, "a"]], [[31, 32, "p"], [34, 34, "v"], [39, 39, "v"]], [], [[57, 57, "v"]], [[72, 72, "a"]], [[82, 82, "v"]], [[86, 86, "v"]], [[97, 97, "v"], [98, 99, "a"]], []], "predicted_relations": [[], [], [], [], [], [], [], [[86, 86, 87, 87, "USED-FOR"]], [], []]}
{"doc_key": "2206.06336-f766a745-a478-4522-af83-02015b84e3c9", "sentences": [["We", "pretrain", "MetaLM", "for", "350k", "steps", "with", "256", "batch", "size", "."], ["We", "use", "AdamW", "optimizer", "with", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2=0.98\\", "-RRB-", "."], ["The", "learning", "rate", "is", "1e-4", "and", "weight", "decay", "is", "0.01", "."], ["We", "use", "linear", "decay", "and", "apply", "warm-up", "at", "the", "first", "2,500", "steps", "."], ["The", "dropout", "rate", "is", "set", "to", "0.1", "."]], "ner": [[[2, 2, "a"], [8, 9, "p"], [7, 7, "v"]], [[14, 14, "p"], [13, 13, "v"], [13, 13, "a"], [19, 19, "v"], [25, 25, "v"]], [[29, 30, "p"], [32, 32, "v"], [34, 35, "p"], [37, 37, "v"], [35, 35, "p"]], [[42, 42, "p"], [41, 41, "v"], [45, 45, "p"], [49, 50, "v"]], [[53, 54, "p"], [58, 58, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"], [7, 7, "v"], [8, 9, "p"]], [[13, 13, "a"]], [[29, 30, "p"], [32, 32, "v"], [34, 35, "p"], [37, 37, "v"]], [[41, 42, "a"], [45, 45, "a"], [49, 49, "v"], [50, 50, "p"]], [[53, 54, "p"], [58, 58, "v"]]], "predicted_relations": [[[8, 9, 2, 2, "USED-FOR"]], [[14, 14, 13, 13, "USED-FOR"]], [[32, 32, 29, 30, "USED-FOR"], [37, 37, 34, 35, "USED-FOR"], [37, 37, 35, 35, "USED-FOR"]], [[41, 41, 45, 45, "USED-FOR"], [49, 50, 45, 45, "USED-FOR"]], []]}
{"doc_key": "2209.13192-4a9d6a18-1c0e-481f-8ba9-e70bcaec4cf6", "sentences": [["Our", "systems", "are", "implemented", "on", "Fairseq-ST", "-LSB-", "67", "-RSB-", ",", "following", "the", "default", "settings", "unless", "stated", "otherwise", "."], ["We", "adopt", "a", "CTC", "compression", "to", "the", "8th", "encoder", "layer", "-LSB-", "41", "-RSB-", ",", "-LSB-", "16", "-RSB-", "that", "also", "reduces", "RAM", "consumption", "."], ["Both", "the", "Conformer", "and", "Transformer", "layers", "have", "a", "512", "embedding", "dimension", "and", "2,048", "hidden", "units", "in", "the", "linear", "layer", "."], ["We", "set", "dropout", "at", "0.1", "in", "the", "linear", "and", "attention", "layers", "."], ["We", "also", "set", "dropout", "at", "0.1", "in", "the", "Conformer", "Convolutional", "layers", "and", "a", "kernel", "size", "of", "31", "for", "the", "point-", "and", "depth-wise", "convolutions", "."], ["For", "the", "constrained", "data", "condition", ",", "we", "train", "a", "one-to-many", "multilingual", "model", "that", "prepends", "a", "token", "representing", "the", "selected", "target", "language", "for", "decoding", "-LSB-", "24", "-RSB-", "on", "all", "the", "7", "languages", "of", "MuST-Cinema", "."], ["Conversely", ",", "for", "the", "unconstrained", "data", "condition", "we", "develop", "two", "separate", "bilingual", "models", "for", "each", "language", "-LRB-", "en-", "-LCB-", "de", ",", "es", "-RCB-", "-RRB-", "."], ["For", "inference", ",", "we", "set", "the", "beam", "size", "to", "5", "for", "both", "subtitles", "and", "captions", "."]], "ner": [[[5, 5, "a"]], [[21, 22, "a"]], [[50, 51, "p"], [49, 49, "v"], [54, 55, "p"], [53, 53, "v"]], [[63, 63, "p"], [65, 65, "v"], [68, 71, "c"], [65, 65, "v"]], [[76, 76, "p"], [78, 78, "v"], [78, 78, "v"], [81, 83, "c"], [86, 87, "p"], [89, 89, "v"], [92, 95, "c"]], [[106, 108, "a"]], [[142, 143, "a"]], [[162, 163, "a"], [162, 163, "p"], [165, 165, "v"], [168, 170, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[21, 21, "a"], [25, 25, "v"]], [[49, 49, "v"], [50, 51, "p"], [53, 53, "v"], [54, 55, "p"]], [[63, 63, "a"], [65, 65, "v"]], [[76, 76, "a"], [78, 78, "v"], [86, 87, "p"], [89, 89, "v"]], [[106, 106, "v"], [126, 126, "v"], [129, 129, "a"]], [[140, 140, "v"]], [[162, 163, "p"], [165, 165, "v"]]], "predicted_relations": [[], [], [[49, 49, 50, 51, "USED-FOR"]], [[65, 65, 63, 63, "USED-FOR"], [65, 65, 63, 63, "USED-FOR"]], [[78, 78, 76, 76, "USED-FOR"], [78, 78, 76, 76, "USED-FOR"], [81, 83, 78, 78, "USED-FOR"], [81, 83, 78, 78, "USED-FOR"], [81, 83, 89, 89, "USED-FOR"], [92, 95, 89, 89, "USED-FOR"]], [], [], [[162, 163, 162, 163, "USED-FOR"], [165, 165, 162, 163, "USED-FOR"]]]}
{"doc_key": "2209.13192-d8b5a79d-ef4c-41a5-8123-16c80b2b6ba8", "sentences": [["We", "train", "with", "Adam", "optimizer", "-LSB-", "33", "-RSB-", "-LRB-", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.98\\", "-RRB-", "-RRB-", "for", "100,000", "steps", "."], ["The", "learning", "rate", "is", "set", "to", "increase", "linearly", "from", "0", "to", "\\", "-LRB-", "2e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "for", "the", "first", "25,000", "warm-up", "steps", "and", "then", "to", "decay", "with", "an", "inverse", "square", "root", "policy", "."], ["For", "fine-tuning", ",", "we", "set", "a", "constant", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["The", "vocabularies", "are", "based", "on", "SentencePiece", "models", "-LSB-", "52", "-RSB-", "with", "size", "8,000", "for", "the", "source", "language", "."], ["For", "all", "the", "target", "languages", "of", "the", "constrained", "data", "conditions", ",", "a", "shared", "vocabulary", "is", "built", "with", "a", "size", "of", "16,000", "while", ",", "for", "the", "unconstrained", "data", "condition", ",", "we", "build", "a", "vocabulary", "for", "each", "language", "-LRB-", "German", "and", "Spanish", "-RRB-", "with", "a", "size", "of", "16,000", "."], ["In", "the", "case", "of", "ASR", "training", ",", "we", "employ", "on", "the", "target", "side", "the", "same", "source", "language", "vocabulary", "of", "size", "8,000", "used", "in", "the", "translation", "settings", "."], ["The", "MT", "model", "is", "trained", "using", "the", "standard", "Fairseq", "multilingual", "machine", "translation", "task", "-LSB-", "48", "-RSB-", "hyper-parameters", ",", "with", "the", "same", "source", "and", "target", "vocabularies", "of", "the", "ST", "task", "."]], "ner": [[[3, 4, "a"], [12, 12, "v"], [18, 18, "v"]], [], [], [[85, 86, "a"]], [], [], [[180, 184, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [22, 22, "v"]], [[26, 27, "p"], [34, 34, "v"], [38, 40, "v"], [47, 47, "v"]], [[68, 69, "p"], [73, 75, "v"]], [[92, 92, "v"]], [[118, 118, "v"], [143, 143, "v"]], [[165, 165, "v"]], [[180, 180, "a"]]], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2209.13192-204a99f9-20b7-46ca-9586-a90b002d68d2", "sentences": [["Training", "is", "performed", "on", "4", "NVIDIA", "A40", "with", "40GB", "of", "RAM", ",", "max", "tokens", "of", "40k", "per", "mini-batch", "and", "an", "update", "frequency", "of", "2", ",", "except", "for", "the", "MT", "models", "for", "which", "8", "NVIDIA", "K80", "are", "used", "with", "4k", "max", "tokens", "and", "an", "update", "frequency", "of", "1", "."]], "ner": [[[5, 6, "a"], [10, 10, "p"], [8, 8, "v"], [12, 13, "p"], [39, 40, "p"], [15, 15, "v"], [16, 17, "c"], [20, 21, "p"], [43, 44, "p"], [23, 23, "v"], [33, 34, "a"], [10, 10, "p"], [12, 13, "p"], [39, 40, "p"], [38, 38, "v"], [20, 21, "p"], [43, 44, "p"], [46, 46, "v"]]], "relations": [[]], "predicted_ner": [[[4, 4, "v"], [8, 8, "v"], [12, 13, "p"], [15, 15, "v"], [23, 23, "v"], [32, 32, "v"], [38, 38, "v"], [46, 46, "v"]]], "predicted_relations": [[[10, 10, 5, 6, "USED-FOR"], [8, 8, 10, 10, "USED-FOR"], [8, 8, 12, 13, "USED-FOR"], [8, 8, 10, 10, "USED-FOR"], [8, 8, 12, 13, "USED-FOR"], [12, 13, 5, 6, "USED-FOR"], [39, 40, 33, 34, "USED-FOR"], [15, 15, 10, 10, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 20, 21, "USED-FOR"], [15, 15, 10, 10, "USED-FOR"], [15, 15, 12, 13, "USED-FOR"], [15, 15, 20, 21, "USED-FOR"], [16, 17, 15, 15, "USED-FOR"], [16, 17, 23, 23, "USED-FOR"], [20, 21, 5, 6, "USED-FOR"], [43, 44, 33, 34, "USED-FOR"], [23, 23, 20, 21, "USED-FOR"], [23, 23, 20, 21, "USED-FOR"], [10, 10, 5, 6, "USED-FOR"], [12, 13, 5, 6, "USED-FOR"], [39, 40, 33, 34, "USED-FOR"], [38, 38, 39, 40, "USED-FOR"], [38, 38, 43, 44, "USED-FOR"], [38, 38, 39, 40, "USED-FOR"], [38, 38, 43, 44, "USED-FOR"], [20, 21, 5, 6, "USED-FOR"], [43, 44, 33, 34, "USED-FOR"], [46, 46, 43, 44, "USED-FOR"], [46, 46, 43, 44, "USED-FOR"]]]}
{"doc_key": "2203.15082-ab6b0ec4-df68-43a9-851d-db9200058777", "sentences": [["We", "train", "the", "IDUS", "with", "mini-batch", "size", "fifteen", "on", "an", "NVIDIA", "Titan", "X", "GPU", "-LRB-", "12GB", "-RRB-", "with", "the", "PyTorch", "package", "-LSB-", "53", "-RSB-", "."], ["The", "loss", "function", "we", "use", "is", "the", "mean", "of", "dice", "loss", "-LSB-", "54", "-RSB-", "and", "cross-entropy", "loss", "."], ["We", "use", "weights", "\\", "-LRB-", "w_m^", "-LCB-", "ept", "-RCB-", "=", "1/r_m\\", "-RRB-", "and", "\\", "-LRB-", "w_m^", "-LCB-", "dice", "-RCB-", "=", "1/\\sqrt", "-LCB-", "r_m", "-RCB-", "\\", "-RRB-", ",", "where", "\\", "-LRB-", "r_m\\", "-RRB-", "was", "the", "proportion", "of", "\\", "-LRB-", "m\\", "-RRB-", "th", "class", "label", "in", "training", "samples", ",", "to", "balance", "the", "class", "weights", "of", "two", "losses", ",", "respectively", "."], ["Batch", "normalization", "layers", "-LSB-", "55", "-RSB-", "are", "added", "after", "each", "convolutional", "layer", "-LRB-", "except", "the", "segmentation", "head", "-RRB-", "to", "accelerate", "the", "loss", "convergence", "."], ["The", "model", "'s", "parameters", "are", "initialed", "by", "a", "uniform", "distribution", "following", "the", "scaling", "of", "-LSB-", "56", "-RSB-", "and", "optimized", "by", "Adam", "-LSB-", "57", "-RSB-", "algorithm", "with", "weight", "decay", "value", "\\", "-LRB-", "10^", "-LCB-", "-9", "-RCB-", "\\", "-RRB-", "."], ["In", "every", "iteration", ",", "the", "learning", "rate", "of", "the", "model", "is", "started", "with", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "decreased", "by", "a", "drop", "rate", "\\", "-LRB-", "0.1\\", "-RRB-", "every", "100", "epochs", "."], ["The", "updating", "interval", "of", "superpixel", "labels", "and", "boundaries", "is", "200", "and", "we", "do", "this", "five", "times", "-LRB-", "five", "iterations", "-RRB-", "throughout", "training", "."], ["Consequently", ",", "we", "train", "for", "1000", "epochs", "where", "every", "200", "epochs", "we", "update", "the", "superpixel", "labels", "and", "boundaries", "."]], "ner": [[[3, 3, "a"], [5, 6, "p"], [7, 7, "v"], [13, 13, "p"], [10, 12, "v"], [15, 15, "v"], [19, 20, "p"]], [[26, 27, "a"], [34, 35, "a"], [40, 41, "a"]], [[45, 45, "a"], [94, 94, "a"], [53, 53, "v"]], [], [[126, 128, "a"], [133, 134, "p"], [151, 153, "p"]], [[168, 169, "p"], [188, 189, "p"], [192, 192, "v"], [196, 196, "a"]], [[199, 205, "a"], [200, 200, "p"], [207, 207, "v"], [216, 216, "p"], [212, 212, "v"], [215, 215, "v"], [207, 207, "v"]], [[230, 230, "v"], [227, 227, "a"], [231, 231, "a"], [226, 226, "v"], [230, 230, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 6, "p"], [7, 7, "v"], [15, 15, "v"]], [[34, 35, "a"], [40, 41, "a"]], [[96, 96, "v"]], [], [[145, 145, "a"], [151, 153, "p"], [156, 159, "v"]], [[168, 169, "p"], [178, 181, "v"], [188, 189, "p"], [192, 192, "v"], [195, 195, "v"], [196, 196, "p"]], [[199, 200, "p"], [207, 207, "v"], [212, 212, "v"], [215, 215, "v"]], [[226, 226, "v"], [227, 227, "p"], [230, 230, "v"], [231, 231, "p"]]], "predicted_relations": [[[13, 13, 3, 3, "USED-FOR"], [15, 15, 13, 13, "USED-FOR"], [19, 20, 3, 3, "USED-FOR"]], [], [], [], [[133, 134, 126, 128, "USED-FOR"], [151, 153, 126, 128, "USED-FOR"]], [], [[207, 207, 200, 200, "USED-FOR"], [207, 207, 216, 216, "USED-FOR"], [216, 216, 199, 205, "USED-FOR"], [207, 207, 200, 200, "USED-FOR"], [207, 207, 216, 216, "USED-FOR"]], []]}
{"doc_key": "2203.15082-3e8fd76c-c6ab-4baf-8fc0-bd09184b8287", "sentences": [["In", "IDSS", ",", "the", "training", "configuration", "of", "unsupervised", "learning", "is", "the", "same", "as", "that", "of", "IDUS", "."], ["For", "the", "supervised", "part", ",", "the", "learning", "rate", "was", "set", "to", "\\", "-LRB-", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "and", "decreased", "by", "\\", "-LRB-", "0.1\\", "-RRB-", "every", "eighty", "epochs", "."], ["We", "first", "update", "the", "parameters", "of", "the", "decoder", "and", "segmentation", "head", "."], ["After", "forty", "epochs", ",", "we", "add", "the", "encoder", "parameters", "to", "the", "optimizer", "to", "jointly", "optimize", "."]], "ner": [[[7, 8, "a"]], [[19, 20, "a"], [23, 24, "p"], [41, 41, "v"], [43, 45, "c"]], [[54, 57, "a"]], [[66, 67, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[1, 1, "a"], [15, 15, "a"]], [[23, 24, "p"], [30, 33, "v"], [41, 41, "v"], [44, 44, "v"], [45, 45, "p"]], [], [[60, 60, "v"], [61, 61, "p"]]], "predicted_relations": [[], [[23, 24, 19, 20, "USED-FOR"]], [], []]}
{"doc_key": "2206.08640-c238080a-d02b-4d2b-a696-9ce5d6fda36e", "sentences": [["We", "use", "a", "CNN", "with", "dropout", "rate", "20", "%", ",", "convolutional", "layers", "with", "kernel", "size", "4", "and", "filter", "size", "200", "."], ["The", "temporal", "cell", "-LRB-", "LSTM", ",", "BiLSTM", "or", "TCN", "-RRB-", "contains", "100", ",", "100", "or", "120", "neurons", ",", "respectively", "."], ["We", "interpolate", "the", "time-series", "to", "64", "time", "steps", ",", "and", "train", "the", "model", "for", "2,000", "epochs", "with", "early", "stopping", "and", "a", "batch", "size", "of", "50", "."]], "ner": [[[3, 3, "a"], [5, 6, "p"], [13, 14, "p"], [15, 15, "v"], [17, 18, "p"], [19, 19, "v"]], [[22, 23, "a"], [37, 37, "p"], [32, 32, "v"], [34, 34, "v"], [25, 25, "c"], [32, 32, "v"], [34, 34, "v"], [27, 27, "c"], [36, 36, "v"], [29, 29, "c"]], [[47, 48, "p"], [46, 46, "v"], [56, 56, "p"], [55, 55, "v"], [62, 63, "p"], [65, 65, "v"], [58, 59, "p"]]], "relations": [[], [], []], "predicted_ner": [[[3, 3, "a"], [5, 6, "p"], [7, 8, "v"], [15, 15, "v"], [19, 19, "v"]], [[25, 25, "a"], [27, 27, "a"], [29, 29, "a"], [32, 32, "v"], [34, 34, "v"], [36, 36, "v"], [37, 37, "p"]], [[46, 46, "v"], [53, 53, "a"], [55, 55, "v"], [56, 56, "p"], [62, 63, "p"], [65, 65, "v"]]], "predicted_relations": [[[5, 6, 3, 3, "USED-FOR"]], [[32, 32, 37, 37, "USED-FOR"], [34, 34, 37, 37, "USED-FOR"], [32, 32, 37, 37, "USED-FOR"], [34, 34, 37, 37, "USED-FOR"], [27, 27, 32, 32, "USED-FOR"], [27, 27, 34, 34, "USED-FOR"], [27, 27, 32, 32, "USED-FOR"], [27, 27, 34, 34, "USED-FOR"], [27, 27, 36, 36, "USED-FOR"], [36, 36, 37, 37, "USED-FOR"]], [[46, 46, 56, 56, "USED-FOR"], [55, 55, 56, 56, "USED-FOR"], [65, 65, 62, 63, "USED-FOR"]]]}
{"doc_key": "2206.08653-9f1a5295-58b8-4275-b941-fb2e2c14bf7e", "sentences": [["Image", "classification", ":", "We", "conduct", "experiments", "across", "two", "different", "backbones", "-LRB-", "Efficientnetv2S", "-LSB-", "25", "-RSB-", "and", "Mobilenetv2", "-LSB-", "26", "-RSB-", "-RRB-", "initialized", "using", "imagenet", "pre-trained", "weights", "followed", "by", "a", "dropout", "layer", "with", "probability", "0.4", "and", "a", "final", "sigmoid", "classification", "layer", "."], ["We", "use", "an", "image", "size", "of", "224", "x", "224", "and", "standard", "augmentations", "like", "Horizontal", "Flip", ",", "Rotation", ",", "Contrast", ",", "Translation", ",", "and", "Zoom", "."], ["It", "is", "important", "to", "note", "that", "state-of-the-art", "approaches", "-LSB-", "27", "-RSB-", "use", "larger", "image", "sizes", "for", "training", "-LRB-", "448", "x", "448", "-RRB-", ",", "autoaugment", "-LSB-", "28", "-RSB-", "and", "cutout", "-LSB-", "29", "-RSB-", "for", "augmentations", ",", "one-cycle", "learning", "rate", "scheduler", "-LSB-", "30", "-RSB-", "among", "other", "tricks", "."], ["We", "are", "not", "trying", "to", "compete", "with", "the", "state-of-the-art", "results", "on", "multi-label", "classification", "and", "want", "to", "demonstrate", "the", "value", "of", "adding", "hierarchical", "knowledge", "."]], "ner": [[[11, 11, "a"], [16, 16, "a"], [32, 32, "p"], [33, 33, "v"]], [[54, 55, "a"], [57, 57, "a"], [59, 59, "a"], [61, 61, "a"], [64, 64, "a"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "v"], [11, 11, "a"], [16, 16, "a"], [23, 23, "a"], [29, 29, "a"], [33, 33, "v"]], [[47, 47, "v"], [49, 49, "v"]], [[84, 84, "v"], [86, 86, "v"], [89, 89, "a"], [94, 94, "a"]], []], "predicted_relations": [[[32, 32, 11, 11, "USED-FOR"], [32, 32, 16, 16, "USED-FOR"]], [], [], []]}
{"doc_key": "2206.08653-11299d95-3ae8-453a-aaae-1f44ef685338", "sentences": [["Text", "classification", ":", "We", "conduct", "experiments", "by", "using", "small", "bert", "-LSB-", "31", "-RSB-", "-LRB-", "uncased", ",", "L=2", ",", "H=768", ",", "A=12", "-RRB-", "and", "-LSB-", "32", "-RSB-", "embeddings", "as", "base", "extractor", "initialised", "by", "weights", "trained", "on", "Wikipedia", "-LSB-", "33", "-RSB-", "and", "Bookscorpus", "datasets", "-LSB-", "34", "-RSB-", "."], ["All", "text", "sentences", "are", "first", "converted", "to", "lower", "case", "."]], "ner": [[[8, 9, "a"], [14, 14, "p"], [16, 16, "p"], [16, 16, "v"], [18, 18, "p"], [18, 18, "v"], [20, 20, "p"], [20, 20, "v"], [26, 26, "a"], [35, 35, "a"], [40, 40, "a"]], []], "relations": [[], []], "predicted_ner": [[[8, 9, "a"], [16, 16, "v"], [18, 18, "v"]], []], "predicted_relations": [[[14, 14, 8, 9, "USED-FOR"], [14, 14, 26, 26, "USED-FOR"], [16, 16, 8, 9, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [16, 16, 26, 26, "USED-FOR"], [16, 16, 14, 14, "USED-FOR"], [16, 16, 16, 16, "USED-FOR"], [16, 16, 18, 18, "USED-FOR"], [16, 16, 20, 20, "USED-FOR"], [18, 18, 8, 9, "USED-FOR"], [18, 18, 26, 26, "USED-FOR"], [18, 18, 14, 14, "USED-FOR"], [18, 18, 16, 16, "USED-FOR"], [18, 18, 18, 18, "USED-FOR"], [18, 18, 20, 20, "USED-FOR"], [20, 20, 8, 9, "USED-FOR"], [20, 20, 20, 20, "USED-FOR"], [20, 20, 26, 26, "USED-FOR"], [20, 20, 14, 14, "USED-FOR"], [20, 20, 16, 16, "USED-FOR"], [20, 20, 18, 18, "USED-FOR"], [20, 20, 20, 20, "USED-FOR"]], []]}
{"doc_key": "2206.08657-ff1cb419-ad0e-43f8-b293-9d48f07f3a6c", "sentences": [["We", "use", "four", "public", "image-caption", "datasets", "for", "pre-training", ":", "Conceptual", "Captions", "-LRB-", "CC", "-RRB-", "-LSB-", "61", "-RSB-", ",", "SBU", "Captions", "-LSB-", "51", "-RSB-", ",", "MSCOCO", "Captions", "-LSB-", "3", "-RSB-", ",", "and", "Visual", "Genome", "-LRB-", "VG", "-RRB-", "-LSB-", "30", "-RSB-", "."], ["The", "total", "number", "of", "the", "unique", "images", "in", "the", "combined", "training", "data", "is", "4M", "."], ["The", "statistics", "of", "these", "datasets", "are", "shown", "in", "Appendix", "."], ["We", "pre-train", "Bridge-Tower\\", "-LRB-", "_", "-LCB-", "\\text", "-LCB-", "BASE", "-RCB-", "-RCB-", "\\", "-RRB-", "for", "100k", "steps", "on", "64", "NVIDIA", "A100", "GPUs", "with", "a", "batch", "size", "of", "\\", "-LRB-", "4,096\\", "-RRB-", "."], ["The", "learning", "rate", "in", "pre-training", "is", "set", "to", "\\", "-LRB-", "1e^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["No", "data", "augmentation", "is", "used", "except", "for", "center-crop", "-LSB-", "54", "-RSB-", ",", "-LSB-", "12", "-RSB-", "."], ["The", "image", "resolution", "in", "pre-training", "is", "set", "to", "\\", "-LRB-", "288", "\\times", "288\\", "-RRB-", "."], ["Other", "hyperparameters", "remain", "unchanged", "based", "on", "the", "ablation", "experiments", "."]], "ner": [[[18, 19, "a"], [24, 25, "a"]], [], [], [], [[97, 98, "p"]], [], [], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "v"], [9, 13, "a"], [24, 25, "a"], [31, 35, "a"]], [[53, 53, "v"]], [], [[79, 79, "v"], [82, 82, "v"], [88, 89, "p"], [93, 93, "v"]], [[97, 98, "p"], [106, 109, "v"]], [[120, 120, "a"]], [[139, 139, "v"], [141, 141, "v"]], []], "predicted_relations": [[], [], [], [], [], [], [], []]}
{"doc_key": "2207.04186-811e2170-e1bf-44a7-9e0f-b837466db4de", "sentences": [["For", "the", "baseline", ",", "we", "follow", "-LSB-", "14", "-RSB-", "to", "train", "a", "BYOL", "model", "for", "300", "epochs", "-LRB-", "top-1", ":", "73.0", "-RRB-", "and", "1,000", "epochs", "-LRB-", "top-1", ":", "74.3", "-RRB-", "."], ["For", "our", "framework", ",", "if", "not", "explicitly", "stated", "otherwise", ",", "we", "use", "\\", "-LRB-", "V=2", ",", "K=8", ",", "s_", "-LCB-", "\\text", "-LCB-", "base", "-RCB-", "-RCB-", "=0.9", ",", "s_", "-LCB-", "\\text", "-LCB-", "view", "-RCB-", "-RCB-", "=0.6\\", "-RRB-", "."], ["We", "use", "LARS", "optimizer", "with", "a", "base", "initial", "learning", "rate", "\\", "-LRB-", "0.3\\times", "\\text", "-LCB-", "batch", "size", "-RCB-", "/256\\", "-RRB-", "for", "300", "epochs", "and", "\\", "-LRB-", "0.2\\times", "\\text", "-LCB-", "batch", "size", "-RCB-", "/256\\", "-RRB-", "for", "1,000", "epochs", ",", "with", "a", "cosine", "learning", "rate", "decay", ",", "and", "a", "warm", "up", "period", "of", "10", "epochs", "."]], "ner": [[[12, 13, "a"], [14, 16, "c"]], [[45, 45, "a"], [47, 47, "a"]], [[70, 71, "a"], [74, 77, "p"], [88, 90, "c"], [102, 104, "c"], [108, 111, "p"], [115, 117, "p"], [119, 120, "v"]]], "relations": [[], [], []], "predicted_ner": [[[12, 13, "a"], [15, 15, "v"], [16, 16, "p"], [20, 20, "v"], [23, 23, "v"], [24, 24, "p"], [28, 28, "v"]], [[33, 33, "a"], [47, 47, "v"], [49, 55, "p"], [58, 64, "p"]], [[70, 70, "a"], [89, 89, "v"], [90, 90, "p"], [103, 103, "v"], [104, 104, "p"], [115, 117, "c"], [119, 119, "v"], [120, 120, "p"]]], "predicted_relations": [[], [], [[74, 77, 70, 71, "USED-FOR"], [88, 90, 119, 120, "USED-FOR"], [102, 104, 119, 120, "USED-FOR"], [119, 120, 115, 117, "USED-FOR"]]]}
{"doc_key": "2212.06742-43b6f82c-529c-41b1-ac20-331c80f7e3ba", "sentences": [["We", "use", "the", "same", "T5", "architecture", "with", "a", "12-layer", "encoder", ",", "a", "12-layer", "decoder", ",", "768", "hidden", "units", "-LRB-", "\\", "-LRB-", "d_\\text", "-LCB-", "model", "-RCB-", "\\", "-RRB-", "-RRB-", ",", "12", "heads", ",", "2048", "feedforward", "linear", "units", "-LRB-", "\\", "-LRB-", "d_\\text", "-LCB-", "ff", "-RCB-", "\\", "-RRB-", "-RRB-", ",", "GELU", "activations", ",", "a", "dropout", "-LSB-", "36", "-RSB-", "rate", "as", "0.1", ",", "and", "no", "embedding", "tying", "."], ["-LSB-", "3", "-RSB-", "find", "no", "difference", "between", "training", "from", "pre-trained", "model", "weights", "and", "that", "from", "scratch", ",", "except", "that", "the", "former", "converges", "more", "quickly", "."], ["To", "this", "end", ",", "we", "use", "mT5", "checkpointhttps", ":", "//github.com/google-research/multilingual-t5", "#", "released-model-checkpoints", "for", "initialization", ",", "which", "already", "contains", "strong", "multilingual", "NL", "representations", "."]], "ner": [[[4, 5, "a"], [16, 17, "p"], [15, 15, "v"], [30, 30, "p"], [8, 8, "v"], [12, 12, "v"], [29, 29, "v"], [33, 35, "p"], [32, 32, "v"], [57, 57, "v"]], [], []], "relations": [[], [], []], "predicted_ner": [[[4, 4, "a"], [8, 8, "v"], [12, 12, "v"], [15, 15, "v"], [29, 29, "v"], [32, 32, "v"], [33, 35, "a"], [47, 47, "v"], [51, 51, "a"], [57, 57, "v"]], [], [[95, 95, "a"]]], "predicted_relations": [[[16, 17, 4, 5, "USED-FOR"], [30, 30, 4, 5, "USED-FOR"], [29, 29, 30, 30, "USED-FOR"], [33, 35, 4, 5, "USED-FOR"], [32, 32, 30, 30, "USED-FOR"]], [], []]}
{"doc_key": "2212.06742-b4b72717-f77b-4ad6-82a3-726b2a511343", "sentences": [["For", "pre-training", ",", "we", "set", "the", "maximum", "length", "-LRB-", "L", "-RRB-", "of", "512/1024", ",", "a", "micro-batch", "size", "of", "8/4", "with", "a", "gradient", "accumulation", "step", "of", "15", "."], ["We", "utilize", "the", "Adafactor", "-LSB-", "34", "-RSB-", "optimizer", "and", "a", "linear", "warmup", "of", "1000", "steps", "with", "a", "peak", "learning", "rate", "of", "1e-4", "."], ["All", "pre-training", "tasks", "are", "run", "on", "a", "cluster", "of", "32", "NVIDIA", "A100", "GPUs", "with", "40G", "memory", "for", "100,000", "training", "steps", "."], ["To", "accelerate", "the", "pre-training", ",", "we", "utilize", "the", "ZeRO", "stage1", "approach", "-LSB-", "31", "-RSB-", "for", "partitioning", "optimizer", "states", "and", "enable", "BFloat16", "half-precision", "format", "for", "mixed-precision", "training", "."], ["The", "total", "pre-training", "time", "lasts", "around", "four", "weeks", "."]], "ner": [[[6, 7, "p"], [12, 12, "v"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"], [18, 18, "v"], [21, 23, "p"], [25, 25, "v"]], [[30, 30, "a"], [48, 48, "v"], [37, 38, "p"], [40, 40, "v"], [41, 41, "c"], [44, 46, "p"], [48, 48, "v"]], [[69, 69, "c"]], [[79, 80, "a"], [91, 91, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[9, 9, "p"], [12, 12, "v"], [15, 16, "p"], [18, 18, "v"], [21, 23, "p"], [25, 25, "v"]], [[30, 30, "a"], [37, 38, "a"], [40, 40, "v"], [44, 46, "p"], [48, 48, "v"]], [[59, 59, "v"], [64, 64, "v"], [67, 67, "v"]], [[79, 79, "v"], [91, 91, "a"]], [[104, 104, "v"]]], "predicted_relations": [[[12, 12, 6, 7, "USED-FOR"], [12, 12, 6, 7, "USED-FOR"], [18, 18, 6, 7, "USED-FOR"], [18, 18, 6, 7, "USED-FOR"]], [[48, 48, 44, 46, "USED-FOR"], [37, 38, 30, 30, "USED-FOR"], [40, 40, 37, 38, "USED-FOR"], [44, 46, 30, 30, "USED-FOR"], [48, 48, 44, 46, "USED-FOR"]], [], [], []]}
{"doc_key": "2210.11610-2569c29a-f2e0-48b4-8008-18d553d2a666", "sentences": [["We", "follow", "previous", "studies", "-LSB-", "43", "-RSB-", ",", "-LSB-", "40", "-RSB-", "and", "conduct", "our", "experiments", "on", "an", "autoregressive", "Transformer-based", "language", "model", "with", "540", "billion", "parameters", "."], ["The", "CoT", "examples", "for", "each", "dataset", "are", "listed", "in", "Appendix", "REF", "."], ["We", "generate", "\\", "-LRB-", "m=32\\", "-RRB-", "reasoning", "paths", "for", "each", "question", "in", "a", "training", "set", "."], ["Since", "each", "reasoning", "path", "is", "augmented", "into", "four", "formats", "in", "Sec", "."], ["REF", ",", "the", "final", "training", "samples", "are", "up", "to", "the", "size", "of", "\\", "-LRB-", "128\\times", "|\\mathcal", "-LCB-", "D", "-RCB-", "^\\mathtt", "-LCB-", "train", "-RCB-", "|\\", "-RRB-", ",", "with", "\\", "-LRB-", "|\\mathcal", "-LCB-", "D", "-RCB-", "^\\mathtt", "-LCB-", "train", "-RCB-", "|\\", "-RRB-", "being", "the", "size", "of", "the", "corresponding", "training", "set", "."], ["For", "all", "datasets", "except", "DROP", ",", "we", "use", "the", "whole", "training", "set", ";", "To", "reduce", "the", "training", "burden", ",", "we", "sample", "5k", "examples", "from", "the", "non-football", "and", "football", "partition", "of", "the", "DROP", "dataset", ",", "and", "sample", "5k", "examples", "from", "ANLI-A2", "and", "ANLI-A3", "."], ["For", "each", "dataset", ",", "we", "fine-tune", "the", "model", "for", "10k", "steps", "with", "a", "learning", "rate", "of", "5e\\", "-LRB-", "-5\\", "-RRB-", "and", "a", "batch", "size", "of", "32", "."], ["For", "multiple", "path", "decoding", ",", "we", "use", "a", "sampling", "temperature", "of", "\\", "-LRB-", "T=0.7\\", "-RRB-", "with", "the", "pre-trained", "model", "as", "suggested", "by", "-LSB-", "40", "-RSB-", "."], ["We", "use", "\\", "-LRB-", "T=1.2\\", "-RRB-", "for", "the", "language", "model", "after", "self-improvement", "-LRB-", "LMSI", "-RRB-", "."], ["We", "set", "the", "maximum", "number", "of", "decoded", "steps", "to", "256", "for", "all", "experiments", "."]], "ner": [[[17, 20, "a"]], [], [], [], [], [], [[170, 171, "p"]], [[192, 193, "a"], [192, 193, "p"], [197, 197, "v"], [201, 202, "c"]], [[214, 214, "v"]], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[17, 18, "a"], [22, 22, "v"]], [], [[42, 42, "v"]], [[61, 61, "v"]], [], [[135, 135, "v"], [150, 150, "v"], [153, 153, "a"], [155, 155, "a"]], [[166, 166, "v"], [170, 171, "p"], [175, 175, "v"], [179, 180, "p"], [182, 182, "v"]], [[192, 193, "p"], [197, 197, "v"]], [[214, 214, "v"]], [[235, 235, "v"], [236, 238, "c"]]], "predicted_relations": [[], [], [], [], [], [], [], [[197, 197, 192, 193, "USED-FOR"], [201, 202, 197, 197, "USED-FOR"]], [], []]}
{"doc_key": "2209.02522-9c483716-4f90-4860-ad7d-f6036107a2ed", "sentences": [["In", "our", "work", ",", "we", "leverage", "the", "work", "of", "Jia", "-LSB-", "14", "-RSB-", "as", "our", "baseline", "."], ["We", "train", "all", "models", "using", "a", "learning", "rate", "of", "\\", "-LRB-", "1e-4\\", "-RRB-", ",", "weight", "decay", "of", "\\", "-LRB-", "5e-4\\", "-RRB-", ",", "and", "the", "Adam", "optimizer", "if", "otherwise", "stated", "."], ["Regarding", "the", "learning", "rate", "schedule", ",", "we", "apply", "a", "plateau", "scheduler", "that", "reduces", "the", "learning", "rate", "by", "a", "factor", "of", "0.1", "if", "the", "validation", "results", "do", "not", "improve", "for", "four", "epochs", "."], ["Batches", "of", "size", "64", "are", "used", "per", "default", ",", "and", "gradient", "clipping", "is", "applied", "after", "computing", "the", "gradients", "based", "on", "the", "weighted", "cross-entropy", "loss", "function", "-LSB-", "15", "-RSB-", "."], ["The", "backbone", "networks", "are", "initialized", "with", "pre-trained", "weights", "from", "the", "ImageNet", "dataset", "-LSB-", "2", "-RSB-", "."], ["More", "details", "can", "be", "found", "in", "the", "supplementary", "material", "."]], "ner": [[], [[41, 42, "a"]], [[56, 57, "a"]], [], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[9, 9, "a"]], [[23, 24, "p"], [28, 28, "v"], [31, 32, "p"], [36, 36, "v"], [41, 41, "a"]], [[61, 62, "p"], [67, 67, "v"], [76, 76, "v"], [77, 77, "p"]], [[82, 82, "v"], [89, 90, "a"], [100, 101, "a"]], [[109, 110, "a"], [118, 119, "a"]], []], "predicted_relations": [[], [], [], [], [], []]}
{"doc_key": "2211.14133-7549cd13-3b48-4590-8d5f-329c4b68f2db", "sentences": [["We", "pretrain", "BERT-Base", "-LSB-", "6", "-RSB-", "on", "the", "English", "Wikipedia", "-LRB-", "Phase", "1", "only", "-RRB-", "by", "NVLAMB", "and", "K-FAC", "."], ["For", "NVLAMB", ",", "we", "set", "mini-batch", "size", "8,192", ",", "max", "sequence", "length", "128", ",", "weight", "decay", "0.01", ",", "base", "learning", "rate", "\\", "-LRB-", "6\\cdot", "10^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", ",", "total", "training", "steps", "7,038", ",", "and", "linear", "learning", "rate", "warming", "up", "steps", "2,000", "."], ["The", "learning", "rate", "at", "the", "\\", "-LRB-", "t\\", "-RRB-", "-th", "step", "after", "warm-up", "is", "determined", "by", "the", "polynomial", "decay", ":", "\\", "-LRB-", "\\eta", "_t=\\mathrm", "-LCB-", "base\\_lr", "-RCB-", "\\times", "-LRB-", "1-t/\\mathrm", "-LCB-", "total\\_steps", "-RCB-", "-RRB-", "^", "-LCB-", "0.5", "-RCB-", "\\", "-RRB-", "."], ["For", "K-FAC", ",", "the", "same", "hyperparameters", "are", "used", "except", "that", "the", "number", "of", "learning", "rate", "warming", "up", "steps", "is", "reduced", "to", "600", ",", "resulting", "in", "larger", "learning", "rates", "than", "NVLAMB", "until", "the", "2,000th", "step", "."], ["The", "pretraining", "loss", "versus", "the", "number", "steps", "is", "shown", "in", "Figure", "5", "-LRB-", "left", "-RRB-", "."], ["fig", ":", "bertbaselr", "shows", "the", "learning", "rate", "schedule", "."]], "ner": [[[2, 2, "a"], [8, 9, "a"], [16, 16, "a"], [18, 18, "a"]], [[25, 26, "p"], [27, 27, "v"], [29, 31, "p"], [32, 32, "v"], [34, 35, "p"], [36, 36, "v"], [38, 40, "p"], [51, 53, "p"], [54, 54, "v"], [57, 62, "p"], [63, 63, "v"], [21, 21, "a"]], [[82, 83, "p"]], [[135, 135, "a"], [107, 107, "a"]], [], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [16, 16, "a"], [18, 18, "a"]], [[21, 21, "a"], [25, 26, "p"], [27, 27, "v"], [29, 31, "p"], [32, 32, "v"], [34, 35, "p"], [36, 36, "v"], [39, 40, "p"], [54, 54, "v"], [63, 63, "v"]], [[66, 67, "p"], [72, 72, "p"], [82, 83, "p"], [101, 101, "v"]], [[107, 107, "a"], [119, 120, "p"], [127, 127, "v"], [135, 135, "a"]], [[142, 143, "a"]], [[159, 159, "a"]]], "predicted_relations": [[], [[25, 26, 21, 21, "USED-FOR"], [27, 27, 29, 31, "USED-FOR"], [29, 31, 21, 21, "USED-FOR"], [32, 32, 29, 31, "USED-FOR"], [34, 35, 21, 21, "USED-FOR"], [36, 36, 34, 35, "USED-FOR"], [36, 36, 38, 40, "USED-FOR"], [38, 40, 21, 21, "USED-FOR"], [51, 53, 21, 21, "USED-FOR"], [63, 63, 51, 53, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2211.14133-469e85f7-e998-4680-bbe2-a0a705229fc4", "sentences": [["Setting", "the", "micro-batch", "size", "to", "32", "-LRB-", "maximum", "number", "of", "powers", "of", "2", "that", "can", "be", "placed", "on", "a", "P100", "GPU", "-RRB-", "would", "require", "256", "GPUs", "to", "run", "training", "with", "mini-batch", "size", "8,192", "."], ["However", ",", "to", "reduce", "total", "GPU", "hours", "and", "energy", "and", "CO\\", "-LRB-", "_2\\", "-RRB-", "overheads", ",", "we", "simulate", "this", "training", "by", "using", "32", "GPUs", "and", "accumulating", "the", "micro-batch", "gradient", "over", "8", "steps", "before", "updating", "parameters", "-LRB-", "\\", "-LRB-", "32\\times", "32\\times", "8", "=8,192\\", "-RRB-", "."], ["-RRB-", "NVLAMB", "on", "32", "GPUs", "takes", "3.74", "seconds", "per", "parameter", "update", "-LRB-", "with", "a", "mini-batch", "of", "size", "8,192", "-RRB-", "while", "128", "GPUs", "takes", "1.23", "seconds", "."], ["Hence", "the", "speedup", "-LRB-", "3.04x", "-RRB-", "is", "not", "linear", "to", "the", "number", "of", "GPUs", "."]], "ner": [[[2, 3, "a"], [2, 3, "p"], [5, 5, "v"]], [[56, 56, "v"], [72, 72, "v"], [73, 73, "v"]], [[79, 79, "a"], [81, 81, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 3, "p"], [5, 5, "v"], [12, 12, "v"], [19, 19, "v"], [24, 24, "v"], [32, 32, "v"]], [[56, 56, "v"], [61, 62, "a"], [64, 64, "v"], [74, 75, "v"]], [[79, 79, "a"], [81, 81, "v"], [84, 84, "v"], [95, 95, "v"], [98, 98, "v"], [101, 101, "v"]], [[108, 108, "v"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2211.14133-d052de7e-a562-48a6-beeb-fc5f61d4df05", "sentences": [["In", "addition", "to", "this", ",", "the", "training", "is", "done", "using", "simple", "data", "parallelism", "without", "pipelines", "for", "reducing", "GPU", "hours", "."], ["This", "is", "because", "the", "entire", "BERT-Base", "model", "fits", "into", "the", "P100", "GPU", "device", "memory", "-LRB-", "16", "GB", "-RRB-", ",", "and", "in", "this", "case", "data", "parallelism", "without", "any", "model", "partitioning", "saves", "the", "most", "GPU", "hours", "on", "32", "GPUs", "in", "the", "GPU", "cluster", "we", "use", "-LRB-", "although", "it", "increases", "the", "communication", "cost", "of", "the", "allreduce", "of", "gradients", "for", "data", "parallelism", ".", "-RRB-"], ["While", "the", "target", "of", "model", "partitioning", "is", "a", "model", "that", "is", "too", "large", "to", "fit", "in", "the", "memory", "of", "a", "single", "device", ",", "our", "study", "simulates", "the", "effects", "of", "pipelining", "with", "relatively", "small", "Transformers", "-LRB-", "i.e", "."], ["BERT-Base", "and", "-Large", "-RRB-", "compared", "to", "today", "'s", "GPU", "memory", "limitations", "."], ["Yet", ",", "the", "same", "techniques", ",", "discussions", ",", "and", "benefits", "of", "pipelining", "-LRB-", "and", "PipeFisher", "-RRB-", "described", "in", "our", "study", "are", "applicable", "to", "even", "larger", "Transformers", "."]], "ner": [[[11, 12, "a"]], [[43, 44, "a"], [76, 77, "a"], [25, 26, "a"], [72, 74, "a"], [47, 48, "a"]], [[84, 85, "a"]], [], [[143, 143, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[], [[25, 25, "a"], [30, 30, "v"], [35, 35, "v"], [55, 55, "v"]], [], [[117, 117, "a"]], []], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2211.14133-26fd6d51-b2ba-4531-992e-14fedb162850", "sentences": [["The", "choice", "of", "the", "parallel", "training", "strategy", "does", "not", "affect", "the", "convergence", "of", "NVLAMB", "as", "long", "as", "the", "micro-batch", "gradients", "are", "synchronizedWe", "use", "the", "fp32", "precision", "for", "every", "quantity", "-LRB-", "parameters", ",", "gradients", ",", "optimization", "state", "-RRB-", "in", "training", ",", "so", "we", "assume", "that", "the", "effect", "of", "the", "numerical", "precision", "is", "negligible.", ",", "which", "is", "the", "case", "in", "all", "of", "our", "experiments", "."], ["For", "K-FAC", ",", "we", "use", "data-", "and", "matpltpurpleinversion-parallel", "K-FAC", "-LRB-", "Figure", "2", "-LRB-", "ii", ",", "b", "-RRB-", "-RRB-", ",", "and", "the", "matpltgreencurvature", "and", "matpltpurpleinverse", "matrices", "are", "refreshed", "once", "in", "10", "steps", "."], ["We", "assume", "this", "does", "not", "affect", "the", "convergence", "by", "PipeFisher", "because", "it", "refreshes", "the", "matrices", "more", "frequently", "-LRB-", "once", "in", "5-10", "steps", "-RRB-", "in", "this", "BERT-Base", "setup", "as", "described", "in", "Figure", "5", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[13, 13, "a"], [25, 25, "p"], [49, 49, "p"], [24, 24, "v"]], [[64, 64, "a"], [71, 71, "a"], [90, 93, "v"]], [[104, 104, "a"], [113, 116, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[13, 13, "a"], [24, 24, "v"]], [[64, 64, "a"], [71, 71, "a"], [92, 92, "v"]], [[104, 104, "a"], [115, 115, "v"], [120, 120, "a"]], []], "predicted_relations": [[[25, 25, 13, 13, "USED-FOR"], [49, 49, 13, 13, "USED-FOR"], [24, 24, 25, 25, "USED-FOR"]], [], [], []]}
{"doc_key": "2208.06061-cbc5cd91-0c97-4ea4-872f-7b7e2b72dc23", "sentences": [["Both", "the", "standard", "Transformer", "and", "the", "TP-Transformer", "-LRB-", "TPT", "-RRB-", "use", "6", "layers", "and", "8", "heads", "per", "layer", "."], ["TPT", "has", "key/value/query/role", "dimensions", "of", "64", ",", "whereas", "the", "standard", "Transformer", "has", "key/value/query", "dimensions", "of", "80", "."], ["The", "reason", "for", "this", "increase", "is", "so", "that", "the", "resulting", "models", "match", "in", "terms", "of", "parameter", "count", ",", "and", "we", "add", "parameters", "are", "the", "most", "homologous", "area", "."], ["The", "standard", "Transformer", "has", "74,375,936", "parameters", ",", "and", "the", "TP-Transformer", "has", "74,385,152", "parameters", "."], ["Both", "networks", "use", "a", "token", "dimension", "of", "512", ",", "a", "feedforward", "dimension", "of", "2048", ",", "and", "32", "relative", "positioning", "buckets", "-LSB-", "35", "-RSB-", "."], ["The", "input", "vocabulary", "size", "is", "50,000", "."], ["We", "set", "a", "training", "batch", "size", "of", "80", "per", "GPU", "and", "used", "the", "Adafactor", "-LSB-", "36", "-RSB-", "optimizer", "with", "square", "root", "learning", "rate", "decay", "."], ["Throughout", "the", "model", ",", "we", "used", "a", "commonly", "used", "dropout", "rate", "of", ".1", "."]], "ner": [[[3, 3, "a"], [6, 6, "a"], [6, 6, "a"]], [[29, 29, "a"], [21, 22, "p"], [24, 24, "v"], [34, 34, "v"], [34, 34, "v"], [21, 22, "p"], [24, 24, "v"], [34, 34, "v"]], [], [[66, 66, "a"], [73, 73, "a"], [73, 73, "a"]], [[82, 83, "p"], [85, 85, "v"], [88, 89, "p"], [91, 91, "v"], [95, 97, "p"], [94, 94, "v"], [82, 83, "p"], [85, 85, "v"], [88, 89, "p"], [91, 91, "v"], [95, 97, "p"], [94, 94, "v"]], [[103, 105, "p"], [107, 107, "v"], [103, 105, "p"], [107, 107, "v"]], [[116, 116, "v"], [112, 114, "p"], [116, 116, "v"], [117, 118, "c"], [126, 126, "p"], [122, 122, "v"], [128, 132, "p"], [112, 114, "p"], [116, 116, "v"], [117, 118, "c"], [126, 126, "p"], [122, 122, "v"], [128, 132, "p"]], [[143, 144, "p"], [143, 144, "p"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[6, 9, "a"], [11, 11, "v"], [14, 14, "v"]], [[24, 24, "v"], [34, 34, "v"]], [], [[68, 68, "v"], [75, 75, "v"]], [[85, 85, "v"], [88, 89, "p"], [91, 91, "v"], [94, 94, "v"]], [[107, 107, "v"]], [[112, 114, "p"], [116, 116, "v"], [122, 122, "a"]], [[143, 144, "p"], [146, 146, "v"]]], "predicted_relations": [[], [[24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"], [24, 24, 21, 22, "USED-FOR"]], [], [], [[85, 85, 88, 89, "USED-FOR"], [85, 85, 88, 89, "USED-FOR"], [91, 91, 88, 89, "USED-FOR"], [91, 91, 88, 89, "USED-FOR"], [94, 94, 88, 89, "USED-FOR"], [94, 94, 88, 89, "USED-FOR"], [85, 85, 88, 89, "USED-FOR"], [85, 85, 88, 89, "USED-FOR"], [91, 91, 88, 89, "USED-FOR"], [91, 91, 88, 89, "USED-FOR"], [94, 94, 88, 89, "USED-FOR"], [94, 94, 88, 89, "USED-FOR"]], [], [[116, 116, 112, 114, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 122, 122, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 122, 122, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [116, 116, 112, 114, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 122, 122, "USED-FOR"], [117, 118, 116, 116, "USED-FOR"], [117, 118, 122, 122, "USED-FOR"]], []]}
{"doc_key": "2205.09470-8a435539-2f76-4ac2-b247-fe1ce4e7ad7b", "sentences": [["The", "prevailing", "Transformer-encoder", "was", "adopted", "as", "the", "backbone", "of", "the", "model", "in", "Scenario-I", "."], ["For", "the", "generators", ",", "a", "structure", "with", "12", "layers", ",", "768", "hidden", "units", ",", "12", "heads", "was", "employed", "."], ["For", "the", "discriminator", ",", "a", "structure", "with", "24", "layers", ",", "1,024", "hidden", "units", ",", "16", "heads", "was", "put", "to", "use", "."], ["The", "activation", "function", "used", "is", "GeLU", "-LSB-", "48", "-RSB-", "."], ["In", "order", "to", "maximize", "the", "utility", "of", "existed", "models", ",", "we", "initialized", "the", "parameters", "of", "the", "generators", "with", "\\", "-LRB-", "\\textsc", "-LCB-", "ERNIE-M", "-RCB-", "_", "-LCB-", "Base", "-RCB-", "\\", "-RRB-", ",", "and", "the", "discriminator", "with", "\\", "-LRB-", "\\textsc", "-LCB-", "ERNIE-M", "-RCB-", "_", "-LCB-", "Large", "-RCB-", "\\", "-RRB-", ",", "respectively", "."], ["We", "used", "the", "Adam", "optimizer", "-LSB-", "49", "-RSB-", "to", "train", "ERNIE-M", "Extra", ";", "the", "learning", "rate", "was", "scheduled", "with", "a", "linear", "decay", "with", "10K", "warm-up", "steps", ",", "and", "the", "peak", "learning", "rate", "was", "\\", "-LRB-", "1e-4\\", "-RRB-", "."], ["The", "hyperparameter", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "and", "\\", "-LRB-", "\\gamma", "\\", "-RRB-", "were", "set", "to", "50", "and", "1", "respectively", "."], ["The", "training", "was", "separated", "into", "two", "steps", ",", "i.e", "."], ["intra-cluster", "and", "inter-cluster", "."], ["During", "intra-cluster", "training", ",", "we", "conducted", "the", "pre-training", "experiments", "using", "64", "NVIDIA", "A100-40GB", "GPUs", "with", "2,048", "batch", "size", "and", "512", "max", "length", "."], ["During", "inter-cluster", "training", ",", "we", "used", "8", "NVIDIA", "V100-32GB", "GPUs", "and", "64", "Ascend", "910-32GB", "NPUs", "and", "keep", "other", "hyperparameters", "the", "same", "."]], "ner": [[[2, 2, "a"]], [], [[43, 43, "v"]], [[59, 59, "a"]], [], [[117, 118, "a"]], [[170, 170, "v"]], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[21, 21, "v"], [22, 22, "p"], [24, 24, "v"], [25, 26, "p"], [28, 28, "v"]], [[40, 40, "v"], [41, 41, "p"], [43, 43, "v"], [44, 45, "p"], [47, 47, "v"]], [[59, 59, "a"]], [], [[117, 117, "a"], [124, 124, "a"], [128, 129, "p"], [134, 135, "a"], [137, 137, "v"], [138, 138, "p"], [144, 145, "p"], [149, 149, "v"]], [[156, 156, "p"], [162, 162, "p"], [168, 168, "v"], [170, 170, "v"]], [[178, 178, "v"]], [], [[197, 197, "v"], [202, 202, "v"], [203, 204, "p"], [206, 206, "v"], [207, 208, "p"]], [[216, 216, "v"], [221, 221, "v"], [223, 223, "v"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2205.09443-eea133de-1b6c-422b-9241-41ed0d5b9269", "sentences": [["The", "hyper", "parameter", "settings", "differ", "a", "lot", "in", "previous", "works", "for", "skeleton-based", "action", "recognition", "using", "GCN", "."], ["In", "PYSKL", ",", "we", "use", "the", "same", "hyper", "parameter", "setting", "to", "train", "all", "GCN", "models", "."], ["We", "set", "the", "initial", "learning", "rate", "to", "0.1", ",", "batch", "size", "to", "128", ",", "and", "train", "each", "model", "for", "80", "epochs", "with", "the", "CosineAnnealing", "LR", "scheduler", "."], ["For", "the", "optimizer", ",", "we", "set", "the", "momentum", "to", "0.9", ",", "weight", "decay", "to", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", ",", "and", "use", "the", "Nesterov", "momentum", "."], ["We", "find", "that", "for", "most", "GCN", "networks", ",", "the", "new", "hyper", "parameter", "setting", "leads", "to", "better", "recognition", "performance", "than", "previous", "settings", "that", "use", "the", "MultiStep", "LR", "scheduler", "."]], "ner": [[], [[30, 31, "a"]], [[36, 38, "p"], [40, 40, "v"], [42, 43, "p"], [45, 45, "v"], [53, 53, "p"], [52, 52, "v"], [57, 58, "p"], [56, 56, "v"]], [[67, 67, "p"], [88, 88, "p"], [69, 69, "v"], [71, 72, "p"], [67, 67, "p"], [88, 88, "p"], [87, 87, "v"]], [[115, 116, "p"], [114, 116, "a"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[15, 15, "a"]], [[18, 18, "a"], [30, 30, "a"]], [[37, 38, "p"], [40, 40, "v"], [42, 43, "p"], [45, 45, "v"], [52, 52, "v"], [53, 53, "p"], [56, 57, "a"]], [[67, 67, "p"], [69, 69, "v"], [71, 72, "p"], [77, 80, "v"], [87, 88, "a"]], []], "predicted_relations": [[], [], [[45, 45, 53, 53, "USED-FOR"], [52, 52, 53, 53, "USED-FOR"], [56, 56, 57, 58, "USED-FOR"]], [], [[115, 116, 114, 116, "USED-FOR"]]]}
{"doc_key": "2212.00942-6529f34b-53c5-4b82-b8dc-1dd085fb38b7", "sentences": [["All", "the", "models", "are", "implemented", "based", "on", "PyTorch", "and", "trained", "using", "NVIDIA", "RTX", "3090", "."], ["The", "batch", "size", "is", "64", "."], ["Adam", "optimizer", "is", "used", "with", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=0.9", ",", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=0.999", "and", "\\", "-LRB-", "\\epsilon", "\\", "-RRB-", "=1e-8", "."], ["We", "use", "cross-entropy", "loss", "as", "the", "loss", "function", "."]], "ner": [[], [], [[21, 22, "a"], [31, 31, "v"], [38, 38, "v"], [45, 45, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[16, 17, "p"], [19, 19, "v"]], [[21, 21, "a"]], [[49, 50, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2201.09199-81fcd5af-f1e3-40ed-a4b5-b54e2d61d482", "sentences": [["We", "evaluate", "MLAS", "under", "different", "pre-training", "parameters", "in", "this", "set", "of", "experiments", "."], ["ATT", "and", "SEQ", "are", "not", "included", "in", "this", "set", "of", "experiments", "since", "they", "only", "utilize", "one", "data", "type", "."], ["Output", "dimension", "is", "set", "to", "5", "."], ["Minimum", "cluster", "size", "is", "set", "at", "50", "."], ["Figure", "REF", "presents", "the", "results", "under", "different", "pre-training", "parameters", "."], ["This", "confirms", "that", "our", "proposed", "MLAS", "method", "is", "not", "sensitive", "to", "different", "pre-training", "parameters", "."]], "ner": [[[2, 2, "a"], [5, 6, "p"]], [], [[32, 33, "v"], [35, 37, "c"]], [[39, 41, "v"], [43, 45, "c"]], [[54, 55, "p"]], [[62, 62, "a"], [69, 70, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[13, 13, "a"], [15, 15, "a"], [28, 28, "v"]], [[37, 37, "v"]], [[45, 45, "v"]], [], [[62, 63, "a"]]], "predicted_relations": [[[5, 6, 2, 2, "USED-FOR"]], [], [[35, 37, 32, 33, "USED-FOR"]], [[43, 45, 39, 41, "USED-FOR"]], [], [[69, 70, 62, 62, "USED-FOR"]]]}
{"doc_key": "2208.01448-043e5ad3-c30b-44ed-9be8-29326e46fe89", "sentences": [["We", "trained", "AlexaTM", "20B", "for", "120", "days", "on", "128", "A100", "GPUs", "for", "the", "total", "of", "500k", "updates", "with", "the", "accumulated", "batch", "size", "of", "2", "million", "tokens", "-LRB-", "total", "of", "1", "trillion", "token", "updates", "-RRB-", "."], ["We", "used", "Adam", "optimizer", "-LSB-", "35", "-RSB-", "with", "\\", "-LRB-", "lr=1e^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "with", "linear", "decay", "to", "\\", "-LRB-", "lr=5e^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", "over", "500k", "updates", "."], ["We", "used", "weight", "decay", "of", "\\", "-LRB-", "0.1\\", "-RRB-", "on", "all", "parameters", "except", "biases", "and", "layernorms", "."], ["Finally", ",", "we", "trained", "the", "model", "in", "BFloat16", "which", "helped", "with", "the", "stability", "of", "training", "-LSB-", "59", "-RSB-", "."]], "ner": [[[2, 3, "a"]], [[37, 38, "a"]], [[69, 70, "p"], [74, 74, "v"], [69, 70, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[2, 3, "a"], [5, 5, "v"], [8, 8, "v"], [15, 15, "v"], [20, 21, "p"], [23, 23, "v"], [29, 29, "v"]], [[37, 37, "a"], [52, 53, "a"], [64, 64, "v"]], [[69, 70, "a"], [74, 74, "v"]], [[91, 91, "a"]]], "predicted_relations": [[], [], [[74, 74, 69, 70, "USED-FOR"]], []]}
{"doc_key": "2208.01448-24420b9e-71c0-4709-997d-ffd837ae28d1", "sentences": [["We", "used", "DeepSpeed", "'s", "ZeRO", "Stage", "3", "-LSB-", "61", "-RSB-", "to", "partition", "model", "weights", ",", "optimizer", "states", ",", "and", "gradients", "across", "all", "GPU", "workers", ",", "allowing", "us", "to", "train", "the", "model", "with", "high", "throughput", "."], ["We", "relied", "on", "an", "internal", "and", "optimized", "version", "of", "DeepSpeed", "that", "we", "have", "since", "open-sourced", "-LSB-", "6", "-RSB-", "to", "obtain", "training", "throughput", "of", "up", "to", "154", "TFLOPS/GPU", "on", "16", "AWS", "p4d.24xlarge", "compute", "instances", "."]], "ner": [[[2, 6, "a"], [2, 2, "a"]], [[44, 44, "a"]]], "relations": [[], []], "predicted_ner": [[[2, 2, "a"], [4, 4, "v"]], [[44, 44, "a"], [60, 60, "v"], [63, 63, "v"]]], "predicted_relations": [[], []]}
{"doc_key": "2203.08243-1d170cb3-1f8a-4cc5-a3bb-008eeb5382e6", "sentences": [["Numerically", ",", "the", "learning", "rate", "for", "parameter", "\\", "-LRB-", "z\\", "-RRB-", "is", "always", "changing", "during", "the", "primal-dual", "algorithm", "process", "."], ["Thurs", ",", "we", "propose", "to", "use", "a", "dynamic", "learning", "rate", "for", "the", "parameter", "\\", "-LRB-", "z\\", "-RRB-", "that", "controls", "the", "budget", "constraint", "."], ["We", "use", "a", "four-step", "schedule", "of", "\\", "-LRB-", "\\lbrace", "1,5,9,13,17\\rbrace", "\\", "-RRB-", "in", "practice", "."]], "ner": [[], [[27, 29, "a"]], [[52, 52, "v"], [52, 52, "v"], [52, 52, "v"], [52, 52, "v"], [52, 52, "v"]]], "relations": [[], [], []], "predicted_ner": [[[3, 4, "p"]], [], []], "predicted_relations": [[], [], []]}
{"doc_key": "2209.00642-b8d15081-ed6d-472f-99b4-24b578fb9016", "sentences": [["In", "our", "experiments", "we", "set", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "r", "-RCB-", "=10\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "k_", "-LCB-", "global", "-RCB-", "-RCB-", "=5\\", "-RRB-", ",", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "k_", "-LCB-", "local", "-RCB-", "-RCB-", "=5\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_", "-LCB-", "voice", "-RCB-", "=5\\", "-RRB-", "."], ["We", "follow", "the", "pre-processing", "procedures", "of", "Lip2Wav", "-LSB-", "35", "-RSB-", "to", "detect", "and", "extract", "face", "crops", "from", "training", "videos", "."], ["We", "create", "video", "inputs", "by", "randomly", "sampling", "a", "window", "of", "\\", "-LRB-", "T=25\\", "-RRB-", "-LRB-", "1", "sec", ".", "-RRB-"], ["contiguous", "face", "crops", "resized", "to", "\\", "-LRB-", "96\\times", "96\\", "-RRB-", "."], ["The", "corresponding", "audio", "segment", "is", "sampled", "at", "16kHz", "."], ["We", "compute", "STFT", "with", "a", "hop", "length", "of", "\\", "-LRB-", "10ms\\", "-RRB-", "and", "a", "window", "length", "of", "\\", "-LRB-", "25ms\\", "-RRB-", "."], ["We", "finally", "obtain", "melspectrograms", "with", "80", "mel-bands", "and", "\\", "-LRB-", "T^", "-LCB-", "\\prime", "-RCB-", "=100\\", "-RRB-", "mel", "time-steps", "-LRB-", "1", "sec", ".", "-RRB-", "."], ["We", "use", "a", "batch", "size", "of", "32", "and", "RMSProp", "-LSB-", "39", "-RSB-", "optimizer", "with", "an", "initial", "learning", "rate", "of", "\\", "-LRB-", "0.00005\\", "-RRB-", "for", "both", "the", "generator", "and", "the", "discriminator", ",", "which", "is", "advised", "for", "training", "a", "WGAN", "model", "-LSB-", "21", "-RSB-", "."], ["The", "generator", "is", "trained", "every", "five", "discriminator", "iterations", "following", "-LSB-", "21", "-RSB-", "."], ["As", "this", "is", "a", "WGAN", ",", "the", "discriminator", "loss", "shows", "the", "progress", "of", "training", "and", "correlates", "with", "the", "quality", "of", "the", "generated", "samples", "."], ["Hence", ",", "we", "stop", "the", "training", "once", "the", "discriminator", "loss", "does", "not", "improve", "for", "10", "epochs", "."], ["During", "inference", ",", "we", "feed", "the", "speaker", "embedding", "and", "the", "lip", "distribution", "to", "the", "decoder", "instead", "of", "the", "content", "distribution", "."], ["Since", "our", "model", "can", "take", "a", "variable", "number", "of", "time", "steps", "as", "input", ",", "it", "can", "directly", "generate", "for", "any", "length", "of", "video", "without", "any", "further", "changes", "."]], "ner": [[], [[57, 57, "a"]], [], [], [], [[112, 112, "a"]], [[138, 138, "p"], [146, 146, "v"], [148, 149, "p"], [135, 135, "a"]], [[164, 164, "a"], [193, 193, "a"]], [], [[216, 216, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[7, 11, "p"], [12, 12, "v"], [17, 24, "p"], [25, 25, "v"], [30, 37, "p"], [38, 38, "v"], [43, 47, "p"]], [[57, 57, "a"]], [[83, 83, "v"], [86, 86, "v"]], [[98, 98, "v"]], [[108, 108, "v"]], [[112, 112, "a"], [129, 129, "v"]], [[135, 135, "a"], [137, 137, "v"], [151, 151, "v"]], [[159, 160, "p"], [162, 162, "v"], [164, 164, "a"], [172, 173, "p"], [177, 177, "v"], [193, 194, "a"]], [[204, 204, "v"]], [[216, 216, "a"]], [[244, 245, "a"], [250, 250, "v"], [251, 251, "p"]], [], [[276, 276, "a"]]], "predicted_relations": [[], [], [], [], [], [], [[138, 138, 135, 135, "USED-FOR"], [146, 146, 138, 138, "USED-FOR"], [146, 146, 148, 149, "USED-FOR"], [148, 149, 135, 135, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2211.00310-b8e78f61-7ef4-4bc6-a754-d63d3eb3054f", "sentences": [["We", "evaluate", "SADT", "by", "classification", "tasks", "using", "CIFAR10", "and", "CIFAR100", "datasets", "."], ["The", "neural", "architectures", "used", "are", "Simple", "CNN", "-LRB-", "custom", "model", "of", "3", "conv", "and", "3", "dense", "layers", "-RRB-", ",", "VGG", "-LSB-", "32", "-RSB-", ",", "and", "InceptionResNet", "-LSB-", "33", "-RSB-", "."], ["The", "SADT", "variants", "are", "compared", "against", "related", "works", "in", "model", "generalization", ":", "Gradient", "Centralization", "-LRB-", "GC", "-RRB-", "-LSB-", "8", "-RSB-", ",", "Adaptive", "Gradient", "Clipping", "-LRB-", "AGC", "-RRB-", "-LSB-", "9", "-RSB-", ",", "and", "Sharpness-Aware", "Minimization", "-LRB-", "SAM", "-RRB-", "-LSB-", "0", "-RSB-", "."], ["In", "particular", ",", "self-distillation", "methods", "were", "not", "included", "to", "the", "comparison", ",", "as", "they", "require", "multiple", "training", "rounds", ",", "which", "makes", "them", "incompatible", "with", "our", "single-round", "experimental", "setting", "."], ["In", "order", "to", "make", "the", "training", "landscape", "uniform", "for", "all", "methods", "considered", ",", "the", "training", "always", "starts", "from", "the", "same", "initial", "point", ",", "and", "all", "methods", "use", "the", "same", "optimizer", "-LRB-", "Adam", "-RRB-", ",", "learning", "rate", "scheduler", "-LRB-", "cosine-decay", "with", "initial", "rate", "of", "0.0001", "-RRB-", ",", "batch", "size", "BS", "-LRB-", "512", "and", "2048", "-RRB-", ",", "epoch", "count", "-LRB-", "200", "for", "BS", "512", "and", "370", "for", "BS", "2048", "-RRB-", ",", "and", "data", "augmentation", "scheme", "-LRB-", "CutMix", "-LSB-", "10", "-RSB-", "-RRB-", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[7, 7, "a"], [9, 9, "a"]], [[17, 18, "a"], [31, 31, "a"], [37, 37, "a"]], [[54, 55, "a"], [63, 65, "a"], [74, 75, "a"]], [], [[143, 143, "a"], [150, 150, "a"], [152, 153, "p"], [155, 155, "v"], [186, 186, "a"]], []], "relations": [[], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 7, "a"], [9, 9, "a"]], [[18, 18, "a"], [23, 23, "v"], [24, 24, "p"], [26, 26, "v"], [31, 31, "a"], [37, 37, "a"]], [[54, 58, "a"], [63, 68, "a"], [74, 78, "a"]], [], [[150, 150, "a"], [152, 153, "p"], [155, 155, "v"], [158, 159, "p"], [162, 162, "v"], [164, 164, "v"], [167, 168, "p"], [170, 170, "v"], [173, 173, "v"], [175, 175, "v"], [178, 178, "v"], [186, 186, "a"]], []], "predicted_relations": [[], [], [], [], [[152, 153, 143, 143, "USED-FOR"], [152, 153, 150, 150, "USED-FOR"]], []]}
{"doc_key": "2212.05289-93a52f13-de36-4cac-b5a5-5542d5c46796", "sentences": [["The", "weights", "of", "the", "TSCNNs", "are", "initialized", "with", "a", "Gaussian", "distribution", "\\", "-LRB-", "\\sim", "N", "-LRB-", "0", ",", "0.01", "-RRB-", "\\", "-RRB-", "."], ["The", "network", "is", "trained", "using", "backpropagation", "to", "minimize", "the", "binary", "cross-entropy", "-LRB-", "BCE", "-RRB-", "loss", "function", ":", "\\", "-LRB-", "BCE", "-LRB-", "y", ",", "\\hat", "-LCB-", "y", "-RCB-", "-RRB-", "=", "-", "-LRB-", "y\\log", "-LRB-", "\\hat", "-LCB-", "y", "-RCB-", "-RRB-", "+", "-LRB-", "1-y", "-RRB-", "\\log", "-LRB-", "1-\\hat", "-LCB-", "y", "-RCB-", "-RRB-", "-RRB-", ",", "\\", "-RRB-"]], "ner": [[[9, 10, "a"], [16, 16, "v"], [18, 18, "v"], [18, 18, "v"]], [[28, 28, "a"], [32, 33, "a"]]], "relations": [[], []], "predicted_ner": [[[4, 4, "a"], [18, 18, "v"]], [[28, 28, "a"], [32, 36, "a"]]], "predicted_relations": [[], []]}
{"doc_key": "2212.05289-b80a13a4-d9ab-466e-87b6-5a78e4d1b6da", "sentences": [["where", "\\", "-LRB-", "y\\", "-RRB-", "denotes", "the", "true", "label", "and", "\\", "-LRB-", "\\hat", "-LCB-", "y", "-RCB-", "\\", "-RRB-", "denotes", "the", "predicted", "label", "."], ["All", "models", "are", "trained", "using", "the", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "0.00025", "-LSB-", "26", "-RSB-", "."], ["The", "dropout", "rate", "and", "the", "batch", "size", "are", "set", "to", "50", "%", "and", "64", ",", "respectively", "."], ["All", "the", "experiments", "are", "conducted", "on", "a", "laptop", "with", "AMD-Ryzen", "7-5800H", "3.20-GHz", "and", "16-GB", "memory", "."]], "ner": [[], [[29, 30, "a"], [33, 34, "p"], [36, 36, "v"]], [[42, 43, "p"], [46, 47, "p"], [54, 54, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[29, 29, "a"], [33, 34, "p"], [36, 36, "v"]], [[42, 43, "p"], [46, 47, "p"], [51, 52, "v"], [54, 54, "v"]], [[69, 69, "v"], [71, 71, "v"]]], "predicted_relations": [[], [[33, 34, 29, 30, "USED-FOR"], [36, 36, 33, 34, "USED-FOR"]], [], []]}
{"doc_key": "2207.06893-3c1e5967-e659-4e26-aba5-63d5b7df6789", "sentences": [["All", "experiments", "are", "implemented", "and", "conducted", "using", "the", "PyTorch", "framework", ",", "on", "a", "server", "platform", "with", "4", "V100", "GPUs", "."], ["All", "models", "are", "trained", "for", "300", "epochs", "from", "scratch", "with", "binary", "weights", "and", "activation", "."], ["The", "initial", "learning", "rate", "is", "set", "to", "2e-4", "and", "halved", "every", "200", "epochs", "."], ["The", "mini-batch", "size", "is", "set", "to", "16", "and", "the", "ADAM", "-LSB-", "8", "-RSB-", "optimizer", "is", "adapted", "."]], "ner": [[[8, 8, "a"], [17, 18, "a"]], [[30, 33, "a"], [25, 26, "p"], [25, 25, "v"], [26, 26, "c"], [25, 26, "a"]], [[36, 38, "a"], [44, 47, "a"], [47, 47, "c"]], [[50, 51, "a"], [58, 58, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[8, 9, "a"], [16, 16, "v"], [17, 17, "v"]], [[25, 25, "v"], [26, 26, "p"]], [[37, 38, "p"], [42, 42, "v"], [46, 46, "v"], [47, 47, "p"]], [[50, 51, "p"], [55, 55, "v"], [58, 58, "a"]]], "predicted_relations": [[], [[25, 26, 25, 26, "USED-FOR"], [25, 25, 25, 26, "USED-FOR"]], [], []]}
{"doc_key": "2207.08457-659159c2-ebb6-4a1c-9bc1-f5528450da4c", "sentences": [["The", "policy", "network", "for", "the", "experiment", "in", "Section", "has", "a", "fully", "connected", "layer", "of", "size", "30", ",", "followed", "by", "an", "LSTM", "layer", "of", "size", "30", "."], ["The", "actor-network", "has", "one", "fully", "connected", "layer", "of", "size", "30", ",", "the", "critic-network", "one", "fully", "connected", "layer", "of", "size", "10", "."], ["The", "length", "of", "each", "episode", "was", "set", "to", "10", "and", "the", "model", "trained", "for", "5", "million", "training", "steps", "."], ["For", "all", "other", "parameters", ",", "the", "default", "values", "were", "used", "."]], "ner": [[[1, 2, "a"], [15, 15, "v"], [24, 24, "v"], [15, 15, "v"], [24, 24, "v"], [15, 15, "v"], [24, 24, "v"]], [[35, 35, "v"], [35, 35, "v"], [27, 27, "a"], [35, 35, "v"], [38, 38, "a"], [45, 45, "v"]], [[55, 55, "v"], [63, 64, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[[1, 2, "a"], [15, 15, "v"], [20, 20, "a"], [24, 24, "v"]], [[27, 27, "a"], [29, 29, "v"], [35, 35, "v"], [38, 38, "a"], [45, 45, "v"]], [[55, 55, "v"], [61, 61, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2207.08457-fd282dee-7397-45b2-b819-f13c98383b50", "sentences": [["The", "following", "configuration", "for", "the", "policy", "network", "worked", "best", "after", "preliminary", "experiments", "for", "the", "3-variable", "-LRB-", "4-variable", "-RRB-", "environments", ":", "One", "-LRB-", "two", "-RRB-", "fully", "connected", "layer", "-LRB-", "s", "-RRB-", "of", "size", "30", "-LRB-", "40", "-RRB-", "followed", "by", "an", "LSTM", "layer", "of", "size", "30", "-LRB-", "160", "-RRB-", "."], ["Its", "outputs", "are", "fed", "into", "a", "fully", "connected", "layer", "of", "size", "30", "-LRB-", "60", "-RRB-", "for", "the", "actor-network", "and", "one", "of", "size", "10", "-LRB-", "20", "-RRB-", "for", "the", "critic-network", "."], ["For", "this", "experiment", ",", "we", "set", "the", "episode", "length", "to", "20", "."], ["The", "network", "was", "evaluated", "every", "500000", "steps", "in", "both", "cases", "."], ["All", "runs", "were", "stopped", "after", "14", "evaluations", "of", "the", "policy", "on", "the", "test", "setwere", "worse", "than", "the", "best", "policy", "found", "so", "far", "to", "avoid", "overfitting", "."], ["In", "the", "3-variable", "set", ",", "we", "use", "the", "first", "18", "environments", "for", "training", "and", "the", "last", "5", "for", "testing", "."], ["In", "the", "4-variable", "set", ",", "we", "use", "the", "first", "500", "environments", "for", "training", "and", "the", "last", "42", "for", "testing", "."], ["The", "best", "model", "for", "the", "3-variable", "-LRB-", "4-variable", "-RRB-", "environments", "is", "obtained", "after", "14.5", "-LRB-", "31", "-RRB-", "million", "training", "steps", "."]], "ner": [[[5, 6, "a"], [32, 32, "v"], [43, 43, "v"], [34, 34, "v"], [32, 32, "v"], [43, 43, "v"], [45, 45, "v"], [32, 32, "v"], [43, 43, "v"]], [[59, 59, "v"], [59, 59, "v"], [59, 59, "v"], [61, 61, "v"], [70, 70, "v"], [72, 72, "v"], [72, 72, "v"]], [[88, 88, "v"], [85, 86, "p"], [88, 88, "v"]], [[95, 95, "v"]], [], [[136, 136, "v"], [129, 130, "c"], [143, 143, "v"], [129, 130, "c"]], [[156, 156, "v"], [149, 150, "c"], [163, 163, "v"], [149, 150, "c"]], [[180, 180, "v"], [185, 186, "a"], [180, 180, "v"], [182, 182, "v"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[5, 6, "a"], [20, 20, "v"], [22, 22, "v"], [32, 32, "v"], [34, 34, "v"], [39, 39, "a"], [43, 43, "v"], [45, 45, "v"]], [[59, 59, "v"], [61, 61, "v"], [65, 65, "a"], [67, 67, "v"], [70, 70, "v"], [72, 72, "v"], [76, 76, "a"]], [[88, 88, "v"]], [[95, 95, "v"]], [[106, 106, "v"]], [[136, 136, "v"], [143, 143, "v"]], [[156, 156, "v"], [163, 163, "v"]], [[180, 180, "v"], [182, 182, "v"]]], "predicted_relations": [[], [], [[88, 88, 85, 86, "USED-FOR"], [88, 88, 85, 86, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2212.02802-2cd5a603-e8f1-4b9b-b112-a03ae063e1cc", "sentences": [["We", "optimize", "the", "learnable", "parameters", "jointly", "on", "77294", "videos", "of", "VoxCeleb1", "dataset", "-LSB-", "15", "-RSB-", "."], ["The", "videos", "are", "aligned", "and", "cropped", "for", "interesting", "face", "regions", "as", "in", "Tzaban", "-LSB-", "31", "-RSB-", "."], ["We", "use", "4", "GPUs", "and", "Adam", "optimizer", "-LSB-", "12", "-RSB-", "with", "the", "learning", "rate", "of", "1e-4", "."], ["Total", "training", "steps", "are", "1", "million", "and", "4", "frames", "per", "video", "so", "the", "total", "of", "16", "frames", "for", "4", "videos", "are", "taken", "for", "a", "single", "training", "step", "."]], "ner": [[[10, 11, "a"]], [], [[38, 39, "a"], [45, 46, "p"], [48, 48, "v"]], []], "relations": [[], [], [], []], "predicted_ner": [[[7, 7, "v"], [10, 10, "a"]], [[28, 28, "a"]], [[35, 35, "v"], [38, 38, "a"], [45, 46, "p"], [48, 48, "v"]], [[54, 54, "v"], [57, 57, "v"], [65, 65, "v"], [68, 68, "v"]]], "predicted_relations": [[], [], [[45, 46, 38, 39, "USED-FOR"], [48, 48, 45, 46, "USED-FOR"]], []]}
{"doc_key": "2210.10759-d7bbb4e6-4468-4fcb-8a57-20806e74b71d", "sentences": [["We", "use", "Adam", "as", "our", "training", "optimizer", "with", "learning", "rate", "of", "\\", "-LRB-", "0.0001\\", "-RRB-", "."], ["The", "loss", "function", "is", "taken", "as", "mean", "squared", "error", "."], ["All", "the", "experiments", "are", "conducted", "on", "a", "Linux", "server", "with", "an", "Intel", "Xeon", "Platinum", "8163", "GPU", "and", "eight", "NVIDIA", "Tesla", "V100", "GPUs", "."]], "ner": [[[2, 2, "a"], [8, 9, "p"], [13, 13, "v"]], [[22, 24, "a"]], []], "relations": [[], [], []], "predicted_ner": [[[2, 2, "a"], [8, 9, "p"], [13, 13, "v"]], [], [[43, 43, "v"]]], "predicted_relations": [[[8, 9, 2, 2, "USED-FOR"]], [], []]}
{"doc_key": "2210.10692-b8b389e1-fe71-4047-a9d4-53fd55babcd6", "sentences": [["The", "filtering", "models", "were", "trained", "to", "accept", "a", "pair", "of", "sentences", "from", "the", "source", "and", "target", "languages", "."], ["During", "training", ",", "the", "-LSB-", "CLS", "-RSB-", "token", "hidden", "representation", "of", "the", "input", "sentence", "pairs", "is", "fed", "into", "a", "linear", "Layer", "and", "the", "model", "is", "optimized", "using", "binary", "cross", "entropy", "loss", "."], ["However", ",", "at", "inference", "time", ",", "we", "add", "a", "sigmoid", "layer", "to", "the", "output", "to", "predict", "a", "number", "between", "\\", "-LRB-", "0.0\\", "-RRB-", "and", "\\", "-LRB-", "1.0\\", "-RRB-", "indicating", "the", "likelihood", "of", "the", "bitexts", "being", "translations", "of", "each", "other", "."], ["We", "fine-tuned", "these", "models", "using", "each", "language", "'s", "train", "split", "of", "positive", "and", "negative", "samples", ",", "then", "evaluated", "performance", "on", "the", "test", "set", "while", "optimizing", "on", "the", "development", "set", "."]], "ner": [[], [[45, 48, "a"]], [[59, 60, "a"]], []], "relations": [[], [], [], []], "predicted_ner": [[], [[45, 48, "a"]], [[71, 71, "v"], [76, 76, "v"]], []], "predicted_relations": [[], [], [], []]}
{"doc_key": "2210.10692-30e466c2-fa93-4af1-8dc0-d770e66639c9", "sentences": [["We", "fine-tuned", "the", "M2M-100", "model", "based", "on", "the", "implementation", "within", "the", "Fairseqhttps", ":", "//github.com/facebookresearch/fairseq", "toolkit", "-LSB-", "50", "-RSB-", "."], ["We", "used", "batch", "sizes", "of", "\\", "-LRB-", "2,048\\", "-RRB-", "tokens", ",", "a", "maximum", "sentence", "length", "of", "\\", "-LRB-", "1,024\\", "-RRB-", ",", "and", "a", "dropout", "of", "\\", "-LRB-", "0.3\\", "-RRB-", "."], ["For", "optimization", ",", "we", "used", "Adam", "-LSB-", "36", "-RSB-", "with", "\\", "-LRB-", "\\beta", "_1\\", "-RRB-", "=", "\\", "-LRB-", "0.9\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "_2\\", "-RRB-", "=", "\\", "-LRB-", "0.998\\", "-RRB-", ",", "a", "learning", "rate", "of", "\\", "-LRB-", "5e-5\\", "-RRB-", "and", "a", "warmup", "of", "\\", "-LRB-", "2,500\\", "-RRB-", "updates", "."], ["The", "optimizer", "uses", "a", "label-smoothed", "cross-entropy", "loss", "function", "with", "a", "label-smoothing", "value", "of", "\\", "-LRB-", "0.2\\", "-RRB-", "."], ["All", "models", "were", "trained", "for", "a", "maximum", "of", "\\", "-LRB-", "1,000,000\\", "-RRB-", "update", "steps", "."], ["We", "tokenized", "all", "data", "using", "the", "model", "'s", "SentencePiece", "-LSB-", "42", "-RSB-", "tokenizer", "."]], "ner": [[[3, 4, "a"]], [[31, 33, "p"], [42, 42, "p"], [46, 46, "v"]], [[54, 54, "a"], [67, 67, "v"], [78, 78, "v"], [82, 83, "p"], [87, 87, "v"], [91, 91, "p"]], [[103, 106, "a"], [109, 110, "p"], [114, 114, "v"]], [], [[140, 140, "a"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[3, 4, "a"]], [[21, 22, "p"], [26, 26, "v"], [37, 37, "v"], [42, 42, "p"], [46, 46, "v"]], [[54, 54, "a"], [67, 67, "v"], [78, 78, "v"], [82, 83, "p"], [87, 87, "v"], [91, 91, "p"], [95, 95, "v"]], [[104, 104, "a"], [109, 110, "p"], [114, 114, "v"]], [[127, 127, "v"], [129, 130, "p"]], []], "predicted_relations": [[], [], [[78, 78, 82, 83, "USED-FOR"], [78, 78, 91, 91, "USED-FOR"], [82, 83, 54, 54, "USED-FOR"], [87, 87, 82, 83, "USED-FOR"], [87, 87, 91, 91, "USED-FOR"]], [[109, 110, 103, 106, "USED-FOR"], [114, 114, 109, 110, "USED-FOR"]], [], []]}
{"doc_key": "2205.11779-a29c3c50-e1fd-4f8e-9fe9-0c3305d53e6c", "sentences": [["If", "\\", "-LRB-", "\\", "#", "-LRB-", "nbr", "-LRB-", "n", "-RRB-", "-RRB-", "=1\\", "-RRB-", ",", "Eqn", "."], ["REF", "can", "be", "simplified", "into", "the", "following", "formula", "with", "the", "sole", "neighbor", "\\", "-LRB-", "k\\", "-RRB-", ":", "\\", "-LRB-", "\\theta", "^", "-LCB-", "\\prime", "-LRB-", "n", "-RRB-", "-RCB-", "_", "-LCB-", "me", "-RCB-", "=", "\\big", "-LRB-", "1-\\frac", "-LCB-", "\\lambda", "-RCB-", "-LCB-", "2", "-RCB-", "\\big", "-RRB-", "\\theta", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "_", "-LCB-", "me", "-RCB-", "+", "\\frac", "-LCB-", "\\lambda", "-RCB-", "-LCB-", "2", "-RCB-", "\\theta", "^", "-LCB-", "-LRB-", "k", "-RRB-", "-RCB-", ".\\", "-RRB-"]], "ner": [[], []], "relations": [[], []], "predicted_ner": [[], []], "predicted_relations": [[], []]}
{"doc_key": "2205.11779-ef0d46bc-0412-4d7d-95f6-2dd1bf3e256c", "sentences": [["This", "means", "that", "the", "model", "parameters", "\\", "-LRB-", "\\theta", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "_", "-LCB-", "me", "-RCB-", "\\", "-RRB-", "is", "shifted", "toward", "\\", "-LRB-", "\\theta", "^", "-LCB-", "-LRB-", "k", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["If", "\\", "-LRB-", "\\lambda", "=2\\", "-RRB-", ",", "it", "will", "be", "replaced", "with", "\\", "-LRB-", "\\theta", "^", "-LCB-", "-LRB-", "k", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["If", "\\", "-LRB-", "\\lambda", "=1\\", "-RRB-", ",", "it", "is", "shifted", "at", "the", "center", "position", "between", "\\", "-LRB-", "\\theta", "^", "-LCB-", "-LRB-", "n", "-RRB-", "-RCB-", "_", "-LCB-", "me", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "\\theta", "^", "-LCB-", "-LRB-", "k", "-RRB-", "-RCB-", "\\", "-RRB-", "."], ["Practically", ",", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "will", "be", "set", "to", "1", "or", "less", ":", "i.e.", ",", "\\", "-LRB-", "0", "<", "\\lambda", "\\le", "1\\", "-RRB-", "."]], "ner": [[[4, 5, "a"], [8, 8, "p"], [26, 26, "p"]], [[50, 50, "p"], [39, 39, "p"], [40, 40, "v"]], [[77, 77, "p"], [93, 93, "p"], [63, 63, "p"], [64, 64, "v"]], [[107, 107, "p"], [124, 124, "p"], [114, 114, "v"], [126, 126, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[], [], [], [[114, 114, "v"]]], "predicted_relations": [[[8, 8, 4, 5, "USED-FOR"], [26, 26, 4, 5, "USED-FOR"]], [[40, 40, 39, 39, "USED-FOR"]], [[64, 64, 63, 63, "USED-FOR"]], [[126, 126, 124, 124, "USED-FOR"]]]}
{"doc_key": "2202.03954-fbff4f0d-506a-465f-8b82-9497062a47ea", "sentences": [["We", "set", "the", "training", "batch", "size", "to", "128", "."], ["The", "model", "was", "trained", "for", "60", "epochs", "using", "adam", "optimizer", "."], ["The", "initial", "learning", "rate", "is", "0.001", ",", "and", "changed", "to", "0.0001", "after", "30", "epochs", "."], ["To", "avoid", "over-fitting", ",", "the", "L2", "regularization", "is", "activate", "and", "the", "regularization", "parameter", "is", "set", "to", "0.1", "."], ["Meanwhile", ",", "the", "dropout", "probability", "\\", "-LRB-", "p_", "-LCB-", "drop", "-RCB-", "\\", "-RRB-", "is", "set", "to", "0.2", "for", "all", "dropout", "layers", "."], ["The", "hyperparameter", "\\", "-LRB-", "\\mathcal", "-LCB-", "H", "-RCB-", "\\", "-RRB-", "of", "interaction", "catergory", "num", "is", "set", "to", "2,4", "and", "6", ",", "respectively", "."], ["The", "temperature", "hyperparameter", "\\", "-LRB-", "\\tau", "\\", "-RRB-", "is", "set", "to", "be", "0.1", "."], ["The", "weights", "hyperparameter", "\\", "-LRB-", "\\lambda", "_z\\", "-RRB-", "and", "\\", "-LRB-", "\\lambda", "_c\\", "-RRB-", "in", "loss", "functions", "are", "set", "to", "be", "0.005", "."]], "ner": [[], [], [[21, 23, "p"], [25, 25, "v"], [30, 30, "v"], [31, 33, "c"]], [[40, 41, "a"], [46, 47, "p"], [51, 51, "v"], [51, 51, "v"]], [[72, 73, "a"], [56, 57, "p"], [69, 69, "v"], [69, 69, "v"]], [[86, 88, "a"], [76, 76, "p"], [92, 92, "v"], [92, 92, "v"], [94, 94, "v"], [76, 76, "p"], [76, 76, "p"]], [[110, 110, "v"], [100, 100, "p"], [99, 100, "a"], [100, 100, "p"], [110, 110, "v"], [100, 100, "p"]], [[114, 114, "p"], [114, 114, "p"], [113, 114, "a"], [114, 114, "p"], [133, 133, "v"], [126, 128, "c"]]], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[3, 5, "p"], [7, 7, "v"]], [[14, 14, "v"], [15, 15, "p"], [17, 17, "a"]], [[22, 23, "p"], [25, 25, "v"], [30, 30, "v"], [32, 32, "v"], [33, 33, "p"]], [[40, 41, "a"], [46, 47, "p"], [51, 51, "v"]], [[56, 57, "p"], [69, 69, "v"], [70, 73, "c"]], [[86, 88, "a"], [94, 94, "v"]], [[110, 110, "v"]], [[133, 133, "v"]]], "predicted_relations": [[], [], [[31, 33, 25, 25, "USED-FOR"], [31, 33, 30, 30, "USED-FOR"]], [[46, 47, 40, 41, "USED-FOR"], [51, 51, 46, 47, "USED-FOR"], [51, 51, 46, 47, "USED-FOR"]], [], [], [[100, 100, 99, 100, "USED-FOR"], [100, 100, 99, 100, "USED-FOR"], [100, 100, 99, 100, "USED-FOR"]], [[114, 114, 113, 114, "USED-FOR"], [114, 114, 113, 114, "USED-FOR"], [114, 114, 113, 114, "USED-FOR"], [126, 128, 133, 133, "USED-FOR"]]]}
{"doc_key": "2203.10741-f1cc8406-e030-45c4-8bab-9f27c9aca2ee", "sentences": [["During", "training", ",", "we", "set", "the", "number", "of", "tokens", "in", "each", "batch", "to", "\\", "-LRB-", "10", "-LCB-", ",", "-RCB-", "240\\", "-RRB-", "for", "QSGen-Hier", ",", "QSGen-ChildQ", ",", "and", "full", "summary", "generation", "on", "WikiBioSum", "."], ["On", "GovReport", ",", "each", "batch", "contains", "\\", "-LRB-", "16", "-LCB-", ",", "-RCB-", "384\\", "-RRB-", "tokens", "."], ["As", "limited", "by", "the", "design", "of", "Longformer", ",", "the", "maximum", "output", "length", "for", "all", "tasks", "is", "set", "to", "\\", "-LRB-", "1", "-LCB-", ",", "-RCB-", "024\\", "-RRB-", "."], ["We", "use", "Adam", "-LSB-", "26", "-RSB-", "as", "the", "optimizer", ",", "with", "a", "maximum", "learning", "rate", "of", "\\", "-LRB-", "5", "\\times", "10^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "."], ["The", "optimizer", "updates", "the", "model", "parameters", "every", "8", "batches", "."], ["We", "set", "the", "maximum", "numbers", "of", "update", "steps", "to", "500", ",", "700", ",", "\\", "-LRB-", "2", "-LCB-", ",", "-RCB-", "400\\", "-RRB-", ",", "and", "\\", "-LRB-", "5", "-LCB-", ",", "-RCB-", "000\\", "-RRB-", "respectively", "for", "QSGen-Hier", ",", "QSGen-ChildQ", ",", "WikiBioSum", ",", "and", "GovReport", "."], ["Importantly", ",", "we", "adopt", "gradient", "checkpointing", "-LSB-", "10", "-RSB-", "to", "reduce", "the", "memory", "consumption", "of", "back", "propagation", "."]], "ner": [[], [], [], [[78, 78, "a"], [88, 90, "p"]], [], [], [[159, 160, "a"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[15, 15, "v"], [19, 19, "v"], [22, 22, "a"], [24, 24, "a"], [31, 31, "a"]], [[34, 34, "a"], [41, 45, "v"]], [[69, 73, "v"]], [[78, 78, "a"], [89, 90, "p"], [94, 94, "v"], [96, 100, "v"]], [[110, 110, "v"]], [[119, 120, "p"], [122, 124, "v"], [128, 132, "v"], [138, 142, "v"], [146, 146, "a"], [148, 148, "a"], [150, 150, "a"], [153, 153, "a"]], [[159, 160, "a"], [170, 171, "a"]]], "predicted_relations": [[], [], [], [[88, 90, 78, 78, "USED-FOR"]], [], [], []]}
{"doc_key": "2210.04726-1d172e24-f601-4eb8-a49e-246a9cfa3f4a", "sentences": [["The", "input", "length", "for", "training", "KPs", "is", "normally", "short", "because", "our", "examples", "are", "masked", "serialized", "triples", "-LRB-", "concatenation", "of", "Subject/Object", "entity", "and", "a", "relation", "-RRB-", "."], ["Therefore", ",", "we", "set", "the", "input", "length", "to", "64", ",", "which", "allows", "us", "to", "use", "very", "large", "batch", "sizes", ":", "between", "4K", "and", "8K", ",", "depending", "on", "the", "model", "size", "."], ["Note", "that", "the", "objective", "when", "training", "KPs", "is", "to", "memorize", "the", "training", "data", "."], ["Hence", ",", "we", "let", "KP", "training", "run", "for", "up", "to", "200", "epochs", "."]], "ner": [[[5, 5, "a"], [1, 2, "p"]], [[31, 32, "p"], [34, 34, "v"], [47, 47, "v"], [49, 49, "v"]], [[63, 63, "a"]], [[82, 82, "p"], [81, 81, "v"]]], "relations": [[], [], [], []], "predicted_ner": [[[5, 5, "a"]], [[34, 34, "v"], [47, 47, "v"], [49, 49, "v"]], [[63, 63, "a"]], [[81, 81, "v"], [82, 82, "p"]]], "predicted_relations": [[[1, 2, 5, 5, "USED-FOR"]], [], [], [[81, 81, 82, 82, "USED-FOR"]]]}
{"doc_key": "2212.09438-9b11e8ef-e7fb-4d49-a6d2-9d89d6806fd2", "sentences": [["We", "trained", "our", "models", "with", "stochastic", "gradient", "descent", "-LRB-", "SGD", "-RRB-", "with", "learning", "rate", "2.5e-4", ",", "Nesterov", "momentum", "0.9", "and", "weight", "decay", "5e-4", "."], ["We", "trained", "the", "model", "with", "100,000", "steps", "each", "including", "a", "minibatch", "of", "16", "samples", "from", "the", "Mapillary", "data", "set", "and", "32", "samples", "from", "the", "FGI", "autonomous", "steering", "data", "set", "."], ["We", "used", "more", "samples", "from", "the", "FGI", "autonomous", "steering", "data", "set", "due", "to", "the", "smaller", "size", "of", "the", "images", "and", "to", "have", "more", "supervision", "for", "the", "steering", "task", ",", "as", "it", "has", "only", "one", "scalar", "value", "for", "supervision", "on", "each", "image", "."], ["We", "chose", "the", "model", "with", "highest", "validation", "accuracy", "which", "was", "evaluated", "every", "1000th", "step", "during", "training", "."], ["The", "discriminators", "are", "trained", "with", "Adam", "optimizers", "using", "learning", "rate", "1e-4", "and", "parameters", "\\", "-LRB-", "\\beta", "_1=0.9\\", "-RRB-", ",", "\\", "-LRB-", "\\beta", "_2=0.99\\", "-RRB-", "."]], "ner": [[[14, 14, "v"], [16, 17, "p"], [18, 18, "v"], [14, 14, "v"], [22, 22, "v"]], [[40, 42, "a"], [48, 52, "a"]], [[60, 64, "a"]], [], [[129, 129, "v"], [118, 119, "a"], [123, 123, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[3, 3, "a"], [5, 10, "a"], [12, 13, "p"], [14, 14, "v"], [18, 18, "v"], [20, 21, "p"], [22, 22, "v"]], [[27, 27, "a"], [29, 29, "v"], [36, 36, "v"], [40, 42, "a"], [44, 44, "v"], [48, 48, "a"]], [[60, 64, "a"], [87, 87, "v"]], [[108, 108, "v"]], [[118, 118, "a"], [121, 122, "p"], [123, 123, "v"], [128, 129, "p"], [134, 135, "p"]]], "predicted_relations": [[[18, 18, 16, 17, "USED-FOR"], [22, 22, 16, 17, "USED-FOR"]], [], [], [], []]}
{"doc_key": "2212.09400-3cd1c368-0c10-4610-aee7-5d6ce2040ed8", "sentences": [["Considering", "the", "size", "of", "train", "set", "is", "relatively", "small", ",", "we", "propose", "two", "different", "training", "settings", ",", "i.e.", ",", "traditional", "deep", "learning", "training", "and", "cross-validation", "training", "-LSB-", "16", "-RSB-", "."], ["In", "traditional", "setting", ",", "the", "train", "and", "dev", "sets", "are", "independent", ",", "and", "we", "train", "the", "model", "only", "train", "data", "and", "evaluate", "model", "on", "dev", "data", ",", "preserve", "the", "highest-accuracy", "model", "within", "at", "most", "10", "training", "epochs", "."], ["In", "cross-validation", "setting", ",", "we", "mix", "train", "and", "dev", "set", "into", "one", "set", ",", "then", "9-fold", "cross-validation", "is", "utilized", "."], ["In", "order", "to", "avoid", "over-fitting", "training", "in", "cross-validation", "setting", ",", "we", "early", "stop", "training", "in", "chronological", "order", "and", "preserve", "three", "models", "for", "official", "evaluations", "."], ["Each", "training", "epoch", "takes", "approximately", "0.5", "hour", ",", "and", "evaluating", "the", "model", "costs", "about", "5", "minutes", "."]], "ner": [[[19, 22, "a"], [24, 25, "a"]], [], [[83, 84, "p"]], [], []], "relations": [[], [], [], [], []], "predicted_ner": [[[12, 12, "v"], [24, 24, "a"]], [[64, 64, "v"]], [[69, 69, "a"], [79, 79, "v"], [83, 83, "v"], [84, 84, "a"]], [[95, 95, "a"], [107, 107, "v"]], [[118, 118, "v"], [127, 127, "v"]]], "predicted_relations": [[], [], [], [], []]}
{"doc_key": "2203.03583-b330b385-e94e-43eb-8a52-798f4a19a76a", "sentences": [["We", "use", "Conformer-M", "-LSB-", "28", "-RSB-", "as", "the", "ASR", "encoder", "."], ["The", "input", "frames", "are", "80-dim", "log-Mel", "filterbanks", "extracted", "from", "25ms", "window", "and", "15ms", "overlap", "."], ["We", "train", "the", "model", "with", "CTC", "loss", "using", "AdamW", "optimizer", "and", "peak", "learning", "rate", "of", "\\", "-LRB-", "1e^", "-LCB-", "-3", "-RCB-", "\\", "-RRB-", "."], ["During", "the", "training", ",", "we", "exploit", "SpecAugment", "-LSB-", "29", "-RSB-", ",", "dropout", "of", "0.1", ",", "and", "weight", "decay", "of", "\\", "-LRB-", "1e^", "-LCB-", "-5", "-RCB-", "\\", "-RRB-", "for", "the", "regularization", "."], ["The", "learning", "rate", "linearly", "increases", "for", "5K", "iterations", "and", "is", "fixed", "at", "the", "peak", "for", "295K", "iterations", "."], ["Then", ",", "the", "learning", "rate", "decays", "following", "the", "inverse", "square", "root", "schedule", "-LSB-", "30", "-RSB-", "for", "700K", "iterations", "."], ["The", "batch", "size", "is", "set", "to", "16", "for", "each", "GPU", "and", "4x", "RTX", "Titan", "-LRB-", "24GB", "-RRB-", "GPUs", "are", "used", "."], ["Gradients", "are", "accumulated", "for", "4", "batches", ",", "expanding", "the", "effective", "batch", "size", "to", "256", "."], ["We", "follow", "additional", "training", "details", "from", "previous", "work", "that", "employed", "the", "same", "encoder", "-LSB-", "31", "-RSB-", "."]], "ner": [[[2, 2, "a"]], [], [[34, 35, "a"], [37, 39, "p"]], [[56, 56, "a"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"]], [[15, 15, "v"], [20, 20, "v"], [23, 23, "v"]], [[31, 32, "a"], [34, 34, "a"], [38, 39, "p"], [43, 46, "v"]], [[56, 56, "a"], [61, 61, "a"], [63, 63, "v"], [66, 67, "p"], [71, 74, "v"]], [[82, 83, "p"], [87, 87, "v"], [96, 96, "v"]], [[102, 103, "p"], [115, 115, "v"]], [[119, 120, "p"], [124, 124, "v"], [125, 127, "c"], [129, 129, "v"], [133, 133, "v"]], [[143, 143, "v"], [152, 152, "v"]], []], "predicted_relations": [[], [], [[37, 39, 34, 35, "USED-FOR"]], [], [], [], [], [], []]}
{"doc_key": "2203.03583-53838a29-769f-4caa-9aa9-7ef63f2b786c", "sentences": [["LSTM-LM", "and", "Transformer-LM", "are", "a", "stack", "of", "LSTM", "and", "Transformer-XL", "-LSB-", "1", "-RSB-", "layers", ",", "respectively", "."], ["We", "train", "these", "neural", "network-based", "LMs", "with", "and", "without", "SkipTC", ",", "sharing", "the", "same", "training", "configuration", "."], ["LMs", "consist", "of", "4", "layers", "where", "the", "hidden", "dimension", "of", "each", "layer", "is", "512", "."], ["Vocabulary", "size", "is", "set", "to", "431", ",", "including", "399", "LC+V", "tokens", ",", "27", "TC", "tokens", "and", "5", "special", "tokens", ":", "<", "pad", ">", ",", "<", "sos", ">", ",", "<", "eos", ">", ",", "<", "unk", ">", "and", "<", "space", ">", "."], ["When", "using", "SkipTC", "token", ",", "the", "<", "unk", ">", "token", "takes", "the", "role", "of", "SkipTC", "token", "."], ["The", "embedding", "weight", "and", "the", "final", "output", "weight", "are", "tied", "as", "the", "common", "practice", "-LSB-", "32", "-RSB-", "."], ["We", "train", "LSTM-LM", "using", "SGD", "with", "a", "momentum", "of", "0.9", ",", "an", "initial", "learning", "rate", "of", "0.1", ",", "weight", "decay", "of", "\\", "-LRB-", "1e^", "-LCB-", "-6", "-RCB-", "\\", "-RRB-", ",", "and", "exponential", "learning", "rate", "decay", "with", "a", "factor", "of", "0.99", "."], ["For", "Transformer-LM", ",", "we", "use", "Adam", "optimizer", "with", "a", "learning", "rate", "of", "0.001", "."], ["The", "training", "is", "conducted", "for", "50", "epochs", "with", "a", "batch", "size", "of", "128", "."]], "ner": [[[0, 0, "a"], [9, 9, "a"]], [[26, 26, "a"]], [[41, 42, "p"], [47, 47, "v"]], [], [[91, 91, "a"], [103, 103, "a"]], [], [[126, 126, "a"], [128, 128, "a"], [131, 131, "p"], [133, 133, "v"], [136, 138, "p"], [140, 140, "v"], [142, 143, "p"], [155, 158, "p"], [163, 163, "v"], [137, 138, "p"], [156, 157, "p"]], [[170, 170, "a"], [174, 175, "p"], [177, 177, "v"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [2, 2, "a"], [7, 7, "a"], [9, 9, "a"]], [[26, 26, "a"]], [[37, 37, "v"], [47, 47, "v"]], [[54, 54, "v"], [57, 57, "v"], [61, 61, "v"], [65, 65, "v"]], [[91, 91, "a"], [103, 103, "a"]], [], [[126, 126, "a"], [128, 128, "a"], [133, 133, "v"], [137, 138, "p"], [140, 140, "v"], [142, 143, "p"], [147, 150, "v"], [163, 163, "v"]], [[166, 166, "a"], [170, 170, "a"], [174, 175, "p"], [177, 177, "v"]], [[184, 184, "v"], [185, 185, "p"], [188, 189, "p"], [191, 191, "v"]]], "predicted_relations": [[], [], [], [], [], [], [[131, 131, 126, 126, "USED-FOR"], [131, 131, 128, 128, "USED-FOR"], [133, 133, 136, 138, "USED-FOR"], [133, 133, 137, 138, "USED-FOR"], [136, 138, 126, 126, "USED-FOR"], [136, 138, 128, 128, "USED-FOR"], [140, 140, 142, 143, "USED-FOR"], [142, 143, 126, 126, "USED-FOR"], [142, 143, 128, 128, "USED-FOR"], [155, 158, 126, 126, "USED-FOR"], [137, 138, 126, 126, "USED-FOR"], [137, 138, 128, 128, "USED-FOR"], [156, 157, 126, 126, "USED-FOR"], [156, 157, 128, 128, "USED-FOR"]], [[174, 175, 170, 170, "USED-FOR"]], []]}
{"doc_key": "2206.02428-3185b283-6019-418f-9c70-44b02f66829a", "sentences": [["All", "models", "were", "implemented", "with", "Pytorch", "and", "Hugging", "Face", "Transformers", "-LSB-", "17", "-RSB-", "."], ["For", "models", "without", "pre-trained", "language", "backbones", "-LRB-", "e.g", "."], ["Bi-DAF", ",", "R-Net", "-RRB-", ",", "Glove", "embedding", "-LSB-", "18", "-RSB-", "was", "utilized", ",", "and", "out-of-vocabulary", "words", "were", "replaced", "with", "the", "\\", "-LRB-", "<", "\\", "-RRB-", "unk\\", "-LRB-", ">", "\\", "-RRB-", "token", "."], ["Hidden", "size", "and", "embedding", "dimension", "were", "300", ",", "and", "those", "of", "Transformer-based", "models", "were", "768", "."], ["We", "used", "Adam", "-LSB-", "7", "-RSB-", "with", "batch", "size", "32", ",", "and", "gradient", "accumulation", "was", "applied", "."], ["The", "initial", "learning", "rates", "were", "set", "at", "2e-5", ",", "and", "dropout", "rate", "-LSB-", "22", "-RSB-", "was", "set", "to", "0.2", "."], ["During", "training", ",", "the", "validation-based", "early", "stop", "strategy", "was", "applied", "."], ["During", "prediction", ",", "we", "selected", "answer", "spans", "using", "the", "maximum", "product", "of", "\\", "-LRB-", "p_", "-LCB-", "start", "-RCB-", "\\", "-RRB-", "and", "\\", "-LRB-", "p_", "-LCB-", "end", "-RCB-", "\\", "-RRB-", "."]], "ner": [[[5, 5, "a"], [7, 9, "a"]], [], [[28, 29, "a"]], [], [[73, 73, "a"], [78, 79, "p"], [80, 80, "v"]], [[95, 95, "v"], [98, 99, "p"], [106, 106, "v"]], [[112, 115, "a"]], []], "relations": [[], [], [], [], [], [], [], []], "predicted_ner": [[[5, 5, "a"]], [], [[23, 23, "a"], [25, 25, "a"]], [[61, 61, "v"], [69, 69, "v"]], [[73, 73, "a"], [78, 79, "p"], [80, 80, "v"], [83, 84, "a"]], [[90, 91, "p"], [95, 95, "v"], [98, 99, "p"], [106, 106, "v"]], [], []], "predicted_relations": [[], [], [], [], [[78, 79, 73, 73, "USED-FOR"]], [[95, 95, 98, 99, "USED-FOR"], [106, 106, 98, 99, "USED-FOR"]], [], []]}
{"doc_key": "2206.10520-66e09dd0-f212-43fc-8cb0-b7e8eec7866d", "sentences": [["We", "trained", "StyleGAN2-ADA", "-LSB-", "13", "-RSB-", "on", "the", "CASIA-WebFace", "dataset", "under", "conditional", "settings", ",", "i.e", "."], ["generating", "images", "of", "specific", "classes", "."], ["The", "number", "of", "classes", "is", "set", "to", "10,575", "-LRB-", "number", "of", "identities", "in", "CASIA-WebFace", "-RRB-", ",", "which", "is", "embedded", "into", "a", "512-D", "vector", "and", "then", "concatenated", "with", "the", "latent", "vector", "-LRB-", "512-D", "-RRB-", "to", "generate", "class-related", "synthetic", "images", "."], ["We", "kept", "most", "of", "the", "implementation", "settings", "of", "StyleGAN2-ADA", "unchanged", "-LRB-", "as", "set", "in", "-LSB-", "13", "-RSB-", "-RRB-", ",", "including", "the", "training", "setup", ",", "network", "architectures", ",", "optimizer", ",", "and", "training", "loss", "."], ["We", "have", "only", "set", "the", "StyleGAN2-ADA", "model", "training", "epochs", "to", "50", ",", "the", "batch-size", "to", "128", ",", "and", "the", "learning", "rate", "to", "\\", "-LRB-", "0.0025\\", "-RRB-", "."]], "ner": [[[2, 2, "a"], [8, 8, "a"]], [], [[35, 35, "a"]], [[69, 69, "a"]], [[99, 99, "a"], [101, 102, "p"], [104, 104, "v"], [107, 107, "p"], [109, 109, "v"], [113, 114, "p"], [118, 118, "v"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [8, 9, "a"]], [], [[29, 29, "v"], [35, 35, "a"], [43, 43, "v"], [53, 53, "v"]], [[69, 69, "a"]], [[99, 100, "a"], [101, 102, "p"], [104, 104, "v"], [107, 107, "p"], [109, 109, "v"], [113, 114, "p"], [118, 118, "v"]]], "predicted_relations": [[], [], [], [], [[101, 102, 99, 99, "USED-FOR"], [104, 104, 101, 102, "USED-FOR"], [107, 107, 99, 99, "USED-FOR"], [109, 109, 101, 102, "USED-FOR"], [113, 114, 99, 99, "USED-FOR"], [118, 118, 113, 114, "USED-FOR"]]]}
{"doc_key": "2206.10520-f64cfd3e-1021-40a1-98e1-a5d704fb9808", "sentences": [["The", "presented", "FR", "models", "in", "this", "paper", "utilize", "ResNet-50", "-LSB-", "11", "-RSB-", "as", "a", "backbone", "architecture", "."], ["We", "train", "five", "instances", "of", "ResNet-50", "."], ["The", "first", "instance", "is", "trained", "with", "CosFace", "loss", "-LSB-", "42", "-RSB-", "on", "the", "authentic", "CASIA-WebFace", "dataset", "-LSB-", "44", "-RSB-", "and", "is", "used", "for", "KT", "-LRB-", "model", "P", "-RRB-", "."], ["We", "followed", "the", "parameter", "selection", "in", "-LSB-", "42", "-RSB-", "for", "the", "CosFace", "loss", "margin", "value", ",", "and", "scale", "parameter", "to", "0.35", "and", "64", ",", "respectively", "."], ["The", "other", "four", "instances", "are", "trained", "on", "the", "synthetic", "SFace", "dataset", "."], ["The", "second", "instance", "is", "solely", "trained", "with", "CosFace", "loss", ",", "i.e", "."], ["CLS", ",", "on", "the", "SFace", "dataset", "."], ["The", "third", "instance", "is", "trained", "with", "only", "KT", "loss", "."], ["The", "fourth", "and", "the", "fifth", "instances", "are", "trained", "with", "the", "CL", "loss", "with", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "in", "Equation", "REF", "of", "1e-5", "and", "2e-5", ",", "respectively", "."], ["The", "models", "trained", "on", "synthetic", "data", "are", "always", "noted", "with", "the", "training", "subset", "-LRB-", "SFace-10", ",", "SFace-20", ",", "SFace-40", ",", "or", "SFace-60", "-RRB-", "and", "the", "training", "strategy", "-LRB-", "CLS", ",", "KT", ",", "or", "CL", "-RRB-", "."]], "ner": [[[8, 8, "a"]], [[22, 22, "a"]], [[30, 31, "a"], [38, 39, "a"]], [[64, 65, "a"]], [[88, 89, "a"]], [[98, 99, "a"]], [[107, 108, "a"], [103, 103, "a"]], [[117, 118, "a"]], [[135, 135, "p"], [142, 142, "v"], [144, 144, "v"], [130, 131, "a"]], [[176, 176, "a"]]], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[8, 8, "a"]], [[19, 19, "v"], [22, 22, "a"]], [[30, 31, "a"], [38, 39, "a"], [47, 47, "a"]], [[64, 65, "a"], [70, 71, "p"], [73, 73, "v"], [75, 75, "v"]], [[81, 81, "v"], [88, 89, "a"]], [[98, 99, "a"]], [[103, 103, "a"], [107, 108, "a"]], [[117, 118, "a"]], [[130, 131, "a"], [135, 135, "p"], [142, 142, "v"], [144, 144, "v"]], [[176, 176, "a"], [178, 178, "a"], [181, 181, "a"]]], "predicted_relations": [[], [], [], [], [], [], [], [], [[135, 135, 130, 131, "USED-FOR"]], []]}
{"doc_key": "2203.00242-c520f679-29fe-4781-94ca-0b9621390ca5", "sentences": [["Our", "transformer", "architecture", "consists", "of", "12", "layers", "of", "transformer", "blocks", ",", "where", "each", "block", "has", "768", "hidden", "units", "and", "12", "self-attention", "heads", "."], ["We", "initialize", "the", "model", "from", "\\", "-LRB-", "\\text", "-LCB-", "BERT", "-RCB-", "_", "-LCB-", "base", "-RCB-", "\\", "-RRB-", "and", "pre-train", "for", "20", "epochs", "on", "their", "respective", "pre-training", "datasets", "with", "a", "batch", "size", "of", "480", "."], ["The", "region", "features", "for", "images", "are", "obtained", "from", "the", "pre-trained", "VinVL", "object", "detectors", "-LSB-", "47", "-RSB-", "."], ["We", "use", "Adam", "optimizer", "-LSB-", "18", "-RSB-", "with", "a", "linear", "warm-up", "for", "the", "first", "10", "%", "of", "training", "steps", ",", "and", "set", "the", "peak", "learning", "rate", "as", "6e-5", "."], ["After", "warm", "up", ",", "a", "linear-decayed", "learning-rate", "scheduler", "gradually", "drops", "the", "learning", "rate", "for", "the", "rest", "of", "training", "steps", "."], ["All", "models", "were", "trained", "on", "4", "NVIDIA", "A100", "GPUs", ",", "with", "40GB", "of", "memory", "per", "GPU", "using", "MMF", "-LSB-", "35", "-RSB-", "."], ["The", "pre-training", "takes", "3", "days", "."], ["We", "evaluate", "our", "pre-trained", "models", "on", "four", "downstream", "tasks", ":", "Visual", "Question", "Answering", "-LRB-", "VQA", "2.0", "-RRB-", "-LSB-", "0", "-RSB-", ",", "Natural", "Language", "for", "Visual", "reasoning", "-LSB-", "37", "-RSB-", "-LRB-", "\\", "-LRB-", "\\text", "-LCB-", "NLVR", "-RCB-", "^2\\", "-RRB-", "-RRB-", ",", "Visual", "Entailment", "-LSB-", "41", "-RSB-", "-LRB-", "VE", "-RRB-", ",", "and", "Referring", "Expression", "-LSB-", "44", "-RSB-", "-LRB-", "RefCOCO+", "-RRB-", "."], ["Detailed", "training", "settings", "for", "each", "task", "can", "be", "found", "in", "our", "supplementary", "material", "."]], "ner": [[[1, 2, "a"], [16, 17, "p"], [15, 15, "v"], [20, 21, "p"], [5, 5, "v"], [19, 19, "v"]], [], [], [[76, 77, "a"], [83, 84, "p"], [85, 87, "c"], [97, 99, "p"], [101, 101, "v"]], [[108, 110, "p"]], [[140, 140, "a"]], [], [], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[1, 2, "a"], [5, 5, "v"], [15, 15, "v"], [16, 17, "p"], [19, 19, "v"]], [[43, 43, "v"], [44, 44, "p"], [52, 53, "p"], [55, 55, "v"]], [[67, 67, "a"]], [[76, 76, "a"], [83, 84, "a"], [88, 89, "v"], [98, 99, "p"], [101, 101, "v"]], [[114, 115, "p"]], [[128, 128, "v"], [134, 134, "v"], [140, 140, "a"]], [[148, 148, "v"]], [[157, 157, "v"], [207, 207, "a"]], []], "predicted_relations": [[], [], [], [[83, 84, 76, 77, "USED-FOR"], [85, 87, 101, 101, "USED-FOR"], [97, 99, 76, 77, "USED-FOR"], [101, 101, 83, 84, "USED-FOR"], [101, 101, 97, 99, "USED-FOR"]], [], [], [], [], []]}
{"doc_key": "2210.02798-ef548698-0201-4058-a023-1cbfbed9cd31", "sentences": [["We", "explore", "pre-training", "strategies", "on", "single", "objects", "-LRB-", "ShapeNet", "-LSB-", "7", "-RSB-", "-RRB-", "and", "complex", "scenes", "with", "multiple", "objects", "-LRB-", "ScanNet", "-LSB-", "12", "-RSB-", "-RRB-", "to", "evaluate", "the", "effectiveness", "of", "SoftClu", "."], ["We", "implemented", "SoftClu", "in", "PyTorch", "and", "executed", "our", "experiments", "on", "two", "Tesla", "V100-PCI-E-32G", "GPUs", "."], ["During", "pre-training", ",", "we", "set", "\\", "-LRB-", "J=64\\", "-RRB-", "and", "\\", "-LRB-", "\\epsilon", "=1e-3\\", "-RRB-", "."]], "ner": [[[8, 8, "a"], [20, 20, "a"], [30, 30, "a"]], [[34, 34, "a"]], [[54, 54, "p"], [54, 54, "v"], [59, 59, "p"], [60, 60, "v"]]], "relations": [[], [], []], "predicted_ner": [[[8, 8, "a"], [20, 20, "a"], [30, 30, "a"]], [[34, 34, "a"], [42, 42, "v"]], [[54, 54, "v"]]], "predicted_relations": [[], [], [[54, 54, 54, 54, "USED-FOR"], [54, 54, 54, 54, "USED-FOR"], [60, 60, 54, 54, "USED-FOR"], [60, 60, 59, 59, "USED-FOR"]]]}
{"doc_key": "2210.02798-f7ee5e70-f014-4eae-9954-e554a80ce0d5", "sentences": [["ShapeNet", "-LSB-", "7", "-RSB-", "is", "a", "collection", "of", "single-object", "CAD", "models", "and", "contains", "57448", "synthetic", "objects", "from", "55", "object", "categories", "."], ["We", "follow", "the", "experimental", "setup", "presented", "in", "-LSB-", "38", "-RSB-", ",", "-LSB-", "20", "-RSB-", ",", "we", "use", "PointNet", "-LSB-", "34", "-RSB-", "and", "DGCNN", "-LSB-", "47", "-RSB-", "as", "encoder", "networks", "."], ["The", "latent", "dimension", "of", "both", "encoders", "is", "1024", "."], ["Following", "-LSB-", "20", "-RSB-", ",", "each", "point", "cloud", "is", "randomly", "downsampled", "to", "2048", "points", "."], ["We", "use", "the", "official", "training", "split", "of", "ShapeNet", "for", "pre-training", "."], ["Our", "pre-training", "involves", "250", "epochs", "by", "using", "the", "AdamW", "-LSB-", "26", "-RSB-", "optimizer", ",", "the", "batch", "size", "is", "equal", "to", "32", ",", "and", "initial", "learning", "is", "equal", "to", "\\", "-LRB-", "0.001\\", "-RRB-", "that", "decays", "by", "\\", "-LRB-", "0.7\\", "-RRB-", "every", "20", "epochs", "."]], "ner": [[[0, 0, "a"]], [[38, 38, "a"], [43, 43, "a"]], [], [], [[82, 82, "a"]], [[94, 94, "a"], [101, 102, "p"], [123, 123, "v"], [109, 110, "p"]]], "relations": [[], [], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [13, 13, "v"], [17, 17, "v"]], [[38, 38, "a"], [43, 43, "a"]], [[58, 58, "v"]], [[72, 72, "v"]], [[82, 82, "a"]], [[89, 89, "v"], [90, 90, "p"], [94, 94, "a"], [101, 102, "p"], [106, 106, "v"], [116, 116, "v"], [123, 123, "v"], [126, 126, "v"], [127, 127, "p"]]], "predicted_relations": [[], [], [], [], [], [[101, 102, 94, 94, "USED-FOR"], [109, 110, 94, 94, "USED-FOR"]]]}
{"doc_key": "2210.02798-cd022fb8-e053-4764-a2c9-72e52d27ebfc", "sentences": [["ScanNet", "-LSB-", "12", "-RSB-", "is", "a", "dataset", "of", "indoor", "scenes", "with", "multiple", "objects", "and", "consists", "of", "1513", "reconstructed", "meshes", "for", "707", "unique", "scenes", "."], ["Following", "-LSB-", "48", "-RSB-", ",", "we", "choose", "SR-UNet", "provided", "in", "PointContrast", "-LSB-", "48", "-RSB-", "as", "backbone", "."], ["For", "pre-training", ",", "we", "use", "an", "SGD", "optimizer", "with", "a", "learning", "rate", "of", "0.1", "and", "a", "batch", "size", "of", "32", "."], ["The", "learning", "rate", "is", "decreased", "by", "a", "factor", "of", "0.99", "every", "1K", "iteration", "."], ["The", "model", "is", "trained", "for", "30K", "iterations", "."]], "ner": [[[0, 0, "a"]], [[31, 31, "a"], [34, 34, "a"]], [[47, 48, "a"], [51, 52, "p"], [57, 58, "p"]], [[63, 64, "p"], [71, 71, "v"], [72, 74, "c"]], [[81, 81, "v"], [82, 82, "p"]]], "relations": [[], [], [], [], []], "predicted_ner": [[[0, 0, "a"], [16, 16, "v"], [20, 20, "v"]], [[31, 31, "a"], [34, 34, "a"]], [[47, 47, "a"], [51, 52, "p"], [54, 54, "v"], [57, 58, "p"], [60, 60, "v"]], [[63, 64, "p"], [71, 71, "v"], [73, 73, "v"]], [[81, 81, "v"]]], "predicted_relations": [[], [], [[51, 52, 47, 48, "USED-FOR"], [57, 58, 47, 48, "USED-FOR"]], [[72, 74, 71, 71, "USED-FOR"]], [[81, 81, 82, 82, "USED-FOR"]]]}
{"doc_key": "2211.02536-b423ea27-2b21-4ada-bde5-a6d9cd432b05", "sentences": [["For", "the", "mppt", "of", "any", "iteration", "-LRB-", "biased", "or", "unbiased", "-RRB-", ",", "around", "50", "%", "of", "the", "input", "frames", "are", "masked", "by", "applying", "overlapping", "masks", "of", "length", "20", "frames", "-LRB-", "equivalent", "to", "200", "ms", ";", "-LSB-", "9", "-RSB-", "used", "masks", "length", "10", "for", "50", "Hz", "features", "i.e", "."], ["also", "200", "ms", "-RRB-", "."], ["This", "is", "done", "by", "choosing", "4", "%", "of", "frames", "as", "starting", "frames", "for", "the", "masks", "of", "length", "20", "."], ["The", "classification", "loss", "is", "computed", "only", "for", "the", "masked", "frames", "."], ["The", "models", "are", "trained", "on", "32", "GPUs", "with", "a", "batch", "size", "of", "87.5", "seconds", "per", "GPU", "-LRB-", "for", "250k", "updates", ",", "this", "is", "equivalent", "to", "169", "epochs", "-RRB-", "."], ["The", "learning", "rate", "ramps", "up", "linearly", "for", "the", "first", "8", "%", "of", "updates", "and", "then", "decays", "linearly", "down", "to", "0", "."], ["The", "peak", "learning", "rate", "is", "5e-4", "."]], "ner": [[[26, 26, "p"], [40, 40, "p"], [27, 28, "v"]], [], [[69, 69, "p"]], [[73, 74, "a"]], [[92, 93, "p"], [95, 98, "v"]], [[113, 114, "p"]], [[135, 136, "p"], [138, 138, "v"], [134, 136, "c"]]], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[13, 14, "v"], [27, 27, "v"], [32, 32, "v"], [41, 41, "v"], [43, 44, "v"]], [[49, 49, "v"]], [[58, 59, "v"], [70, 70, "v"]], [], [[88, 88, "v"], [92, 93, "p"], [95, 95, "v"], [101, 101, "v"], [108, 108, "v"], [109, 109, "p"]], [[113, 114, "p"], [121, 122, "v"], [131, 131, "v"]], [[135, 136, "p"], [138, 138, "v"]]], "predicted_relations": [[[27, 28, 26, 26, "USED-FOR"]], [], [], [], [], [], [[138, 138, 135, 136, "USED-FOR"], [134, 136, 138, 138, "USED-FOR"]]]}
{"doc_key": "2211.12047-f6180674-5586-4a57-b846-a5cea4911fd1", "sentences": [["where", "\\", "-LRB-", "\\lambda", "\\", "-RRB-", "is", "modulation", "factor", "meant", "to", "control", "the", "time", "scale", "of", "the", "evolution", "of", "the", "error", "filters", "-LRB-", "and", "generally", "set", "to", "be", "less", "than", "one", ",", "e.g.", ",", "\\", "-LRB-", "0.9\\", "-RRB-", "-RRB-", "-", "note", "that", "this", "update", "rule", "is", "discarded", "if", "\\", "-LRB-", "\\mathbf", "-LCB-", "E", "-RCB-", "^\\ell", "_", "-LCB-", "ji", "-RCB-", "=", "-LRB-", "\\mathbf", "-LCB-", "W", "-RCB-", "^\\ell", "_", "-LCB-", "ij", "-RCB-", "-RRB-", "^T\\", "-RRB-", "as", "we", "do", "in", "this", "work", "."], ["Note", "that", "the", "above", "local", "update", "rule", "is", "a", "generalization", "of", "the", "rule", "proposed", "in", "-LSB-", "38", "-RSB-", ",", "-LSB-", "36", "-RSB-", "to", "the", "case", "of", "a", "-LRB-", "de", "-RRB-", "convolutional", "filter", "."], ["After", "the", "update", "for", "any", "particular", "filter", "has", "been", "calculated", "and", "it", "has", "been", "used", "to", "adjust", "the", "current", "physical", "state", "of", "the", "kernel", "synapses", ",", "we", "further", "normalize/constrain", "each", "kernel", "such", "that", "its", "Euclidean", "norm", "does", "not", "exceed", "one", "-LRB-", "see", "Algorithm", "REF", "for", "the", "specific", "re-projection", "step", "-RRB-", "."], ["This", "constraint", "ensures", "that", "Conv-NGC", "avoids", "the", "degenerate/trivial", "solution", "of", "simply", "increasing", "its", "synaptic", "kernel", "values", "while", "obtaining", "only", "small/near-zero", "latent", "activity", "values", ",", "much", "as", "is", "done", "in", "convolutional", "sparse", "coding", "-LSB-", "18", "-RSB-", "-LRB-", "this", "also", "means", "that", "one", "could", "alternatively", "view", "Conv-NGC", "as", "a", "sort", "of", "\u201c", "deep", "\u201d", "convolutional", "sparse", "coding", "-RRB-", "."]], "ner": [[[43, 44, "a"], [7, 8, "p"], [36, 36, "v"]], [[85, 86, "a"]], [], []], "relations": [[], [], [], []], "predicted_ner": [[[30, 30, "v"], [36, 36, "v"]], [], [[152, 152, "v"]], [[168, 168, "a"], [193, 195, "a"], [204, 204, "v"], [208, 208, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2209.10359-3da72887-ae8f-4bef-9763-45801fbf036d", "sentences": [["If", "not", "otherwise", "specified", ",", "we", "set", "the", "momentum", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "in", "Eq", "."], ["REF", "to", "\\", "-LRB-", "0.95\\", "-RRB-", "and", "the", "length", "of", "the", "noise", "vector", "to", "256", "."], ["We", "train", "the", "student", "\\", "-LRB-", "\\mathtt", "-LCB-", "S", "-RCB-", "\\", "-RRB-", "using", "SGD", "and", "Adam", "for", "the", "small", "and", "large", "datasets", ",", "respectively", "."], ["We", "train", "the", "generator", "\\", "-LRB-", "\\mathtt", "-LCB-", "G", "-RCB-", "\\", "-RRB-", "using", "Adam", "for", "both", "the", "small", "and", "large", "datasets", "."], ["To", "reduce", "the", "difficulty", "of", "training", "\\", "-LRB-", "\\mathtt", "-LCB-", "G", "-RCB-", "\\", "-RRB-", "for", "the", "large", "datasets", ",", "we", "pretrain", "\\", "-LRB-", "\\mathtt", "-LCB-", "G", "-RCB-", "\\", "-RRB-", "for", "some", "steps", "before", "the", "main", "KD", "training", "by", "setting", "the", "coefficient", "of", "\\", "-LRB-", "\\mathcal", "-LCB-", "L", "-RCB-", "_", "-LCB-", "\\text", "-LCB-", "KD", "-RCB-", "-RCB-", "\\", "-RRB-", "to", "0", "and", "only", "optimizing", "the", "remaining", "losses", "in", "Eq", "."], ["REF", "."], ["The", "generator", "\\", "-LRB-", "\\mathtt", "-LCB-", "G", "-RCB-", "\\", "-RRB-", "is", "class-conditional", "-LRB-", "as", "described", "in", "Section", "REF", "-RRB-", "for", "the", "large", "datasets", ",", "and", "unconditional", "for", "the", "small", "datasets", "."], ["We", "empirically", "found", "that", "this", "leads", "to", "better", "results", "."], ["For", "further", "details", "about", "the", "training", "settings", "of", "\\", "-LRB-", "\\text", "-LCB-", "MAD", "-RCB-", "\\", "-RRB-", ",", "please", "refer", "to", "Appdx", "."], ["REF", "."]], "ner": [[], [[21, 21, "v"]], [[46, 46, "a"], [48, 48, "a"]], [[71, 71, "a"]], [[115, 116, "a"], [138, 138, "v"]], [], [], [], [], []], "relations": [[], [], [], [], [], [], [], [], [], []], "predicted_ner": [[[11, 11, "p"]], [[21, 21, "v"], [28, 29, "p"], [31, 31, "v"]], [[46, 46, "a"], [48, 48, "a"]], [[71, 71, "a"]], [[138, 138, "v"]], [], [], [], [], []], "predicted_relations": [[], [], [], [], [], [], [], [], [], []]}
{"doc_key": "2210.00944-18196f92-a397-4225-8960-2705cebc14b8", "sentences": [["Datasets", "."], ["In", "our", "experiments", ",", "ImageNet-Subset", "-LSB-", "48", "-RSB-", "is", "used", "for", "ablation", "study", "and", "to", "compare", "with", "other", "self-supervised", "knowledge", "distillation", "methods", "."], ["This", "dataset", "contains", "100", "classes", "and", "\\", "-LRB-", "\\approx", "\\", "-RRB-", "130k", "images", "in", "high", "resolution", "-LRB-", "resized", "to", "224\\", "-LRB-", "\\times", "\\", "-RRB-", "224", "-RRB-", "-LSB-", "46", "-RSB-", "."], ["For", "comparison", "with", "SSL", "methods", ",", "we", "employ", "the", "ImageNet-1K", "dataset", "-LSB-", "48", "-RSB-", "."]], "ner": [[], [[6, 6, "a"]], [], [[64, 64, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[], [[6, 6, "a"]], [[28, 28, "v"], [36, 36, "v"], [49, 49, "v"]], [[64, 65, "a"]]], "predicted_relations": [[], [], [], []]}
{"doc_key": "2210.00960-8ce90ce0-a0cb-4ae2-9059-ee457631aca4", "sentences": [["We", "mainly", "consider", "the", "experiments", "on", "CIFAR-10", "-LSB-", "28", "-RSB-", ",", "CIFAR-100", ",", "and", "SVHN", "-LSB-", "35", "-RSB-", "."], ["We", "also", "provide", "one", "experiment", "on", "ImageNet", "-LSB-", "12", "-RSB-", "."], ["For", "the", "first", "three", "datasets", ",", "we", "conduct", "the", "experiments", "on", "training", "PreActResNet-18", ",", "which", "follows", "-LSB-", "41", "-RSB-", ",", "For", "the", "experiment", "on", "ImageNet", ",", "we", "use", "ResNet-50", "-LSB-", "21", "-RSB-", ",", "following", "the", "experiment", "of", "-LSB-", "32", "-RSB-", "."], ["For", "the", "inner", "problems", ",", "we", "adopt", "the", "\\", "-LRB-", "\\ell", "_\\infty", "\\", "-RRB-", "PGD", "adversarial", "training", "in", "-LSB-", "32", "-RSB-", ",", "the", "step", "size", "in", "the", "inner", "maximization", "is", "set", "to", "be", "\\", "-LRB-", "\\epsilon", "/4\\", "-RRB-", "on", "CIFAR-10", "and", "CIFAR100", "and", "is", "set", "to", "be", "\\", "-LRB-", "\\epsilon", "/8\\", "-RRB-", "on", "SVHN", "."], ["Weight", "decay", "is", "set", "to", "be", "\\", "-LRB-", "5\\times", "10^", "-LCB-", "-4", "-RCB-", "\\", "-RRB-", "."], ["Additional", "experiments", "are", "provided", "in", "Appendix", "REF", "."], ["https", ":", "//github.com/JiancongXiao/Stability-of-Adversarial-Training", "-LCB-", "FIGURE", "-RCB-"]], "ner": [[[6, 6, "a"], [11, 11, "a"], [14, 14, "a"], [14, 14, "c"]], [[25, 25, "a"]], [[54, 54, "a"], [42, 42, "a"], [58, 58, "a"]], [[110, 110, "a"], [124, 124, "a"], [94, 95, "p"], [110, 112, "c"], [124, 124, "c"]], [[126, 127, "a"]], [], []], "relations": [[], [], [], [], [], [], []], "predicted_ner": [[[6, 6, "a"], [11, 11, "a"], [14, 14, "a"]], [[22, 22, "v"], [25, 25, "a"]], [[33, 33, "v"], [54, 54, "a"], [58, 58, "a"]], [[110, 110, "a"], [112, 112, "a"], [124, 124, "a"]], [[126, 127, "a"], [135, 137, "v"]], [], []], "predicted_relations": [[], [], [], [], [], [], []]}
{"doc_key": "2212.12326-911ab257-2ac1-437f-b43c-d17cb7b5f0c6", "sentences": [["We", "fine-tuned", "a", "model", "trained", "on", "the", "Places2", "dataset", "-LSB-", "33", "-RSB-", "using", "our", "landscape", "dataset", "-LSB-", "34", "-RSB-", "."], ["The", "original", "pre-trained", "model", "has", "respectively", "trained", "2", "million", "iterations", "for", "edge", "inference", "and", "content", "inpainting", ",", "where", "content", "inpainting", "includes", "training", "taking", "ground", "truth", "as", "conditions", "and", "training", "taking", "generated", "edge", "maps", "as", "conditions", "."], ["Additionally", ",", "we", "trained", "our", "edge", "inference", "model", "with", "75,000", "iterations", ",", "the", "content", "inpainting", "model", "taking", "ground", "truth", "edge", "maps", "as", "conditions", "with", "75,000", "iterations", ",", "and", "the", "content", "inpainting", "model", "taking", "generated", "edge", "maps", "as", "conditions", "with", "75,000", "iterations", "."], ["All", "training", "is", "done", "on", "RTX-2080", "Super", "graphics", "."], ["-LCB-", "FIGURE", "-RCB-"]], "ner": [[[7, 8, "a"], [14, 15, "a"]], [[21, 23, "a"], [29, 29, "p"], [27, 28, "v"], [31, 32, "c"], [27, 28, "v"], [34, 35, "c"], [38, 39, "c"], [31, 32, "c"]], [[66, 66, "p"], [81, 81, "p"], [96, 96, "p"], [61, 62, "c"], [69, 70, "c"], [85, 86, "c"], [65, 65, "v"], [80, 80, "v"], [95, 95, "v"], [61, 62, "c"], [65, 65, "v"], [80, 80, "v"], [95, 95, "v"], [65, 65, "v"], [80, 80, "v"], [95, 95, "v"]], [[103, 105, "a"]], []], "relations": [[], [], [], [], []], "predicted_ner": [[[7, 8, "a"], [14, 15, "a"]], [[27, 27, "v"]], [[61, 63, "a"], [65, 65, "v"], [80, 80, "v"], [95, 95, "v"]], [[103, 103, "a"]], []], "predicted_relations": [[], [[29, 29, 21, 23, "USED-FOR"], [27, 28, 29, 29, "USED-FOR"], [27, 28, 29, 29, "USED-FOR"]], [[61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [65, 65, 66, 66, "USED-FOR"], [80, 80, 81, 81, "USED-FOR"], [95, 95, 96, 96, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [61, 62, 65, 65, "USED-FOR"], [61, 62, 80, 80, "USED-FOR"], [65, 65, 66, 66, "USED-FOR"], [80, 80, 81, 81, "USED-FOR"], [95, 95, 96, 96, "USED-FOR"], [65, 65, 66, 66, "USED-FOR"], [80, 80, 81, 81, "USED-FOR"], [95, 95, 96, 96, "USED-FOR"]], [], []]}
{"doc_key": "2212.12937-8d0823a4-9b49-4808-955b-07126a13e92f", "sentences": [["The", "model", "trainable", "parameters", "in", "\\", "-LRB-", "-LCB-", "GAE", "-RCB-", "_", "-LCB-", "doc", "-RCB-", "\\", "-RRB-", ",", "\\", "-LRB-", "-LCB-", "GAE", "-RCB-", "_", "-LCB-", "sent", "-RCB-", "\\", "-RRB-", ",", "GRU", ",", "and", "sentence", "scoring", "-LCB-", "\\", "-LRB-", "\\omega", "\\", "-RRB-", ",", "\\", "-LRB-", "W1\\", "-RRB-", ",", "\\", "-LRB-", "W2\\", "-RRB-", "-RCB-", "are", "described", "below", "."], ["To", "perform", "document", "summarization", "using", "GAE-ISumm", ",", "we", "set", "the", "first", "convolution", "layer", "'s", "embedding", "size", "as", "128", "for", "distributed", "word", "embeddings", "and", "256", "for", "remaining", "representations", "."], ["The", "input", "feature", "vectors", "are", "extracted", "from", "different", "language", "models", "with", "an", "input", "size", "of", "300", "for", "word", "embeddings", "and", "768", "for", "other", "representations", "."], ["Since", "IndicBERT", "-LSB-", "28", "-RSB-", "shows", "superior", "performance", "over", "other", "multilingual", "models", ",", "in", "this", "paper", ",", "we", "use", "IndicBERT", "for", "input", "feature", "extraction", "for", "all", "other", "experiments", "."]], "ner": [[[2, 3, "p"], [2, 3, "p"], [29, 29, "a"], [2, 3, "p"], [32, 33, "a"], [43, 43, "p"], [48, 48, "p"]], [[69, 70, "p"], [72, 72, "v"], [74, 76, "c"], [78, 78, "v"], [80, 81, "c"], [75, 76, "c"]], [[95, 96, "p"], [98, 98, "v"], [100, 101, "c"], [103, 103, "v"], [105, 106, "c"]], [[109, 109, "a"], [127, 127, "a"]]], "relations": [[], [], [], []], "predicted_ner": [[[29, 29, "a"]], [[60, 60, "a"], [72, 72, "v"], [78, 78, "v"]], [[98, 98, "v"], [103, 103, "v"]], [[109, 109, "a"], [127, 127, "a"]]], "predicted_relations": [[[43, 43, 32, 33, "USED-FOR"], [48, 48, 32, 33, "USED-FOR"]], [[72, 72, 69, 70, "USED-FOR"]], [[100, 101, 98, 98, "USED-FOR"], [100, 101, 103, 103, "USED-FOR"], [105, 106, 98, 98, "USED-FOR"], [105, 106, 103, 103, "USED-FOR"]], []]}
{"doc_key": "2212.12937-658c7b7b-3089-418d-a7e5-ac86e999a311", "sentences": [["We", "use", "Adam", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.001", "to", "train", "\\", "-LRB-", "GAE_", "-LCB-", "doc", "-RCB-", "\\", "-RRB-", "."], ["We", "use", "the", "scikit-learn", "package", "of", "Spectral", "Clustering", "to", "perform", "sentence", "graph", "clusterization", "."], ["After", "experimenting", "with", "various", "values", ",", "the", "number", "of", "clusters", "is", "considered", "close", "to", "the", "average", "number", "of", "sentences", "in", "annotated", "summaries", "."], ["The", "joint", "loss", "function", "is", "optimized", "with", "an", "Adam", "optimizer", "and", "a", "learning", "rate", "of", "0.0005", "."], ["We", "experimented", "with", "a", "range", "of", "values", "to", "determine", "the", "choice", "of", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "and", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "."], ["The", "model", "was", "effective", "when", "\\", "-LRB-", "\\alpha", "\\", "-RRB-", "=0.6", "and", "\\", "-LRB-", "\\beta", "\\", "-RRB-", "=0.4", "."], ["To", "extract", "the", "summary", ",", "we", "chose", "the", "value", "of", "K", "-LRB-", "number", "of", "sentences", "in", "the", "predicted", "summary", "-RRB-", "dependent", "on", "the", "number", "of", "clusters", "."], ["We", "train", "each", "phase", "of", "the", "model", "to", "a", "maximum", "of", "40", "epochs", "."], ["The", "experiments", "were", "performed", "on", "a", "single", "V100", "16GB", "RAM", "GPU", "machine", "."]], "ner": [[[2, 3, "a"], [6, 8, "p"], [10, 10, "v"], [2, 3, "a"], [7, 8, "p"]], [[28, 29, "a"]], [[43, 45, "p"], [48, 57, "v"]], [[67, 68, "a"], [67, 68, "a"], [71, 72, "p"], [74, 74, "v"]], [], [], [[142, 144, "p"], [129, 129, "a"]], [[155, 158, "a"]], []], "relations": [[], [], [], [], [], [], [], [], []], "predicted_ner": [[[2, 2, "a"], [7, 8, "p"], [10, 10, "v"]], [[28, 29, "a"]], [], [[67, 67, "a"], [71, 72, "p"], [74, 74, "v"]], [[90, 90, "p"], [96, 96, "p"]], [[107, 107, "p"], [114, 114, "p"]], [[129, 129, "p"]], [[157, 157, "v"], [158, 158, "p"]], []], "predicted_relations": [[[6, 8, 2, 3, "USED-FOR"], [6, 8, 2, 3, "USED-FOR"], [7, 8, 2, 3, "USED-FOR"], [7, 8, 2, 3, "USED-FOR"]], [], [], [[71, 72, 67, 68, "USED-FOR"], [71, 72, 67, 68, "USED-FOR"], [74, 74, 71, 72, "USED-FOR"]], [], [], [], [], []]}
